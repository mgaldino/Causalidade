[["index.html", "Curso de Inferência Causal Capítulo 1 Introdução 1.1 Revisão de Regressão 1.2 Inferência 1.3 Resumo e próximos passos 1.4 Referências", " Curso de Inferência Causal Manoel Galdino 2026-02-16 Capítulo 1 Introdução Escolas que recebem mais recursos financeiros produzem melhores resultados educacionais? Municípios governados por prefeitos reeleitos são mais ou menos corruptos? Programas de transferência de renda reduzem a pobreza? Se olharmos os dados, frequentemente encontramos correlações que sugerem respostas — mas correlação não é causalidade. O desafio central da inferência causal é justamente ir além da associação estatística e identificar relações de causa e efeito a partir de dados observacionais ou experimentais. Este curso apresenta os principais métodos de inferência causal utilizados em Ciência Política e áreas afins. Começamos pelo modelo de resultados potenciais (potential outcomes) e por grafos acíclicos direcionados (DAGs), que fornecem os fundamentos teóricos. Em seguida, estudamos os principais desenhos de pesquisa: experimentos aleatorizados, matching, variáveis instrumentais, regressão descontínua e diferenças em diferenças. Ao longo do curso, também discutimos controle sintético, dados em painel, aprendizado de máquina para inferência causal e outros tópicos avançados. Mas por que começar com uma revisão de regressão? Porque a regressão é a ferramenta estatística mais utilizada nas ciências sociais — e muitos dos métodos causais que estudaremos são implementados por meio de alguma forma de regressão. Compreender bem o que a regressão faz (e o que ela não faz) é essencial para entender quando ela pode ser interpretada causalmente e quando não pode. 1.1 Revisão de Regressão Comecemos pelo modelo de regressão populacional dado por: \\[y = \\beta_0 + \\beta_1 x + u\\] As suposições básicas do modelo são: Média do erro é zero (sem perda de generalidade): \\(\\mathbb{E}[u] = 0\\) Independência na média do erro: \\(\\mathbb{E}[u|x] = \\mathbb{E}[u]\\). Essa é a suposição mais consequente do modelo de regressão. Como é sobre o termo de erro, não é testável. Um exemplo é útil para entender o que significa essa suposição. Suponha que estamos interessados no efeito do gasto de campanha (\\(x\\)) sobre o voto (\\(y\\)). O termo de erro \\(u\\) seria a qualidade da candidata, não observável. A suposição implica então que a qualidade média das candidatas que gastam 100 mil reais é a mesma das que gastam 500 mil e um milhão (e assim por diante). Se candidatas melhores arrecadam mais dinheiro e, portanto, gastam mais, a suposição foi violada. Conectando 1 e 2, temos: \\(\\mathbb{E}[u|x] = 0\\). Essa suposição é chamada de “média condicional zero” ou “esperança condicional zero” do termo de erro. Ela implica que: \\(\\mathbb{E}[y|x] = \\beta_0 + \\beta_1 x\\). Essa equação é chamada de Conditional Expectation Function, ou CEF. De posse de uma amostra aleatória simples, podemos derivar os estimadores de mínimos quadrados (MQO ou OLS na sigla em inglês). Vou pular os passos da derivação. Para nós, o importante é lembrar a fórmula do \\(\\hat{\\beta}_1\\): \\(\\hat{\\beta}_1 = \\frac{\\text{covariância amostral}}{\\text{variância amostral}} = \\frac{\\sum_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n(x_i - \\bar{x})^2}\\) E \\(\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1\\bar{x}\\). Podemos então demonstrar que o estimador é não-viesado. Para isso, é necessário supor que o modelo é linear nos parâmetros (não nas variáveis), temos uma amostra aleatória simples da população, existe variância no preditor (para não dividir por zero na fórmula do estimador de OLS) e a média condicional zero. Para a derivação completa dos estimadores e a demonstração de não-viés, ver Wooldridge (2013, cap. 2). 1.1.1 Teorema da Anatomia da Regressão Na prática, raramente rodamos uma regressão com um único preditor. O que acontece quando adicionamos variáveis de controle a uma regressão? Como o coeficiente de uma variável muda quando “controlamos” por outras? O Teorema da Anatomia da Regressão nos dá uma resposta precisa a essas perguntas. Esse teorema, também conhecido como teorema de Frisch, Waugh e Lovell ou Frisch-Waugh-Lovell, é útil para ajudar a entender regressão múltipla. Suponha que nosso modelo possui \\(2\\) preditores: \\(y_i=\\beta_0+\\beta_1 x_{1i}+ \\beta_2 x_{2i}+ e_i\\). Agora, suponha que, em vez de rodar a regressão acima, eu rodo uma regressão (chamada de auxiliar) em que \\(x_1\\) é a variável dependente, e \\(x_2\\) o único preditor. \\(x_{1i}=\\gamma_0+\\gamma_{1}x_{2i} + f_i\\). E os resíduos são dados por: \\(\\tilde{x}_{1i}=x_{1i} - \\widehat{x}_{1i}\\). Então, é possível mostrar que: \\(\\beta_1 = \\frac{\\text{Cov}(y_i, \\tilde{x}_{1i})}{\\text{Var}(\\tilde{x}_{1i})}\\), onde \\(\\text{Cov}(\\cdot,\\cdot)\\) denota a covariância populacional e \\(\\text{Var}(\\cdot)\\) a variância populacional. O que essa fórmula nos diz é que o efeito de \\(\\beta_1\\) é a covariância entre a variável dependente e o resíduo da regressão auxiliar, isto é, a parte de \\(x_1\\) não explicada pelos demais preditores. Vamos visualizar essa relação com um exemplo do livro do Scott Cunningham: library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.4 ✔ readr 2.1.5 ## ✔ forcats 1.0.0 ✔ stringr 1.5.1 ## ✔ ggplot2 3.5.2 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.3 ✔ tidyr 1.3.1 ## ✔ purrr 1.1.0 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors library(haven) read_data &lt;- function(df) { full_path &lt;- paste0(&quot;https://github.com/scunning1975/mixtape/raw/master/&quot;, df) haven::read_dta(full_path) } auto &lt;- read_data(&quot;auto.dta&quot;) %&gt;% mutate(length = length - mean(length)) lm1 &lt;- lm(price ~ length, auto) lm2 &lt;- lm(price ~ length + weight + headroom + mpg, auto) lm_aux &lt;- lm(length ~ weight + headroom + mpg, auto) auto &lt;- auto %&gt;% mutate(length_resid = residuals(lm_aux)) lm2_alt &lt;- lm(price ~ length_resid, auto) coef_lm1 &lt;- lm1$coefficients coef_lm2_alt &lt;- lm2_alt$coefficients resid_lm2 &lt;- lm2$residuals y_single &lt;- tibble(price = coef_lm2_alt[1] + coef_lm1[2]*auto$length_resid, length_resid = auto$length_resid) y_multi &lt;- tibble(price = coef_lm2_alt[1] + coef_lm2_alt[2]*auto$length_resid, length_resid = auto$length_resid) auto %&gt;% ggplot(aes(x=length_resid, y = price)) + geom_point() + geom_smooth(data = y_multi, color = &quot;blue&quot;) + geom_smooth(data = y_single, color = &quot;red&quot;) ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; O gráfico acima mostra os pontos correspondentes ao preço do carro (price) contra o resíduo de length após controlar pelas demais variáveis (length_resid). A linha azul representa a relação estimada pela regressão múltipla (com controles), ou seja, o coeficiente de length após “limpar” o efeito das demais variáveis. A linha vermelha representa o coeficiente da regressão simples de price contra length, sem controles. A diferença entre as duas linhas ilustra a intuição central do Teorema FWL: controlar por outras variáveis muda o coeficiente estimado porque estamos isolando a parte da variação de length que não é explicada por weight, headroom e mpg. Quando variáveis omitidas estão correlacionadas tanto com o preditor quanto com a variável dependente, o coeficiente da regressão simples pode ser bastante diferente do coeficiente da regressão múltipla. 1.2 Inferência Como sabemos, inferência lida com a generalização da amostra para a população e, portanto, com a variabilidade inerente de amostra para amostra. Eu não vou revisar aqui os cálculos para derivar o erro padrão. Quero apenas enfatizar três pontos que não são usualmente abordados em cursos de regressão. 1.2.1 Generalização amostral vs. generalização causal Em primeiro lugar, generalização da amostra para a população é diferente de generalização causal, também conhecida como validade externa. Esse ponto foi confundido por muitos autores, em particular o livro conhecido como KKV (King, Keohane e Verba, 1994), e levou muitos pesquisadores a acreditarem que uma regressão possuía maior capacidade de generalização causal do que estudos de caso. Uma regressão (supondo que o erro padrão foi calculado corretamente) permite generalizar as estimativas para uma população. Porém, o que significa falar em generalização quando temos o universo de casos (por exemplo, todos os deputados, ou todos os candidatos, ou todos os municípios)? Quando temos o universo, não é diferente de estudos de caso que possuem todos os casos relevantes e, portanto, a noção de generalização da amostra para a população não se aplica. Essa distinção nos leva a uma pergunta natural: se temos todos os casos, ainda assim existe incerteza? 1.2.2 Incerteza com o universo dos casos A resposta é sim. Na inferência causal, em particular nesses casos em que temos o universo dos casos, ainda assim há incerteza. O trabalho de Abadie et al. (2020) discute a ideia de design-based inference. Nós vamos explicar no curso em mais detalhes o que é uma pesquisa design-based (em oposição a model-based), especialmente no Capítulo 2 (Resultados Potenciais). A ideia desse tipo de incerteza (e seu correspondente erro-padrão) é a seguinte. Imagine que estamos interessados em estimar o efeito causal da reeleição de prefeitos sobre a corrupção municipal. Suponha que tenho todos os municípios na amostra. Por fim, suponha que temos um experimento natural de forma que podemos supor que (talvez condicional a algumas variáveis) a reeleição é aleatória. Não há incerteza amostral para a população, mas há incerteza sobre o que aconteceria com a corrupção para os prefeitos reeleitos, caso não fossem reeleitos (e para os que perderam, como seria a corrupção caso fossem reeleitos). Em particular, se acreditamos que a reeleição foi aleatória, então uma nova rodada de amostragem (em um universo alternativo?) produziria outra configuração de prefeitos reeleitos e não reeleitos e alguma variação na estimativa do efeito causal. Isso antecipa nossa discussão sobre causalidade no Capítulo 2, mas o ponto central é que existe incerteza na estimativa do efeito causal que não deriva de variação amostral propriamente, mas da aleatoriedade da intervenção. Nas palavras dos autores: “it will be useful to distinguish between descriptive estimands, where uncertainty stems solely from not observing all units in the population of interest, and causal estimands, where the uncertainty stems, at least partially, from unobservability of some of the potential outcome” (p. 267). Meu ponto é que KKV e cia confundiram incerteza de estimandos descritivos com estimandos causais. 1.2.3 Validade externa O que me leva de volta ao ponto anterior sobre a comparação entre estudos de caso e métodos quantitativos, quando o objetivo é inferência causal. A incerteza inerente é sobre o efeito da intervenção, não sobre variações amostrais. Além disso, em ambos os casos não sabemos (a princípio) se os estudos possuem validade externa, isto é, se os resultados valem para outras populações, no tempo e espaço. É preciso avançar nessa agenda, tanto em métodos quali como quanti. É um problema em aberto e que tem atraído muitas pesquisas novas, que não iremos cobrir no curso (até por desconhecimento meu de boa parte dessa literatura). 1.3 Resumo e próximos passos Neste capítulo introdutório, revisamos três pontos fundamentais: A regressão como ponto de partida: o modelo de regressão por MQO estima a Função de Esperança Condicional (CEF), mas a interpretação causal do coeficiente depende de suposições fortes — em particular, a média condicional zero do termo de erro. O Teorema FWL e o papel dos controles: adicionar variáveis de controle a uma regressão muda o coeficiente estimado porque estamos isolando a variação do preditor que não é explicada pelos controles. Isso é crucial para entender o que “controlar por \\(X\\)” realmente significa. Incerteza vai além da amostragem: mesmo quando temos o universo dos casos, há incerteza causal — ela vem da aleatoriedade da intervenção, não da variação amostral. Essa distinção entre incerteza descritiva e causal é central para o curso. No próximo capítulo, formalizamos a noção de causalidade por meio do modelo de resultados potenciais (potential outcomes), que fornece a linguagem e o arcabouço teórico para definir efeitos causais de forma precisa. 1.4 Referências Abadie, Alberto, Susan Athey, Guido W. Imbens, and Jeffrey M. Wooldridge. 2020. “Sampling-Based Versus Design-Based Uncertainty in Regression Analysis.” Econometrica 88 (0): 265–96. Angrist, Joshua D., and Jörn-Steffen Pischke. 2009. Mostly Harmless Econometrics: An Empiricist’s Companion. Princeton University Press. King, Gary, Robert O. Keohane, and Sidney Verba. 1994. Designing Social Inquiry: Scientific Inference in Qualitative Research. Princeton University Press. Wooldridge, Jeffrey M. 2013. Introductory Econometrics: A Modern Approach. 5th ed. South-Western Cengage Learning. "],["resultados-potenciais.html", "Capítulo 2 Resultados Potenciais 2.1 Da intuição comparativa ao modelo formal 2.2 Resultados Potenciais (Potential Outcomes) 2.3 Notação 2.4 Problema Fundamental da Inferência Causal 2.5 Estimando 2.6 Estimandos Mais Comuns 2.7 Nota sobre estimandos 2.8 Exercício - Qual o estimando e o estimador (se possível)? 2.9 Identificação 2.10 Identificação do ATE 2.11 Equações estruturais 2.12 Modelo versus Desenho 2.13 Exercício em sala 2.14 Resumo e próximos passos 2.15 Referências", " Capítulo 2 Resultados Potenciais Durante muito tempo, inferência causal com regressão era caracterizada por recomendações vagas, ad hoc e inconsistências. O debate sobre o efeito causal do cigarro sobre câncer de pulmão é ilustrativo a esse respeito. Durante décadas, pesquisadores enfrentaram dificuldades para diferenciar correlação de causalidade em estudos epidemiológicos sobre tabagismo. Muitos estudos iniciais baseados apenas em correlação eram contestados por não apresentarem mecanismos claros ou critérios objetivos para validar inferências causais. Fisher (1958), por exemplo, questionou os resultados iniciais que ligavam o cigarro ao câncer por falta de critérios explícitos para identificar uma relação causal, argumentando que a correlação observada poderia decorrer de fatores confundidores, causalidade reversa ou problemas de mensuração. A situação mudou gradualmente com contribuições metodológicas importantes, como os critérios de causalidade propostos por Hill (1965). Os critérios de Bradford Hill ofereceram uma lista explícita e sistemática para avaliar a plausibilidade causal em estudos observacionais: O efeito deveria ser grande reproduzível em estudos independentes possuir uma relação monotônica com “dose” (isto é, aumento na dose não pode reduzir o efeito se o efeito é positivo e vice-versa se for negativo). corresponde a um “experimento natural” se comporta apropriadamente quando a causa é aplicada, removida e então reinstalada. é consistente com o conhecimento especializado do tema é, por exemplo, predita por alguma teoria bem estabelecida. Nós temos amplas evidências de que muitas intervenções são causais, mesmo na ausência de qualquer experimento aleatório controlado. Sabemos, por exemplo, que desfibrilação, manobra de Heimlich e uso de paraquedas são eficazes para prevenir mortes [@howick_etal_2009]. Em um artigo clássico dos primórdios da estatística escrito por Yule [@yule_1989], temos um dos primeiros exemplos de utilização da regressão para estudar o efeito causal de uma política (ajuda sobre pobreza). E a despeito do título do artigo falar em causalidade (“An investigation into the causes of changes in pauperism in england, chiefly during the last two intercensal decades”), a certa altura ele diz, em nota de rodapé, que “due to” deve ser lido como “associated to”. Quase cem anos depois, o grande estatístico Cox afirmaria em um artigo sobre causalidade: “it is remarkable how relatively little causality is mentioned in the general statistics literature, except in a social science context” [@cox_1992, p. 292]. Exemplo da perspectiva de que falava Cox quando, por exemplo, @muthen_1987 chegou a afirmar que “It would be very healthy if more researchers abandon thinking of and using terms such as cause and effect” (p. 180). Algo ecoado em uma entrevista com um dos líderes da revolução causal desde os anos 70/80, Jamie Robins, que relata que seus papers (em journals de estatística) eram rejeitados por usar linguagem causal, algo rejeitado na época [@robins_2022]. Então parece bastante seguro dizer que a sensação geral na estatística até os anos 80 é que não se deveria usar linguagem causal fora de estudos experimentais, isto é, em estudos observacionais. 2.1 Da intuição comparativa ao modelo formal A ideia de causalidade está presente há muito tempo na ciência política, especialmente na tradição de política comparada qualitativa. Os métodos comparativos de Stuart Mill — como o método da diferença e o método da concordância — buscam identificar relações causais comparando casos que diferem apenas na presença ou ausência de um fator de interesse. No fundo, essa lógica comparativa já contém o germe do raciocínio contrafactual: perguntar “o que teria acontecido se este fator estivesse ausente?” é exatamente o que fazemos ao comparar um caso tratado com um caso de controle. A moderna forma de pensar causalidade formaliza essa intuição, abandonando o paradigma de relações necessárias e/ou suficientes (que pressupõe determinismo) para adotar um framework probabilístico baseado em resultados potenciais. Essa formalização nos permite definir com precisão o que é um efeito causal, explicitar as suposições que precisamos fazer, e entender quando e por que nossas estimativas podem ser viesadas. 2.2 Resultados Potenciais (Potential Outcomes) Neste capítulo, formalizamos a ideia de causalidade usando o modelo de resultados potenciais (potential outcomes), também conhecido como Modelo Causal de Neyman-Rubin. Esse framework nos dará uma linguagem precisa para definir efeitos causais e explicitar as suposições necessárias para estimá-los. Objetivos de aprendizado: Compreender a notação de resultados potenciais e a switching equation Distinguir entre estimando, estimador e estimativa Definir os principais estimandos causais: ATE, ATT e CATE Enunciar as condições de identificação do ATE (ignorabilidade forte) Conectar o modelo de resultados potenciais à regressão linear e interpretar o viés Vamos começar fixando a notação que utilizaremos ao longo de todo o curso. 2.3 Notação Vamos assumir que existe um tratamento binário, que recebe o valor \\(1\\) se a unidade \\(i\\) recebe o tratamento, e \\(0\\) caso contrário, dado por: \\(D_i \\in \\{1,0\\}\\). Suponha que eu tenha \\(N\\) unidades que podem receber o tratamento ou controle. Então, o resultado potencial para a unidade \\(i\\) é \\(Y_i(\\mathbf{D})\\), ou seja, o resultado (potencial) da unidade \\(i\\) dado o conjunto de tratamento recebido por todas as \\(N\\) unidades. Em outras palavras, o resultado potencial depende do status de tratamento de todas as unidades. O que nos leva à primeira suposição simplificadora: Suposição 1: SUTVA (Stable Unit Treatment Value Assumption) Se \\(D_i = D&#39;_i\\), então \\(Y_i(\\mathbf{D}) = Y_i(\\mathbf{D}&#39;)\\). Em palavras, se mudarmos o tratamento de \\(i\\) de \\(D\\) para \\(D&#39;\\), então o resultado potencial depende apenas dessa mudança, e não dos demais tratamentos. Ou seja, o resultado potencial depende apenas do próprio tratamento, não dos demais. Essa suposição também é chamada de não-interferência. Então podemos escrever o resultado potencial apenas como função de \\(D_i\\): \\(Y_i(D_i)\\). Entretanto, os resultados potenciais não são observáveis. O que nós observamos é o resultado se a pessoa foi ou não tratada. O que nos leva à “switching equation”: \\(Y_i = D_i \\cdot Y_i(1) + (1-D_i) \\cdot Y_i(0)\\) Podemos agora definir o efeito causal do tratamento ao nível da unidade: \\(\\tau_i = Y_i(1) - Y_i(0)\\) A switching equation conecta o observado aos resultados potenciais e vice-versa. Esse modelo é chamado de Modelo Causal de Neyman-Rubin. Recapitulando: introduzimos três ingredientes essenciais — o tratamento binário \\(D_i\\), os dois resultados potenciais \\(Y_i(1)\\) e \\(Y_i(0)\\), e a switching equation que liga o mundo potencial ao observado. A suposição SUTVA garante que podemos tratar cada unidade isoladamente. Com essas peças, podemos agora enfrentar o desafio central da inferência causal. 2.4 Problema Fundamental da Inferência Causal O Problema Fundamental da Inferência Causal (PFIC), batizado assim por Holland (1986), diz que não podemos observar, simultaneamente, ambos os resultados potenciais \\(Y_i(1)\\) e \\(Y_i(0)\\). Para tornar o PFIC concreto, considere o seguinte exemplo. Maria participa de um programa de treinamento profissional (\\(D_i = 1\\)) e, ao final, recebe um salário de R$ 3.000 (\\(Y_i(1) = 3000\\)). Gostaríamos de saber: qual seria o salário de Maria se ela não tivesse participado do programa? Esse é o resultado potencial \\(Y_i(0)\\), que nunca observaremos — Maria não pode simultaneamente ter participado e não ter participado do programa. O efeito causal individual \\(\\tau_i = Y_i(1) - Y_i(0)\\) é, portanto, fundamentalmente não-observável. Possíveis soluções para o PFIC: Assumir homogeneidade temporal (comparação antes e depois da mesma unidade) Assumir homogeneidade da unidade (comparar dois indivíduos, um tratado, outro no controle) Método estatístico (foco na esperança) 2.5 Estimando O PFIC nos mostrou que o efeito causal individual \\(\\tau_i\\) é não-observável. A saída, como indicado na terceira solução acima, é trabalhar com médias — ou seja, com o valor esperado do efeito causal sobre uma população. Mas antes de estimar, precisamos definir com precisão o que queremos estimar. O que nós estamos interessados em estimar é o nosso Estimando. Lundberg et al. (2021), definem de maneira bem completa o que é um estimando. Informalmente, é a quantidade causal que queremos estimar. Os autores separam o estimando teórico do estimando estatístico. O estimando teórico especifica a unidade teórica de interesse (ex.: o efeito de instituições inclusivas sobre o desenvolvimento econômico do país \\(i\\); “A Dilma teria sofrido impeachment se a lava-jato não existisse?”). O segundo componente é a população-alvo. Se formos agregar essa unidade, é sobre quem ou quê? No primeiro caso, é a categoria de países em desenvolvimento em 1990? Todos os países independentes do globo no século XX? No segundo caso, é mais difícil pensar qual é a população alvo. Talvez já seja a população e, nesse caso, não cabe se perguntar sobre quem agregaríamos a quantidade. Ou talvez a pergunta de pesquisa seja sobre crises econômicas e impeachment, e o Brasil é só um caso. Daí a população alvo pode ser, talvez, países latino-americanos. Nesse caso, a pesquisadora deverá argumentar sobre como o estudo de caso é informativo sobre a população-alvo. Estimando estatístico ou empírico é a quantidade que pode ser estimada estatisticamente (a princípio). Estimativa: a aproximação do estimando usando uma amostra finita de dados Estimador: o método ou fórmula para se chegar a uma estimativa para um estimando. 2.6 Estimandos Mais Comuns 2.6.1 ATE Vamos definir o ATE e mostrar condições suficientes para identificação desse estimando. O ATE é simplesmente o efeito causal médio entre todos os indivíduos de uma população. Às vezes chamado de PATE, de Population Average Treatment Effect. Definição 2.1. Chamamos de ATE na população: \\[\\tau_{\\text{ATE}} = \\mathbb{E}[\\tau_i] = \\mathbb{E}[Y_i(1) - Y_i(0)] = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)]\\] O ATE nos dá o efeito do tratamento em toda a população de interesse. Note que \\(\\tau_i = Y_i(1) - Y_i(0)\\) é o efeito causal individual que definimos na seção de Notação; o ATE é simplesmente a esperança dessa quantidade sobre toda a população. 2.6.2 ATT Definição 2.2. Chamamos de Average Treatment Effect on the Treated (ATT): \\[\\tau_{\\text{ATT}} = \\mathbb{E}[\\tau_i|D_i=1] = \\mathbb{E}[Y_i(1) - Y_i(0)|D_i=1] = \\underbrace{\\mathbb{E}[Y_i(1)|D_i=1]}_{\\text{observado}} - \\mathbb{E}[Y_i(0)|D_i=1]\\] Note que \\(\\mathbb{E}[Y_i(1)|D_i=1]\\) é um resultado potencial que podemos observar, já que é igual ao resultado realizado dos tratados. Esse estimando estima o efeito do tratamento apenas entre os tratados. Essa quantidade é, tipicamente, a mais relevante em políticas públicas. Considere a política pública de vacinação. O que é mais importante, saber o efeito causal da vacina em toda a população, ou em toda a população que tomaria a vacina (tratados)? Ou para dar um exemplo mais claro ainda. Não é relevante o efeito do Bolsa-Família sobre redução da pobreza em toda a população, nem mesmo se considerarmos que a população alvo é toda a população pobre. Pessoas que não vão participar do programa não importam muito. Importam as que efetivamente irão receber o programa. 2.6.3 CATE Vamos definir o Conditional Average Treatment Effect (CATE). Seja \\(X_i\\) um conjunto de covariáveis pré-determinadas (não causadas pelo tratamento). Então, podemos definir o CATE como: \\[\\tau_{\\text{CATE}} = \\mathbb{E}[\\tau_i|X_i=x] = \\mathbb{E}[Y_i(1) - Y_i(0)|X_i=x] = \\mathbb{E}[Y_i(1)|X_i=x] - \\mathbb{E}[Y_i(0)|X_i=x]\\] Retornando ao nosso exemplo da introdução da urna eletrônica em um município sobre a pobreza municipal. ATE: O efeito médio de um município ter urna eletrônica sobre a pobreza municipal comparado a voto em papel. ATT: O efeito médio da urna eletrônica nos municípios que receberam urna eletrônica sobre a pobreza municipal comparado a voto em papel. CATE: O efeito médio de urna eletrônica sobre a pobreza municipal, em um determinado grupo de municípios (ex. do semiárido do Nordeste), comparado a voto em papel. Se \\(X\\) for discreto, podemos estabelecer a seguinte relação entre ATE e CATE: \\[\\tau_{\\text{ATE}} = \\sum_{x \\in X} \\tau_{\\text{CATE}}(x) p(X_i = x)\\] Há outros estimandos possíveis, mas esses são os mais comuns. Definir o estimando é apenas o primeiro passo. A pergunta seguinte — e central para a inferência causal — é: sob quais condições conseguimos identificar esse estimando a partir de dados observáveis? É disso que trataremos a seguir. 2.7 Nota sobre estimandos A rigor, podemos caracterizar ao nível da população dois contrastes: a distribuição de probabilidade de resultados potenciais do tratamento com a do controle, para um dado conjunto de covariáveis de pré-tratamento \\(\\mathbf{X}\\). Formalmente, sejam \\(f(Y(1)|\\mathbf{X})\\) e \\(f(Y(0)|\\mathbf{X})\\) as densidades dos dois resultados potenciais, então \\(f(Y(1)|\\mathbf{X}) - f(Y(0)|\\mathbf{X})\\) configura uma nova distribuição, da diferença entre os dois resultados potenciais. Nossa ênfase na esperança, portanto, é tanto uma questão de conveniência matemática quanto potencial interesse de pesquisa em um estimando em torno da média da diferença dessas duas distribuições, mas nada impede, a princípio, que estimemos toda a distribuição da diferença. Outra observação: como veremos mais para frente no curso, dados longitudinais não possuem estimandos claros. Alguns pesquisadores mais rigorosos em política comparada, por exemplo, falam em efeito de país-ano, pois esta é a unidade de análise e o estimando é definido nesse nível. Como veremos também mais para frente (e é um tema de pesquisa meu), também é complicado definir as condições de identificação em dados longitudinais. Voltaremos a isso. 2.8 Exercício - Qual o estimando e o estimador (se possível)? Abstract 1 Abstract 2 Abstract 3 2.9 Identificação “Econometric identification really means just one thing: model parameters or features being uniquely determined from the observable population that generates the data” (Lewbel, apud Paul GP). Ou seja, se você tiver acesso a uma amostra infinita, isto é, não há problemas inferenciais de amostra pequena, é possível estimar precisamente o parâmetro de interesse? Dizemos que, nesse caso, o estimando é identificável. O que seria um estimando não-identificável? Digamos que estou interessado em estimar o efeito causal da segunda dose de uma vacina sobre internação por uma doença. Para a pessoa receber a segunda dose, obviamente ela precisa receber a primeira. Suponha que a primeira dose ajuda a reduzir a internação. É impossível estimar o efeito causal da segunda dose. Para mostrar que o ATE é identificado, vamos supor o que chamamos de ignorabilidade forte (strong ignorability). Definição. Dizemos que \\(D_i\\) é fortemente ignorável condicional a um vetor \\(\\mathbf{X_i}\\) se: 1. \\(Y_i(1), Y_i(0) \\perp D_i | \\mathbf{X_i}\\) 2. \\(\\exists \\eta &gt; 0 \\text{ tal que } \\eta &lt; Pr(D_i = 1 | \\mathbf{X_i}) &lt; 1 - \\eta\\) Em palavras, a primeira condição diz que os resultados potenciais são independentes de receber ou não o tratamento. Quando pensamos em modelos com seres humanos ou unidades com agência, a principal preocupação é que as unidades não se auto-selecionam no tratamento que lhes é mais benéfico (ou que acreditam sê-lo). Às vezes na literatura essa condição aparece como permutabilidade (exchangeability): Como dizem Hernan e Robins em seu livro, “the treated and the untreated are exchangeable because the treated, had they remained untreated, would have experienced the same average outcome as the untreated did, and vice versa.” (p. 29). A segunda condição, conhecida como common support ou overlapping condition, diz que não existe unidade que não possa receber o tratamento ou controle. Essa condição é mais forte do que a positividade (toda unidade tem probabilidade positiva de receber o tratamento). Quero explorar aqui essa condição por meio de uma simulação. Vamos supor que um efeito causal \\(\\tau_i\\) tem distribuição normal com média \\(2\\) e desvio-padrão \\(2\\). E vamos supor que pessoas com \\(\\tau_i &gt;6\\) não podem receber o tratamento, apenas o controle. Veremos que o efeito causal para esse subgrupo não é identificado e mesmo o ATE não é identificado. ## d1 ## d 0 1 ## 0 5019 0 ## 1 396 4585 ## [1] 2.013731 ## [1] 1.37696 Note o resultado: quando todos podem receber tratamento ou controle (common support satisfeito), a diferença de médias recupera o ATE. Porém, quando impedimos que unidades com \\(Y_i(1) &gt; 6\\) recebam o tratamento, a estimativa se torna viesada — estamos comparando “maçãs com laranjas”, pois o grupo tratado e o grupo controle passam a ter composições diferentes. Essa é a intuição central da condição de common support: precisamos que, para cada perfil de covariáveis, existam unidades tanto no tratamento quanto no controle. Um último comentário: ignorability às vezes aparece como “tratamento é exógeno”. Porém, exogeneidade ignora a segunda condição e trata apenas da primeira. Em uma audiência de ciência política, dizemos que o tratamento é condicionalmente aleatório ou exógeno (o que é impreciso). 2.10 Identificação do ATE Com as duas condições de ignorabilidade forte em mãos, podemos agora demonstrar formalmente que o ATE é identificado — isto é, que pode ser expresso inteiramente em termos de quantidades observáveis. Teorema 1: Se \\(D_i\\) é fortemente ignorável condicional a \\(\\mathbf{X_i}\\), então: \\[\\mathbb{E}[\\tau_i] = \\sum_{x \\in X}(\\mathbb{E}[(Y_i|D_i=1, \\mathbf{X_i} = x)] - \\mathbb{E}[(Y_i|D_i=0, \\mathbf{X_i} = x)])Pr(\\mathbf{X_i = x})\\] Prova: O ATE foi definido como: \\[\\mathbb{E}[\\tau_{\\text{ATE}}] = \\mathbb{E}[\\tau_i] = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)]\\] Pela LIE, temos que: \\[\\mathbb{E}[Y_i(1)] = \\mathbb{E}[\\mathbb{E}[Y_i(1)|\\mathbf{X_i}]]\\] \\[\\mathbb{E}[Y_i(0)] = \\mathbb{E}[\\mathbb{E}[Y_i(0)|\\mathbf{X_i}]]\\] Com ignorabilidade forte, \\(\\mathbb{E}[Y_i(0)|\\mathbf{X_i}] = \\mathbb{E}[Y_i(0)|D_i=0, \\mathbf{X_i}] = \\mathbb{E}[Y_i|D_i=0, \\mathbf{X_i}]\\). Similarmente, \\(\\mathbb{E}[Y_i(1)|\\mathbf{X_i}] = \\mathbb{E}[Y_i(1)|D_i=1, \\mathbf{X_i}] = \\mathbb{E}[Y_i|D_i=1, \\mathbf{X_i}]\\). Juntando tudo, chegamos à proposição do teorema. Ou seja, com ignorabilidade forte, podemos estimar o ATE não-parametricamente apenas a partir de observáveis. O CATE também é identificado, como corolário. Em termos práticos, o teorema nos diz que, se conseguirmos argumentar convincentemente que o tratamento é “como se” aleatório condicional às covariáveis observadas \\(\\mathbf{X_i}\\), podemos estimar efeitos causais comparando tratados e controles dentro de cada estrato de \\(\\mathbf{X_i}\\) — sem precisar de suposições sobre a forma funcional da relação entre variáveis. 2.11 Equações estruturais Até aqui, trabalhamos inteiramente com resultados potenciais e esperanças. Mas na prática, a ferramenta mais comum de estimação em ciências sociais é a regressão linear. Qual é a relação entre o modelo de resultados potenciais e a regressão? O que exatamente estamos estimando quando rodamos uma regressão do resultado sobre o tratamento? Normalmente nós temos um modelo que queremos estimar o efeito causal, e não algo sobre o mecanismo de assignment do tratamento. Vamos conectar as duas abordagens. Seja o modelo: \\(Y_i = \\alpha + \\beta D_i + \\epsilon_i\\). Nós interpretamos \\(\\beta\\) como a diferença média no \\(y\\) de uma unidade no tratamento, formalmente: \\(\\mathbb{E}[Y|D_i=1] - \\mathbb{E}[Y|D_i=0] = \\mathbb{E}[\\alpha + \\beta D_i + \\epsilon_i|D_i=1] - \\mathbb{E}[\\alpha + \\beta D_i + \\epsilon_i|D_i=0] = \\beta + \\mathbb{E}[\\epsilon_i|D_i=1] - \\mathbb{E}[\\epsilon_i|D_i=0]\\). E dizemos que, sob a suposição de esperança condicional zero do erro, ou seja, \\(\\mathbb{E}[\\epsilon_i|D_i=1] = \\mathbb{E}[\\epsilon_i|D_i=0] = 0\\). Portanto, temos que \\(\\mathbb{E}[Y|D_i=1] - \\mathbb{E}[Y|D_i=0] = \\beta\\). E o estimador de MQO é não-viesado. E de forma geral, temos que \\(\\mathbb{E}[Y|D_i] = \\alpha + \\beta D_i\\), sob a suposição de esperança condicional zero do erro. Vamos mapeá-lo ao modelo de resultados potenciais com a switching equation. \\[ \\begin{aligned} Y_i &amp;= Y_i(0)(1-D_i) + Y_i(1)D_i \\\\ &amp;= Y_i(0) + \\tau_i D_i \\\\ &amp;= Y_i(0) + \\tau_i D_i + \\tau D_i - \\tau D_i\\\\ &amp;= Y_i(0) + \\tau D_i + (\\tau_i - \\tau)D_i \\\\ &amp;= \\mathbb{E}[Y_i(0)|D_i=0] - \\mathbb{E}[Y_i(0)|D_i=0] + Y_i(0) + \\tau D_i + (\\tau_i - \\tau)D_i \\\\ &amp;= \\underbrace{\\mathbb{E}[Y_i(0)|D_i=0]}_{\\alpha} + \\underbrace{\\tau}_{\\beta} D_i + \\underbrace{(\\tau_i - \\tau)D_i + (Y_i(0) - \\mathbb{E}[Y_i(0)|D_i=0])}_{\\epsilon_i} \\\\ \\end{aligned} \\] Nós sabemos que em uma regressão estamos estimando \\(\\mathbb{E}[Y_i|D_i]\\). Podemos agora ver com clareza o que de fato estamos estimando em termos causais. \\[ \\begin{aligned} \\mathbb{E}[Y_i|D_i=1] &amp;= \\alpha + \\tau + \\mathbb{E}[\\epsilon_i|D_i=1] \\\\ \\mathbb{E}[Y_i|D_i=0] &amp;= \\alpha + \\mathbb{E}[\\epsilon_i|D_i=0] \\\\ \\mathbb{E}[\\epsilon_i|D_i=1] &amp;= \\mathbb{E}[(\\tau_i - \\tau)D_i + (Y_i(0) - \\mathbb{E}[Y_i(0)|D_i=0])|D_i=1] \\\\ &amp;= \\mathbb{E}[(\\tau_i - \\tau)D_i|D_i=1] + \\mathbb{E}[(Y_i(0) - \\mathbb{E}[Y_i(0)|D_i=0])|D_i=1] \\\\ &amp;= \\mathbb{E}[\\tau_i D_i|D_i=1] -\\tau\\mathbb{E}[ D_i|D_i=1] + \\mathbb{E}[Y_i(0)|D_i=1] - \\mathbb{E}[\\mathbb{E}[Y_i(0)|D_i=0]|D_i=1] \\\\ &amp;= (\\mathbb{E}[\\tau_i|D_i=1] -\\tau) + \\mathbb{E}[Y_i(0)|D_i=1] - \\mathbb{E}[Y_i(0)|D_i=0] \\\\ \\mathbb{E}[\\epsilon_i|D_i=0] &amp;= \\mathbb{E}[(\\tau_i - \\tau)D_i + (Y_i(0) - \\mathbb{E}[Y_i(0)|D_i=0])|D_i=0] \\\\ &amp;= \\mathbb{E}[Y_i(0)|D_i=0] - \\mathbb{E}[\\mathbb{E}[Y_i(0)|D_i=0]|D_i=0] \\\\ &amp;= 0 \\end{aligned} \\] Portanto, \\(\\mathbb{E}[Y_i|D_i=1] - \\mathbb{E}[Y_i|D_i=0] = \\tau + (\\mathbb{E}[\\tau_i|D_i=1] -\\tau) + \\mathbb{E}[Y_i(0)|D_i=1] - \\mathbb{E}[Y_i(0)|D_i=0]\\) Em palavras, estimamos o efeito causal médio, \\(\\tau\\), mais um componente que tem a ver com os efeitos causais heterogêneos mais um componente que é a diferença no resultado potencial do controle entre os tratados e o controle. Se \\(\\mathbb{E}[Y_i(0)|D_i=1] - \\mathbb{E}[Y_i(0)|D_i=0] \\neq 0\\), o efeito estimado é viesado. Similarmente, se \\(\\mathbb{E}[\\tau_i|D_i=1] \\neq \\tau\\), também teremos viés, ou seja, se o efeito causal dos tratados for diferente do efeito médio da população, também temos uma estimativa viesada do ATE. Porém, nesse caso, note que estamos viesando para estimar o efeito médio dos tratados, que é o ATT. Para ver isso, suponha que não há diferença nos resultados potenciais de não receber o tratamento entre os tratados e os do grupo controle, de modo que \\(\\mathbb{E}[Y_i(0)|D_i=1] - \\mathbb{E}[Y_i(0)|D_i=0] = \\tau + (\\mathbb{E}[\\tau_i|D_i=1] -\\tau) = \\mathbb{E}[\\tau_i|D_i=1]\\), que é o ATT. Em resumo, a diferença de médias simples \\(\\mathbb{E}[Y_i|D_i=1] - \\mathbb{E}[Y_i|D_i=0]\\) pode ser decomposta em três componentes: ATE (\\(\\tau\\)): o efeito causal médio que gostaríamos de estimar; Viés de heterogeneidade (\\(\\mathbb{E}[\\tau_i|D_i=1] - \\tau\\)): surge quando o efeito causal dos tratados difere do efeito médio na população; Viés de seleção (\\(\\mathbb{E}[Y_i(0)|D_i=1] - \\mathbb{E}[Y_i(0)|D_i=0]\\)): surge quando tratados e controles teriam resultados diferentes mesmo na ausência do tratamento. A ignorabilidade forte elimina ambos os vieses, garantindo que a diferença de médias recupere o ATE. 2.12 Modelo versus Desenho Há na literatura (mais de economia) uma distinção entre estimando baseado em modelos e baseado em designs (desenhos): Model-based (baseado em modelo): O estimando é identificado a partir de um modelo dos resultados potenciais, condicional ao tratamento e covariáveis. O exemplo arquetípico é o modelo de diferença em diferenças ou controle sintético, em que estimamos o efeito causal a partir de estimativa do contrafactual com dados observados. Design-based (baseado em desenho): O estimando é identificado a partir de suposições sobre o mecanismo de atribuição do tratamento e covariáveis. O exemplo arquetípico desse tipo de pesquisa é o experimento aleatório controlado. Ao longo deste curso, veremos estratégias de ambos os tipos e discutiremos quando cada abordagem é mais apropriada. 2.13 Exercício em sala Na década de 1970, houve um programa de treinamento e emprego conhecido como National Supported Work (NSW). Este programa temporário visava ajudar trabalhadores desfavorecidos e sem habilidades básicas a ingressarem no mercado de trabalho, oferecendo experiência profissional e orientação em um ambiente protegido. Um aspecto inovador do NSW foi a seleção aleatória de candidatos qualificados para os treinamentos, garantindo que o grupo de tratamento recebesse todos os benefícios do programa, enquanto o grupo de controle não tinha suporte. Os participantes do grupo de tratamento tinham emprego garantido por 9 a 18 meses, dependendo do grupo-alvo e do local. Eles trabalhavam em equipes de 3 a 5 pessoas, reunindo-se frequentemente com um orientador para discutir questões do programa e desempenho. Embora recebessem salários inferiores aos de um emprego regular, havia possibilidade de aumento conforme o desempenho e a frequência. Ao término do período, os participantes precisavam procurar emprego regular. O programa também coletou dados de renda e informações demográficas de ambos os grupos, realizando entrevistas periódicas, o que gerou diferentes tamanhos de amostra entre os estudos. O NSW utilizava um desenho experimental aleatório. Lalonde (1986) comparou os resultados experimentais com dados observacionais. Para isso, substituiu os dados do grupo controle atribuídos aleatoriamente, com dados de três amostras do Current Population Survey (CPS) e do Panel Survey of Income Dynamics (PSID). E usou as técnicas econométricas usuais para isso. O resultado não foi bom para a econometria. Voltaremos a isso mais para frente. Por ora, vamos estimar efeitos causais com os dados experimentais. O exercício a seguir é adaptado do exercício disponibilizado por Paul GP em seu github, no seu curso de métodos. Esta análise utilizará a amostra de Dehejia e Wahba do conjunto de dados Lalonde do experimento NSW. O conjunto de dados é “lalonde nsw.csv”. A variável de resultado é “re78” (rendimento real em 1978). O indicador de tratamento é “treat”. As demais variáveis são potenciais covariáveis. Para os fins deste conjunto de problemas, assuma que “treat” é atribuído de forma aleatória. Calcule o efeito médio do tratamento da política, \\(\\mathbb{E}[\\tau_i]\\), utilizando uma simples diferença de médias. Calcule o efeito médio do tratamento sobre os tratados da política, \\(\\mathbb{E}[\\tau_i|treat=1]\\). Como ele se compara à parte (a)? ## ## Anexando pacote: &#39;data.table&#39; ## Os seguintes objetos são mascarados por &#39;package:lubridate&#39;: ## ## hour, isoweek, mday, minute, month, quarter, second, wday, week, ## yday, year ## Os seguintes objetos são mascarados por &#39;package:dplyr&#39;: ## ## between, first, last ## O seguinte objeto é mascarado por &#39;package:purrr&#39;: ## ## transpose ## [1] 1794.342 ## [1] 1794.342 2.14 Resumo e próximos passos Neste capítulo, construímos o arcabouço formal dos resultados potenciais, que será a base de todo o restante do curso. Recapitulando os pontos centrais: Resultados potenciais e switching equation. Cada unidade possui dois resultados potenciais, \\(Y_i(1)\\) e \\(Y_i(0)\\), mas observamos apenas um deles. A switching equation \\(Y_i = D_i \\cdot Y_i(1) + (1-D_i) \\cdot Y_i(0)\\) conecta os resultados potenciais ao dado observado. Estimandos causais. Definimos os três estimandos mais comuns — ATE, ATT e CATE — e discutimos quando cada um é mais relevante para a pesquisa aplicada. Identificação. Mostramos que, sob ignorabilidade forte (independência condicional e common support), o ATE é identificado a partir de quantidades observáveis, sem necessidade de suposições paramétricas. Conexão com regressão. A decomposição do viés da regressão revelou que a diferença de médias simples estima o ATE apenas sob condições restritivas; caso contrário, o viés possui dois componentes — heterogeneidade do efeito causal e diferença nos resultados potenciais de base. No próximo capítulo, introduziremos os grafos acíclicos direcionados (DAGs), que oferecem uma linguagem visual e formal para representar suposições causais, complementando o framework algébrico que desenvolvemos aqui. 2.15 Referências Lalonde, Robert. 1986. “Evaluating the Econometric Evaluations of Training Programs with Experimental Data.” American Economic Review 76 (4): 604–20. Rajeev Dehejia and Sadek Wahba, “Causal Effects in Non-Experimental Studies: Reevaluating the Evaluation of Training Programs,” Journal of the American Statistical Association, Vol. 94, No. 448 (December 1999), pp. 1053-1062. Rajeev Dehejia and Sadek Wahba, “Propensity Score Matching Methods for Non-Experimental Causal Studies,” Review of Economics and Statistics, Vol. 84, (February 2002), pp. 151-161. Robert Lalonde, “Evaluating the Econometric Evaluations of Training Programs,” American Economic Review, Vol. 76 (1986), pp. 604-620. Lundberg, I., Johnson, R., &amp; Stewart, B. M. (2021). What is your estimand? Defining the target quantity connects statistical evidence to theory. American Sociological Review, 86(3), 532-565. Paul W Holland. Statistics and causal inference. Journal of the American statistical Association, 81(396):945–960, 1986. "],["dags.html", "Capítulo 3 DAGs 3.1 Causalidade 3.2 Introdução 3.3 Os Tipos Básicos de DAGs 3.4 Simulação no R: Ilustrando o Collider Bias 3.5 Definições 3.6 Controle e Ajuste 3.7 Fatorização da Probabilidade Conjunta 3.8 Fatorização e DAGs 3.9 Fatorização, DAGs e Causalidade 3.10 Resumo e próximos passos 3.11 Referências", " Capítulo 3 DAGs 3.1 Causalidade 3.2 Introdução Uma das principais abordagens para fazer inferência causal utiliza diagramas causais chamados de Directed Acyclic Graphs (DAG). Ela foi desenvolvida na ciência da computação entre os anos 80 e 90 e é associada ao trabalho pioneiro de Judea Pearl. Veja o livro The Book of Why para uma história de como surgiu essa abordagem. Abaixo temos um exemplo simples de um DAG: Eles são chamados de DAGs porque os gráficos são direcionados (apontam em uma direção), acyclic porque não permitem ciclos (isto é, se A causa B, B não pode causar A) e graphs porque, como você pode imaginar, são grafos. No exemplo acima, o DAG é formado por três variáveis {y, x, z} que são, em geral, variáveis aleatórias. E as flechas indicam direção de causalidade. Ou seja, \\(x\\) causa \\(y\\) e \\(z\\) causa \\(y\\). É importante saber que DAGs são não paramétricos. Eles podem ser interpretados como: \\(y = f(x, z)\\). Ou seja, qualquer função de x e z é igualmente possível. Eis alguns exemplos compatíveis com o DAG acima: \\(y = x + z\\) \\(y = 10 + x + z + x*z\\) \\(y = 3*x^z\\) \\(y = \\pi*z/x + x^2 + 1/(z^3)\\) A razão pela qual não escrevemos DAGs como equações é que \\(y = f(x, z)\\) não expressa adequadamente a relação de causalidade, pois, em matemática, é indiferente escrever \\(f(x, z) = y\\) ou \\(y = f(z, x)\\). Porém, dizer que \\(x\\) e \\(z\\) causam \\(y\\) é muito diferente de dizer que \\(y\\) causa \\(x\\) e \\(z\\). E, com o DAG, as flechas indicam a direção da causalidade. 3.3 Os Tipos Básicos de DAGs 3.3.1 1. Chains Em uma chain, \\(x\\) causa \\(w\\) que, por sua vez, causa \\(y\\). Aqui, \\(w\\) pode ser considerado o mediador do efeito de \\(x\\) sobre \\(y\\). Exemplo: O desempenho econômico de um país pode aumentar a popularidade do presidente, o que leva a mais votos. Representação: 3.3.2 2. Forks Em um fork, uma variável \\(w\\) causa tanto \\(x\\) quanto \\(y\\). Dessa forma, \\(w\\) é uma causa comum que pode gerar correlação espúria entre \\(x\\) e \\(y\\). Exemplo: A qualidade de um candidato pode fazer com que ele arrecade mais dinheiro para a campanha e, ao mesmo tempo, obtenha mais votos. Representação: 3.3.3 3. Colliders Em um collider, \\(x\\) causa \\(w\\) e \\(y\\) também causa \\(w\\). Esse tipo de estrutura é também chamado de “fork invertido”. Apesar de \\(x\\) e \\(y\\) não terem relação causal direta, controlar para \\(w\\) (ou um de seus descendentes) pode introduzir uma correlação espúria entre \\(x\\) e \\(y\\). Exemplo: Imagine que você organiza uma festa e convida apenas pessoas que fazem ciência política ou são canhotas. Na população geral, pode não haver relação entre essas características, mas na festa pode surgir uma correlação: se uma pessoa é canhota, ela pode ter maior probabilidade de fazer ciência política. Esses três tipos básicos — chains, forks e colliders — são os blocos fundamentais a partir dos quais qualquer DAG pode ser construído. Compreender como cada um deles afeta a dependência entre variáveis é essencial para decidir quais variáveis controlar em uma análise causal. Vejamos agora uma simulação que ilustra o viés que pode surgir quando condicionamos em um collider. 3.4 Simulação no R: Ilustrando o Collider Bias Vamos rodar uma simulação para ilustrar o collider bias. Suponha que 10% das pessoas fazem ciência política e 5% são canhotas. library(dplyr) set.seed(4) # Gerando as variáveis cp &lt;- rbinom(1000, 1, p = 0.1) # 10% fazem ciência política canhoto &lt;- rbinom(1000, 1, p = 0.05) # 5% são canhotos # Definindo a condição da festa: convida se faz ciência política ou é canhoto festa &lt;- ifelse(cp == 1, 1, ifelse(canhoto == 1, 1, 0)) tabela &lt;- data.frame(cp, canhoto, festa) # Correlação na população geral cor_geral &lt;- round(cor(cp, canhoto), 2) print(cor_geral) ## [1] -0.02 # Correlação entre os que foram à festa cor_festa &lt;- tabela %&gt;% filter(festa == 1) %&gt;% summarise(cor = round(cor(cp, canhoto), 2)) print(cor_festa) ## cor ## 1 -0.95 Na população em geral, a correlação é próxima de zero (aproximadamente -0,02). Porém, entre as pessoas que foram à festa, a correlação pode chegar a -0,95, evidenciando como condicionar em um collider (neste caso, a variável festa) pode induzir correlação espúria. Esse resultado reforça a importância de entender a estrutura causal antes de decidir por quais variáveis condicionar. 3.5 Definições Path (caminho): É uma sequência de flechas conectadas. Um directed path (caminho dirigido) é aquele em que todas as flechas seguem a mesma direção (por exemplo, \\(x \\to z \\to y\\)). 3.5.1 Relações entre Variáveis (nós): As relações são descritas usando termos da genética, como pais, filhos, ancestrais, descendentes e vizinhos. Pais e filhos referem-se a relações diretas. Ancestrais e descendentes incluem todas as variáveis em qualquer posição no caminho. Um path sem collider está aberto; um path com collider está fechado. Duas variáveis (ou conjuntos) estão d-separated se não houver caminho aberto entre elas. Caso contrário, podem ou não ser independentes, pois múltiplos caminhos abertos podem se cancelar. 3.6 Controle e Ajuste Agora que conhecemos os elementos básicos dos DAGs e as definições de caminhos e d-separação, podemos abordar uma questão central: como decidir quais variáveis controlar em uma análise causal? No contexto dos DAGs, controlar para variáveis pode ter diferentes significados: Experimentos: Controlar significa manipular o valor da variável pelo pesquisador. Exemplo: Um experimento em que o resultado do lançamento de uma moeda determina se um pedido de acesso à informação será feito por um homem ou mulher. Estudos Observacionais: Controlar significa condicionar (estratificar ou incluir em uma regressão). Para visualizar isso em um DAG, considere o seguinte DAG: Controlar para C, nesse DAG, significa efetuar os seguintes passos, na sequência: 1. Eliminar todas as flechas que saem de C. Se C for um collider, elimine as flechas que vão para C e conecte os pais de C por meio de linhas tracejadas. Elimine C Manipular: Determinar o valor da variável. Alterar o Gráfico: Para controlar a variável G (por exemplo, se relacionada a C): Eliminar as flechas que saem de G. Eliminar as flechas do collider (no caso, c e u, pais de G) e criar relação bidirecional espúria. Remover G do gráfico. Em resumo, se C depende de A e B de forma independente, condicionar em C pode criar uma relação espúria entre A e B. Por exemplo, se A e B são binárias e \\(C = A + B\\), para \\(C = 1\\) saber o valor de A determina automaticamente o valor de B, e vice-versa. De modo geral, condicionar em um collider inverte o status dos caminhos: caminhos que estavam abertos podem se fechar e vice-versa. Além disso, condicionar em um descendente de um collider também pode alterar os efeitos, atenuando ou abrindo caminhos que originalmente estavam fechados. 3.7 Fatorização da Probabilidade Conjunta Até aqui, discutimos DAGs sob a perspectiva qualitativa: quais variáveis causam quais. Agora veremos como a estrutura de um DAG se conecta formalmente à distribuição de probabilidade conjunta das variáveis, por meio da fatorização. Toda distribuição de probabilidade obedece à regra da cadeia de probabilidades (nenhuma suposição adicional). Lembremos: \\(Pr(X,Y) = Pr(Y|X) Pr(X) = Pr(X|Y) Pr(Y)\\) Similarmente, \\(Pr(X,Y,Z) = Pr(Y|X,Z) Pr(X|Z) Pr(Z) = Pr(X|Y,Z) Pr(Y|Z) Pr(Z) = Pr(Z|Y,X) Pr(X|Y) Pr(X) = \\cdots\\) De maneira geral, se temos \\(n\\) variáveis marginais, temos no total \\(n!\\) maneiras distintas de fatorar a distribuição conjunta. A lógica é assim: Seja uma função de massa de probabilidade (pmf) conjunta \\(Pr(x_1, x_2, ..., x_k)\\). Então, podemos usar a regra do produto: \\(Pr(x_1, x_2, ..., x_k) = Pr(x_1) Pr(x_2, ..., x_k|x_1)\\) Aplicando a regra iterativamente, \\(Pr(x_2, ..., x_k|x_1) = Pr(x_2|x_1)Pr(x_3, ..., x_k|x_1, x_2)\\), de forma que: \\(Pr(x_1, x_2, ..., x_k) = Pr(x_1) Pr(x_2|x_1)Pr(x_3, ..., x_k|x_1, x_2)\\) E assim por diante, até: \\(Pr(x_1, x_2, ..., x_k) = Pr(x_1) Pr(x_2|x_1) Pr(x_3| x_2, x_1) \\cdots Pr(x_k|x_1, x_2, x_3, ... , x_{k-1})\\) A Regra do produto pode ser aplicada em qualquer ordem, gerando fatorizações distintas. 3.8 Fatorização e DAGs Existem teoremas que mostram que existe uma relação entre DAGs e fatorização de probabilidades conjuntas. Dado um DAG, em que um nó é condicionalmente independente de outro nó, isso implica a fatorização da probabilidade conjunta de acordo com essa relação, e vice-versa. Dois exemplos abaixo ilustram essa propriedade. Considere o DAG abaixo: Nós sabemos que, condicional a X, Y é independente de Z, W e M. Similarmente, X é independente de M, condicional a Z e W. Podemos então fatorar a distribuição conjunta da seguinte maneira: \\[Pr(M, Z, W, X, Y) = Pr(M) Pr(Z|M) Pr(W|M) Pr(X|W,Z) Pr(Y|X)\\] Ou seja, basta escrever a probabilidade condicional nas variáveis que tornam cada nó independente para descrever a distribuição de probabilidade conjunta. 3.9 Fatorização, DAGs e Causalidade De volta à causalidade, um DAG em que não há confounding, isto é, sem back-door aberto, como o DAG abaixo, implica que a fatorização observacional é igual à fatorização intervencional: \\[Pr(Y = y |do (X = x)) = Pr(Y|X)\\] Logo, é verdade que \\[Pr(Y,X) = Pr(X)Pr(Y|X) = Pr(X)Pr(Y = y |do (X = x)).\\] O operador “do” aqui é uma inovação de Pearl, e diz que fizemos uma cirurgia no gráfico e determinamos, exogenamente, por assim dizer, que o valor de \\(X\\) é \\(x\\). 3.10 Resumo e próximos passos Neste capítulo, introduzimos os DAGs como ferramenta para representar e raciocinar sobre relações causais. Vimos os três tipos básicos de estruturas — chains, forks e colliders — e como eles determinam quais caminhos estão abertos ou fechados. Aprendemos que condicionar (controlar) em uma variável pode fechar um caminho aberto (no caso de forks e chains) ou abrir um caminho fechado (no caso de colliders). Também vimos como a estrutura de um DAG implica uma fatorização específica da distribuição de probabilidade conjunta, e como a fatorização observacional pode coincidir com a intervencional quando não há confounding. No próximo capítulo, utilizaremos esses conceitos para entender por que experimentos aleatórios são considerados o padrão-ouro para inferência causal: a aleatorização garante que não haja caminhos abertos entre o tratamento e os resultados potenciais. 3.11 Referências Hernán MA, Robins JM (2019). Causal Inference. Boca Raton: Chapman &amp; Hall/CRC. Disponível temporariamente em: https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/ Greenland, S., &amp; Pearl, J. (2014). Causal diagrams. Wiley StatsRef: Statistics Reference Online, 1-10. "],["experimentos.html", "Capítulo 4 Experimentos 4.1 Introdução 4.2 Experimentos aleatórios 4.3 Restrição de Exclusão 4.4 Tipos de experimentos 4.5 Estimador ATE 4.6 Resumo do Capítulo 4.7 Declare Design 4.8 Exercício", " Capítulo 4 Experimentos 4.1 Introdução Um experimento é o desenho de pesquisa no qual a pesquisadora controla o mecanismo de atribuição do tratamento e controle Seja \\(p_i = P(T_i=1)\\). Então \\(p_i\\) é conhecido e controlado pela pesquisadora. Em contraposição, um estudo observacional é quando a pesquisadora não controla o mecanismo (natureza ou realidade social) Quando uma quantidade potencial (estimando) pode ser descrita em função da distribuição de dados observáveis, dizemos que o estimando é identificável. De outro modo, não identificado. Veremos por que experimentos produzem desenhos críveis de identificação causal Vamos supor experimentos ideais (sem attrition ou non-compliance) Nós já vimos que uma suposição crítica é a SUTVA. Stable Unit Treatment Values Assumption Não interferência e sem variação escondida no tratamento PO não varia com o tratamento atribuído a outras unidades PO de uma unidade não é impactado pelo nível de tratamento de outras unidades Para cada unidade, não há formas distintas ou versões de cada nível de tratamento Definição não-ambígua do tratamento Supondo SUTVA, Diferença Simples de Média pode ser decomposta em ATE + viés de seleção \\(\\underbrace{\\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0]}_{\\text{Simple Difference in Outcomes (SDO)}} = \\mathbb{E}[Y_i^1|T_i=1] - \\mathbb{E}[Y_i^0|T_i=0]\\) Podemos adicionar e subtrair os resultados contrafactuais para os tratados \\(= \\mathbb{E}[Y_i^1|T_i=1] - \\color{blue}{\\mathbb{E}[Y_i^0|T_i=1]} + \\color{red}{\\mathbb{E}[Y_i^0|T_i=1]} - \\mathbb{E}[Y_i^0|T_i=0]\\) \\(= \\underbrace{\\mathbb{E}[Y_i^1 - Y_i^0|T_i=1]}_{\\text{ATT}} + \\underbrace{\\mathbb{E}[Y_i^0|T_i=1] - \\mathbb{E}[Y_i^0|T_i=0]}_{\\text{Viés de Seleção}}\\) 4.2 Experimentos aleatórios Mecanismo de atribuição de tratamento é probabilístico (Positividade): \\(0 &lt; p_i &lt; 1\\). Unconfoundedness ou Permutabilidade (ou assignment mechanism–ignorability): \\(P(T_i=1|y^1, y^0) = P(T_i)\\). O que é Permutabilidade (unconfoundedness)? A distribuição dos resultados potenciais é independente do tratamento. \\(\\mathbb{E}[Y^1|T=1] = \\mathbb{E}[Y^1|T=0]\\) \\(\\mathbb{E}[Y^0|T=1] = \\mathbb{E}[Y^0|T=0]\\) Resultados potenciais são independentes do tratamento, dadas as covariáveis. Se a condição de tratamento fosse hipoteticamente trocada, os resultados esperados permaneceriam os mesmos. Isso significa que em um experimento com permutabilidade, não temos viés de seleção (Por quê?). Independência entre tratamento e resultados potenciais implica que \\(\\mathbb{E}[Y^0_i|T_i=1] = \\mathbb{E}[Y^0_i|T_i=0] = \\mathbb{E}[Y^0_i]\\) Portanto, o viés de seleção, dado por \\(\\mathbb{E}[Y_i^0|T_i=1] - \\mathbb{E}[Y_i^0|T_i=0]\\), fica: \\(\\mathbb{E}[Y_i^0|T_i=1] - \\mathbb{E}[Y_i^0|T_i=0] = \\mathbb{E}[Y_i^0] - \\mathbb{E}[Y_i^0] = 0\\) Ou seja, SDO estima o ATE (via ATT). \\(\\underbrace{\\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0]}_{\\text{Simple Difference in Outcomes (SDO)}} = \\underbrace{\\mathbb{E}[Y_i^1 - Y_i^0|T_i=1]}_{\\text{ATT}} = ATE\\) 4.3 Restrição de Exclusão Formalmente, podemos separar a alocação do tratamento e o tratamento efetivamente recebido. Seja \\(Z_i\\) a alocação do tratamento e \\(T_i\\) o tratamento recebido. Então, a restrição de exclusão quer dizer que o que importa é o tratamento efetivamente recebido \\(T_i\\), e não a variável que aloca o tratamento \\(Z_i\\). Formalmente, isso quer dizer que: \\(Y^{1,z=1, T}_i = Y^{1,z=0, T}_i = Y^{1,T}_i\\) e similarmente, \\(Y^{0,z=1,T}_i = Y^{0,z=0,T}_i = Y^{0,T}_i\\) Quando não ocorre isso? Se o mecanismo de atribuição do tratamento dispara outras causas Suponha que um experimento é sobre efeito de transferência de dinheiro em bem-estar Se ongs, sabendo do experimento, forem ajudar quem não tiver sido alocado para receber dinheiro Se houver erro de mensuração assimétrico? Pesquisadores distintos entrevistam recipientes e não-recipientes da transferência de dinheiro, com habilidades distintas Ou questionários diferentes. Erro de mensuração assimétrico Nova switching equation. Seja \\(e_{i1}\\) o erro de mensuração cometido se uma observação é atribuída para o tratamento, e, analogamente, \\(e_{i0}\\) o erro para o controle. De \\(Y_i = T_iY^1_i + (1- T_i)Y^0_i\\) para \\(Y_i = T_i(Y^1_i + e_{i1}) + (1- T_i)(Y^0_i + e_{i0})\\). Novo SDO: \\(\\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0] = \\mathbb{E}[Y^1_i + e_{i1}|T_i=1] - \\mathbb{E}[Y^0_i + e_{i0}|T_i=0] = \\mathbb{E}[Y^1_i|T_i=1] + \\mathbb{E}[e_{i1}|T_i=1] - \\mathbb{E}[Y^0_i|T_i=0] - \\mathbb{E}[e_{i0}|T_i=0]\\) Novo SDO pode se rearranjado: \\(\\underbrace{\\mathbb{E}[Y^1_i|T_i=1] - \\mathbb{E}[Y^0_i|T_i=0]}_{\\text{antigo SDO}} + \\underbrace{\\mathbb{E}[e_{i1}|T_i=1] - \\mathbb{E}[e_{i0}|T_i=0]}_{\\text{Dif média no erro de mensuração}}\\) Se \\(\\mathbb{E}[e_{i1}|T_i=1] \\neq \\mathbb{E}[e_{i0}|T_i=0]\\), então SDO será viesado. Como Garantir a restrição de Exclusão? Double blindness (duplo cego) Paralelismo na administração do experimento (mesmo questionário e mesmos entrevistadores) Na pior das hipóteses, aleatorização dos entrevistadores. 4.4 Tipos de experimentos 4.4.1 Aleatorização de Bernoulli É o experimento com aleatorização simples (basicamente, lançamento de moeda) Matematicamente, \\(p_i(T_i=1) = p\\). Problema: Possível “má aleatorização” (todo mundo no controle ou tratamento) ps.: toda aleatorização realizada é matematicamente equivalente. Possui \\(2^n\\) configurações possíveis de alocação entre tratamento e controle set.seed(10) n &lt;- 50 hist(replicate(1000, sum(rbinom(n, 1, 0.5))), main = &quot;aleatorização de Bernoulli&quot;, xlab = &quot;Número de tratados&quot;, col = &quot;lightblue&quot;) + xlim(0,50) 4.4.2 Aleatorização Completa Seleciono aleatoriamente um número fixo de pessoas para tratamento e controle Ex.: 25 para tratamento e 25 para controle Basta numerar cada unidade (de 1 a 50) e amostrar 25 aleatoriamente para tratamento (e restante para controle) Vantagem: garanto número de obs em cada condição Possui \\({N \\choose \\frac{n}{2}}\\) configurações possíveis de alocação entre tratamento e controle. Intuição: estamos jogando fora as aleatorizações “indesejáveis”. Cálculo da variância é mais complexo 4.4.3 Aleatorização Condicional (Block Random Assignment) Definição: Experimento é condicionalmente aleatório se a aleatorização depende de variáveis pré-tratamento \\(X\\). Exemplo Binário: Duas moedas, uma para \\(X=1\\) e outra para \\(X=0\\). Aleatorização Marginal vs. Condicional: Marginal: Aleatorização uniforme para todos os indivíduos. Condicional: Aleatorização depende de \\(X\\), gerando permutabilidade condicional a \\(X\\). Permutabilidade Condicional: \\((Y^1, Y^0 | X=x) \\perp T\\). Não gera permutabilidade (não-condicional). Permutabilidade condicional a \\(X\\) é crucial para inferência em contextos com variáveis pré-tratamento. 4.4.4 Pensando aleatorização em bloco Ex.: digamos que em uma amostra de 100 pessoas, queremos 25 homens e 25 mulheres no tratamento e controle Sorteio 25 homens para tratamento e depois 25 mulheres. Cada bloco possui tamanho 25, neste exemplo. Blocos de tamanho \\(2\\) são chamados de pair-matched design. Em geral, estudos com matching em muitas variáveis Útil para amostras pequenas 4.4.5 ATE com Aleatorização Condicional (Bloco) Estratificação Efeito heterogêneo por estrato? Podemos calcular o ATE por estrato, já que é aleatório no interior de cada estrato. Efeito geral na população. Podemos calcular ponderando os ATEs. Seja \\(J\\) o número de estratos, indexados por \\(j\\). Seja \\(N\\) o número de unidades e \\(N_j\\) o número de unidades no bloco \\(j\\). Então: \\(ATE = \\sum_{j=1}^J \\frac{N_j}{N}ATE_j\\) 4.4.6 Aleatorização em bloco Pela Lei dos Grandes números, tende a gerar balanceamento entre blocos Balanceamento quer dizer que blocos são similares Em variáveis observadas e não-observadas Probabilidade de tratamento pode variar por bloco. Chamada de propensity score. 4.4.7 Precisão da aleatorização em bloco Em geral a precisão aumenta (erro padrão diminui) com aleatorização em bloco. Intuição é que removemos parte da variância (amostras possíveis), condicionando nos estratos Vamos checar uma simulação no R para ver um exemplo do ganho na precisão Lembrem-se que se \\(X\\) e \\(Y\\) são independentes, então \\(Var(aX + bY) = a^2Var(X) + b^2Var(Y)\\). # Set up Potential outcomes and units and blocks n1 &lt;- 10 n2 &lt;- 16 N &lt;- n1+n2 J &lt;- 2 index_block &lt;- c(rep(2, n2), rep(1, n1)) set.seed(12) # potential outcome control y0 &lt;- c(rnorm(n1, 2, 1),rnorm(n2, 6, 1)) y1 &lt;- y0 + 1.5 # potential outcome treatment # block assignment t_bloco1 &lt;- sample(1:n1, n1/2) c_bloco1 &lt;- (1:n1)[!(1:n1 %in% t_bloco1)] t_bloco2 &lt;- sample((n1+1):(n1+n2), n2/2) c_bloco2 &lt;- ((n1+1):(n1+n2))[!((n1+1):(n1+n2) %in% t_bloco2)] y1_obs_bloco1 &lt;- y1[t_bloco1] y1_obs_bloco2 &lt;- y1[t_bloco2] y0_obs_bloco1 &lt;- y0[c_bloco1] y0_obs_bloco2 &lt;- y0[c_bloco2] # random assignment units_simple_treatment &lt;- c(t_bloco1, t_bloco2) units_simple_control &lt;- c(c_bloco1, c_bloco2) y1_obs &lt;- y1[units_simple_treatment] y0_obs &lt;- y0[units_simple_control] # erro padrão erro_pad_simple &lt;- t.test(y1_obs, y0_obs)$stderr simple_p_value &lt;- t.test(y1_obs, y0_obs)$p.value my_t &lt;- mean(y1_obs - y0_obs)/erro_pad_simple erro_pad1 &lt;- t.test(y1_obs_bloco1, y0_obs_bloco1)$stderr erro_pad2 &lt;- t.test(y1_obs_bloco2, y0_obs_bloco2)$stderr erro_padrao_geral &lt;- sqrt(erro_pad1^2*(n1/N)^2 + erro_pad2^2*(n2/N)^2) ate1 &lt;- mean(y1_obs_bloco1 - y0_obs_bloco1)*(n1/N) ate2 &lt;- mean(y1_obs_bloco2 - y0_obs_bloco2)*(n2/N) ate &lt;- ate1 + ate2 my_t &lt;- ate/erro_padrao_geral p_value &lt;- 2*(1 - pt(abs(my_t), df = 23.76567)) print(erro_pad1) ## [1] 0.646563 print(erro_pad2) ## [1] 0.4502482 print(erro_padrao_geral) ## [1] 0.3723061 print(p_value) ## [1] 0.0006818314 4.4.8 Comparação de SEs library(knitr) ## Warning: pacote &#39;knitr&#39; foi compilado no R versão 4.4.3 comparison_table &lt;- data.frame( Method = c(&quot;Simple Randomization&quot;, &quot;Block 1&quot;, &quot;Block 2&quot;, &quot;General Block Randomization&quot;), Standard_Error = c(erro_pad_simple, erro_pad1, erro_pad2, erro_padrao_geral) ) knitr::kable(comparison_table, caption = &quot;Comparação de Erros padrão&quot;, align = &#39;c&#39;, format = &quot;latex&quot;) 4.4.9 Cluster randomization Quando aleatorizo o cluster, em vez das unidades. Ex.: Se não for possível aleatorizar um tratamento entre estudantes, aleatorizo escolas No interior de cada escola, todo mundo é tratado ou não-tratado. Não há variação within escolas, apenas entre (between) escolas. Grande perda de variabilidade nos dados, reduzindo precisão (aumento no erro padrão) Às vezes é a única aleatorização possível. 4.4.10 Tabelas em artigos 4.5 Estimador ATE estimativa: \\(\\frac{\\sum_{i=1}^{n}Y_iT_i}{n_1} - \\frac{\\sum_{i=1}^{n}Y_i(1-T_i)}{n_0} = .0608 - .0353 = 0.0255\\) Erro padrão: \\(\\sqrt{\\frac{\\hat{\\sigma_1^2}}{n_1} + \\frac{\\hat{\\sigma_0^2}}{n_0}} = \\sqrt{\\frac{.0608\\cdot(1-.0608)}{1217} + \\frac{.0353\\cdot (1-.0353)}{1217}} = 0.00865\\) Pequena diferença com os coeficientes da tabela Typo? Alguma informação não reproduz exatamente? Fizemos algo errado? treatment &lt;- c(rep(1, 74), rep(0, 1217 - 74)) control &lt;- c(rep(1, 43), rep(0, 1217 - 43)) var_treat &lt;- var(treatment) var_control &lt;- var(control) erro_padrao &lt;- sqrt(var_treat/1217 + var_control/1217) round(erro_padrao, 5) ## [1] 0.00866 t.test(treatment, control) ## ## Welch Two Sample t-test ## ## data: treatment and control ## t = 2.9414, df = 2286.3, p-value = 0.0033 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.008490408 0.042454539 ## sample estimates: ## mean of x mean of y ## 0.06080526 0.03533279 4.6 Resumo do Capítulo Neste capítulo, vimos como experimentos aleatórios eliminam o viés de seleção sob a suposição de SUTVA. Os principais pontos são: A aleatorização garante que tratamento e controle sejam comparáveis em expectativa, eliminando o viés de seleção. A validade do experimento depende também da restrição de exclusão (o que importa é o tratamento efetivamente recebido) e da simetria na administração. Existem vários tipos de aleatorização — Bernoulli, completa, em bloco e por cluster — cada qual com vantagens e limitações. A aleatorização em bloco tende a aumentar a precisão das estimativas. Com amostras grandes, as diferenças entre os tipos de aleatorização diminuem. Ao longo do capítulo, sempre supusemos condições ideais (sem attrition, compliance perfeito etc.). No próximo capítulo, veremos o que acontece quando não temos aleatorização e precisamos recorrer a estratégias observacionais como matching. 4.7 Declare Design Uma ferramenta muito útil para experimentos (mas também para estudos observacionais) é o pacote do R Declare Design. Blair, Coppock e Humphreys criaram um framework para definir e avaliar um desenho de pesquisa. Com o resultado, escreveram um livro “Research Design in the Social Sciences”, e um pacote no R para implementar os conceitos desenvolvidos no livro, chamado “DeclareDesign”. Para instalar (junto com os datasets usados no livro), basta rodar . O framework é baseado no acrônimo MIDA, que contempla os quatro elementos básicos de um desenho de pesquisa: models, inquiries, data strategies, and answer strategies. Ou seja, você deve especificar um modelo, qual pergunta de pesquisa (aka estimando), quais dados vai utilizar e como vai estimar o estimando. Um modelo descreve o que causa o que e como. Tipicamente especifica as unidades, o tamanho da amostra e a equação de resultados potenciais. Suponha que quero rodar um experimento aleatório com um tratamento e controle (two-arm randomized experiment). Assim, podemos declarar um modelo com: library(DeclareDesign) model &lt;- declare_model( N = 500, X = rep(c(0, 1), each = N / 2), # tratamento e controle U = rnorm(N, sd = 0.25), # heterogeneidade exógena potential_outcomes(Y ~ 0.2 * Z + X + U) ) Vamos entender o que fizemos. Declaramos que nossa população terá \\(500\\) observações: . Nesse exemplo, a amostra será igual à população, mas poderíamos amostrar da população se quiséssemos. Declaramos que \\(X\\), uma covariável, pode assumir dois valores (0,1), e atribuímos a primeira metade para \\(0\\) e a outra metade para \\(1\\): . Declaramos que existe uma variável \\(U\\) que tem distribuição normal, com \\(N\\) observações e média \\(0\\) e desvio-padrão \\(.25\\):. Declaramos que os resultados potenciais diferem em \\(20\\%\\) entre tratamento e controle (\\(Z\\)) para cada unidade. Uma forma alternativa e talvez mais clara de declarar a relação entre tratamento/controle e resultados potenciais seria escrever . 4.1. Além disso, \\(X\\) tem efeito de \\(1\\) para todas as unidades. Vamos passar agora ao nosso estimando ou inquiry. inquiry &lt;- declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) Se estamos interessados no ATE, é só declarar que é a média da diferença entre os resultados potenciais. Podemos também usar a função Outras possibilidades incluem o ATT e CATE: , por exemplo. Formulação equivalente para o ATT seria . Estratégia de dados data &lt;- declare_assignment(Z = complete_ra(N = N, m = 250)) + # assigment mechanism declare_measurement(Y = reveal_outcomes(Y ~ Z)) # reveal_outcomes é a switching equation estimator &lt;- declare_estimator(Y ~ Z, inquiry = &quot;ATE&quot;) two_arm_trial &lt;- model + inquiry + data + estimator # Draw a simulated dataset head(draw_data(two_arm_trial), 10) ## ID X U Y_Z_0 Y_Z_1 Z Y ## 1 001 0 0.013136040 0.013136040 0.21313604 1 0.213136040 ## 2 002 0 0.306059991 0.306059991 0.50605999 0 0.306059991 ## 3 003 0 0.248393137 0.248393137 0.44839314 1 0.448393137 ## 4 004 0 0.037319115 0.037319115 0.23731912 0 0.037319115 ## 5 005 0 0.352668514 0.352668514 0.55266851 0 0.352668514 ## 6 006 0 0.364146534 0.364146534 0.56414653 1 0.564146534 ## 7 007 0 0.366437409 0.366437409 0.56643741 1 0.566437409 ## 8 008 0 -0.280273943 -0.280273943 -0.08027394 1 -0.080273943 ## 9 009 0 -0.007617163 -0.007617163 0.19238284 0 -0.007617163 ## 10 010 0 0.195182802 0.195182802 0.39518280 1 0.395182802 Após declarar um desenho de pesquisa, podemos diagnosticar se nosso desenho de pesquisa pode ser respondido adequadamente (isto é, se é identificável, se possui poder para estimar com precisão o efeito de interesse etc.). Podemos inclusive modificar o desenho para responder a outras perguntas (é generalizável para outras populações, diferentes estimadores desempenham melhor etc.) Eis um exemplo de diagnóstico: diagnose_design(two_arm_trial, sims = 100) ## ## Research design diagnosis based on 100 simulations. Diagnosis completed in 1 secs. Diagnosand estimates with bootstrapped standard errors in parentheses (100 replicates). ## ## Design Inquiry Estimator Outcome Term N Sims Mean Estimand ## two_arm_trial ATE estimator Y Z 100 0.20 ## (0.00) ## Mean Estimate Bias SD Estimate RMSE Power Coverage ## 0.20 0.00 0.05 0.05 0.99 0.95 ## (0.00) (0.00) (0.00) (0.00) (0.01) (0.02) Podemos ajustar o desenho de pesquisa designs &lt;- redesign(two_arm_trial, N = c(100, 200, 300, 400, 500)) diagnose_design(designs) ## ## Research design diagnosis based on 500 simulations. Diagnosis completed in 8 secs. Diagnosand estimates with bootstrapped standard errors in parentheses (100 replicates). ## ## Design N Inquiry Estimator Outcome Term N Sims Mean Estimand Mean Estimate ## design_1 100 ATE estimator Y Z 500 0.20 0.20 ## (0.00) (0.00) ## design_2 200 ATE estimator Y Z 500 0.20 0.20 ## (0.00) (0.00) ## design_3 300 ATE estimator Y Z 500 0.20 0.20 ## (0.00) (0.00) ## design_4 400 ATE estimator Y Z 500 0.20 0.20 ## (0.00) (0.00) ## design_5 500 ATE estimator Y Z 500 0.20 0.20 ## (0.00) (0.00) ## Bias SD Estimate RMSE Power Coverage ## -0.00 0.05 0.05 0.97 0.94 ## (0.00) (0.00) (0.00) (0.01) (0.01) ## 0.00 0.05 0.05 0.98 0.95 ## (0.00) (0.00) (0.00) (0.01) (0.01) ## -0.00 0.05 0.05 0.97 0.95 ## (0.00) (0.00) (0.00) (0.01) (0.01) ## -0.00 0.05 0.05 0.98 0.95 ## (0.00) (0.00) (0.00) (0.01) (0.01) ## -0.00 0.05 0.05 0.98 0.96 ## (0.00) (0.00) (0.00) (0.01) (0.01) 4.8 Exercício O exercício abaixo é uma tradução de questões que estavam presentes no exame de qualificação (prelims) da área de métodos do programa de doutorado em ciência política de Yale. 4.8.1 Experimento com envio de cartões-postais e participação eleitoral Você conduz um experimento aleatório para testar o efeito de um cartão-postal sobre a participação eleitoral, sorteando independentemente uma moeda para cada sujeito com probabilidade \\(0 &lt; p &lt; 1\\) de receber o tratamento. Assuma o pressuposto de SUTVA (Stable Unit Treatment Value Assumption). Você estima o seguinte modelo por Mínimos Quadrados Ordinários (OLS): \\[ Y_i = \\beta_0 + \\beta_1 T_i + \\beta_2 S_i + \\beta_3 T_i S_i + u_i \\] em que: - \\(Y_i\\) indica se o indivíduo votou (variável dependente); - \\(T_i\\) é o indicador binário de tratamento (receber ou não o cartão-postal); - \\(S_i\\) é um indicador binário que vale 1 se o indivíduo vive em um estado eleitoralmente competitivo (battleground state) e 0 caso contrário; - \\(T_i S_i\\) é a interação entre o tratamento e o contexto competitivo. 4.8.1.1 (a) Interprete os quatro coeficientes \\(\\beta\\) \\(\\beta_0\\): média de \\(Y_i\\) (taxa de votação) para o grupo controle (\\(T_i = 0\\)) em estados não competitivos (\\(S_i = 0\\)). \\(\\beta_1\\): efeito médio do tratamento (cartão-postal) em estados não competitivos. Como o tratamento foi atribuído aleatoriamente, \\(\\beta_1\\) tem interpretação causal. \\(\\beta_2\\): diferença na taxa média de votação entre estados competitivos e não competitivos no grupo controle. Não tem interpretação causal. \\(\\beta_3\\): diferença no efeito do tratamento entre estados competitivos e não competitivos. Se \\(\\beta_3 \\neq 0\\), o efeito do cartão-postal depende do tipo de estado. Como o tratamento é aleatório, \\(\\beta_3\\) também tem interpretação causal. 4.8.1.2 (b) Como testar a hipótese de que o efeito do tratamento é igual entre os dois tipos de estado? Testa-se a hipótese nula \\(H_0: \\beta_3 = 0\\). Isso pode ser feito diretamente a partir do resultado da regressão usando um teste t para o coeficiente da interação \\(T_i S_i\\). 4.8.2 Experimento com anúncios de TV e participação eleitoral Você quer testar se anúncios de TV aumentam a participação eleitoral. O experimento pode ser conduzido em até 16 mercados de mídia, dos quais até 8 podem ser sorteados para o grupo de tratamento. Os anúncios só podem ser exibidos para o mercado de mídia como um todo. Você tem informações individuais para todos os eleitores elegíveis nesses mercados: mercado de mídia, idade, sexo, raça/etnia e participação nas duas eleições anteriores. Após a eleição, você receberá os dados atualizados sobre participação no pleito atual. 4.8.2.1 (a) Como alocar aleatoriamente os mercados ao tratamento? Sorteie aleatoriamente 8 dos 16 mercados de mídia para o grupo de tratamento. Como o tratamento é atribuído no nível do mercado, essa é a unidade de aleatorização. Recomenda-se balancear o sorteio usando pareamento ou estratificação com base em características agregadas dos mercados (por exemplo, participação passada, composição demográfica), se houver variação relevante entre eles. 4.8.2.2 (b) Como analisar esse experimento? A análise deve ser feita no nível do mercado de mídia, que é a unidade de tratamento. Uma abordagem válida é calcular a média da taxa de votação em cada mercado e rodar uma regressão simples: \\[ \\bar{Y}_j = \\alpha + \\tau D_j + \\varepsilon_j \\] em que: - \\(\\bar{Y}_j\\) é a média da taxa de votação no mercado \\(j\\); - \\(D_j\\) é um indicador de tratamento para o mercado; - \\(\\tau\\) estima o efeito médio do tratamento. É possível incluir covariáveis no nível do mercado para aumentar a precisão, mas não é necessário para validade causal. 4.8.3 Exclusão de participantes em experimentos de survey Pesquisadores às vezes excluem participantes de um experimento de survey por: 1. Não passarem em uma checagem de atenção pré-tratamento; 2. Não passarem em uma checagem de atenção pós-tratamento; 3. Completarem o survey muito rapidamente (por exemplo, 3 desvios-padrão abaixo da média de tempo). 4.8.3.1 (a) Se o interesse é no efeito médio do tratamento entre os sujeitos que não foram excluídos, qual dessas estratégias é não-viesada? Todas essas estratégias podem fornecer estimativas não viesadas para o efeito médio do tratamento entre os sujeitos que permanecem na amostra, desde que os critérios de exclusão sejam pré-tratamento ou não afetem diferencialmente os grupos de tratamento e controle. A exclusão baseada em variáveis observadas antes do tratamento (como checagem pré-tratamento ou tempo de resposta) é menos problemática. Já a exclusão com base em comportamentos após o tratamento (como falha em atenção pós-tratamento) pode introduzir viés, pois pode estar correlacionada com a resposta ao tratamento. 4.8.3.2 (b) Se o interesse é no efeito médio do tratamento entre todos os participantes que iniciaram o experimento, qual dessas estratégias é não-viesada? Nenhuma das exclusões garante uma estimativa não viesada nesse caso. Excluir participantes com base em qualquer critério — mesmo que relacionado à atenção ou tempo de resposta — altera a composição da amostra em relação ao universo original. Para estimar o efeito médio para todos os participantes que começaram o experimento, é necessário manter todos os sujeitos, independentemente do desempenho em checagens ou tempo de resposta. "],["propensity-score-e-matching.html", "Capítulo 5 Propensity Score e Matching 5.1 Introdução 5.2 Propensity Score 5.3 Matching 5.4 Suposições de identificação 5.5 Matching 5.6 Matching exato 5.7 Matching aproximado 5.8 Estimando 5.9 Declare Design e Matching 5.10 Recomendações Práticas sobre Matching 5.11 Referências", " Capítulo 5 Propensity Score e Matching 5.1 Introdução Na aula de hoje, iremos aprender sobre a principal estratégia de “seleção em observáveis”, que é matching. Mas antes, vamos falar de subclassificação, que é uma técnica mais simples e é útil para introduzir a ideia de matching. 5.2 Propensity Score O propensity score nada mais é que a probabilidade de uma unidade ser tratada, dadas as covariáveis, ou seja, \\(Pr(D_i = 1| X_i)\\). A ideia chave para propensity-score vem de um paper de Rosenbaum-Rubin (1983) em que eles mostram que, se a condição 1 de ignorabilidade forte (isto é, \\(Y_i(1), Y_i(0) \\perp D_i|X_i\\)) for satisfeita, então também é verdade que a condição \\(Y_i(1), Y_i(0) \\perp D_i|\\pi(X_i)\\) também é satisfeita. E por que isso é importante? Nós nunca sabemos o verdadeiro modelo que relaciona as covariáveis \\(X_i\\) com \\(D_i\\) e \\(Y_i\\), de modo que podemos ter algum problema de modelo mal especificado (por exemplo, supomos um modelo linear, quando na verdade é não-linear). Então, em vez de estimar dezenas de modelos, posso condicionar (“controlar”) apenas pelo propensity score \\(\\pi(X_i)\\). A intuição é que o propensity score cria balanceamento entre tratados e não-tratados. Para ilustrar o poder desse resultado, vamos considerar um exemplo simulado, em que ignorability forte é satisfeita, mas um modelo mal-especificado gera amostras não-balanceadas e, portanto, estimativas viesadas. library(knitr) library(tidyverse) library(ggdag) library(arm) # true DGP dag &lt;- dagify( y ~ D + w1, D ~ w1 ) ggdag(dag) O DAG acima ilustra bem qual a relação causal entre variáveis. Para estimar o ATE de \\(D\\) sobre \\(Y\\), precisamos fechar o backdoor de \\(w_1\\). A forma usual como fazemos isso é com regressão. O problema que estamos abordando aqui é quando a amostra é não-balanceada entre tratados e não-tratados. Vamos visualizar dois tipos de relações (uma linear e outra não-linear) entre a variável de controle \\(w_1\\) e a resposta \\(Y\\) para ilustrar o problema do desbalanceamento: library(ggplot2) set.seed(202) n &lt;- 1e4 w1 &lt;- rnorm(n) # único confundidor tau &lt;- 3 # efeito causal verdadeiro # GERAMOS UM PROPENSITY SCORE NÃO‐LINEAR p &lt;- plogis(-0.5 + 2 * w1) D &lt;- rbinom(n, 1, p) # GERAÇÃO DOS RESULTADOS POTENCIAIS linear (apenas função de w1, forte ignorabilidade): y0 &lt;- 5 * w1 + rnorm(n) y1 &lt;- y0 - tau # efeito constante y &lt;- ifelse(D == 1, y1, y0) df &lt;- data.frame(y=y, D=D, w1=w1) df %&gt;% mutate( D = factor(D, levels = c(0,1), labels = c(&quot;Controle (D = 0)&quot;, &quot;Tratado (D = 1)&quot;)) ) %&gt;% ggplot(aes(x = w1, y = y, colour = D)) + geom_point(alpha = 0.6) + scale_colour_manual( name = &quot;Tratamento (binário)&quot;, values = c(&quot;Controle (D = 0)&quot; = &quot;steelblue&quot;, &quot;Tratado (D = 1)&quot; = &quot;firebrick&quot;) ) + theme_bw() No primeiro gráfico, o efeito causal (ATE) do tratamento é \\(-3\\) e podemos ver nos dados que de fato em média a resposta é menor entre tratados que no controle. Além disso, vemos também que o efeito é basicamente linear. Mas o ponto importante aqui é que existem duas regiões dos dados em que praticamente só temos unidades no controle (\\(w_1 &lt; -2\\)) e ou no tratamento (\\(w_1 &gt; -2\\)). Isso significa que para que a regressão possa estimar o efeito causal deve extrapolar a estimativa da região em que ambos tratamento e controle estão presentes nos dados para uma região em que não estão presentes. Como o efeito é constante para todas as regiões de \\(w_1\\), isso não causa problema e a regressão consegue recuperar o ATE sem viés. O gráfico abaixo ilustra o que a regressão está fazendo: df %&gt;% mutate( D = factor(D, levels = c(0,1), labels = c(&quot;Controle (D = 0)&quot;, &quot;Tratado (D = 1)&quot;)) ) %&gt;% ggplot(aes(x = w1, y = y, colour = D)) + geom_point(alpha = 0.6) + geom_smooth(method = &quot;lm&quot;) + scale_colour_manual( name = &quot;Tratamento (binário)&quot;, values = c(&quot;Controle (D = 0)&quot; = &quot;steelblue&quot;, &quot;Tratado (D = 1)&quot; = &quot;firebrick&quot;) ) + theme_bw() O gráfico mostra duas retas de regressão ajustadas, uma para o controle (em azul) e outra para o tratamento (em vermelho). Efetivamente, temos de estender as duas retas para as regiões em que não há dados, por meio de extrapolação, que no caso significa continuar a linha reta. Assim, temos uma estimativa dos resultados potenciais nessas regiões e podemos computar o efeito causal médio. Como a extrapolação é razoável, não há problema. Vejamos agora uma situação em que o efeito de \\(w_1\\) é não linear sobre \\(Y\\). set.seed(202) n &lt;- 1e4 w1 &lt;- rnorm(n) # único confundidor tau &lt;- 3 # efeito causal verdadeiro # GERAMOS UM PROPENSITY SCORE NÃO‐LINEAR p &lt;- plogis(-0.5 + 2 * w1) D &lt;- rbinom(n, 1, p) # GERAÇÃO DOS RESULTADOS POTENCIAIS não-linear (apenas função de w1, forte ignorabilidade): y0 &lt;- 5 * w1^2 + rnorm(n) y1 &lt;- y0 - tau # efeito constante y &lt;- ifelse(D == 1, y1, y0) df &lt;- data.frame(y=y, D=D, w1=w1) df %&gt;% mutate( D = factor(D, levels = c(0,1), labels = c(&quot;Controle (D = 0)&quot;, &quot;Tratado (D = 1)&quot;)) ) %&gt;% ggplot(aes(x = w1, y = y, colour = D)) + geom_point(alpha = 0.6) + scale_colour_manual( name = &quot;Tratamento (binário)&quot;, values = c(&quot;Controle (D = 0)&quot; = &quot;steelblue&quot;, &quot;Tratado (D = 1)&quot; = &quot;firebrick&quot;) ) + theme_bw() Aqui, vemos que o efeito é não-linear de \\(w_1\\) sobre \\(Y\\) e também o desbalanceamento na amostra. Vamos ver o mesmo gráfico com as duas retas ajustadas para entender como a extrapolação pode ficar bem ruim nesse caso. df %&gt;% mutate( D = factor(D, levels = c(0,1), labels = c(&quot;Controle (D = 0)&quot;, &quot;Tratado (D = 1)&quot;)) ) %&gt;% ggplot(aes(x = w1, y = y, colour = D)) + geom_point(alpha = 0.6) + geom_smooth(method = &quot;lm&quot;) + scale_colour_manual( name = &quot;Tratamento (binário)&quot;, values = c(&quot;Controle (D = 0)&quot; = &quot;steelblue&quot;, &quot;Tratado (D = 1)&quot; = &quot;firebrick&quot;) ) + theme_bw() Um problema óbvio do modelo é que o efeito de w1 é quadrático, então podemos tentar corrigir isso incluindo um termo quadrático. reg_sq &lt;- lm(y ~ D + w1 + I(w1^2), data = df) summary(reg_sq) ## ## Call: ## lm(formula = y ~ D + w1 + I(w1^2), data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.5311 -0.6586 -0.0043 0.6679 3.8928 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.012244 0.015950 -0.768 0.443 ## D -2.996063 0.025632 -116.890 &lt;2e-16 *** ## w1 -0.013777 0.012639 -1.090 0.276 ## I(w1^2) 5.005598 0.007154 699.737 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9976 on 9996 degrees of freedom ## Multiple R-squared: 0.9806, Adjusted R-squared: 0.9806 ## F-statistic: 1.688e+05 on 3 and 9996 DF, p-value: &lt; 2.2e-16 O efeito causal é negativo, o que é bom, pois está na direção certa, mas ainda está distante do efeito verdadeiro. Isso ilustra também como a estimativa é dependente do modelo, o que é bem ruim, pois não sabemos qual o modelo certo. Em resumo, quando há desbalanceamento, causamos dependência do modelo, o que é problemático. Agora, vamos comparar com o propensity score: library(knitr) library(tidyverse) library(ggdag) # true DGP reg_aux&lt;- glm(D ~ w1, family = binomial, data=df) p_score &lt;- reg_aux$fitted.values reg1 &lt;- lm(y ~ D + p_score) summary(reg1) ## ## Call: ## lm(formula = y ~ D + p_score) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.921 -4.258 -2.462 1.647 70.708 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.2799 0.1179 36.307 &lt; 2e-16 *** ## D -2.9562 0.1858 -15.910 &lt; 2e-16 *** ## p_score 1.6681 0.2917 5.718 1.11e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 7.069 on 9997 degrees of freedom ## Multiple R-squared: 0.02781, Adjusted R-squared: 0.02761 ## F-statistic: 143 on 2 and 9997 DF, p-value: &lt; 2.2e-16 w &lt;- ifelse(D == 1, 1/p_score, 1/(1-p_score)) # pesos IPTW reg2 &lt;- lm(y ~ D , weights = w) summary(reg2) ## ## Call: ## lm(formula = y ~ D, weights = w) ## ## Weighted Residuals: ## Min 1Q Median 3Q Max ## -15.95 -5.52 -2.87 2.04 324.89 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.67183 0.09553 48.90 &lt;2e-16 *** ## D -2.57016 0.13452 -19.11 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.499 on 9998 degrees of freedom ## Multiple R-squared: 0.03523, Adjusted R-squared: 0.03513 ## F-statistic: 365.1 on 1 and 9998 DF, p-value: &lt; 2.2e-16 Conseguimos recuperar o ATE sem problemas. E não precisei especificar corretamente a forma funcional da variável de controle \\(w_1\\) no modelo principal, pois usei o propensity score. Note que precisei modelar corretamente a regressão que calcula o propensity score. É útil ver como o pscore está distribuído entre os grupos de tratamento e controle: library(knitr) library(tidyverse) library(ggdag) # true DGP df &lt;- df %&gt;% mutate(pscore = p_score) df %&gt;% ggplot(aes(pscore, group=D)) + geom_boxplot() df %&gt;% mutate(D = as.factor(D)) %&gt;% ggplot()+ geom_density(aes(x=pscore, group=D, colour = D)) Há desbalanceamento e falta de overlap ou suporte comum, o que leva à extrapolação. 5.3 Matching A ideia do matching pode ser ilustrada se notarmos o seguinte. A projeção da reta vermelha para pontos abaixo de \\(-2\\) é de um \\(y\\) médio muito baixo, enquanto que o \\(y\\) médio é muito alto para o controle. O oposto é verificado para a região em que \\(w_1 &gt; 2\\). Portanto, se eu restringir (excluir os casos) a análise para uma região onde a necessidade de extrapolação é menor, o resultado tende a se aproximar do ATE. library(knitr) library(tidyr) library(broom) library(kableExtra) reg_sub &lt;- lm(y ~ D + w1, data = df) reg_sub %&gt;% tidy() %&gt;% kable(digits = c(0, 2, 3, 2, 3)) term estimate std.error statistic p.value (Intercept) 4.27 0.104 41.00 0 D -1.30 0.180 -7.18 0 w1 -0.80 0.089 -8.94 0 reg_sub &lt;- lm(y ~ D + w1, data = subset(df, w1 &gt; -2 &amp; w1 &lt; 2)) reg_sub %&gt;% tidy() %&gt;% kable(digits = c(0, 2, 3, 2, 3)) term estimate std.error statistic p.value (Intercept) 3.46 0.069 50.52 0 D -1.99 0.119 -16.70 0 w1 -0.35 0.066 -5.32 0 reg_sub &lt;- lm(y ~ D + w1, data = subset(df, w1 &gt; -1.5 &amp; w1 &lt; 1.5)) reg_sub %&gt;% tidy() %&gt;% kable(digits = c(0, 2, 3, 2, 3)) term estimate std.error statistic p.value (Intercept) 2.57 0.047 55.02 0 D -2.48 0.080 -30.78 0 w1 -0.21 0.053 -3.88 0 reg_sub &lt;- lm(y ~ D + w1, data = subset(df, w1 &gt; -1 &amp; w1 &lt; 1)) reg_sub %&gt;% tidy() %&gt;% kable(digits = c(0, 2, 3, 2, 3)) term estimate std.error statistic p.value (Intercept) 1.41 0.029 49.57 0 D -2.77 0.048 -57.27 0 w1 -0.17 0.043 -3.93 0 reg_sub &lt;- lm(y ~ D + w1, data = subset(df, w1 &gt; -1 &amp; w1 &lt; 1)) reg_sub %&gt;% tidy() %&gt;% kable(digits = c(0, 2, 3, 2, 3)) term estimate std.error statistic p.value (Intercept) 1.41 0.029 49.57 0 D -2.77 0.048 -57.27 0 w1 -0.17 0.043 -3.93 0 A ideia do matching é um pouco diferente do que fizemos acima, pois estamos excluindo as observações que estão no tratamento e que não possuem controle correspondente, e do controle que não possuem tratamento correspondente. Não há erro em excluir os dois tipos de observações, mas sempre temos de nos perguntar qual é o estimando de interesse. Se faço esse procedimento, o meu estimando não é nenhum dos usuais ATT ou ATE. No matching, nós nos concentramos em estimar o ATT, de forma que procuramos achar observações no controle que são próximas das tratadas, ou seja, excluímos os controles que não são um match para as observações tratadas. 5.4 Suposições de identificação Antes de aplicar qualquer método de matching, é fundamental explicitar as suposições que garantem a identificação causal nesse contexto. Supondo para simplificar um tratamento binário \\(T\\), e uma covariável categórica \\(X\\), temos: \\((Y^1, Y^0) \\perp T|X \\text{ (Independência Condicional)}\\) \\(0 &lt; P(T=1|X) &lt; 1 \\text{ (Suporte comum)}\\) Temos então a seguinte derivação (usando o fato de que os resultados potenciais são independentes do treatment assignment, condicional à covariável) e a switching equation no último passo: \\[\\begin{align} \\mathbb{E}[Y^1-Y^0|X] &amp; = \\mathbb{E}[Y^1 - Y^0 | X, T=1] \\\\ &amp; = \\mathbb{E}[Y^1| X, T=1] - \\mathbb{E}[Y^0| X,T=0] \\\\ &amp; = \\mathbb{E}[Y| X, D=1] - \\mathbb{E}[Y| X, D=0] \\end{align}\\] E o estimador que usamos pode ser representado (supondo suporte comum) como: \\(\\widehat{\\delta_{ATE}} = \\sum_{x\\in X}{(\\mathbb{E}[Y| X=x, D=1] - \\mathbb{E}[Y| X=x, D=0])P(X=x)}\\) E o que estamos fazendo é computar a média do efeito do tratamento condicional ponderado pela distribuição de \\(X\\). Para identificar o ATE, nós precisamos supor independência condicional a ambos os resultados potenciais. Se porém isso for crível apenas para \\(Y^0\\), podemos estimar o ATT. Basta lembrarmos que \\(\\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0] = \\mathbb{E}[Y_i^1 - Y_i^0|T_i=1] + \\mathbb{E}[Y_i^0|T_i=1] - \\mathbb{E}[Y_i^0|T_i=0]\\) 5.5 Matching A técnica de matching trata os resultados potenciais como missing data. Assim, se pudermos supor CIA com credibilidade, pelo menos com relação a \\(Y^0\\), então podemos imputar esses resultados potenciais e estimar o ATT. A ideia é achar uma unidade a mais similar possível a unidade tratada para servir como contrafactual. Assim, poderíamos computar “diretamente” o ATT, já que teríamos os \\(Y^1\\) e \\(Y^0\\) para cada unidade, este último imputado. Há dois grandes grupos de métodos de matching: exato e aproximado. 5.6 Matching exato Uma vez que temos as suposições de identificação, podemos discutir os métodos para realizar o matching. O mais simples deles é o matching exato. Nesse método, nós achamos uma unidade (ou mais) que tenham um valor exatamente igual nas covariáveis (ou no propensity score), e imputamos o controle. 5.7 Matching aproximado Para aproximar o matching, utilizamos alguma noção de distância entre variáveis. Para mais de uma variável, podemos utilizar algumas métricas de distância. A primeira é a distância euclidiana (supondo \\(K\\) variáveis). \\[ \\lVert X_i - X_j \\rVert = \\sqrt{(X_i - X_j)&#39;(X_i - X_j)} \\] \\[ \\lVert X_i - X_j \\rVert = \\sqrt{\\sum_{n=1}^k(X_{ni} - X_{nj})^2} \\] A distância euclidiana utiliza a escala das próprias variáveis, então é comum usar a distância euclidiana normalizada: \\[ \\lVert X_i - X_j \\rVert = \\sqrt{\\sum_{n=1}^k\\frac{(X_{ni} - X_{nj})^2}{\\hat{\\sigma}_n^2}} \\] Outra métrica é a distância de Mahalanobis, que basicamente divide pela covariância (amostral) entre as variáveis em vez da variância. Mas na prática a gente usa a euclidiana. 5.8 Estimando Uma vez que fizemos o matching entre unidades, qual nosso estimador? Lembrando que o estimando é o ATT. \\[ \\widehat{\\delta}_{ATT} = \\dfrac{1}{N_T} \\sum_{D_i=1} (Y_i - Y_{j(i)}) \\] library(MatchIt) result_0 &lt;- matchit(D ~ w1, data = df, method = NULL, distance = &#39;glm&#39;) summary(result_0) ## ## Call: ## matchit(formula = D ~ w1, data = df, method = NULL, distance = &quot;glm&quot;) ## ## Summary of Balance for All Data: ## Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean ## distance 0.6549 0.2493 1.5714 1.2566 0.3685 ## w1 0.7004 -0.5362 1.6030 0.9132 0.3685 ## eCDF Max ## distance 0.5761 ## w1 0.5761 ## ## Sample Sizes: ## Control Treated ## All 5806 4194 ## Matched 5806 4194 ## Unmatched 0 0 ## Discarded 0 0 5.9 Declare Design e Matching Pode ser útil usar o declare design para investigar o uso de matching. Vamos fazer isso para o dataset lalonde. Esse é um banco de dados famoso na economia, pois o pesquisador Lalonde (1986) foi investigar se a aplicação de métodos (então) tradicionais de modelagem econométrica eram capazes de recuperar o efeito causal de um estudo experimental chamado National Supported Work Demonstration (NSW), um programa de emprego temporário para dar experiência de trabalho. Ele coletou dados de um survey “representativo” de trabalhadores americanos (PSID) e elencou esses trabalhadores como grupo controle e empregou métodos econométricos para tentar estimar o efeito causal. Os resultados foram desastrosos, no sentido de altamente variáveis dependendo do modelo e subconjunto de dados e longe da estimativa experimental (incluindo com sinal errado). Vamos replicar esse trabalho, usando matching e pscore. A variável resposta do banco de dados é re78 (real earnings in 1978). O tratamento é a variável treat. As demais variáveis são covariáveis. library(tidyverse) library(data.table) library(here, quietly=TRUE) library(fixest) here() ## [1] &quot;/Users/manoelgaldino/Documents/DCP/Cursos/Causalidade/Causalidade&quot; set.seed(1234) lalonde &lt;- fread(here(&quot;Dados&quot;, &quot;lalonde_nsw.csv&quot;)) dt &lt;- lalonde[, .(re78, treat)] %&gt;% rename(Y = re78, D = treat) dt %&gt;% group_by(D) %&gt;% sample_n(3) %&gt;% kableExtra::kable(digits = 0, col.names = c(&quot;Income&quot;, &quot;Treatment&quot;)) Income Treatment 0 0 290 0 7010 0 13830 1 0 1 60308 1 dt %&gt;% group_by(D) %&gt;% summarize(mean(Y)) %&gt;% kableExtra::kable(digits = 0, col.names = c(&quot;Treatment&quot;, &quot;Income&quot;)) Treatment Income 0 4555 1 6349 y1 = dt[dt$D == 1, Y] y0 &lt;- dt[dt$D == 0, Y] tau &lt;- mean(y1) - mean(y0) A diferença simples na média é 1794. 5.9.1 Matching e Propensity scores Usando age, education, hispanic, black, married, nodegree, RE74 e RE75, vamos modelar o propensity score usando o grupo dos tratados em lalonde_nsw.csv e a amostra de controle de lalonde_psid.csv. Report the average p-score for the treated and control samples, and plot the propensity score densities for the treatment and control groups. nsw_data &lt;- lalonde psid_data &lt;- fread(here(&quot;Dados&quot;, &quot;lalonde_psid.csv&quot;)) nsw_treat &lt;- nsw_data[nsw_data$treat == 1, ] psid_control &lt;- psid_data[psid_data$treat == 0, ] dw_data &lt;- rbind(nsw_treat, psid_control) library(MatchIt) m.out1 &lt;- matchit(treat ~ age + education + hispanic + black + married + nodegree + re74 + re75, data = dw_data, method = &quot;nearest&quot;, distance = &quot;glm&quot;) ## Warning: glm.fit: probabilidades ajustadas numericamente 0 ou 1 ocorreu summary(m.out1) ## ## Call: ## matchit(formula = treat ~ age + education + hispanic + black + ## married + nodegree + re74 + re75, data = dw_data, method = &quot;nearest&quot;, ## distance = &quot;glm&quot;) ## ## Summary of Balance for All Data: ## Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean ## distance 0.6364 0.0270 2.1674 8.0268 0.4816 ## age 25.8162 34.8506 -1.2627 0.4696 0.2317 ## education 10.3459 12.1169 -0.8808 0.4255 0.1091 ## hispanic 0.0595 0.0325 0.1139 . 0.0269 ## black 0.8432 0.2506 1.6301 . 0.5926 ## married 0.1892 0.8663 -1.7287 . 0.6771 ## nodegree 0.7081 0.3052 0.8862 . 0.4029 ## re74 2095.5737 19428.7458 -3.5471 0.1329 0.4684 ## re75 1532.0553 19063.3377 -5.4458 0.0561 0.4695 ## eCDF Max ## distance 0.8817 ## age 0.3771 ## education 0.4029 ## hispanic 0.0269 ## black 0.5926 ## married 0.6771 ## nodegree 0.4029 ## re74 0.7292 ## re75 0.7736 ## ## Summary of Balance for Matched Data: ## Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean ## distance 0.6364 0.2934 1.2200 1.4702 0.0432 ## age 25.8162 30.4811 -0.6520 0.4149 0.1196 ## education 10.3459 10.3784 -0.0161 0.4745 0.0407 ## hispanic 0.0595 0.0649 -0.0229 . 0.0054 ## black 0.8432 0.7568 0.2379 . 0.0865 ## married 0.1892 0.4595 -0.6901 . 0.2703 ## nodegree 0.7081 0.6216 0.1902 . 0.0865 ## re74 2095.5737 4499.8428 -0.4920 1.1020 0.0722 ## re75 1532.0553 3204.3968 -0.5195 0.7389 0.0605 ## eCDF Max Std. Pair Dist. ## distance 0.5568 1.2200 ## age 0.1784 1.3561 ## education 0.0919 1.3281 ## hispanic 0.0054 0.5257 ## black 0.0865 0.9515 ## married 0.2703 1.0213 ## nodegree 0.0865 0.9036 ## re74 0.4162 0.8667 ## re75 0.2973 0.9044 ## ## Sample Sizes: ## Control Treated ## All 2490 185 ## Matched 185 185 ## Unmatched 2305 0 ## Discarded 0 0 plot(summary(m.out1)) m.data &lt;- match_data(m.out1) head(m.data) ## treat age education black hispanic married nodegree re74 re75 re78 ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; ## 1: 1 37 11 1 0 1 1 0 0 9930.0459 ## 2: 1 22 9 0 1 0 1 0 0 3595.8940 ## 3: 1 30 12 1 0 0 0 0 0 24909.4492 ## 4: 1 27 11 1 0 0 1 0 0 7506.1460 ## 5: 1 33 8 1 0 0 1 0 0 289.7899 ## 6: 1 22 9 1 0 0 1 0 0 4056.4939 ## distance weights subclass ## &lt;num&gt; &lt;num&gt; &lt;fctr&gt; ## 1: 0.3773454 1 1 ## 2: 0.8849355 1 2 ## 3: 0.7201238 1 3 ## 4: 0.8717413 1 4 ## 5: 0.7896888 1 5 ## 6: 0.9030698 1 6 library(&quot;marginaleffects&quot;) fit &lt;- lm(re78 ~ treat * (age + education + black + married + nodegree + re74 + re75), data = m.data, weights = weights) avg_comparisons(fit, variables = &quot;treat&quot;, vcov = ~subclass, newdata = subset(treat == 1)) ## ## Estimate Std. Error z Pr(&gt;|z|) S 2.5 % 97.5 % ## 1881 879 2.14 0.0325 4.9 157 3605 ## ## Term: treat ## Type: response ## Comparison: 1 - 0 library(MatchIt) library(DeclareDesign) exact_matching &lt;- function(data) { matched &lt;- matchit(D ~ X, method = &quot;exact&quot;, data = data) match.data(matched) } declaration_16.2 &lt;- declare_model( N = 100, U = rnorm(N), X = rbinom(N, 1, prob = 0.5), D = rbinom(N, 1, prob = 0.25 + 0.5 * X), Y_D_0 = 0.2 * X + U, Y_D_1 = Y_D_0 + 0.5 ) + declare_inquiry(ATT = mean(Y_D_1[D == 1] - Y_D_0[D == 1])) + declare_step(handler = exact_matching) + declare_measurement(Y = reveal_outcomes(Y ~ D)) + declare_estimator(Y ~ D, weights = weights, .method = difference_in_means, inquiry = &quot;ATT&quot;, label = &quot;Matched difference-in-means&quot;) + declare_estimator(Y ~ D, .method = difference_in_means, inquiry = &quot;ATT&quot;, label = &quot;Raw difference-in-means&quot;) library(MatchIt) m.out0 &lt;- matchit(treat ~ age + education + hispanic + black + married + nodegree + re74 + re75, data = dw_data, method = NULL, distance = &quot;glm&quot;) ## Warning: glm.fit: probabilidades ajustadas numericamente 0 ou 1 ocorreu # Checking balance prior to matching summary(m.out0) ## ## Call: ## matchit(formula = treat ~ age + education + hispanic + black + ## married + nodegree + re74 + re75, data = dw_data, method = NULL, ## distance = &quot;glm&quot;) ## ## Summary of Balance for All Data: ## Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean ## distance 0.6364 0.0270 2.1674 8.0268 0.4816 ## age 25.8162 34.8506 -1.2627 0.4696 0.2317 ## education 10.3459 12.1169 -0.8808 0.4255 0.1091 ## hispanic 0.0595 0.0325 0.1139 . 0.0269 ## black 0.8432 0.2506 1.6301 . 0.5926 ## married 0.1892 0.8663 -1.7287 . 0.6771 ## nodegree 0.7081 0.3052 0.8862 . 0.4029 ## re74 2095.5737 19428.7458 -3.5471 0.1329 0.4684 ## re75 1532.0553 19063.3377 -5.4458 0.0561 0.4695 ## eCDF Max ## distance 0.8817 ## age 0.3771 ## education 0.4029 ## hispanic 0.0269 ## black 0.5926 ## married 0.6771 ## nodegree 0.4029 ## re74 0.7292 ## re75 0.7736 ## ## Sample Sizes: ## Control Treated ## All 2490 185 ## Matched 2490 185 ## Unmatched 0 0 ## Discarded 0 0 library(MatchIt) m.out1 &lt;- matchit(treat ~ age + education + hispanic + black + married + nodegree + re74 + re75, data = dw_data, method = &quot;nearest&quot;, distance = &quot;glm&quot;) ## Warning: glm.fit: probabilidades ajustadas numericamente 0 ou 1 ocorreu # Full matching on a probit PS m.out2 &lt;- matchit(treat ~ age + education + black + married + nodegree + re74 + re75, data = lalonde, method = &quot;full&quot;, distance = &quot;glm&quot;, link = &quot;probit&quot;) m.data &lt;- match_data(m.out2) library(&quot;marginaleffects&quot;) fit &lt;- lm(re78 ~ treat * (age + education + black + married + nodegree + re74 + re75), data = m.data, weights = weights) avg_comparisons(fit, variables = &quot;treat&quot;, vcov = ~subclass, newdata = subset(treat == 1)) ## ## Estimate Std. Error z Pr(&gt;|z|) S 2.5 % 97.5 % ## 2064 679 3.04 0.00238 8.7 733 3396 ## ## Term: treat ## Type: response ## Comparison: 1 - 0 full_matching &lt;- function(data) { matched &lt;- matchit(treat ~ age + education + hispanic + black + married + nodegree + re74 + re75, method = &quot;full&quot;, data = data) match.data(matched) } declaration_16.2 &lt;- declare_model( N = 1000, U = rnorm(N), X = rbinom(N, 1, prob = 0.5), D = rbinom(N, 1, prob = 0.25 + 0.5 * X), Y_D_0 = 0.2 * X + U, Y_D_1 = Y_D_0 + 0.5 ) + declare_inquiry(ATT = mean(Y_D_1[D == 1] - Y_D_0[D == 1])) + declare_step(handler = exact_matching) + declare_measurement(Y = reveal_outcomes(Y ~ D)) + declare_estimator(Y ~ D, weights = weights, .method = difference_in_means, inquiry = &quot;ATT&quot;, label = &quot;Matched difference-in-means&quot;) + declare_estimator(Y ~ D, .method = difference_in_means, inquiry = &quot;ATT&quot;, label = &quot;Raw difference-in-means&quot;) 5.10 Recomendações Práticas sobre Matching Rotina ou algoritmo: Defina o que é proximidade: alguma distância de medida para determinar se um caso é um bom match e quais variáveis utilizar. Em geral, distância euclidiana. Implemente o método do match. Avalie a qualidade do método, por meio do balanceamento antes e depois do match. Se necessário, altere o passo 1 ou 2 e itere. Faça a inferência sobre o efeito causal do tratamento sobre a resposta, dado o matching feito em 3. ### Avaliação do matching feito É melhor usar matching exato ou aproximado do que propensity score matching, pois o poder do teste é melhor (cf. King &amp; Nielsen, 2019). Não devemos fazer teste de hipótese para checar que o balanceamento após matching é melhor do que antes (amostra menor reduz o poder do teste de detectar desbalanceamento. Além disso, não há superpopulação alvo da inferência, pois balanceamento é uma propriedade de uma amostra em particular). Cf. Austin 2009. Além de comparar médias, é recomendado comparar variâncias ou desvios-padrão (Austin 2009). Por exemplo, razão de variâncias. Jamais use a variável resposta para fazer o matching. Matching com reposição gera dificuldades para calcular o erro padrão, já que as observações não são independentes. Em resumo, matching é uma ferramenta poderosa para estimar efeitos causais em estudos observacionais, mas requer atenção ao balanceamento, à escolha do método e à plausibilidade da suposição de independência condicional. No próximo capítulo, veremos uma abordagem alternativa — variáveis instrumentais — que permite a identificação causal mesmo quando a seleção em observáveis não é crível. 5.11 Referências Austin, P. C. (2009). Balance diagnostics for comparing the distribution of baseline covariates between treatment groups in propensity‐score matched samples. Stat Med. King, G., &amp; Nielsen, R. (2019). Why propensity scores should not be used for matching. Political analysis, 27(4), 435-454. Stuart, E. A. (2010). Matching methods for causal inference: A review and a look forward. Statistical science: a review journal of the Institute of Mathematical Statistics, 25(1), 1. "],["variáveis-instrumentais.html", "Capítulo 6 Variáveis Instrumentais 6.1 Introdução 6.2 IV com modelo estrutural 6.3 MQO em 2 Estágios 6.4 Principais usos de IV 6.5 Efeito heterogêneo 6.6 Restrição de Exclusão 6.7 Monotonicidade 6.8 Estimação (aka estatística F) 6.9 Resumo e próximos passos 6.10 Referências", " Capítulo 6 Variáveis Instrumentais 6.1 Introdução Considere o seguinte DAG canônico de Variáveis Instrumentais: Nós vemos que o efeito causal do tratamento \\(T\\) é confundido pela variável não observada \\(U\\), já que temos um backdoor aberto. Porém, a variável \\(Z\\) não tem nenhum caminho aberto para \\(Y\\) exceto via \\(T\\), isto é, \\(T\\) é um mediador do efeito causal de \\(Z\\). Do ponto de vista não paramétrico (DAGs), dizemos que a variável \\(Z\\) é uma candidata a variável instrumental (IV) se: \\(Z\\) está conectado a \\(T\\) no grafo original. Condição de relevância. No grafo em que a seta de \\(T\\) para \\(y\\) é removida, \\(Z\\) é d-separado de \\(Y\\). Exclusion Restriction. A variável instrumental \\(Z\\) não compartilha causa comum com \\(Y\\), incluindo, portanto, não ser descendente de \\(T\\). Causa comum. Remark: Pode acontecer de ser necessário controlar para um conjunto de covariáveis \\(X\\) para que a segunda condição seja satisfeita. Chamamos isso de IV condicional. Remark 2: Dizemos que uma variável \\(Z\\) é candidata a ser VI porque as três condições acima, ainda que necessárias, não são suficientes para uma variável ser considerada VI. Veremos mais à frente por que isso acontece e o que mais é necessário para uma variável ser considerada VI. Considere o DAG abaixo. Remark 3: A literatura econométrica não costuma deixar muito clara a condição 3. Às vezes falam que \\(Z\\) deve causar \\(T\\) (o que implica que não há causa comum em um DAG). Porém, isso não é correto, como o DAG abaixo mostra, em que, controlando para \\(V_3\\), que é um collider, induzimos correlação entre \\(Z\\) e \\(T\\) para a condição de relevância ser satisfeita, e \\(Z\\) é uma VI candidata. Do mesmo jeito, se \\(V_3\\) for causa comum de \\(Z\\) e \\(T\\), não controlar para ela torna \\(Z\\) admissível como VI. Será que \\(Z\\) pode ser uma IV no DAG abaixo? Vamos verificar as condições. É fácil ver que \\(Z\\) está conectado a \\(T\\), já que temos dois caminhos abertos, um via \\(W\\) e outro via \\(L\\) (e ainda um via \\(W\\) via \\(L\\)). Portanto, a primeira condição está satisfeita. Note que se eu controlar simultaneamente para \\(W\\) e \\(L\\), então eu fecho todos os caminhos abertos. Com relação à segunda condição, remover a flecha de \\(T\\) para \\(Y\\) é, efetivamente, ter um novo DAG: Por fim, \\(Z\\) não compartilha causa comum com \\(Y\\). Nesse DAG, \\(Z\\) não está d-separado de \\(Y\\), pois existe um caminho aberto para \\(Y\\) via \\(L\\). Portanto, controlando para \\(L\\) (mas não \\(W\\)), tenho um instrumento que passa nas duas condições. Até aqui vimos as condições para que uma variável seja candidata a instrumento a partir da perspectiva de DAGs. Vejamos agora como essas condições se traduzem em um modelo estrutural paramétrico. 6.2 IV com modelo estrutural \\(y_i = \\beta D_i + \\delta_2 U + e_i\\) \\(D_i = \\delta_1 U + \\gamma z_i + u_i\\) As duas equações são estruturais, no sentido de que representam relações causais. A restrição de exclusão do tratamento \\(D_i\\) é que \\(\\mathbb{E}[D_i|e_i] = 0\\). Sabemos que não é verdade porque \\(D_i\\) é endógeno, ou seja, há um viés de variável omitida, \\(U\\). Já a restrição de exclusão da variável instrumental é que \\(\\mathbb{E}[z_i|u_i] = 0\\) Vamos supor, para simplificar, que tanto \\(D_i\\) quanto \\(Z_i\\) são binários. Considere o seguinte exemplo: Nós sabemos que diferença simples de média identifica o ATE da segunda equação: \\(\\gamma = \\frac{\\sum_{i=1}^n z_i}{n} - \\frac{\\sum_{i=1}^n (1-z_i)}{n}\\). 6.3 MQO em 2 Estágios Considere novamente o DAG canônico para IV. Como poderíamos estimar o efeito causal de \\(T\\) sobre \\(Y\\)? Uma possibilidade é a chamada forma reduzida, que pode ser derivada a partir da suposição de independência. Antes, vamos introduzir uma notação: A notação \\(Y^{T=t,Z=z}\\) indica o resultado potencial para um nível do tratamento \\(t\\) efetivamente recebido, que pode ser \\(0\\) ou \\(1\\), e para um nível do treatment assignment, que pode ser \\(0\\) ou \\(1\\), para um instrumento binário. E também temos um status potencial do tratamento (em oposição ao tratamento observado): \\(T^1_i\\) é o status do tratamento quando \\(Z=1\\). Similarmente, \\(T^0_i\\) é o status do tratamento quando \\(Z=0\\). E aqui temos uma nova switching equation: \\(T_i = T^0_i + (T^1_i - T^0_i)Z_i\\) \\[\\begin{align} E\\big[Y_i\\mid Z_i=1\\big]-E\\big[Y_i\\mid Z_i=0\\big] &amp; = E\\big[Y_i(D_i^1,1)\\mid Z_i=1\\big]- E\\big[Y_i(D_i^0,0)\\mid Z_i=0\\big] \\\\ &amp; = E[Y_i(D_i^1,1)] - E[Y_i(D_i^0,0)] \\end{align}\\] O estimador é o efeito causal (total) de \\(Z\\) sobre \\(Y\\). Em um experimento, isso é chamado de intent to treat, pois se a aleatorização é o instrumento, então é o efeito causal da intenção de tratar. library(stargazer) n &lt;- 100000 set.seed(123) z &lt;- rnorm(n) u &lt;- rnorm(n, 0 , 3) treatment &lt;- rbinom(n, 1, plogis(z - u + rnorm(n, 0, 2))) y &lt;- 2*treatment + u reg_vies &lt;- lm(y ~ treatment) summary(reg_vies) Call: lm(formula = y ~ treatment) Residuals: Min 1Q Median 3Q Max -11.4112 -1.6433 0.0048 1.6470 10.8586 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 1.75964 0.01096 160.56 &lt;2e-16 treatment -1.49476 0.01551 -96.35 &lt;2e-16 — Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1 Residual standard error: 2.453 on 99998 degrees of freedom Multiple R-squared: 0.08495, Adjusted R-squared: 0.08494 F-statistic: 9283 on 1 and 99998 DF, p-value: &lt; 2.2e-16 reg_1s &lt;- lm(treatment ~ z) reg_2s &lt;- lm(y ~ fitted(reg_1s)) stargazer(reg_vies, reg_1s, reg_2s, type = &quot;html&quot;, title=&quot;OLS e 2SLS&quot;) OLS e 2SLS Dependent variable: y treatment y (1) (2) (3) treatment -1.495*** (0.016) z 0.095*** (0.002) fitted(reg_1s) 1.916*** (0.085) Constant 1.760*** 0.499*** 0.058 (0.011) (0.002) (0.043) Observations 100,000 100,000 100,000 R2 0.085 0.036 0.005 Adjusted R2 0.085 0.036 0.005 Residual Std. Error (df = 99998) 2.453 0.491 2.558 F Statistic (df = 1; 99998) 9,283.268*** 3,739.184*** 505.426*** Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 Uma regra de bolso, baseada em um artigo de Stock &amp; Yogo (2002), diz que a estatística F da regressão do primeiro estágio deve ser maior que 10. library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.4 ✔ readr 2.1.5 ## ✔ forcats 1.0.0 ✔ stringr 1.5.1 ## ✔ ggplot2 3.5.1 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.3 ✔ tidyr 1.3.1 ## ✔ purrr 1.0.4 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors library(ggplot2) simulate_and_fit &lt;- function(n) { z &lt;- rnorm(n) u &lt;- rnorm(n, 0, 3) treatment &lt;- rbinom(n, 1, plogis(z - u + rnorm(n, 0, 2))) y &lt;- 2 * treatment + u # Naive regression reg_vies &lt;- lm(y ~ treatment) # 2SLS reg_1s &lt;- lm(treatment ~ z) predicted_treatment &lt;- predict(reg_1s) reg_2s &lt;- lm(y ~ predicted_treatment) # Return coefficients tibble( naive_coef = coef(reg_vies)[2], tsls_coef = coef(reg_2s)[2] ) } # Sample sizes to simulate sample_sizes &lt;- seq(1000, 100000, by = 1000) # Use map to apply the function to each sample size results &lt;- tibble(sample_size = sample_sizes) %&gt;% mutate( simulation_results = map(sample_size, simulate_and_fit) ) %&gt;% unnest(cols = c(simulation_results)) results %&gt;% pivot_longer(cols = c(naive_coef, tsls_coef), names_to = &quot;method&quot;, values_to = &quot;coefficient&quot;) %&gt;% ggplot(aes(x = sample_size, y = coefficient, color = method)) + geom_line() + geom_smooth(data = . %&gt;% filter(method == &quot;2sls_coef&quot;), method = &quot;lm&quot;, se = FALSE, color = &quot;red&quot;) + labs( title = &quot;Convergence of Regression Coefficients with Increasing Sample Size&quot;, x = &quot;Sample Size&quot;, y = &quot;Estimated Coefficient&quot;, color = &quot;Method&quot; ) + theme_minimal() + scale_color_manual(values = c(&quot;naive_coef&quot; = &quot;blue&quot;, &quot;tsls_coef&quot; = &quot;red&quot;)) + theme( plot.title = element_text(hjust = 0.5), legend.title = element_blank() ) 6.4 Principais usos de IV 6.4.1 Experimentos Quando pesquisadores utilizam o processo de assignment como instrumento para lidar com problema de non-compliance. Estimativas do Local Average Treatment Effect são críveis. Contraposição a intent-to-treat estimates. 6.4.2 Regras com variação quasi-aleatória Kin (2019) utiliza uma regra na Suécia que obriga cidades com população acima de certo nível a adotar democracia direta. Dinas (2014) utiliza idade para votar no momento da eleição como instrumento para comparecimento eleitoral do eleitor. 6.4.3 Teoria Quando a restrição de exclusão é baseada em teoria ou conhecimento substantivo. Aqui estão os instrumentos baseados em geografia ou clima (por exemplo, proximidade a faculdade como instrumento para ensino superior) ou (Zhu, 2017) que usou proximidade geográfica de cinco centros comerciais fora da China (ponderados pelo PIB dos centros comerciais) como instrumento para presença de multinacional (que causaria corrupção). Há o clássico instrumento de chuva como instrumento para, por exemplo, comparecimento eleitoral de eleitores democratas. Mellon (2023) revisou 289 estudos e concluiu que 195 variáveis distintas foram conectadas com chuva, o que significa que podem ser potenciais violações da restrição de exclusão. Cinelli and Hazlett Friedman et al. (2000) usaram origem legal (francesa, inglesa, sueca etc.) como instrumento para qualidade das instituições. Djankov et al. (2003) usaram origem legal como instrumento para grau de formalismo de instituições. Glaeser et al. (2004) usaram origem legal como instrumento para restrições ao executivo (“executive constraints”). Henderson and Brooks, 2016, usam chuva ao redor do dia da eleição como instrumento para votação de candidatos democratas, e concluem que aumento da chuva reduz comparecimento que causa democratas terem comportamento legislativo mais direitoso. Os resultados acima supõem que o efeito do tratamento é homogêneo. Mas o que acontece quando diferentes indivíduos respondem de maneira diferente ao tratamento? 6.5 Efeito heterogêneo Se houver efeito heterogêneo (apenas mulheres mudam comportamento em razão do instrumento, por exemplo), então estamos estimando o efeito apenas para aquele subgrupo (são os compliers com o instrumento). Se o instrumento explicar pouco da variação no Tratamento, então teremos pouca variação no tratamento para explicar a variação em Y. Ou seja, o sinal é fraco. Isso se traduz em baixo poder estatístico. Para discutir efeito casual heterogêneo, vamos utilizar um estudo em ciência política (White, 2019). Qual o efeito de misdemeanor (algo como contravenção penal) sobre comparecimento eleitoral? O autor argumenta que o efeito deve variar por raça (maior para negros que brancos), de modo que o efeito causal é heterogêneo. Segundo o autor, casos são atribuídos aleatoriamente para diferentes cortes judiciais, e elas variam em sua leniência (ou severidade). Aqui, o tratamento é a condenação (\\(1\\) se condenado, \\(0\\) se não), e temos uma variável instrumental, o sorteio do juiz mais ou menos leniente. Alguns acusados têm tantas evidências que serão condenados não importa para que tipo de corte são enviados. Outros, podem ser sempre absolvidos, não importa o juiz. Há os “azarados”, que só serão condenados se enviados para a corte severa. O que não faz sentido é ter alguém que só é condenado se enviado para um juiz leniente e absolvido se enviado para um severo. Nós iremos agrupar esses quatro tipos (incluindo o último) em quatro tipos: Os primeiros são chamados de always-takers. Sempre recebem o tratamento (são presos), não importa o que foi atribuído a eles pelo mecanismo de atribuição. O segundo são os never takers, que nunca recebem o tratamento. Por fim, o terceiro grupo são os compliers, que seguem o tratamento prescrito e o quarto grupo são os defiers, aqueles que fazem o contrário do prescrito. Nesse caso, não faz muito sentido imaginar que existem os defiers, mas teoricamente é possível. Digamos que o efeito causal do tratamento é heterogêneo, isto é, \\(\\delta_i = Y^1_i - Y^0_i\\). Nesse caso, não podemos mais estimar o efeito causal geral (ATE), pois o efeito causal é heterogêneo e o instrumento só explica a variação no tratamento para os compliers. 6.5.1 Suposições para estimar o LATE Além das suposições que já discutimos, vale sempre lembrar que temos também a SUTVA. Resultados potenciais para unidade \\(i\\) não estão relacionadas ao tratamento que \\(j\\) recebe. Claramente existe potencial para SUTVA ser violada no estudo de encarceramento e voto. Se dois irmãos (indivíduo \\(i\\) e \\(j\\)) são acusados e um deles é preso, é possível que o tratamento de um deles impacte a probabilidade de voto do outro e vice-versa. Salvo engano, White não discute essa possibilidade de violação da suposição, o que é problemático. Mas vamos supor que SUTVA está garantido. Vale lembrar também que Independência é diferente da restrição de exclusão Também chamada de as good as random assignment e no confounding for the effect of Z on Y. Afirma que a IV é independente dos resultados potenciais e das potenciais atribuições de tratamento. Em termos de nosso DAG, quer dizer que \\(Z\\) não compartilha causa comum com \\(Y\\). Essa suposição parece tranquilamente satisfeita no estudo em questão, já que a atribuição da corte é aleatória e parece difícil imaginar que algo que causa a leniência da corte ser causado por alguma variável que também causa o comparecimento. Aqui o DAG: 6.6 Restrição de Exclusão A restrição de exclusão requer que o instrumento \\(Z\\) afete o resultado \\(Y\\) apenas por meio do tratamento \\(T\\). Em outras palavras, não há efeito direto de \\(Z\\) sobre \\(Y\\) que não passe por \\(T\\). Essa suposição é não testável diretamente e deve ser justificada com argumentos substantivos. 6.7 Monotonicidade Por fim, precisamos assumir monotonicidade. Ela requer que a variável instrumental opera (fracamente) em todas as direções para todos os indivíduos. Ou seja, todo mundo que é afetado pelo instrumento é afetado da mesma maneira. Em outras palavras, o instrumento apenas move as pessoas do controle para o tratamento (ou não move a pessoa), mas nunca o contrário. Ou seja, estamos assumindo que não há defiers na nossa população. Matematicamente e de maneira geral, dizemos que a monotonicidade é válida quando \\(T^{Z=1} \\geq T^{Z=0}\\) para todas as unidades. Com essas suposições, nós estimamos o LATE: Local Average Treatment Effect of T on Y. Isso porque nosso estimador é: \\[\\begin{align} \\mathbb{E}[Y(Z=1) - Y(Z=0)] = \\\\ =&amp; \\mathbb{E}[Y(Z=1) - Y_i(Z=0)|T^1 = 1, T^0 = 1]P(T^1 = 1, T^0 = 1) \\text{ always-takers} \\\\ +&amp; \\mathbb{E}[Y(Z=1) - Y_i(Z=0)|T^1 = 0, T^0 = 0]P(T^1 = 0, T^0 = 0) \\text{ never-takers} \\\\ +&amp; \\mathbb{E}[Y(Z=1) - Y_i(Z=0)|T^1 = 1, T^0 = 0]P(T^1 = 1, T^0 = 0) \\text{ compliers} \\\\ +&amp; \\mathbb{E}[Y(Z=1) - Y_i(Z=0)|T^1 = 0, T^0 = 1]P(T^1 = 0, T^0 = 1) \\text{ defiers} \\end{align}\\] Porém, sabemos que o instrumento não tem efeito causal sobre always-takers nem never-takers, então o efeito causal é zero para esses grupos. E a proporção de defiers é zero, de modo que ficamos apenas com a parte dos compliers. E nesse grupo, \\(Z = T\\), de modo que o efeito do instrumento é o efeito do tratamento. Então podemos reescrever como: \\[\\delta_{IV,LATE} = \\mathbb{E}[Y(1) - Y(0)|T^1 - T^0 = 1]\\] Vejam que o denominador nos dá a proporção da população que mudou seu status por causa do instrumento. O LATE é um parâmetro local: ele se refere apenas ao subgrupo de compliers. Isso é ao mesmo tempo uma força (é um efeito causal bem definido) e uma limitação (pode não representar o efeito para toda a população). Vejamos agora questões práticas de estimação. 6.8 Estimação (aka estatística F) Considere nosso modelo em que as variáveis estão centradas (sem constante) e não há controle. \\(y_i = \\beta D_i + e_i\\) \\(D_i = \\pi z_i + u_i\\) Posso reescrever a equação de resultado como: \\(y_i = \\beta (\\pi z_i + u_i) + e_i = \\underbrace{\\beta \\pi}_{\\delta} z_i + \\beta u_i + e_i\\) Essa equação é chamada de forma reduzida. Lembrando que nosso estimador \\(\\hat{\\beta}_{2sls} = \\frac{\\hat{\\delta}}{\\hat{\\pi}}\\) Ou seja, o estimador de 2sls é a razão da forma reduzida e o primeiro estágio O que acontece se \\(Cov(D_i, z_i)\\) for muito pequeno? Pequenas variações podem impactar bastante as estimativas. É possível mostrar (supondo homocedasticidade) como o viés do nosso estimador em dois estágios se relaciona com a estatística F: \\[ \\mathbb{E}[\\hat{\\beta_{2sls}} - \\beta] \\approx \\underbrace{\\frac{Cov(u,e)}{Var(u)}}_{\\text{OVB}} \\frac{k}{F + 1} \\] Se a estatística F é zero, ou seja, o poder do teste é zero, então o viés é igual ao de MQO normal, ou seja, a estimativa com IV é a mesma de OLS/MQO. Quanto maior a estatística F, menor o viés. E por fim, quanto maior o número de instrumentos (isso não está explícito, mas entra na fórmula), maior o viés em amostras finitas. É por essa razão que a literatura se concentrou em uma heurística para a estatística F, que vimos é ser maior que 10. Que basicamente é dizer que será no máximo 10% do viés com 95% de certeza. 6.8.1 F stat A estatística F do primeiro estágio é a parcela explicada no primeiro estágio, relativo ao ruído no primeiro estágio. Quanto maior a estatística F, menor o viés. Se o poder é zero, \\(F = 0\\) e IV é apenas a estimativa de MQO. Ponto chave: quando existem muitos instrumentos, o viés aumenta. This is the approach initially developed by Staiger and Stock (1997) and Stock and Yogo (2005). - Typical rule of thumb: first-stage F-statistic above 10 means that bias won’t be larger than 10% with size of 5%. Very popular! - Suposição chave: homocedasticidade! Montiel Olea and Pfluger( 2013) desenvolveram um teste robusto a heterocedasticidade, com uma estatística F mais apropriada a (allows for clustering, autocorrelation, etc.) - O novo ponto de corte é mais como 23.1 O pacote ivDiag computa essa estatística F. Função eff_F. Alternativa é computar um intervalo de confiança de Anderson-Rubin, que é válido mesmo com instrumento fraco. Novamente, ivDiag computa esse IC. 6.9 Resumo e próximos passos Neste capítulo, vimos que variáveis instrumentais permitem estimar efeitos causais mesmo na presença de confundidores não observados. As condições para que uma variável seja um instrumento válido — relevância, restrição de exclusão e ausência de causa comum — são necessárias mas não suficientes; a monotonicidade é adicionalmente requerida para estimar o LATE. Na prática, a estatística F do primeiro estágio é uma ferramenta essencial para avaliar a força do instrumento, com limiares recomendados de 10 (regra clássica) ou 23,1 (teste robusto a heterocedasticidade). No próximo capítulo, veremos Regressão Descontínua (RDD), um desenho quasi-experimental que explora pontos de corte em variáveis contínuas para identificar efeitos causais. 6.10 Referências Henderson, J., &amp; Brooks, J. (2016). Mediating the electoral connection: The information effects of voter signals on legislative behavior. The Journal of Politics, 78(3), 653-669. Mellon, J. (2023). Rain, Rain, Go Away: 195 Potential Exclusion-Restriction Violations for Studies Using Weather as an Instrumental Variable. Available at SSRN 3715610. White, A. (2019). Misdemeanor disenfranchisement? The demobilizing effects of brief jail spells on potential voters. American Political Science Review, 113(2), 311-324. "],["desenho-de-regressão-descontínua.html", "Capítulo 7 Desenho de Regressão Descontínua 7.1 Outline da aula 7.2 Características-chave da RDD 7.3 Fuzzy RDD 7.4 Suposição de continuidade 7.5 Suposições na RDD 7.6 Testabilidade da Suposição de não-Manipulação 7.7 Estimação em RDD 7.8 Métodos de Estimação 7.9 Trade-off de Viés-Variância 7.10 Regras arbitrárias 7.11 Simulação 7.12 Simulação - Potential Outcomes Y0 7.13 Simulação - Potential Outcomes Y1 7.14 Simulação - Potential Outcomes Y1 e Y0 7.15 Simulação - Y observado 7.16 Quando o RDD funciona? 7.17 Raw Data versus Bin 7.18 Permutation tests (balancing) 7.19 McCrary test 7.20 Robustez 7.21 Densidade descontínua - results 7.22 Regressão RDD 7.23 Placebo Tests 7.24 PCRD 7.25 Checklist para um paper de RDD 7.26 Referências", " Capítulo 7 Desenho de Regressão Descontínua 7.1 Outline da aula Na aula de hoje, iremos aprender sobre identificação causal do aspecto mais simples da RD e como funciona. Em seguida, estimação e checagem. Falaremos rapidamente de extensões. 7.2 Características-chave da RDD A Regressão Discontínua (RDD) é caracterizada por uma variável contínua \\(X_i\\), que determina quem recebe tratamento, denotado por \\(T_i\\) (1 se tratado). Por convenção, \\(X\\) é chamada de “running variable”, “assignment variable” ou “forcing variable”. 7.2.1 Determinação do Tratamento Em um desenho RDD sharp, uma unidade é tratada se \\(X_i \\geq c\\) e não tratada se \\(X_i &lt; c\\). Assim, \\(T_i\\) é uma função determinística de \\(X_i\\): \\(T_i = f(X_i)\\). A running variable determina completamente quem recebe tratamento. 7.3 Fuzzy RDD Pode acontecer do ponto de corte não determinar quem recebe ou não o tratamento, mas apenas a probabilidade de receber o tratamento. Nesse caso, a regra serve como variável instrumental ao redor do ponto de corte. Ex.: regra de voto determina número de cadeiras. Mas migração partidária altera o número. Então quem fica abaixo do número mínimo em um distrito pode ter cadeiras naquele distrito via migração partidária. 7.3.1 Observação e Corte É essencial observar \\(X\\) e conhecer o ponto de corte ou limiar \\(c\\). Uma das suposições da RDD é que ela requer a continuidade da variável \\(X\\) para identificação, embora, na prática, alguns estudos de RDD tenham usado running variables discretas. A continuidade de \\(X\\) é necessária porque a identificação ocorre no limite. Mas a suposiçao chave é que os resultados potenciais devem ser contínuos ao redor do ponto de corte. Como sempre, essa suposição é intestável, devido ao problema fundamental da inferência causal. Lee (2008), em um artigo clássico, mostrou que uma condição mais restritiva é suficiente para identificação causal: que as unidades podem controlar a running variável, exceto ao redor do ponto de corte. Isso implica também que as covariáveis de pré-tratamento são contínuas no cutoff. Isso é potencialmente testável, pelo menos nas variáveis observadas e em geral olhando para a média das variáveis, o que não é a mesma coisa que olhar para outros momentos, que podem ser descontínuos. 7.3.2 Estimativa dos Efeitos do Tratamento A comparação de \\(\\lim_{x \\uparrow c} E[Y_i | X_i = x]\\) com \\(\\lim_{x \\downarrow c} E[Y_i | X_i = x]\\) fornece uma estimativa dos efeitos do tratamento (note a direção das setas). Esta comparação é equivalente a: \\(\\lim_{x \\uparrow c} E[Y_i | X_i = x, T_i=0]\\) e \\(\\lim_{x \\downarrow c} E[Y_i | X_i = x, T_i=1]\\), uma vez que, neste exemplo, à direita de \\(c\\) todos recebem tratamento; à esquerda, ninguém recebe. Portanto: \\(\\lim_{x \\uparrow c} E[Y_i | X_i = x] \\approx E[Y_{0i} | X_i = c]\\) \\(\\lim_{x \\downarrow c} E[Y_i | X_i = x] \\approx E[Y_{1i} | X_i = c]\\) Se fôssemos usar regressão linear, o modelo seria: \\(y_i = \\alpha + \\beta_1 (x_i &gt; c) + \\beta_2 x_i + \\beta_3 x (x_i &gt; c) + e_i\\), em que \\(c\\) é o ponto de corte, e \\(x\\) é a running variable. 7.4 Suposição de continuidade A suposição de continuidade é tão crítica que vale discutirmos um pouco mais sobre ela. Se há continuidade, isso significa que, na ausência do ponto de corte \\(c\\), x (e outras covariáveis) não devem apresentar descontinuidade. Ex.: Suponha que estamos interessados em estudar o efeito da incumbência sobre a chance de reeleição futura ou riqueza futura desses políticos. Habilidades e carisma são variáveis que devem influenciar tanto a chance de serem incumbentes como os resultados de interesse. Em um RDD, podemos usar close elections para estimar o efeito. E a suposição de continuidade requer que carisma e habilidades não tenham descontinuidade no cut off de 50%. Na verdade, apenas o resultado eleitoral é descontínuo no cut off, que vai de não-eleito para eleito. 7.5 Suposições na RDD 7.5.1 Suposição de Não-manipulação com Precisão A identificação dos efeitos do tratamento na RDD baseia-se na premissa de que \\(X\\) atua como um aleatorizador ao redor de \\(c\\). Imagine que \\(X\\) seja uma variável aleatória uniforme usada para atribuir tratamento. Se \\(X \\geq c\\), uma unidade recebe tratamento. Na RDD, \\(X\\) tem o mesmo papel, exceto que não assumimos que \\(X\\) é independente do resultado \\(Y\\). Na maioria das aplicações, \\(X\\) e \\(Y\\) são correlacionados de alguma forma. 7.5.2 Problemas de Manipulação No entanto, se \\(c\\) não for arbitrário ou tiver uma relação determinística com \\(Y\\), ou se as unidades puderem — com precisão — determinar seus escores \\(X\\) e, assim, escolher receber tratamento ou não, então \\(X\\) ao redor de \\(c\\) não se comporta mais como um aleatorizador — há alguma forma de auto-seleção que poderia depender de variáveis não observáveis. 7.6 Testabilidade da Suposição de não-Manipulação Em parte, isso é testável. As unidades não pareceriam semelhantes perto de \\(c\\) e haveria um “acúmulo” próximo a \\(c\\). No entanto, não podemos descartar a manipulação com precisão apenas com dados — devemos argumentar isso com conhecimento do assunto (é uma restrição de exclusão). Tendo estabelecido as suposições de identificação, passamos agora à questão prática: como estimar o efeito do tratamento em um RDD? 7.7 Estimação em RDD 7.7.1 Problema de Complete Overlapping Um problema chave na estimação em RDD estrita é a completa falta de sobreposição. Em matching, discutimos como a ausência de sobreposição gerava problemas de extrapolação. Sobreposição requer que \\(0 &lt; P(T_i = 1 | X_i) &lt; 1\\) para o domínio de \\(X_i\\). No domínio da running variable \\(X_i\\), isso claramente não é satisfeito. Em RDD estrita, temos \\(P(T_i = 1 | X_i &lt; c) = 0\\) e \\(P(T_i = 1 | X_i \\geq c) = 1\\). 7.7.2 Dependência de Extrapolação Devido à falta de sobreposição, dependemos de extrapolação para estimar os efeitos do tratamento. Dito de outra forma, podemos não ser capazes de estimar corretamente os efeitos do tratamento se errarmos a forma funcional \\(Y_i = f(X_i)\\). Novamente, essa foi uma motivação para usar matching. O problema é que nunca sabemos se acertamos, então a especificação do modelo é uma questão chave na estimação RDD. 7.8 Métodos de Estimação O problema sugere a necessidade de um método de estimação não paramétrico. Utilizaremos métodos paramétricos, não paramétricos (ou semiparamétricos) para tentar abordar essas questões. 7.8.1 Identificação no Limite A identificação dos efeitos do tratamento ocorre no limite, à medida que \\(X_i \\rightarrow c\\). Quanto mais usarmos observações distantes de \\(c\\) em \\(X\\), mais dependeremos de extrapolação e das suposições sobre a forma funcional. 7.9 Trade-off de Viés-Variância Mais perto de c: Melhor em termos de precisão, mas pode haver uma amostra insuficiente. Resulta em menos viés, mas mais variância. Mais distante de c: Dependemos menos de extrapolação, mas introduzimos mais viés, mesmo com menor variância. 7.9.1 Métodos de Largura de Banda Ótima A ideia é restringir a estimativa a uma janela ao redor de \\(X_i = c\\), que pode ter tamanhos diferentes à esquerda ou à direita. Estes métodos buscam equilibrar a precisão das estimativas minimizando viés e variância conforme a proximidade do ponto de corte \\(c\\). 7.10 Regras arbitrárias Atribuição de “coisas” a partir de regras com pontos de cortes Bolsa família: a partir de certa renda Educação: aprovação no ensino superior a partir de certa nota de corte Espacial: política pública para donos de áreas abaixo ou acima de certas áreas. Data: regras para aposentadoria, idade para entrar na escola, data para perdão de dívida: Desenrola: “…cujas dívidas tenham sido incluídas no cadastro de inadimplentes no período entre 1º de janeiro de 2019 e 31 de dezembro de 2022”. Política: regras de número de vereadores, regras de população para ter segundo turno, regras para ter biometria etc. 7.11 Simulação ## Basic RD Model set.seed(123) N &lt;- 1000 # number of observations X &lt;- runif (N , -5,5) Y0 &lt;- rnorm ( n =N , mean =X , sd=1) # control potential outcome Y1 &lt;- rnorm ( n =N , mean = X+2, sd=1) # treatment potential outcome #You only get treatment if X&gt;0 Treatment &lt;- ( X &gt;= 0) # What we observe Y = Y1* Treatment + Y0*(1- Treatment ) 7.12 Simulação - Potential Outcomes Y0 7.13 Simulação - Potential Outcomes Y1 7.14 Simulação - Potential Outcomes Y1 e Y0 ## Warning: No shared levels found between `names(values)` of the manual scale and the ## data&#39;s colour values. 7.15 Simulação - Y observado A simulação acima ilustra os elementos fundamentais de um RDD. Vejamos agora em que condições as estimativas de RDD são válidas. 7.16 Quando o RDD funciona? A suposição chave para o RDD é que tenha descontinuidade ao redor do ponto de corte, e que não haja descontinuidade ao redor do ponto de corte em outra variável omitida. Vamos ver o que isso significa, comparando quatro gráficos, três em que a estimativa do RDD é válida, mas com diferentes validades “externas” e uma em que é inválida. ## [1] 3.965471 ## [1] 0.1726892 ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. 7.17 Raw Data versus Bin Como escolher os bins? 1. Espaçamentos iguais ou quantis? 2. Quantos bins? No exemplo, escolhi espaçamento igual e 20 bins. Podemos usar quantis. Não faz muita diferença neste exemplo, mas usar quantis é mais transparente e mais crível retoricamente, pois não mascara a densidade. Sobre o número de bins, Cattaneo et al. (2020) discutem o tema e sugerem duas abordagens: 1. IMSE-minimizing (proporcional a \\(n^{1/3}\\)) 2. Mimicking-variance (proporcional a \\(n/log(n)^2\\)) E usamos o pacote rdplot para implementar isso automaticamente 7.18 Permutation tests (balancing) Para checar balancing, podemos usar testes de permutação. library(RATest) df &lt;- df_u head(df) ## y x treatment y0 y1 u ## 1 -4.9108800 -2.8126930 FALSE -4.9108800 0.24201180 -0.56047565 ## 2 -3.4521053 -3.2945724 FALSE -3.4521053 0.06456756 -0.23017749 ## 3 3.3243805 -5.0368128 FALSE 3.3243805 -10.37746355 1.55870831 ## 4 1.5797551 0.1039258 TRUE -0.4349002 1.57975508 0.07050839 ## 5 0.6339174 -0.1709231 FALSE 0.6339174 2.58972091 0.12928774 ## 6 1.3680416 -0.5215457 FALSE 1.3680416 1.57907203 1.71506499 resultado &lt;- RDperm( W = &quot;u&quot;, # Substitua pelos nomes das suas covariáveis z = &quot;x&quot;, # Substitua pelo nome da sua variável de corte data = df, # Substitua pelo seu data frame cutoff = 0 # Substitua pelo valor do ponto de corte, se diferente de 0 ) summary(resultado) ## ## ********************************************************** ## ** RD Distribution Test using permutations ** ## ********************************************************** ## Running Variable: x ## Cutoff: 0 ## q: Defined by User ## Test Statistic: CvM ## Number of Permutations: 499 ## Number of Obs: 1000 ## ## ********************************************************** ## H0: &#39;Continuity of the baseline covariates at the cutoff&#39; ## ********************************************************** ## ## Estimates: ## T(Sn) Pr(&gt;|z|) q ## u 0.01 0.92 10 ## --- ## Signif. codes: 0.01 &#39;***&#39; 0.05 &#39;**&#39; 0.1 &#39;*&#39; plot(resultado, w=&quot;u&quot;, &quot;cdf&quot;) Canay &amp; Kamat (2018) utilizaram esse teste para revisitar o trabalho de Lee (2008) e descobriram que havia problema de balanceamento. Caughey and Sekhon (2011) na political analysis mostraram que de fato havia problemas de balanceamento no estudo de Lee (2008). Do paper da PA: Houve um debate na ciência política sobre isso. Erikson &amp; Rader (2017) e Cuesta &amp; Imai (2016) argumentam que o RDD é identificado. Até onde eu sei, cientistas políticos não revisitaram a controvérsia com os novos metodos desenvolvidos pelos economistas. De todo modo, as evidências de De Magalhães et al. (2025) sugerem que a recomendação que estou adotando no curso de quais práticas usar são as melhores e mais robustas. 7.19 McCrary test Um dos principais desafios à identificação causal em RDDs é a possibilidade de manipulação por parte dos agentes sobre ficar acima ou abaixo do ponto de corte. A lógica esperada é que se o tratamento é desejável, indivíduos tentarão receber o tratamento, levando a um gap justamente abaixo do ponto de corte. Se o tratamento é indesejável (efeitos negativos), indivíduos vão evitar o tratamento, levando a um gap justamente acima do ponto de corte. O exemplo mais evidente para nós cientistas políticos é a aprovação de um projeto de lei no legislativo. Nós sabemos que os legisladores agem estrategicamente retirando propostas que não vão ser aprovadas ou postergando a votação, até terem a maioria, ainda que por margem mínima. Nesse caso, a aplicação de RDD produzirá estimativas viesadas. McCrary, em um artigo de 2008, argumentou que tais casos apareceriam como descontinuidade na densidade da running variable ao redor do ponto de corte. Eis o gráfico feito por McCrary em seu estudo original: Para formalizar essa ideia, McCrary estima os limites da densidade pela esquerda e pela direita e avalia se a diferença (do logaritmo) das estimativas é estatisticamente significante diferente de zero. Portanto, rejeitar a hipótese nula é encontrar evidências de que há manipulação. Cattaneo, Jansson, &amp; Ma 2018; 2020 introduziram uma versão alternativa do teste, com espírito similar. Na prática, de um ponto de vista retórico, o que pesquisadores querem é falhar em rejeitar a nula. Como o teste tem baixo poder de rejeitar a nula, ausência de evidência não quer dizer evidência de ausência. library(rdd) # Simulated data without discontinuity DCdensity(df$x, 0) # No discontinuity ## [1] 0.6885203 Cattaneo Density Test (Improved Version) library(rddensity) # Simulated continuous density rdd &lt;- rddensity(X = df$x, vce = &quot;jackknife&quot;) summary(rdd) ## ## Manipulation testing using local polynomial density estimation. ## ## Number of obs = 1000 ## Model = unrestricted ## Kernel = triangular ## BW method = estimated ## VCE method = jackknife ## ## c = 0 Left of c Right of c ## Number of obs 484 516 ## Eff. Number of obs 136 229 ## Order est. (p) 2 2 ## Order bias (q) 3 3 ## BW est. (h) 1.63 2.095 ## ## Method T P &gt; |T| ## Robust 0.6125 0.5402 ## ## ## P-values of binomial tests (H0: p=0.5). ## ## Window Length &lt;c &gt;=c P&gt;|T| ## 0.174 + 0.174 20 20 1.0000 ## 0.336 + 0.349 34 45 0.2604 ## 0.498 + 0.523 52 60 0.5085 ## 0.659 + 0.697 65 82 0.1868 ## 0.821 + 0.872 81 96 0.2926 ## 0.983 + 1.046 96 116 0.1918 ## 1.145 + 1.220 109 133 0.1391 ## 1.306 + 1.395 122 153 0.0702 ## 1.468 + 1.569 128 173 0.0111 ## 1.630 + 1.743 136 189 0.0039 Essa é uma área ativa de pesquisa, com novos testes sendo desenvolvidos, por exemplo, Fitzgerald (2025), que é um working paper. 7.20 Robustez Mostrar várias estimativas, para várias escolhas de estimações (bandwidth etc.) Uma possibilidade é simplesmente apresentar várias estimativas, como faremos abaixo. Ou então, uma tabela. Mas o mais simples seria um gráfico dos efeitos com seus respectivos ICs, em que cada entrada no eixo x é uma estimação, e no y temos o efeito. Abaixo apresento duas dessas possibilidades para ilustrar como a última é a melhor. df1 &lt;- data.frame( estimate = vec_estimate, se = se_estimate, lower = vec_estimate - 2 * se_estimate, upper = vec_estimate + 2 * se_estimate, h = c(&quot;Aut&quot; , &quot;h=1&quot;, &quot;h=.5&quot; , &quot;h=.1&quot;) # ou names(vec_estimate) se o vetor for nomeado ) # 2) Plote com pontos e barras de erro ggplot(df1, aes(x = h, y = estimate)) + geom_point(size = 2) + geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.1) + labs( x = &quot;h&quot;, y = &quot;Estimativa&quot;, title = &quot;Efeitos estimados com IC (±2×SE)&quot; ) + theme_minimal() 7.21 Densidade descontínua - results 7.22 Regressão RDD library(rdrobust) # Assuming the cutoff is at x=0 basic_model &lt;- rdrobust(y = df$y, x = df$x, c = 0) summary(basic_model) ## Sharp RD estimates using local polynomial regression. ## ## Number of Obs. 1000 ## BW type mserd ## Kernel Triangular ## VCE method NN ## ## Number of Obs. 484 516 ## Eff. Number of Obs. 124 152 ## Order est. (p) 1 1 ## Order bias (q) 2 2 ## BW est. (h) 1.375 1.375 ## BW bias (b) 2.375 2.375 ## rho (h/b) 0.579 0.579 ## Unique Obs. 484 516 ## ## ============================================================================= ## Method Coef. Std. Err. z P&gt;|z| [ 95% C.I. ] ## ============================================================================= ## Conventional 2.221 0.305 7.283 0.000 [1.623 , 2.818] ## Robust - - 6.539 0.000 [1.630 , 3.025] ## ============================================================================= 7.23 Placebo Tests Testando descontinuidade em covariáveis predeterminadas: covariáveis que não devem ser afetadas pelo tratamento não devem apresentar salto no ponto de corte. Testando descontinuidades em outros pontos: verificar a existência de descontinuidades em pontos arbitrários ao longo da variável de ordenação. Uso de VDs placebos: se uma variável dependente que não deveria ser afetada pelo tratamento apresentar descontinuidade significativa, isso levanta dúvidas sobre a validade do desenho RD. Avaliação de sensibilidade às covariáveis: as estimativas de RD não devem ser altamente sensíveis à inclusão ou exclusão de covariáveis. 7.24 PCRD Marshall (2024) na AJPS introduz a nomenclatura do desenho de pesquisa Politician characteristic regression discontinuity (PCRD). Basicamente, o argumento é que RDD não permite identificar efeito de características de políticos (como gênero, profissão, raça, ideologia, alinhamento com governo federal etc.) “In contrast, the treatment in PCRD designs — which instead seek to estimate the LATE of an elected politician characteristic — is defined by possessing (or not) predetermined characteristic X, conditional on narrowly winning an election. (…) restricting attention to close elections entails conditioning on candidate vote shares that may be affected by X. (…) [It] generally introduce bias — even when X is independent of other predetermined variables and the weak continuity assumption underpinning standard RD designs holds.” (p. 495) Basicamente, Marshall está dizendo que nesses casos, close election é um collider, e isso abre as portas para vieses de variáveis que causem \\(y\\) e se a eleição é apertada. 7.25 Checklist para um paper de RDD Teste de balanceamento de variáveis de pré-tratamento (não impactadas pelo tratamento) Teste de permutação no cutoff (outra forma de olhar balanceamento) Densidade da running variable (teste de McCrary) Testes de placebo (cutoffs arbitrários. Estimativa não muda) Gráfico com a descontinuidade Estimativas baseadas em bandwidth ótimos, e local linear regression Análise de robustez junto com a escolha do bandwidth (apresente graficamente) Ordem preferida: primeiro estabelecer a validade da estratégia, depois detalhes da estimação. 7.26 Referências Canay, I. A., &amp; Kamat, V. (2018). Approximate permutation tests and induced order statistics in the regression discontinuity design. The Review of Economic Studies, 85(3), 1577-1608. Cattaneo, M. D., Idrobo, N., &amp; Titiunik, R. (2024). A practical introduction to regression discontinuity designs: Extensions. Cambridge University Press. Cattaneo, M. D., Idrobo, N., &amp; Titiunik, R. (2019). A Practical Introduction to Regression Discontinuity Designs: Foundations. Elements in Quantitative and Computational Methods for the Social Sciences. Cattaneo, M. D., &amp; Titiunik, R. (2022). Regression discontinuity designs. Annual Review of Economics, 14(1), 821-851. De Magalhães, L., Hangartner, D., Hirvonen, S., Meriläinen, J., Ruiz, N. A., &amp; Tukiainen, J. (2025). When Can We Trust Regression Discontinuity Design Estimates from Close Elections? Evidence from Experimental Benchmarks. Political Analysis, 1-8. Fitzgerald, J. (2025). Manipulation Tests in Regression Discontinuity Design: The Need for Equivalence Testing. Gelman, A., &amp; Imbens, G. (2019). Why high-order polynomials should not be used in regression discontinuity designs. Journal of Business &amp; Economic Statistics, 37(3), 447-456. Marshall, J. (2024). Can close election regression discontinuity designs identify effects of winning politician characteristics?. American Journal of Political Science, 68(2), 494-510. Erikson, R. S., &amp; Rader, K. (2017). Much ado about nothing: rdd and the incumbency advantage. Political Analysis, 25(2), 269-275. De la Cuesta, B., &amp; Imai, K. (2016). Misunderstandings about the regression discontinuity design in the study of close elections. Annual Review of Political Science, 19(1), 375-396. Marshall, J. (2024). Can close election regression discontinuity designs identify effects of winning politician characteristics?. American Journal of Political Science, 68(2), 494-510. Tutorial: https://congressdata.joshuamccrain.com/regression_discontinuity.html "],["diferença-em-diferenças.html", "Capítulo 8 Diferença em Diferenças 8.1 Modelo básico 2x2 8.2 TWFE 8.3 Pressupostos 8.4 Aplicação 8.5 Múltiplos períodos 8.6 Tendências Paralelas 8.7 Múltiplos períodos pós-tratamento 8.8 Análise de sensibilidade em DiD 8.9 DiD generalizado 8.10 DID com adoção escalonada (staggered timing) 8.11 Paper Voter Gratitude Last Long? 8.12 Resumo e próximos passos 8.13 Referências", " Capítulo 8 Diferença em Diferenças 8.1 Modelo básico 2x2 Vamos considerar primeiro um cenário de dois grupos \\(G \\in \\{1,2\\}\\) e dois períodos de tempo \\(T \\in \\{1,2\\}\\). A notação de resultados potenciais é: \\(Y_{gt}(0,0)\\) é o resultado potencial da unidade \\(g\\) no período \\(t\\) se não for tratada nos dois períodos. \\(Y_{gt}(0,1)\\) é o resultado potencial da unidade \\(g\\) no período \\(t\\) se for tratada no segundo período. Usualmente nós simplificamos a notação com dois períodos para \\(Y_{gt}(0)\\) e \\(Y_{gt}(1)\\). A vantagem da notação mais complexa é para manter a ideia de que o path (caminho) pode vir a ser relevante. Supondo, como usual, que temos um tratamento binário \\(D\\), e que ele é ativado (implementado) apenas no período \\(2\\) para um dos grupos, temos a seguinte tabela para descrever como usualmente se pensa as relações causais. \\(t = 0\\) \\(t = 1\\) \\(D = 0\\) \\(\\gamma_0 + \\alpha_i\\) \\(\\gamma_1 + \\alpha_i\\) \\(D = 1\\) \\(\\gamma_0 + \\alpha_i + \\tau_i\\) \\(\\gamma_1 + \\alpha_i + \\tau_i\\) A diferença para cada grupo \\(g\\) é: \\[ y_{g1} - y_{g0} = (\\lambda_1 - \\lambda_0) + \\tau_i(D_{i,1} - D_{i,0}) \\] Como pode haver mudança nos resultados apenas pela passagem do tempo, o efeito causal é não-identificado. Contudo, veja que: \\[ \\mathbb{E}[y_{g1} - y_{g0}|D_{i1} - D_{i0} = 1] - \\mathbb{E}[y_{g1} - y_{g0}|D_{i1} - D_{i0} = 0] = \\mathbb{E}[\\tau_i(D_{i1} - D_{i0})|D_{i1} - D_{i0} = 1] \\] Unpacking: \\(\\mathbb{E}[y_{g1} - y_{g0}|D_{i,1} - D_{i0} = 1] = (\\lambda_1 - \\lambda_0) + \\mathbb{E}[\\tau_i|(D_{i1} - D_{i0})=1]\\) e \\(\\mathbb{E}[y_{g1} - y_{g0}|D_{i,1} - D_{i0} = 0] = (\\lambda_1 - \\lambda_0)\\), então a diferença é \\((\\lambda_1 - \\lambda_0) + \\tau_i - (\\lambda_1 - \\lambda_0) = \\mathbb{E}[\\tau_i|D_{i1}=1]\\). O modelo básico 2x2 nos dá a intuição do DiD. Na prática, estimamos esse efeito por meio de regressão, como veremos a seguir. 8.2 TWFE É possível estimar um modelo de DiD com regressão. \\[ y_{gt} = \\alpha + \\beta_1 Post_t + \\beta_2 Treat_g + \\tau (Post_t \\times Treat_g) + e_{gt} \\] Outra parametrização é: \\[ y_{gt} = \\alpha_g + \\lambda_t + \\tau D_{it} + e_{gt} \\] A segunda parametrização é chamada de “two-way fixed effects”, pois usamos um efeito fixo de unidade e um de tempo. 8.3 Pressupostos Os pressupostos de identificação de DiD são: Tendências Paralelas.”Na ausência de tratamento, a média dos resultados potenciais teria evoluído em paralelo”. \\(\\mathbb{E}[Y_{g2}(0) - Y_{g1}(0)|D_g=1] = \\mathbb{E}[Y_{g2}(0) - Y_{g1}(0)|D_g=0]\\) Suposição paramétrica das PT: \\(Y_{gt}(0) = \\alpha_g + \\lambda_t + e_{gt}\\) Isso é na verdade um resultado: é possível mostrar que supor este modelo implica PT. Não-antecipação: tratamento não possui efeito no período anterior. \\(\\mathbb{E}[Y_{g1}(0)] = \\mathbb{E}[Y_{g1}(1)]\\) 8.4 Aplicação Vamos ver um exemplo no R, a partir de um estudo meu. Os dados são de um projeto da Transparência Brasil, chamado de Obra Transparente. O projeto consistiu em uma intervenção em 20 cidades do Sudeste, em que treinamento e informações foram dados a ongs locais para monitoramento de obras de creches e escolas. O projeto começou em maio de 2017 e terminou em junho de 2019. Os dados trazem informações sobre as obras nas cidades do projeto e nas demais cidades onde havia obras similares nos mesmos estados. library(here, quietly=TRUE) library(knitr) data_ot &lt;- readRDS(here(&quot;Dados&quot;, &quot;obra_transparente.RDS&quot;)) head(data_ot) %&gt;% kable() id municipio uf concluida group_treated periodo time_treated1 post_treat 1366 Conchas SP 1 0 1 0 0 1367 Itararé SP 1 0 1 0 0 1391 Brotas SP 1 0 1 0 0 1392 Buritizal SP 1 0 1 0 0 1393 Caconde SP 1 0 1 0 0 1400 Porteirinha MG 1 0 1 0 0 Como o gráfico abaixo mostra, o grupo controle possui percentual mais elevado de obras concluídas em comparação ao grupo de tratamento, mesmo antes do projeto ter se iniciado. Olhando para outras covariáveis (não mostradas aqui), de fato os dois grupos eram bastante desbalanceados. Porém, apesar da diferença de nível, as mudanças (evolução temporal) são similares. Isso sugere um dif in dif como uma metodologia adequada para estimar o efeito causal. A partir do período 4 o tratamento já poderia fazer efeito, mas ele é muito pequeno (leve mudança na inclinação) e o efeito é relevante apenas após o período 5. Temos, portanto, efeitos dinâmicos. Vamos inicialmente ajustar um modelo estático, considerando apenas o período 1 e 5. library(estimatr) library(modelsummary) library(fixest) data_ot_reg &lt;- data_ot %&gt;% filter(periodo %in% c(1,5)) %&gt;% mutate(post = ifelse(periodo == 5, 1, 0)) did &lt;- lm_robust(concluida ~ post + group_treated + post*group_treated, data=data_ot_reg, clusters = municipio) msummary(did, stars = c(&#39;*&#39; = .1, &#39;**&#39; = .05, &#39;***&#39; = .01)) /* tinytable css entries after */ .table td.tinytable_css_83y0azwaq1kosw772g9g, .table th.tinytable_css_83y0azwaq1kosw772g9g { text-align: center; border-bottom: solid #d3d8dc 0.1em; } .table td.tinytable_css_sn4wt5ll3o1wjtnt3dxi, .table th.tinytable_css_sn4wt5ll3o1wjtnt3dxi { text-align: center; border-bottom: solid black 0.05em; } .table td.tinytable_css_shsz39eaqgv3b76e8r8j, .table th.tinytable_css_shsz39eaqgv3b76e8r8j { text-align: center; } .table td.tinytable_css_y7cl39wqj5ihl6uljuee, .table th.tinytable_css_y7cl39wqj5ihl6uljuee { text-align: center; border-top: solid #d3d8dc 0.1em; border-bottom: solid #d3d8dc 0.05em; } .table td.tinytable_css_sjztzirheanz7xcfycup, .table th.tinytable_css_sjztzirheanz7xcfycup { text-align: left; border-bottom: solid #d3d8dc 0.1em; } .table td.tinytable_css_6hbkq0v7927dzdnq8b9d, .table th.tinytable_css_6hbkq0v7927dzdnq8b9d { text-align: left; border-bottom: solid black 0.05em; } .table td.tinytable_css_88tt0mwaj59p76ewsjxe, .table th.tinytable_css_88tt0mwaj59p76ewsjxe { text-align: left; } .table td.tinytable_css_9yc4qux24a3bl91gv7ck, .table th.tinytable_css_9yc4qux24a3bl91gv7ck { text-align: left; border-top: solid #d3d8dc 0.1em; border-bottom: solid #d3d8dc 0.05em; } (1) * p (Intercept) 0.382*** (0.014) post 0.481*** (0.010) group_treated -0.224*** (0.057) post × group_treated 0.155** (0.062) Num.Obs. 9020 R2 0.258 R2 Adj. 0.258 AIC 9911.2 BIC 9946.8 RMSE 0.42 Std.Errors by: municipio did_alt &lt;- feols(concluida ~ post_treat| municipio + periodo, cluster = &quot;municipio&quot;, data = data_ot_reg) summary(did_alt) ## OLS estimation, Dep. Var.: concluida ## Observations: 9,020 ## Fixed-effects: municipio: 2,020, periodo: 2 ## Standard-errors: Clustered (municipio) ## Estimate Std. Error t value Pr(&gt;|t|) ## post_treat 0.15401 0.059179 2.60247 0.0093232 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## RMSE: 0.338161 Adj. R2: 0.376909 ## Within R2: 0.002425 # teste de hipóteses paralelas # Create dataset start_t &lt;- 1 end_t &lt;- 5 data_ot_reg_pt &lt;- data_ot_reg %&gt;% dplyr::group_by(id) %&gt;% # Create group variable that take value end_t if state was ever treated in this period, and 0 otherwise dplyr::mutate(group = max(group_treated &gt; 0, na.rm=TRUE)*end_t) # test_2007_2015 &lt;- didFF( # data = data_ot_reg_pt, # idname = &quot;id&quot;, # yname = &quot;concluida&quot;, # tname = &quot;periodo&quot;, # gname = &quot;group&quot;, # est_method = &quot;reg&quot;, # allow_unbalanced_panel = TRUE, # seed = 1 # ) # # test_2007_2015$plot 8.5 Múltiplos períodos O que acontece se tivermos múltiplos períodos, isto é, \\(t&gt;2\\)? Múltiplos períodos antes do tratamento ser implementado Múltiplos períodos após o tratamento ser implementado. Precisamos escolher um período de comparação, \\(t_0\\). Nos últimos 10 anos, uma grande problematização e desenvolvimento de testes, estimadores e entendimento do que é DiD com múltiplos períodos. Impossível cobrir tudo em uma única aula. Recomendo as vídeo-aulas do grupo de estudo em DiD. 8.6 Tendências Paralelas A suposição de tendências paralelas significa que \\(\\mathbb{E}[Y_{i,t}(0) − Y_{g,t−1}(0)]\\) não varia entre grupos \\(g\\). Essa suposição implica que os nunca-tratados seguem um modelo de efeitos fixos duplo (Two-way fixed effects ou TWFE): \\[ \\mathbb{E}[Y_{g,t}(0)] = \\alpha_g + \\lambda_t \\] Uma outra forma de escrever essa suposição é: \\[ Y_{g,t}(0) = \\alpha_g + \\lambda_t + e_{gt} \\text{, com } \\mathbb{E}[e_{gt}] = 0 \\] Demonstrar equivalência é demonstrar que um implica o outro. Vamos começar mostrando que TWFE implica PT. Supondo que TWFE é verdade, então \\(\\mathbb{E}[Y_{g,t}(0) − Y_{g,t−1}(0)] = \\alpha_g + \\lambda_t - (\\alpha_g + \\lambda_{t-1}) = \\lambda_t - \\lambda_{t-1}\\), para todo \\(g\\). Como a diferença no tempo \\(\\lambda_t - \\lambda_{t-1}\\) não depende de \\(g\\), então a PT é satisfeita. Vamos agora mostrar a outra implicação. Sem perda de generalidade, defina \\(\\lambda_1 = 0\\), isto é, o efeito do período 1 é 0. Poderia ser qualquer outro valor, mas zero vai facilitar. E vamos definir \\(\\alpha_g = \\mathbb{E}[Y_{g,1}(0)]\\), ou seja, Se as tendências não forem exatamente paralelas, Rambachan e Roth (2023) desenvolveram uma forma de impor restrições sobre quão diferentes as tendências podem não ser paralelas pós-tratamento em comparação com o período pré-tratamento. O pacote no R honestDiD permite implementar isso. Assim conseguimos obter identificação parcial (intervalo para as estimativas), em vez de estimação pontual. O parâmetro M controla quanto o desvio é maior em relação ao observado no pré-teste. Se M é igual a 1, temos o mesmo desvio no máximo. Se M igual a 2, duas vezes maior e assim por diante. library(HonestDiD) library(tidyverse) library(knitr) library(fixest) # Install remotes package if not installed #install.packages(&quot;remotes&quot;) # Turn off warning-error-conversion, because the tiniest warning stops installation #Sys.setenv(&quot;R_REMOTES_NO_ERRORS_FROM_WARNINGS&quot; = &quot;true&quot;) # install from github #remotes::install_github(&quot;asheshrambachan/HonestDiD&quot;) # Run model # twfe_results &lt;- feols(rating ~ i(goodr, qa) | year_month + asin, # cluster = c(&quot;asin&quot;), # data = GoodAma) # # fixest::iplot(twfe_results) # # # Save coefficients # betahat &lt;- summary(model_4)$coefficients # # # Save the covariance matrix # sigma &lt;- summary(model_4)$cov.scaled # # ## Identificação Parcial # # delta_rm_results &lt;- createSensitivityResults_relativeMagnitudes( # betahat = betahat, #coefficients # sigma = sigma, #covariance matrix # numPrePeriods = 1, #num. of pre-treatment coefs # numPostPeriods = 1, #num. of post-treatment coefs # Mbarvec = seq(0.5,2,by=0.5) #values of Mbar # ) # # delta_rm_results %&gt;% # kable() 8.7 Múltiplos períodos pós-tratamento Provavelmente, \\(\\tau\\) não é constante no tempo e entre unidades. Efeito do tratamento pode depender de quando começou. Pode depender da duração. Precisamos de um modelo mais sofisticado de regressão. O modelo que fizemos estima uma média dos efeitos. É preciso ter cuidado, pois se a amostra não for completa (não-balanceada), pode gerar problemas. A primeira extensão do modelo é considerar um did dinâmico. Como fazemos isso? \\[ Y_{g,t} = \\alpha_i + \\lambda_t + \\sum_{t=1, t \\neq t_0}^T \\delta_t D_{gt} + e_{gt} \\] Essa equação toma como referência o período \\(t_0\\), em que o tratamento foi implementado (para todas as unidades tratadas) ao mesmo tempo. Um dos coeficientes é não identificado por causa do \\(\\alpha_i\\), por isso precisamos excluir um período como categoria de referência. E todos os coeficientes medem o efeito relativo ao período \\(t_0\\) de referência. Suposição de PT foi mais forte no modelo acima: \\(Y_{g,t}(d) - Y_{g,t-k}(d) = \\lambda_t - \\lambda_{t-k}\\) para todos os \\(k\\) e \\(d\\). Podemos testar pré-tratamento. 8.8 Análise de sensibilidade em DiD \\[ y_{gt} = \\alpha_g + \\lambda_t + \\tau_{gt}D_{it} + e_{gt} \\] Podemos pensar que o \\(\\tau\\) é a média dos \\(\\tau_{gt}\\). Veja que se nós pudéssemos reescrever a equação de regressão como \\(y_{gt} -\\alpha_g - \\lambda_t = \\tau_{gt}D_{it} + e_{gt}\\), bastaria rodar um modelo de OLS tradicional e estimar essa média. Nossa vd seria \\(y_{gt} -\\alpha_g - \\lambda_t\\) e o tratamento uma variável binária indicando se o tratamento ocorreu. Acontece que não sabemos os efeitos fixos. E se nós estimarmos eles? Utilizando o teorema FWL, temos: Primeiro, extraio os resíduos de uma regressão apenas com os efeitos fixos: \\[ y_{gt} = \\alpha_g + \\lambda_t + \\text{resíduos}_Y \\] Se chamar os resíduos de \\(\\tilde{y}_{gt}\\), tenho tudo de \\(y_{gt}\\) que não é explicado pelos efeitos fixos. E posso reescrever: \\(y_{gt} = \\alpha_g + \\lambda_t + \\text{resíduos}_Y\\) como \\(\\tilde{y}_{gt} = y_{gt} -\\alpha_g - \\lambda_t\\). Em seguida, residualizo o tratamento: \\[ D_{gt} = \\alpha_g + \\lambda_t + \\text{resíduos}_D \\] Novamente, vou chamar os resíduos de \\(\\tilde{D}_{gt}\\) Então, posso rodar uma regressão \\(\\tilde{y}_{gt} = \\tilde{D}_{gt} + e_{gt}\\). Ou ainda: \\[ y_{gt} - \\tilde{\\alpha}_g - \\tilde{\\lambda}_t = \\tau_{gt}\\tilde{D}_{it} + e_{gt} \\] Essa regressão estima \\(\\hat{\\tau} = \\sum w_{gt}\\tau_{gt} \\neq \\tau\\). Esses pesos podem até mesmo ser negativos e a estimativa \\(\\hat{\\tau}\\) ter sinal oposto a \\(\\tau\\). A intuição é porque estamos comparando bananas com laranjas. Há grupos que são tratados em momentos distintos, e dependendo do tamanho dos efeitos em cada momento do tempo, a média ponderada dessas comparações dá algo estranho. A solução proposta do Gardner de regressão DiD em dois estágios é justamente evitar esse problema rodando \\(y_{gt} - \\tilde{\\alpha}_g - \\tilde{\\lambda}_t = \\tau_{gt}D_{it} + e_{gt}\\). Estágio 1: Estime os efeitos fixos usando observações não tratadas ou ainda não tratadas. Estágio 2. Rode a regressão \\(y_{gt} - \\tilde{\\alpha}_g - \\tilde{\\lambda}_t = \\tau_{gt}D_{it} + e_{gt}\\). Obviamente, o cálculo do erro padrão se torna mais complexo nesse caso, pois há ruído extra introduzido na nova VD. Felizmente, o pacote {did2s} faz tudo isso pra gente. Se você olhar os papers mais recentes publicados nos top journals, eles estão usando esse tipo de estimador. 8.9 DiD generalizado Nós permitimos que cada unidade, por exemplo, tenha sua própria tendência. Ou que o resultado potencial do controle (não-tratado) dependa de covariáveis que variam no tempo, ou seja, a tendência paralela é condicional às covariáveis. A única coisa não permitida é interação entre efeitos fixos de unidade e tempo. did_din = feols(concluida ~ i(periodo, group_treated, ref=3) | id + periodo, data_ot) summary(did_din) ## OLS estimation, Dep. Var.: concluida ## Observations: 22,609 ## Fixed-effects: id: 4,530, periodo: 5 ## Standard-errors: Clustered (id) ## Estimate Std. Error t value Pr(&gt;|t|) ## periodo::1:group_treated -0.009828 0.028085 -0.349923 7.2641e-01 ## periodo::2:group_treated -0.004025 0.018226 -0.220847 8.2522e-01 ## periodo::4:group_treated 0.022207 0.015355 1.446207 1.4819e-01 ## periodo::5:group_treated 0.143744 0.033830 4.249033 2.1901e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## RMSE: 0.247446 Adj. R2: 0.685451 ## Within R2: 0.002541 Até aqui, consideramos cenários em que o tratamento é implementado simultaneamente para todas as unidades tratadas. Contudo, em muitas aplicações, o tratamento é adotado em momentos diferentes por diferentes unidades. 8.10 DID com adoção escalonada (staggered timing) No meu exemplo, tratamento foi o mesmo para todas as unidades ao mesmo tempo. Mas é comum que não aconteça assim. Qual é o estimando quando tenho adoção escalonada no tempo? Com quem estou comparando? Digamos que quero ver o efeito da biometria sobre comparecimento eleitoral. Como ela foi escalonada no tempo, podemos adotar um modelo de DiD. Nesse caso, uma vez implementado (turned on), não volta atrás (turn off). Porém, há casos em que a política pode ser ativada ou desativada. Exemplo: política de uso de câmeras corporais pela polícia. Tarcísio desativou por um tempo (STF impediu). Isso cria complicações para definir o grupo de controle adequado. 8.11 Paper Voter Gratitude Last Long? library(haven) elbe1994_98 &lt;- read_dta(here(&quot;Dados&quot;, &quot;Elbe&quot;, &quot;1994_1998.dta&quot;)) elbe0 &lt;- elbe1994_98 %&gt;% dplyr::select(wkr, wkrname, year, spd_z_vs, Flooded) elbe1998_02 &lt;- read_dta(here(&quot;data&quot;, &quot;Elbe&quot;, &quot;1998_2002.dta&quot;)) elbe1 &lt;- elbe1998_02 %&gt;% dplyr::select(wkr, wkrname, year, spd_z_vs, Flooded) %&gt;% dplyr::filter(year == 2002) elbe1998_05 &lt;- read_dta(here(&quot;data&quot;, &quot;Elbe&quot;, &quot;1998_2005.dta&quot;)) elbe2 &lt;- elbe1998_05 %&gt;% dplyr::filter(year == 2005) %&gt;% dplyr::select(wkr, wkrname, year, spd_z_vs, Flooded) elbe &lt;- bind_rows(elbe0, elbe1, elbe2) did_short &lt;- feols(spd_z_vs ~ Flooded| wkr + year, cluster = &quot;wkr&quot;, data = elbe1998_02) summary(did_short) ## OLS estimation, Dep. Var.: spd_z_vs ## Observations: 598 ## Fixed-effects: wkr: 299, year: 2 ## Standard-errors: Clustered (wkr) ## Estimate Std. Error t value Pr(&gt;|t|) ## Flooded 7.14401 0.468184 15.259 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## RMSE: 1.80615 Adj. R2: 0.905029 ## Within R2: 0.255154 did_din = feols(spd_z_vs ~ i(year, Flooded, ref=1998) | wkr + year, elbe) summary(did_din) ## OLS estimation, Dep. Var.: spd_z_vs ## Observations: 1,254 ## Fixed-effects: wkr: 328, year: 4 ## Standard-errors: Clustered (wkr) ## Estimate Std. Error t value Pr(&gt;|t|) ## year::2002:Flooded 0.458643 1.52364 0.301018 0.7635917 ## year::2005:Flooded -4.806790 1.34447 -3.575220 0.0004027 *** ## ... 1 variable was removed because of collinearity (year::1994:Flooded) ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## RMSE: 4.71647 Adj. R2: 0.591674 ## Within R2: 0.017113 Sys.setenv(RGL_USE_NULL = TRUE) library(DIDmultiplegtDYN) elbe_het &lt;- elbe %&gt;% rename(Y = spd_z_vs, G = wkr, D = Flooded, T = year) did_het &lt;- did_multiplegt_dyn( df = elbe, outcome = &quot;spd_z_vs&quot;, group = &quot;wkr&quot;, time = &quot;year&quot;, treatment = &quot;Flooded&quot;, effects = 2, placebo = 2, cluster = &quot;wkr&quot; ) summary(did_het) ## ## ---------------------------------------------------------------------- ## Estimation of treatment effects: Event-study effects ## ---------------------------------------------------------------------- ## Estimate SE LB CI UB CI N Switchers ## Effect_1 0.20036 0.69213 -1.15620 1.55692 874 65 ## Effect_2 -3.75276 1.14577 -5.99843 -1.50709 557 40 ## ## Test of joint nullity of the effects : p-value = 0.0000 ## ---------------------------------------------------------------------- ## Average cumulative (total) effect per treatment unit ## ---------------------------------------------------------------------- ## Estimate SE LB CI UB CI N Switchers ## -1.47405 0.95447 -3.34478 0.39667 914 105 ## Average number of time periods over which a treatment effect is accumulated: 1.6882 ## ## ---------------------------------------------------------------------- ## Testing the parallel trends and no anticipation assumptions ## ---------------------------------------------------------------------- ## Estimate SE LB CI UB CI N Switchers ## 0.37683 0.40786 -0.42256 1.17622 546 29 ## ## ## ## ## The development of this package was funded by the European Union. ## ERC REALLYCREDIBLE - GA N. 101043899 did_short &lt;- feols(spd_z_vs ~ Flooded| wkr + year, cluster = &quot;wkr&quot;, data = elbe1998_02) summary(did_short) ## OLS estimation, Dep. Var.: spd_z_vs ## Observations: 598 ## Fixed-effects: wkr: 299, year: 2 ## Standard-errors: Clustered (wkr) ## Estimate Std. Error t value Pr(&gt;|t|) ## Flooded 7.14401 0.468184 15.259 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## RMSE: 1.80615 Adj. R2: 0.905029 ## Within R2: 0.255154 did_din = feols(spd_z_vs ~ i(year, Flooded, ref=1998) | wkr + year, elbe) summary(did_din) ## OLS estimation, Dep. Var.: spd_z_vs ## Observations: 1,254 ## Fixed-effects: wkr: 328, year: 4 ## Standard-errors: Clustered (wkr) ## Estimate Std. Error t value Pr(&gt;|t|) ## year::2002:Flooded 0.458643 1.52364 0.301018 0.7635917 ## year::2005:Flooded -4.806790 1.34447 -3.575220 0.0004027 *** ## ... 1 variable was removed because of collinearity (year::1994:Flooded) ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## RMSE: 4.71647 Adj. R2: 0.591674 ## Within R2: 0.017113 8.12 Resumo e próximos passos Neste capítulo, introduzimos o estimador de Diferença em Diferenças e a suposição central de tendências paralelas. Vimos como o DiD pode ser estimado por TWFE e como extensões recentes lidam com efeitos heterogêneos, múltiplos períodos e adoção escalonada do tratamento. A análise de sensibilidade de Rambachan e Roth (2023) é uma ferramenta importante para avaliar a robustez dos resultados quando tendências paralelas não são exatamente satisfeitas. No próximo capítulo, discutiremos dados de painel (TSCS) de forma mais geral, incluindo as suposições de exogeneidade estrita e sequencial. 8.13 Referências de Chaisemartin, C., &amp; D’Haultfœuille, X. (2023). Credible answers to hard questions: Differences-in-differences for natural experiments. Available at SSRN. Rambachan, A., &amp; Roth, J. (2023). A more credible approach to parallel trends. Review of Economic Studies, 90(5), 2555-2591. "],["time-series-cross-section-tscs.html", "Capítulo 9 Time-Series Cross-Section (TSCS) 9.1 Introdução 9.2 OVB 9.3 Estimandos 9.4 Resultados Potenciais 9.5 Modelo AR(1) 9.6 Sequential ignorability 9.7 Resumo 9.8 Suposições para Inferência 9.9 Efeitos aleatórios 9.10 Referências", " Capítulo 9 Time-Series Cross-Section (TSCS) 9.1 Introdução Dados de Painel são definidos como consistindo de observações repetidas de uma mesma unidade \\(i = 1, \\ldots, N\\) no período \\(t = 1, \\ldots, T\\). O termo dados de painel tem origem em surveys em ondas, em que o mesmo indivíduo era rastreado ao longo do tempo. Em ciência política também chamamos esse tipo de dado de Time-Series Cross-Section, TSCS abreviado. É basicamente a mesma coisa. A distinção foi introduzida na literatura de ciência política porque tipicamente surveys em ondas possuem \\(T\\) pequeno, enquanto dados de TSCS (país, estados, municípios) típicos da política comparada e Relações Internacionais possuem \\(T\\) “grande”, eventualmente maior do que \\(N\\) (exemplo, países da OCDE ao longo de 50 anos, estados brasileiros ao longo de 30 anos etc.). Uma observação de uma Vd e uma VI é dada pelo par \\((y_{it}, x_{it})\\), em que \\(i\\) indexa a unidade e \\(t\\) o tempo. Tradicionalmente a literatura categorizava os dados de painel em balanceados (mesmo período de tempo para todas as unidades) e não-balanceados (períodos de tempo diferentes para as unidades). Essa terminologia confunde com nossa ideia de balanceamento em matching, de forma que mais recentemente tem sido substituída por dados completos (todas as unidades são observadas pelo mesmo período \\(T\\)) ou incompletos (algumas observações são ausentes para alguns períodos de algumas unidades). Em TSCS, podemos ter países que deixam de existir (URSS, Iugoslávia) ou serem criados (Sérvia, Montenegro). Isso vale também para estados e municípios. Não é muito claro que pensar como dados ausentes faz sentido, pois não é que não foram observados (como em um survey), mas a entidade nem existe mais (ou passou a existir apenas após um tempo). Isso cria potencialmente alguns tipos de problemas que a literatura metodológica basicamente tem ignorado. Em meu doutorado, eu estudei o efeito de regimes políticos sobre a adesão a tratados de patentes. Porém, não é muito claro se a adesão da URSS em um período \\(t^{\\star}\\) deve ser atribuída à Rússia em (\\(t &gt; t^{\\star}\\)). E no caso da Iugoslávia? Ou Sérvia e Montenegro, que posteriormente se dividiram? As consequências dessas decisões são uma questão tanto substantiva quanto metodológica. Mas, até onde sei, pouco ou nada investigada. Os dados podem ser organizados no banco de dados em dois formatos: long e wide. O formato long, que é o padrão, organiza os dados com a coluna de unidade repetindo nas linhas tantas vezes quanto observações no tempo existirem. Já o formato wide apresenta cada unidade aparecendo em uma única linha. long vs wide format. Fonte: https://tavareshugo.github.io/r-intro-tidyverse-gapminder/09-reshaping/index.html 9.1.1 Within versus Between Uma distinção importante quando se trata de dados de painel é entre variação within subject e between subject. Para entender essa distinção, contrastemos dois estudos hipotéticos. Em um estudo “within subject”, cada indivíduo é exposto às múltiplas versões do tratamento (ex. tratamento e controle) e analisamos como os indivíduos mudaram entre exposições às variações do tratamento. Em um desenho “between-subject”, aleatorizamos o tratamento e controle em dois grupos de indivíduos, os tratados e não-tratados e comparamos a diferença na variável resposta dos dois grupos. Em dados de painel, a questão retorna, pois observamos as mesmas unidades repetidamente no tempo. Isso quer dizer que podemos, potencialmente, fazer comparações entre unidades (“between”) e intra-unidades (within). Imagine que tenho uma variável \\(y_{it}\\) medida para \\(N\\) indivíduos em \\(T\\) períodos, por exemplo, intenção de voto no candidato democrata. Posso então fazer os seguintes cálculos: média individual: \\(\\bar{x}_i = \\frac{1}{T}\\sum_{t=1}^T x_{it}\\). Ou seja, média de intenção de votos de cada indivíduo nos \\(T\\) períodos. média temporal: \\(\\bar{x}_t = \\frac{1}{N}\\sum_{i=1}^N x_{it}\\). Ou seja, a média de intencão de voto de cada período de tempo. Média geral: \\(\\bar{x} = \\frac{1}{NT}\\sum_{i=1}^N\\sum_{t=1}^T x_{it}\\) Podemos então definir a variação between: \\(B = \\sum_{i=1}^N n_i(\\bar{x}_i - \\bar{x})^2\\). Se o painel é completo, a fórmula simplifica para: \\(B = n\\sum_{i=1}^N(\\bar{x}_i - \\bar{x})^2\\). Veja que essa fórmula mede quanto de variação temos nos dados que se deve à variação entre unidades. Para definir a variação within, temos: Para um dado indivíduo \\(i\\), a variabilidade das suas observações ao longo do tempo, em relação à sua média \\(\\bar{x}_i\\), é dada por \\(\\sum_t (x_{it} - \\bar{x}_i)^2\\). Se quisermos medir a soma total da variação within, podemos então definir: \\(W = \\sum_{i=1}^N \\sum_{t=1}^{n_i}(x_{it} - \\bar{x}_i)^2\\). A variação total, ou seja, a soma da variação em torno da média geral, é dada por: \\(\\sum_{i=1}^N\\sum_{t=1}^{n_i} (x_{it} - \\bar{x})^2 = W + B\\) Com essa estrutura de dados em mente, podemos agora discutir o principal desafio em dados de painel: o viés de variável omitida causado por características não observadas das unidades. 9.2 OVB Suponha o DAG abaixo, em que \\(a\\), uma variável invariante no tempo é não observada: library(ggdag) dag &lt;- dagify( y ~ x + a, x ~ a, latent = &quot;a&quot; ) ggdag(dag) Ela leva ao clássico problema de variável omitida. Dados de painel nos permitem remover essa variável de confusão. Há várias formas de mostrar isso, e vou optar pela abordagem de centrar as variáveis. Suponha uma forma paramétrica do modelo estrutural dado por: \\(y_{it} = \\alpha + \\beta_0 x_{it} + a_i + e_{it}\\). Suponha, para simplificar, que o painel é completo. Agora, considerem os seguintes passos: \\[\\begin{aligned} \\bar{y}_i &amp;= \\frac{1}{T}\\sum_{t=1}^T y_{it} \\\\ &amp;= \\frac{1}{T}\\sum_{t=1}^T (\\alpha + \\beta_0 x_{it} + a_i + e_{it}) \\\\ &amp;= \\frac{1}{T}\\sum_{t=1}^T \\alpha + \\frac{1}{T}\\sum_{t=1}^T\\beta_0 x_{it} + \\frac{1}{T}\\sum_{t=1}^T a_i + \\frac{1}{T}\\sum_{t=1}^Te_{it} \\\\ &amp;= \\alpha + \\frac{\\beta_0}{T}\\sum_{t=1}^T x_{it} + a_i + \\frac{1}{T}\\sum_{t=1}^Te_{it} \\\\ &amp;= \\alpha + \\beta_0 \\bar{x}_i + a_i + \\bar{e}_i \\end{aligned}\\] Agora, definindo \\(\\tilde{y}_{it} = y_{it} - \\bar{y}_i\\), temos: \\[\\begin{aligned} \\tilde{y}_{it} &amp;= y_{it} - \\bar{y}_i \\\\ &amp;= \\alpha + \\beta_0 x_{it} + a_i + e_{it} - (\\alpha + \\beta_0 \\bar{x}_i + a_i + \\bar{e}_i) \\\\ &amp;= (\\alpha - \\alpha) + (\\beta_0 x_{it} - \\beta_0 \\bar{x}_i) + (a_i - a_i) + (e_{it} - \\bar{e}_i) \\\\ &amp;= \\beta_0(x_{it} - \\bar{x}_i) + (e_{it} - \\bar{e}_i) \\\\ &amp;= \\beta_0 \\tilde{x} + \\tilde{e}_{it} \\text{, em que } \\tilde{x} = x_{it} - \\bar{x}_i \\text{ e } \\tilde{e}_{it} = e_{it} - \\bar{e}_i \\end{aligned}\\] Temos então um modelo de regressão em que os \\(a_i\\) foram removidos da equação estrutural e, portanto, não podem mais causar viés de variável omitida. A pergunta para vocês agora é: qual o estimando que tal estimador estima? Pensem antes de responder… Vamos formular a questão um pouco em termos de resultados potenciais. Tendo discutido o modelo clássico de efeitos fixos e aleatórios, vejamos agora como formalizar os estimandos de interesse em TSCS usando a linguagem de resultados potenciais. 9.3 Estimandos Há muitos estimandos possíveis com dados TSCS. Eis alguns possíveis estimandos de interesse (baseado em Blackwell e Glynn, 2018). Antes, vamos definir: todos os tratamentos para uma dada unidade formam a história do tratamento \\(X_i = \\{x_{i1}, x_{i2}, \\cdots, x_{iT}\\}\\). A história parcial dos tratamentos até \\(t\\) é \\(X_{i, 1:t} = \\{x_{i1}, x_{i2}, \\cdots, x_{it}\\}\\). Variáveis de controle \\(W\\) podem ser definidas de maneira similar. O efeito de uma história de tratamento. Posso estar interessado em entender o efeito de uma particular história em contraposição a outra. Digamos, um país que sempre foi democracia versus um que sempre foi ditadura. Em termos de resultados potenciais: \\(Y_{it}(X_{i, 1:t}) - Y_{it}(X^{\\prime}_{i, 1:t})\\), em que \\(\\prime\\) indica uma história alternativa. No caso, \\(Y_{it}(1, 1, \\cdots, 1)\\) versus \\(Y_{it}(0, 0, \\cdots, 0)\\). Como sempre, nosso estimando típico é uma média, isto é: \\(\\tau_{X_{i, 1:t}, X^{\\prime}_{i, 1:t}} = \\mathbb{E}[Y_{it}(X_{i, 1:t}) - Y_{it}(X^{\\prime}_{i, 1:t})]\\). Obviamente, existem muitas combinações de histórias possíveis (de fato, \\(2^t\\) se o tratamento é binário). Como vamos observar muitas histórias distintas, teremos em geral poucas ou nenhuma observação de uma dada história para estimar o efeito causal com precisão. Efeito de história parcial (recente) do tratamento. Vamos definir resultado potencial dos últimos \\(j\\) períodos \\(Y_{it}(X_{t-j:t}) = Y_{it}(X_{i,1: t-j-1}, X_{t-j:t})\\). Nós interpretamos essa quantidade como o efeito causal de observar a história até o período \\(t-j-1\\) e então fixar o valor do tratamento na história \\(X_{t-j,:t}\\). Efeito Contemporâneo do Tratamento (Contemporaneous Treatment Effect, CET): \\(\\tau_c(t) = \\mathbb{E}[Y_{it}(X_{i,1: t-j-1}, X_{t-j:1}) - Y_{it}(X_{i,1: t-j-1}, X_{t-j:0})]\\). Ou seja, deixamos as unidades terem qualquer história, e investigamos o efeito do tratamento no último período. Veja que estamos calculando a média sobre todas as histórias até o período \\(t\\). 9.4 Resultados Potenciais Vamos considerar, inicialmente, um caso de dois períodos e em que indivíduos são tratados nos dois períodos ou não tratados nos dois períodos. Isso significa que de quatro resultados potenciais possíveis \\(Y_i(0,0), Y_i(0,1), Y_i(1,0), Y_i(1,1)\\) só observamos \\(Y_i(0,0), Y_i(1,1)\\). Digamos que estamos interessados em \\(\\mathbb{E}[Y_i(1,1) - Y_i(0,0)]\\). Se a sequência de tratamento for atribuída aleatoriamente, isto é, sorteamos que irá receber \\(x_i = (1,1)\\) e \\(x_i = (0,0)\\), então podemos utilizar os resultados observados para recuperar nosso estimando: \\(\\mathbb{E}[Y_i|x_{i1} = 1, x_{i2}=1] - \\mathbb{E}[Y_i|x_{i1} = 0, x_{i2}=0]\\). Veja que nós aleatorizamos a sequência dos tratamentos. Tal tipo de aleatorização implica que exogeneidade estrita é satisfeita, que formalizamos a seguir com resultados potenciais: \\[ Y_{it}(1), Y_{it}(0) \\perp x_{it}|\\mathbf{W}^{1:T}_i, a_i, \\mathbf{f}^{1:T}\\text{, para todo } i, t, s, \\] As variáveis em negrito indicam que são (potencialmente) um vetor de variáveis. A suposição de exogeneidade estrita implica a suposição de tendências paralelas. Em palavras, essa suposição (que é uma restrição de exclusão) quer dizer que: não há time-varying confoundings; Resposta passada não causa diretamente resposta presente, isto é, sem flecha de \\(y_{t-1}\\) para \\(y_t\\); Sem feedback de variáveis causadas por tratamentos passados (resultados passados ou outras covariáveis) e o status de tratamento corrente e futuro. Ou seja, sem flechas de \\(y_{t-1}\\) para \\(x_t\\) ou de \\(w_{t-1}\\) para \\(x_t\\). Sem “carryover effects” do tratamento presente para resultados futuros, ou seja, sem flecha de \\(x_{t-1}\\) para \\(y_t\\) ou \\(y_{t+1}\\). Qualquer violação de uma ou mais condições acima implica que a suposição de exogeneidade estrita não foi satisfeita. O DAG abaixo apresenta exogeneidade estrita para um caso simplificado de três períodos: Obviamente, essa restrição de exclusão é difícil de ser satisfeita na prática. Se supusermos \\(\\mathbb{E}[e_t|x_{t1}, x_{t2}, \\cdots, x_{tk}]=0\\), temos o que chamamos de exogeneidade contemporânea, ou seja, as variáveis independentes e o termo de erro são não-correlacionadas no tempo \\(t\\). Isso, porém, não garante que o estimador de OLS é não-viesado. Para obtermos um estimador não-viesado, precisamos supor exogeneidade estrita: É possível mostrar, porém, que o estimador de OLS é consistente com exogeneidade contemporânea. Vale destacar que exogeneidade estrita exclui a possibilidade de que o termo de erro no presente possa causar mudanças futuras em \\(x\\). Ou seja, não pode haver feedback do \\(y\\) para futuros valores de \\(x\\). Em outras palavras, tratamentos estritamente exógenos não podem reagir pelo que aconteceu com o \\(y\\) no passado. Considere o que a literatura chama de Distributed Lag Model (DLM), que basicamente consiste em introduzir valores defasados (além do presente) do tratamento. O modelo simples fica: \\[ y_{it} = \\alpha + \\beta_1x_{it} + \\beta_2 x_{it-1} + \\cdots + \\beta_k x_{it-k} + e_{it} \\] Um modelo relacionado, chamado de ADL (autoregressive distributed lag) inclui a VD defasadada: Se for um AR(1), temos: \\[ y_{it} = \\alpha + \\alpha_1y_{it-1} + \\beta_1x_{it} + \\beta_2 x_{it-1} + e_{it} \\] Vale a pena escrever a equação de resultados potenciais implicada por esse modelo: \\[ Y_{it}(x_{1:t}) = \\alpha + \\alpha_1 y_{it-1}(x_{1:t-1}) + \\beta_1x_{it} + \\beta_2 x_{it-1} + e_{it} \\] Nessa formulação fica claro porque é difícil interpretar o efeito causal do tratamento em \\(t-1\\), pois ele tem um efeito direto, via \\(\\beta_2\\) e um efeito indireto, via \\(y_{it-1}\\). 9.5 Modelo AR(1) Considere o modelo AR(1): \\[ y_{t} = \\beta_0 + \\beta_1 y_{t-1} + e_t \\] Suponha ademais que \\(\\mathbb{E}[e_t|y_{t-1}, y_{t-2}, ...] = 0\\). Esse pressuposto implica que \\(\\mathbb{E}[y_{t}|y_{t-1}, y_{t-2}, ...] = \\mathbb{E}[\\beta_0 + \\beta_1 y_{t-1} + e_t|y_{t-1}, y_{t-2}, ...] = \\beta_0 + \\beta_1\\mathbb{E}[y_{t-1}|y_{t-1}, y_{t-2}, ...] + 0 = \\beta_0 + \\beta_1 y_{t-1}\\). Portanto, \\(e_t\\) e \\(y_{t}\\) são correlacionados. O modelo AR(1), isto é, com VD defasada, viola exogeneidade estrita. 9.6 Sequential ignorability Uma suposição alternativa e menos demandante é a de ignorability sequencial (sequential ignorability). O experimento equivalente a essa suposição seria quando, em cada período, o tratamento \\(x_{it}\\) é aleatorizado condicional aos valores passados do tratamento e covariáveis variantes no tempo (incluindo valores passados da variável resposta, \\(y\\)). O DAG abaixo ilustra a suposição de ignorability sequencial. 9.7 Resumo A princípio, e de maneira mais geral, se a história importa (isto é, os estados passados, bem como sua ordem importam), o que Scott Page (2006) chamou de path dependence, então precisamos escrever os resultados potenciais de um indivíduo \\(i\\) em \\(t = 1, \\cdots, T\\), para um tratamento binário \\(x_{it} \\in \\{0,1\\}\\) da seguinte forma: \\[ y(x_{i1}, x_{i2}, \\cdots, x_{it}, \\cdots x_{iT}) \\] Em que o valor de \\(x_{it} \\in \\{0,1\\}\\) determina se, naquele período, o indivíduo foi tratado ou não. Se a história importa, no sentido de path dependence, então cada sequência é substantivamente diferente. Uma outra possibilidade é que importe quantos tratamentos e controles a unidade recebeu, mas não a ordem. Nesse caso: \\[ y(x_{i1}, x_{i2}, \\cdots, x_{it}, \\cdots x_{iT}) = y(\\sum_{t=1}^T x_{it}) \\] Para uma dada unidade \\(i\\) no tempo \\(t\\), e supondo um tratamento binário \\(x_{it}\\), o resultado potencial é: \\(Y(1)_{it}\\) para o tratamento, e \\(Y(0)_{it}\\) para o controle. Uma suposição implícita na nossa derivação é que se eu denotar a sequência (ou caminho) de tratamento e controle no tempo por algo como \\(Y(1,0,..., 1)_{it^{\\star}}\\) para uma resposta em \\(t^{\\star} &gt; 1\\), a história dos resultados potenciais é irrelevante, de modo que posso simplesmente escrever \\(Y(1)_{it^{\\star}}\\) e similarmente para o controle. Então, sabemos que \\(Y(1)_{it^{\\star}} = \\alpha + \\beta_0 x_{it^{\\star}} + a_i + e_{it^{\\star}}\\) e \\(Y(0)_{it^{\\star}} = \\alpha + a_i + e_{it^{\\star}}\\). O efeito do tratamento entre indivíduos no período \\(t^{\\star}\\) é dado justamente por \\(Y(1)_{it^{\\star}} - Y(0)_{it^{\\star}} = \\alpha + \\beta_0 x_{it^{\\star}} + a_i + e_{it^{\\star}} - (\\alpha + a_i + e_{it^{\\star}}) = \\beta_0 x_{it^{\\star}}\\). Como só posso observar um dos resultados potenciais para cada indivíduo no período \\(t^{\\star}\\), parece natural pensar que inha regressão de efeitos. 9.7.1 Remark Sob a suposição de exogeneidade contemporânea, o estimador de OLS é consistente, isto é, converge para o verdadeiro valor do parâmetro quando a amostra vai para infinito. Supondo que a série é estacionária e fracamente dependente. Formalmente, a dependência fraca implica que \\(|\\beta_1| &lt; 1\\). 9.8 Suposições para Inferência Para fazer inferência (calcular o erro padrão e fazer testes de hipótese, por exemplo), precisamos supor, além da exogeneidade estrita, a suposição de não-correlação serial. Ou seja, Conditional on X, the errors in two different time periods are uncorrelated: Corr ut,us X 5 0, for all t 2 s. 9.8.1 Remark Problemas de correlação serial impactam o cálculo do erro padrão, mas não o viés. 9.9 Efeitos aleatórios Um modelo simples de efeito aleatório é dado por: \\(y_{it} = \\beta_{0t} + \\beta_1 x_{it} + e_{it}\\), micro model \\(\\beta_{0t} = \\beta_0 + \\beta_2 z_t + \\mu_t\\), macro model Modelo completo: \\[ y_{it} = \\beta_0 + \\beta_2 z_t + \\beta_1 x_{it} + (e_{it} + \\mu_t) \\] A parte “fixa” é \\(\\beta_0 + \\beta_2 z_t + \\beta_1 x_{it}\\) e a parte “aleatória” é \\(e_{it} + \\mu_t\\). Tipicamente, assumimos que \\(\\mu_t \\sim N(0, \\sigma^2_{\\mu})\\) e \\(e_{it} \\sim N(0, \\sigma^2_e)\\). Isso é também chamado de partial pooling (shrinkage), pois os “varying-intercept” possuem uma distribuição comum, com variância estimada pelos dados. Vejam que, se \\(\\sigma^2_{\\mu} = 0\\), então os interceptos são todos iguais, e temos uma “pooled regression”. Se \\(\\sigma^2_{\\mu} \\to \\infty\\), então cada intercepto poderia ser estimado separadamente para cada \\(t\\): “unpooled regression”. A suposição de identificação é: \\[ \\mathbb{E}[e_{it}|x_{it}, z_t] = 0 \\] e \\[ \\mathbb{E}[\\mu_{t}|x_{it}, z_t] = 0 \\] As implicações dos dois pressupostos são que \\(Cov(e_{it},x_{it}) = 0\\) e \\(Cov(\\mu_{t},x_{it}) = 0\\). Vamos comparar com o modelo de efeitos fixos, mas usando outra formulação. O modelo padrão com variáveis binárias pode ser escrito como: \\[ y_{it} = \\sum_{t=1}^T \\beta_{0t} D_t + \\beta_1 x_{it} + e_{it} \\] Nós podemos estimar esse modelo diretamente, e nesse caso teremos uma estimativa para os efeitos fixos \\(\\beta_{0t}\\). Porém, tipicamente eles não são de interesse, e portanto, uma outra parametrização equivalente mostra a suposta vantagem dos efeitos fixos. Vamos centrar todas as variáveis do modelo. Primeiro, vamos definir: \\(\\bar{y}_t = \\sum_{i=1}^N y_{it}\\) \\(\\bar{x}_t = \\sum_{i=1}^N x_{it}\\) \\(\\bar{e}_t = \\sum_{i=1}^N e_{it}\\) \\(\\bar{z}_t = \\sum_{i=1}^N z_{it}\\) Defina a equação de regressão centrada na média como: \\[ \\bar{y}_t = \\frac{1}{N} \\sum_{i=1}^N y_{it} = \\frac{1}{N} \\sum_{i=1}^N (\\beta_0 + \\beta_2 z_{it} + \\beta_1 x_{it} + \\mu_t + e_{it})= \\beta_0 + \\beta_2\\bar{z_{t}} + \\beta_1\\bar{x}_t + \\mu_t + \\bar{e}_t \\] Subtraindo esta equação da original, temos: \\[ y_{it} - \\bar{y_{t}} = \\beta_2 (z_t - \\bar{z_{t}}) + \\beta_1 (x_{it} - \\bar{x_{t}}) + (e_{it} - \\bar{e}_t) \\] E eliminamos o intercepto e os efeitos fixos da equação, de modo que não precisamos mais de nenhum pressuposto sobre os efeitos fixos e os termos de erro. O custo que nós pagamos é remover a variação entre unidades, ou seja, estamos estimando um modelo apenas com base na variação “within”, isto é, intra-unidades no tempo. Obviamente, não há nada especial em ter utilizado efeitos fixos de tempo. Poderíamos igualmente usar um efeito fixo de unidade, centrar e subtrair do modelo original, e obter estimativas apenas com variação entre unidades, mas não intra-unidades. O problema de OVB com efeitos aleatórios pode ser explicado da seguinte maneira (seguindo Bell e Jones, 2015). A variação no tratamento pode ser decomposta em: \\(x_{it} = x_t^B + x_{it}^W\\) No modelo de efeitos aleatórios \\(y_{it} = \\beta_0 + \\beta_2 z_t + \\beta_1 x_{it} + (e_{it} + \\mu_t)\\), implicitamente assumimos que o efeito between e within sao iguais. Quando são diferentes, \\(\\beta_1\\) é uma média ponderada dos dois processos, e isso produz justamente o OVB, porque o efeito between é omitido. Bell e Jones chamam de “heterogeneity bias”, para distinguir do clássico OVB. A solução proposta por Bell e Jones, ecoando Mundlak, é adicionar um termo que capture o efeito between: a média temporal. A equação fica então: \\(y_{it} = \\beta_0 + \\beta_2 z_t + \\beta_1 x_{it} + \\beta_3 \\bar{x}_t + (e_{it} + \\mu_t)\\). Essa equação pode ser reformulada para: \\[ y_{it} = \\beta_0 + \\beta_2 z_t + \\beta_1 (x_{it} - \\bar{x}_t) + \\beta_4 \\bar{x}_t + (e_{it} + \\mu_t) \\] \\(\\beta_1\\) é o efeito within, e \\(\\beta_4\\) é o efeito between. 9.10 Referências Bell, A., &amp; Jones, K. (2015). Explaining fixed effects: Random effects modeling of time-series cross-sectional and panel data. Political Science Research and Methods, 3(1), 133-153. Blackwell, M., &amp; Glynn, A. N. (2018). How to make causal inferences with time-series cross-sectional data under selection on observables. American Political Science Review, 112(4), 1067-1082. Page, S. E. (2006). Path dependence. Quarterly Journal of Political Science, 1(1), 87-115. "],["synthetic-control.html", "Capítulo 10 Synthetic Control 10.1 Implementação no R 10.2 Synthetic DiD 10.3 Resumo e próximos passos 10.4 Referências", " Capítulo 10 Synthetic Control Vamos começar com um exemplo, já famoso na literatura, de Controle Sintético. O estado da Califórnia implementou uma proibição de uso de cigarro e digamos que queremos ver o efeito dessa proibição, isto é, nosso estimando é \\(\\tau_{\\text{ban}, \\text{CA}} = Y(1)_{\\text{ban}, CA} - Y(0)_{\\text{ban}, \\text{CA}}\\). Como não observamos \\(Y(0)_{\\text{ban}, \\text{CA}}\\), temos de criar uma “Califórnia sintética”. Antigamente, iremos usar alguma média dos demais estados “não-tratados” para estimar o contrafactual. Contudo, não é muito convincente. state year cigsale retprice california after_treatment 1 1970 89.8 39.6 FALSE FALSE 1 1971 95.4 42.7 FALSE FALSE 1 1972 101.1 42.3 FALSE FALSE 1 1973 102.9 42.1 FALSE FALSE 1 1974 108.2 43.1 FALSE FALSE 1 1975 111.7 46.6 FALSE FALSE Suponha que obtivemos dados para \\(J+1\\) unidades para unidades \\(j = 1, 2, ..., J+1\\), e sem perda de generalidade, a primeira unidade \\(j=1\\) é a de tratamento ou sob intervenção. O grupo de unidades para comparação (donor pool) é dado por \\(j = 2, ..., J+1\\), uma coleção de unidades não-tratadas. Os dados são observados por \\(T\\) períodos \\(1, 2, ..., t_0, t_1, t_2, ..., T\\), em que de \\(1\\) até \\(t_0\\) nenhuma unidade foi tratada ou sofreu intervenção. Para cada unidade \\(j\\), observamos também um conjunto de \\(k\\) preditores, \\(X_{1j}, X_{2j}, ..., X_{kj}\\), que pode incluir valores pré-intervenção da variável resposta \\(y_{jt}\\). A ideia é usar uma combinação linear do donor pool, com pesos apropriados, para estimar o contrafactual, isto é, o resultado potencial dos tratados. Lembrando que o estimando usual de interesse é o ATT: \\[ \\mathbb{E}[Y(1)_{it}|D_{it}=1] - \\mathbb{E}[Y(0)_{it}|D_{it}=1] \\] A dificuldade, como sempre, é que não observamos \\(\\mathbb{E}[Y(0)_{it}|D_{it}=1]\\). Estimar ou imputar esse missing data a partir de uma média ponderada é o objetivo de nosso estimador. A ideia é um pouco parecida com matching, em que nós pareávamos unidades de controle com as tratadas, minimizando a distância a partir das covariáveis. Aqui, vamos fazer algo parecido, mas com uma diferença chave: vamos incluir nas covariáveis a variável resposta defasada. Esse método foi introduzido por Abadie et al. em um journal de ciência política. Vamos usar a abordagem de Doudchenko e Imbens (2018) para apresentar o método, pois vai facilitar a introdução posterior de diferença em diferenças sintéticas. Nossos dados podem ser organizados da seguinte forma: 10.0.1 Tratamento Suponha, como no caso da proposição 99, que temos uma unidade tratada e o tratamento é absorvente. O banco de dados para o tratamento pode ser representado como: \\[\\begin{aligned} D \\;=\\; \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; \\cdots 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; \\cdots 0 &amp; 0\\\\ \\vdots \\\\ 0 &amp; 0 &amp; 0 &amp; \\cdots 0 &amp; 1\\\\ 0 &amp; 0 &amp; 0 &amp; \\cdots 0 &amp; 1\\\\ \\end{bmatrix} \\end{aligned}\\] Aqui, os estados estão nas colunas, Califórnia é a última coluna, e nas linhas temos os períodos de tempo. E podemos simplificar a matriz acima para apenas quatro blocos: \\[\\begin{aligned} D \\;=\\; \\begin{pmatrix} \\mathbf{0} &amp; \\mathbf{0} \\\\ \\mathbf{0} &amp; \\mathbf{1} \\end{pmatrix} \\end{aligned}\\] O que nos leva à seguinte matriz de resultados: \\[\\begin{aligned} Y \\;=\\; \\begin{pmatrix} \\mathbf{Y_{co, pre}} &amp; \\mathbf{Y_{tr, pre}} \\\\ \\mathbf{Y_{co, post}} &amp; \\mathbf{Y_{tr, post}} \\end{pmatrix} \\;=\\; \\begin{pmatrix} Y_{co, pre}(0) &amp; Y_{tr, pre}(0) \\\\ Y_{co, post}(0) &amp; Y_{tr, post}(1) \\end{pmatrix} \\end{aligned}\\] E de maneira similar para as covariáveis, mas vamos simplificar e supor que não temos nenhuma, sem perda de generalidade. Relembrando, nosso estimando é dado por: \\[ \\mathbb{E}[Y(1)_{it}|D_{it}=1] - \\mathbb{E}[Y(0)_{it}|D_{it}=1] \\] E preciso para isso estimar \\(\\mathbb{E}[Y(0)_{it}|D_{it}=1]\\), em nossa nova notação: \\(Y(0)_{it}|D_{it}=1 \\text{, p/ todo t} &gt; t_0 = Y_{tr, post}(0)\\). E nosso estimador será: \\[ Y_{tr, post}(0) = \\mu + \\sum_{i \\in co}w_iY_{i,t} \\] Em que \\(w_i\\) são os pesos do donor pool. Em ADH (2010), as restrições são: \\(\\mu = 0\\) \\(\\sum_i w_i = 1\\) \\(w_i \\geq 0 \\text{, } \\forall i\\) Restrição 1 significa que não há diferença de nível. Suposição 2 significa que o contrafactual tem de ser construído no suporte do donor pool. Suposição 3 A intuição para o cálculo do peso é parecida com a da regressão linear, em que estamos minimizando a soma da distância. A diferença é que é uma soma diferente. \\[ ||\\mathbf{X}_{tr} - \\mathbf{X}_{co}\\mathbf{W}|| \\] Lembrando que vamos incluir a VD defasada em \\(X\\). Vamos para o R para ver isso em ação. Dica: Há vários pacotes, mas o original, synth, é muito complexo de usar e não recomendamos. augsynth/tidysynth and synthdid packages (original package is tough to use) 10.1 Implementação no R # tidysynth library(tidysynth) library(tidyverse) data(smoking) smoking %&gt;% head() %&gt;% kable() state year cigsale lnincome beer age15to24 retprice Rhode Island 1970 123.9 NA NA 0.1831579 39.3 Tennessee 1970 99.8 NA NA 0.1780438 39.9 Indiana 1970 134.6 NA NA 0.1765159 30.6 Nevada 1970 189.5 NA NA 0.1615542 38.9 Louisiana 1970 115.9 NA NA 0.1851852 34.3 Oklahoma 1970 108.4 NA NA 0.1754592 38.4 smoking_out &lt;- smoking %&gt;% # initial the synthetic control object synthetic_control(outcome = cigsale, # outcome unit = state, # unit index in the panel data time = year, # time index in the panel data i_unit = &quot;California&quot;, # unit where the intervention occurred i_time = 1988, # time period when the intervention occurred generate_placebos=T # generate placebo synthetic controls (for inference) ) %&gt;% # Generate the aggregate predictors used to fit the weights # average log income, retail price of cigarettes, and proportion of the # population between 15 and 24 years of age from 1980 - 1988 generate_predictor(time_window = 1980:1988, ln_income = mean(lnincome, na.rm = T), ret_price = mean(retprice, na.rm = T), youth = mean(age15to24, na.rm = T)) %&gt;% # average beer consumption in the donor pool from 1984 - 1988 generate_predictor(time_window = 1984:1988, beer_sales = mean(beer, na.rm = T)) %&gt;% # Lagged cigarette sales generate_predictor(time_window = 1975, cigsale_1975 = cigsale) %&gt;% generate_predictor(time_window = 1980, cigsale_1980 = cigsale) %&gt;% generate_predictor(time_window = 1988, cigsale_1988 = cigsale) %&gt;% # Generate the fitted weights for the synthetic control generate_weights(optimization_window = 1970:1988, # time to use in the optimization task margin_ipop = .02,sigf_ipop = 7,bound_ipop = 6 # optimizer options ) %&gt;% # Generate the synthetic control generate_control() # série do observado e controle sintético smoking_out %&gt;% plot_trends(time_window = 1970:2000) A quantidade causal de interesse pode ser visualizada do seguinte modo: smoking_out %&gt;% plot_differences() E é possível visualizar os pesos de cada unidade e das variáveis: smoking_out %&gt;% plot_weights() Podemos também olhar o balanceamento entre o observado e o sintético: smoking_out %&gt;% grab_balance_table() ## # A tibble: 7 × 4 ## variable California synthetic_California donor_sample ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ln_income 10.1 9.85 9.83 ## 2 ret_price 89.4 89.4 87.3 ## 3 youth 0.174 0.174 0.173 ## 4 beer_sales 24.3 24.2 23.7 ## 5 cigsale_1975 127. 127. 137. ## 6 cigsale_1980 120. 120. 138. ## 7 cigsale_1988 90.1 91.4 114. A Inferência é complicada. O método tradicional é o chamado teste placebo, cuja intuição é a de um teste de permutação, ou seja, a gente diz que um outro estado foi tratado (NY, por exemplo), e roda o modelo de novo e assim por diante para todas as unidades do donor pool. O gráfico abaixo traz isso pronto. smoking_out %&gt;% plot_placebos() O controle sintético apresentado acima é uma ferramenta poderosa para estudos de caso. Uma extensão natural é combinar essa ideia com o estimador de Diferença em Diferenças, gerando o chamado Synthetic DiD. 10.2 Synthetic DiD Synth DiD combina controle sintético com DiD, em algo novo. Então, vamos começar revisitando DiD. Nós vimos que o estimador de DiD é equivalente a uma regressão linear com efeitos fixos de unidade e tempo. Vamos aplicar nosso estimador para os dados da proposição 99. library(fixest) smoking_did &lt;- smoking %&gt;% mutate(treatment = ifelse(state == &quot;California&quot; &amp; year &gt; 1988, 1, 0)) did &lt;- feols(cigsale ~ treatment | state + year, data = smoking_did) summary(did) ## OLS estimation, Dep. Var.: cigsale ## Observations: 1,209 ## Fixed-effects: state: 39, year: 31 ## Standard-errors: Clustered (state) ## Estimate Std. Error t value Pr(&gt;|t|) ## treatment -27.3491 2.80238 -9.75925 6.6913e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## RMSE: 11.5 Adj. R2: 0.870229 ## Within R2: 0.032671 O problema dessa estimativa é que a suposição de tendências paralelas na média não é muito crível. library(did2s) library(ggfixest) df &lt;- smoking_did %&gt;% mutate(event_time = year - 1988, id = as.integer(as.factor(state))) %&gt;% group_by(state) %&gt;% mutate(g = ifelse(state == &quot;California&quot;, 1988, 0), cohort = ifelse(state == &quot;California&quot;, 1, 0), g1 = ifelse(state == &quot;California&quot; &amp; year &gt;= 1980, 1980, 0)) # est_did = feols(cigsale ~ i(event_time, cohort, -1) | id+year, df) # ggiplot(est_did) ## this package out_es &lt;- event_study( data = df, idname = &quot;id&quot;, tname = &quot;year&quot;, gname = &quot;g&quot;, # coluna que indica o período de tratamento para cada i yname = &quot;cigsale&quot;, estimator = &quot;all&quot; ) ## Error in create_Atheta_list_for_event_study(eventTime = eventTime, g_list = g_list, : ## There are no comparison cohorts for the given eventTime plot_event_study(out_es) E se a gente combinasse controle sintético com DiD, isto é, usasse peso para criar tendências paralelas, e então aplicasse DiD? Arkhangelsky et al (2021) mostraram que podemos reescrever o estimador de controle sintético como: \\[ (\\hat{\\mu}, \\hat{\\gamma}, \\hat{\\tau}) = \\text{arg}\\,\\min\\limits_{\\mu, \\gamma, \\tau}\\ \\sum_i \\sum_t (y_{it} - \\mu - \\gamma_t -D_{it}\\tau)^2\\hat{w}_i \\] Já o DiD é dado por: \\[ (\\hat{\\mu}, \\hat{\\alpha}, \\hat{\\gamma}, \\hat{\\tau}) = \\text{arg}\\,\\min\\limits_{\\mu, \\gamma, \\tau}\\ \\sum_i \\sum_t (y_{it} - \\mu - \\alpha_i - \\gamma_t -D_{it}\\tau)^2 \\] A proposta dos autores, o Synthetic DiD é dada pelo estimador: \\[ (\\hat{\\mu}, \\hat{\\alpha}, \\hat{\\gamma}, \\hat{\\tau}) = \\text{arg}\\,\\min\\limits_{\\mu, \\gamma, \\tau}\\ \\sum_i \\sum_t (y_{it} - \\mu - \\alpha_i - \\gamma_t -D_{it}\\tau)^2\\hat{w}_i\\hat{\\lambda}_t \\] Como antes, \\(\\hat{w}_i\\) são pesos para cada unidade que procuram balancear a tendência pré-exposição ao tratamento nos grupos controle e de tratamento (no exemplo, demais estados e Califórnia). E introduzem pesos \\(\\hat{\\lambda}_t\\) para os períodos de tempo \\(t\\) que procuram balancear os períodos pré-exposição com os períodos pós-exposição. Contraste o SDiD com o DiD, e a diferença são os dois pesos. Basicamente, estamos estimando regressão linear local ao colocar mais peso em unidades que são, em média, mais similares aos tratados no período pré-exposição e enfatiza períodos mais similares ao alvo (período tratado). Em outras palavras, “Time weights are designed so that the average post-treatment outcome for each of the control units differs by a constant from the weighted average of the pre-treatment outcomes for the same control units”(p. 4) Esse estimador relaxa a suposição de tendências paralelas. Agora, precisamos que um fator latente seja paralelo. # devtools::install_github(&quot;synth-inference/synthdid&quot;) library(synthdid) estimators = list(did=did_estimate, sc=sc_estimate, sdid=synthdid_estimate) str(synthdid_estimate) ## function (Y, N0, T0, X = array(dim = c(dim(Y), 0)), noise.level = sd(apply(Y[1:N0, ## 1:T0], 1, diff)), eta.omega = ((nrow(Y) - N0) * (ncol(Y) - T0))^(1/4), ## eta.lambda = 1e-06, zeta.omega = eta.omega * noise.level, zeta.lambda = eta.lambda * ## noise.level, omega.intercept = TRUE, lambda.intercept = TRUE, weights = list(omega = NULL, ## lambda = NULL), update.omega = is.null(weights$omega), update.lambda = is.null(weights$lambda), ## min.decrease = 1e-05 * noise.level, max.iter = 10000, sparsify = sparsify_function, ## max.iter.pre.sparsify = 100) # converte para matriz df_sdid &lt;- df %&gt;% dplyr::select(state, year, cigsale, treatment) %&gt;% mutate(treatment = as.integer(treatment), year = as.integer(year), state = as.factor(state)) %&gt;% as.data.frame() # aparentemente panel.matrices não funciona com tibble setup &lt;- panel.matrices(df_sdid) head(setup) %&gt;% kable() 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 Alabama 89.8 95.4 101.1 102.9 108.2 111.7 116.2 117.1 123.0 121.4 123.2 119.6 119.1 116.3 113.0 114.5 116.3 114.0 112.1 105.6 108.6 107.9 109.1 108.5 107.1 102.6 101.4 104.9 106.2 100.7 96.2 Arkansas 100.3 104.1 103.9 108.0 109.7 114.8 119.1 122.6 127.3 126.5 131.8 128.7 127.4 128.0 123.1 125.8 126.0 122.3 121.5 118.3 113.1 116.8 126.0 113.8 108.8 113.0 110.7 108.7 109.5 104.8 99.4 Colorado 124.8 125.5 134.3 137.9 132.8 131.0 134.2 132.0 129.2 131.5 131.0 133.8 130.5 125.3 119.7 112.4 109.9 102.4 94.6 88.8 87.4 90.2 88.3 88.6 89.1 85.4 83.1 81.3 81.2 79.6 73.0 Connecticut 120.0 117.6 110.8 109.3 112.4 110.2 113.4 117.3 117.5 117.4 118.0 116.4 114.7 114.1 112.5 111.0 108.5 109.0 104.8 100.6 91.5 86.7 83.5 79.1 76.6 79.3 76.0 75.9 75.5 73.4 71.4 Delaware 155.0 161.1 156.3 154.7 151.3 147.6 153.0 153.3 155.5 150.2 150.5 152.6 154.1 149.6 144.0 144.5 142.4 141.0 137.1 131.7 127.2 118.8 120.0 123.8 126.1 127.2 128.3 124.1 132.8 139.5 140.7 Georgia 109.9 115.7 117.0 119.8 123.7 122.9 125.9 127.9 130.6 131.0 134.0 131.7 131.2 128.6 126.3 128.8 129.0 129.3 124.1 117.1 113.8 109.6 109.2 109.2 107.8 100.3 102.7 100.6 100.5 97.1 88.4 Idaho 102.4 108.5 126.1 121.8 125.6 123.3 125.1 125.0 122.8 117.5 115.2 114.1 111.5 111.3 103.6 100.7 96.7 95.0 84.5 78.4 90.1 85.4 85.1 86.7 93.0 78.2 73.6 75.0 78.9 75.1 66.9 Illinois 124.8 125.6 126.6 124.4 131.9 131.8 134.4 134.0 136.7 135.3 135.2 133.0 130.7 127.9 124.0 121.6 118.2 109.5 107.6 104.6 94.1 96.1 94.8 94.6 85.7 84.3 81.8 79.6 80.3 72.2 70.0 Indiana 134.6 139.3 149.2 156.0 159.6 162.4 166.6 173.0 150.9 148.9 146.9 148.5 147.7 143.0 137.8 135.3 137.6 134.0 134.0 132.5 128.3 127.2 128.2 126.8 128.2 135.4 135.1 135.3 135.9 133.3 125.5 Iowa 108.5 108.4 109.4 110.6 116.1 120.5 124.4 125.5 127.1 124.2 124.6 132.9 116.2 115.6 111.2 109.4 104.1 101.1 100.2 94.4 95.4 97.1 95.2 92.5 93.4 93.0 94.0 93.9 94.0 91.7 88.9 Kansas 114.0 102.8 111.0 115.2 118.6 123.4 127.7 127.9 127.1 126.4 127.1 132.0 130.9 127.6 121.7 115.7 109.4 105.2 103.2 96.5 94.3 91.8 90.0 89.9 89.1 90.1 88.7 89.2 87.6 83.3 79.8 Kentucky 155.8 163.5 179.4 201.9 212.4 223.0 230.9 229.4 224.7 214.9 215.3 209.7 210.6 201.1 183.2 182.4 179.8 171.2 173.2 171.6 182.5 170.4 167.6 167.6 170.1 175.3 179.0 186.8 171.3 165.3 156.2 Louisiana 115.9 119.8 125.3 126.7 129.9 133.6 139.6 140.0 142.7 140.1 143.8 144.0 143.9 133.7 128.9 125.0 121.2 116.5 110.9 103.6 101.5 107.2 108.5 106.2 105.3 105.7 106.8 105.3 103.2 101.0 104.3 Maine 128.5 133.2 136.5 138.0 142.1 140.7 144.9 145.6 143.9 138.5 141.2 138.9 139.5 135.4 135.5 127.9 119.0 125.0 125.0 122.4 117.5 116.1 114.5 108.5 101.6 102.3 100.0 101.1 94.5 85.5 82.9 Minnesota 104.3 116.4 96.8 106.8 110.6 111.5 116.7 117.2 118.9 118.3 117.7 120.8 119.4 113.2 110.8 113.0 104.3 108.8 94.1 92.3 90.7 86.2 83.8 81.6 83.4 84.1 81.7 84.1 83.2 80.7 76.0 Mississippi 93.4 105.4 112.1 115.0 117.1 116.8 120.9 122.1 124.9 123.9 127.0 125.3 125.8 122.3 116.4 115.3 113.2 110.0 109.0 108.3 101.8 105.6 103.9 105.4 106.0 107.5 106.9 106.3 107.0 103.9 97.2 Missouri 121.3 127.6 130.0 132.1 135.4 135.6 139.5 140.8 141.8 140.2 142.1 140.5 139.7 134.1 130.0 129.2 128.8 128.7 127.4 122.8 119.1 119.9 122.3 121.6 119.4 124.0 124.1 120.6 120.1 118.0 113.8 Montana 111.2 115.6 122.2 119.9 121.9 123.7 124.9 127.0 127.2 120.3 122.0 121.1 122.4 113.7 110.1 103.6 97.8 91.7 87.1 86.2 84.7 82.9 86.6 86.0 88.2 90.5 87.3 88.9 89.1 82.6 75.5 Nebraska 108.1 108.6 104.9 106.6 110.5 114.1 118.1 117.7 117.4 116.1 116.3 117.0 117.1 110.8 107.7 105.1 103.1 101.3 92.9 93.8 89.9 92.4 90.6 91.1 85.9 88.5 86.2 85.5 83.1 86.6 77.6 Nevada 189.5 190.5 198.6 201.5 204.7 205.2 201.4 190.8 187.0 183.3 177.7 171.9 165.1 159.2 136.6 146.7 142.6 147.7 141.9 137.9 137.3 115.5 110.0 108.1 105.2 100.9 99.0 95.6 102.4 103.9 93.2 New Hampshire 265.7 278.0 296.2 279.0 269.8 269.1 290.5 278.8 269.6 254.6 247.8 245.4 239.8 232.9 215.1 201.1 195.9 195.1 180.4 172.9 152.4 144.8 143.7 148.9 153.8 158.5 158.0 174.4 173.8 171.7 147.3 New Mexico 90.0 92.6 99.3 98.9 100.3 103.1 102.4 102.4 103.1 101.0 102.7 103.0 97.5 96.3 88.9 88.0 88.2 82.3 77.7 74.4 70.8 69.9 71.4 69.0 68.2 67.0 65.7 61.8 62.6 59.7 53.8 North Carolina 172.4 187.6 214.1 226.5 227.3 226.0 230.2 217.0 205.5 197.3 187.8 179.3 179.0 169.8 160.6 156.3 154.4 150.5 146.0 139.3 133.7 132.7 128.9 129.7 112.7 124.9 129.7 125.6 126.0 113.1 109.0 North Dakota 93.8 98.5 103.8 108.7 110.5 117.9 125.4 122.2 121.9 121.3 123.7 125.7 126.8 119.6 109.4 103.2 99.8 92.3 87.1 84.1 77.1 85.2 74.3 83.0 81.0 80.6 80.8 77.5 79.1 74.7 72.5 Ohio 121.6 124.6 124.4 120.5 122.1 122.5 124.6 127.3 131.3 130.9 133.5 132.8 134.0 130.0 127.1 126.7 126.3 124.6 122.4 118.6 115.5 113.2 112.3 108.9 108.6 111.7 107.6 108.6 106.4 104.0 99.9 Oklahoma 108.4 115.4 121.7 124.1 130.5 132.9 138.6 140.4 143.6 141.6 141.6 143.7 147.0 140.0 128.1 124.2 119.9 113.1 103.6 97.5 88.4 87.8 86.3 86.2 104.8 109.5 110.8 111.8 112.2 111.4 108.9 Pennsylvania 107.3 106.3 109.0 110.7 114.2 114.6 118.8 120.1 122.3 122.6 124.0 125.2 123.3 125.3 115.3 115.8 113.9 110.6 107.6 107.1 101.3 102.5 96.2 94.7 95.4 95.4 93.3 92.9 92.1 91.1 87.9 Rhode Island 123.9 123.2 134.4 142.0 146.1 154.7 150.2 148.8 146.8 145.8 149.3 151.2 146.3 135.8 136.9 133.4 136.3 124.4 138.0 120.8 101.4 103.6 100.1 94.1 91.9 90.8 87.5 90.0 88.7 86.9 83.1 South Carolina 103.6 115.0 118.7 125.5 129.7 130.5 136.8 137.2 140.4 135.7 138.3 136.1 136.0 131.1 127.0 125.4 126.6 126.6 124.4 122.4 118.6 121.5 112.8 115.2 112.2 109.2 102.9 124.5 126.9 109.4 103.9 South Dakota 92.7 96.7 103.0 103.5 108.4 113.5 116.7 115.6 116.9 117.4 114.7 115.7 113.0 109.8 105.7 104.4 97.0 95.8 91.9 87.4 88.3 91.8 93.0 91.6 94.8 98.6 92.3 88.8 88.3 83.5 75.1 Tennessee 99.8 106.3 111.5 109.7 114.8 117.4 121.7 124.6 127.3 127.2 130.4 129.1 131.4 129.0 125.1 128.7 129.0 130.6 125.3 124.7 121.8 120.6 121.0 120.8 118.8 125.4 119.2 118.9 119.7 115.6 108.7 Texas 106.4 108.9 108.6 110.4 114.7 116.0 121.4 124.2 126.6 126.4 129.7 129.0 131.2 126.4 117.2 115.9 113.7 105.8 96.5 94.5 85.6 79.4 77.2 81.3 78.8 75.2 74.6 72.6 73.2 67.6 69.3 Utah 65.5 67.7 71.3 72.7 75.6 75.8 77.9 78.0 79.6 79.1 74.8 77.6 73.6 69.0 66.3 66.5 64.4 67.7 55.0 57.0 53.4 53.5 55.0 56.2 55.8 52.0 54.0 57.0 42.3 43.9 40.7 Vermont 122.6 124.4 138.0 146.8 151.8 155.5 171.1 169.4 162.4 160.9 161.6 163.8 162.3 153.8 144.3 144.5 131.2 128.3 128.7 120.9 124.3 120.9 126.5 117.2 120.3 123.2 102.5 97.7 97.0 94.1 88.9 Virginia 124.3 128.4 137.0 143.1 149.6 152.7 158.1 157.7 155.9 151.8 148.9 149.9 147.4 144.7 136.8 134.6 135.8 133.0 129.5 122.5 118.9 109.1 108.2 105.4 106.2 106.7 104.6 108.0 105.6 102.1 96.7 West Virginia 114.5 111.5 117.5 116.6 119.9 123.2 129.7 133.9 131.6 122.1 122.3 120.5 119.8 115.7 111.9 109.1 112.1 107.5 109.1 104.0 104.1 100.1 97.9 111.0 104.2 115.2 112.7 114.5 114.6 112.4 107.9 Wisconsin 106.4 105.4 108.8 109.5 111.8 113.5 115.4 117.2 116.7 117.1 117.6 119.9 115.6 106.3 105.6 107.0 105.4 106.0 102.6 100.3 94.0 95.5 96.2 91.2 91.8 93.5 92.1 91.9 88.7 84.4 80.1 Wyoming 132.2 131.7 140.0 141.2 145.8 160.7 161.5 160.4 160.3 168.6 158.1 163.1 157.7 141.2 128.9 125.7 124.8 110.4 114.3 111.4 96.9 109.1 110.8 108.4 111.2 115.0 110.3 108.8 102.9 104.8 90.5 California 123.0 121.0 123.5 124.4 126.7 127.1 128.0 126.4 126.1 121.9 120.2 118.6 115.4 110.8 104.8 102.8 99.7 97.5 90.1 82.4 77.8 68.7 67.5 63.4 58.6 56.4 54.5 53.8 52.3 47.2 41.6 x 38 x 19 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 Alabama 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Arkansas 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Colorado 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Connecticut 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Delaware 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Georgia 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Idaho 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Illinois 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Indiana 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Iowa 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Kansas 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Kentucky 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Louisiana 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Maine 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Minnesota 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Mississippi 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Missouri 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Montana 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Nebraska 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Nevada 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 New Hampshire 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 New Mexico 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 North Carolina 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 North Dakota 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Ohio 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Oklahoma 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Pennsylvania 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Rhode Island 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 South Carolina 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 South Dakota 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Tennessee 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Texas 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Utah 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Vermont 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Virginia 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 West Virginia 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Wisconsin 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Wyoming 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 California 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 estimates &lt;- lapply(estimators, function(estimator) { estimator(setup$Y, setup$N0, setup$T0) } ) head(estimates) ## $did ## synthdid: -27.349 +- NA. Effective N0/N0 = 38.0/38~1.0. Effective T0/T0 = 19.0/19~1.0. N1,T1 = 1,12. ## ## $sc ## synthdid: -19.620 +- NA. Effective N0/N0 = 3.8/38~0.1. Effective T0/T0 = Inf/19~Inf. N1,T1 = 1,12. ## ## $sdid ## synthdid: -15.604 +- NA. Effective N0/N0 = 16.4/38~0.4. Effective T0/T0 = 2.8/19~0.1. N1,T1 = 1,12. standard.errors = mapply(function(estimate, name) { set.seed(12345) if(name == &#39;mc&#39;) { mc_placebo_se(setup$Y, setup$N0, setup$T0) } else { sqrt(vcov(estimate, method=&#39;placebo&#39;)) } }, estimates, names(estimators)) head(standard.errors) ## did sc sdid ## 17.740267 9.917426 8.367993 Plot comparando as estimativas. synthdid_plot(estimates[1:3], facet.vertical=FALSE, control.name=&#39;control&#39;, treated.name=&#39;california&#39;, lambda.comparable=TRUE, se.method = &#39;none&#39;, trajectory.linetype = 1, line.width=.75, effect.curvature=-.4, trajectory.alpha=.7, effect.alpha=.7, diagram.alpha=1, onset.alpha=.7) + theme(legend.position=c(.26,.07), legend.direction=&#39;horizontal&#39;, legend.key=element_blank(), legend.background=element_blank(), strip.background=element_blank(), strip.text.x = element_blank()) Plot comparando os pesos. synthdid_units_plot(rev(estimates[1:3]), se.method=&#39;none&#39;) 10.3 Resumo e próximos passos Neste capítulo, apresentamos o método de Controle Sintético, que permite estimar o efeito causal de uma intervenção sobre uma única unidade tratada, construindo um contrafactual a partir de uma combinação ponderada de unidades não-tratadas. Vimos também o Synthetic DiD, que combina as vantagens do controle sintético (pesos para unidades) com as do DiD (pesos para períodos de tempo), relaxando a suposição de tendências paralelas. No próximo capítulo, veremos como técnicas de Machine Learning podem ser adaptadas para inferência causal, em particular o Double LASSO e o Double/Debiased Machine Learning. 10.4 Referências Alcocer, J. J. (2025). Minority Legislators Sponsor and Cosponsor Differently from White Legislators: Causal Evidence from U.S. Congress. The Journal of Race, Ethnicity, and Politics, 1–13. doi:10.1017/rep.2025.29 Arkhangelsky, D., Athey, S., Hirshberg, D. A., Imbens, G. W., &amp; Wager, S. (2021). Synthetic difference-in-differences. American Economic Review, 111(12), 4088-4118. Arkhangelsky, D., &amp; Imbens, G. (2024). Causal models for longitudinal and panel data: A survey. The Econometrics Journal, 27(3), C1-C61. "],["llms-e-outras.html", "Capítulo 11 LLMs e outras 11.1 Google Colab", " Capítulo 11 LLMs e outras 11.1 Google Colab Para a aula de hoje, vamos usar o Google Colab, que é uma ferramenta online, gratuita, para programar e analisar dados. Ela permite escrever e rodar códigos em Python sem a necessidade de instalar nenhum programa. Além disso, é possível ter acesso a processadores poderosos, inclusive de GPUs, se necessário (mas pagando). Para usar o Google Colab, precisamos de uma conta Google, o que nós já temos com nosso e-mail usp. Vamos acessar o endereço: https://colab.google Vamos clicar em new notebook. Vamos renomear o arquivo para aula_llm.ipynb A terminação diz que é um notebook. Que é como se fosse um Rmarkdown no R, só que nesse caso, hospedado online. https://macartan.github.io/dd_bootcamp/dd.html#/using-a-design-1 https://macartan.github.io/dd_bootcamp/exercises.html https://gist.github.com/saudiwin/dd0edec5786c7edb393bd84615aafb45 https://www.datacamp.com/tutorial/fine-tuning-openais-gpt-4-step-by-step-guide https://community.revelo.com.br/tutorial-aplicacao-do-fine-tuning-para-treinamento-no-chatgpt/ "],["machine-learning.html", "Capítulo 12 Machine Learning 12.1 Introdução 12.2 Terminologia 12.3 DL - Algoritmo 12.4 Termos de Interação 12.5 Aplicação 12.6 DML 12.7 Double Debiasing 12.8 Cross-fitting 12.9 Questões Práticas 12.10 Resumo e próximos passos 12.11 Referências", " Capítulo 12 Machine Learning 12.1 Introdução Em estudos observacionais, como vimos, análises baseadas no pressuposto de conditional ignorability do tratamento e positividade permitem a estimação de quantidades causais de interesse. As técnicas de machine learning foram desenvolvidas em geral voltadas para o problema de previsão, não de inferência causal. Por isso, não são normalmente uma alternativa boa para as questões de identificação causal que temos discutido no curso. Contudo, com algumas adaptações, podem ser usadas para análise de causa e efeito. Uma das abordagens mais populares é a sugerida por Belloni et al. (2014), de usar LASSO (Least Absolute Shrinkage and Selection Operator) para inferir causalidade. 12.2 Terminologia Estatística Machine Learning observações 12.2.1 LASSO O estimador de Mínimos Quadrados Ordinários é obtido minimizando a soma dos quadrados dos resíduos, isto é, em uma regressão \\(y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\ldots + \\beta_p x_{pi} + e_i\\), minimizamos \\(\\sum_{i=1}^n [y_i - (\\alpha + \\beta_1x_{1i} + \\beta_2 x_{2i} + \\ldots + \\beta_px_{pi})]^2\\). Nós podemos pensar essa minimização como uma função de custo. Quanto menor o erro total, menor o custo. O estimador de LASSO adiciona uma penalidade a essa função de minimização \\(\\lambda \\sum_{j=1}^p |\\beta_j|\\), ou seja, passamos a minimizar: \\(\\sum_{i=1}^n [y_i - (\\alpha + \\beta_1x_{1i} + \\beta_2x_{2i} + \\ldots + \\beta_px_{pi})]^2 + \\lambda \\sum_{j=1}^p |\\beta_j|\\) O termo \\(\\sum_{j=1}^p |\\beta_j|\\) é chamado de norma L1. Ele envolve a soma absoluta dos parâmetros. Existem outras normas (L0, L2 etc.), isto é, outras formas de penalizar a estimação dos coeficientes. A norma L1 é conhecida como distância de Manhattan, e a intuição é que, se tenho dois pontos em Manhattan, \\((x_1, y_1)\\) e \\((x_2, y_2)\\), que são ruas em esquinas opostas de uma quadra (na diagonal). Como as ruas são, em geral, em formato de grade, temos de andar uma quadra na vertical e outra na horizontal para sair de um ponto a outro. Essa distância é a norma L1. Se usássemos a norma L2, por exemplo, poderíamos ir na diagonal, que é dada pela distância euclidiana. E \\(\\lambda\\) é um parâmetro não negativo que controla a força da penalização. Veja que coeficientes positivos dos \\(\\beta\\) aumentam o custo total, de modo que eles precisam ser compensados pelo ganho gerado na capacidade preditiva da variável associada (quanto maior a correlação parcial, menor o erro). Assim, ao introduzir essa penalidade, o LASSO estimula que apenas as variáveis com maior capacidade preditiva possuam coeficientes positivos, enquanto as de baixa capacidade preditiva terão coeficiente igual a zero. Nós chamamos isso de esparsidade do vetor de coeficientes, já que muitos deles serão zero. Dizemos também que a regressão foi estimada com regularização. Veja que o LASSO é o equivalente a uma regressão Bayesiana com uma priori nos parâmetros igual a um dupla exponencial, levando à interpretação de que a priori é uma forma de regularizar estimativas. Quando \\(\\lambda \\to 0\\), os coeficientes convergem para os estimadores de MQO, e quando \\(\\lambda \\to \\infty\\) apenas o intercepto resta. Em ML, o método usual para achar \\(\\lambda\\) é validação cruzada (CV, de cross-validation), que é utilizada para favorecer previsões fora da amostra. Belloni et al. (2012) advogam uma escolha baseada em teoria, também conhecido como LASSO rigoroso. Angrist &amp; Frandsen (2022) concluíram que essa abordagem rigorosa tende a favorecer modelos mais parsimoniosos (\\(\\lambda\\) maiores) do que com CV. 12.2.2 Double Lasso O estimador robusto mais popular é o Double Lasso. A ideia é que se eu tentar usar LASSO diretamente na equação de regressão \\(y_i = \\alpha + \\beta_1D_i + BX + e_i\\), variáveis correlacionadas entre si terão coeficientes zero, e potencialmente o tratamento será uma delas, impedindo a estimação da quantidade causal de interesse. Estratégias como forçar \\(D_i\\) a permanecer na equação implicam que ficará fora da equação de penalização. Contudo, isso pode causar viés na estimação de \\(\\beta_1\\) (Belloni et al., 2014). Essa regularização força variáveis correlacionadas com o tratamento a serem dropadas, o que significa dropar potenciais variáveis de confusão. Resumo: não use as técnicas de ML diretamente na equação de regressão. Exemplo. # vou rodar mil simulações com n=100 set.seed(10) k &lt;- 90 # número de controles n &lt;- 100 # número de obs alpha &lt;- .2 # intercepto beta &lt;- 0 # efeito do tratamento gamma &lt;- runif(min=-1, max=1, n=k) # efeito do vetor de controles delta &lt;- runif(min=-1, max=1, n=k) erro &lt;- rnorm(n) vec_x &lt;- rnorm(n*k, mean = rep(0,k)) # vetor de controles x &lt;- matrix(vec_x, ncol=k) D &lt;- x%*%delta + rnorm(n) y &lt;- alpha + beta*D + x%*%gamma + erro fit &lt;- lm(y ~D + x) coef(summary(fit))[2] library(MASS) library(arm) sim_pvalue_dl &lt;- function(n_sim=1000, n_sample=100) { vec_p_values &lt;- numeric() beta_hat &lt;- numeric() theta_hat &lt;- numeric() lista_df &lt;- list() for ( i in 1:n_sim) { k &lt;- 20 # número de controles n &lt;- n_sample # número de obs alpha &lt;- .2 # intercepto beta &lt;- 0 # efeito do tratamento theta &lt;- 1 # efeito D*V que nos interessa gamma &lt;- runif(min=-1, max=1, n=k) # efeito do vetor de controles no y gamma[sample(1:k, (k/4))] &lt;- 0 # k/4 zeros delta &lt;- runif(min=-1, max=1, n=k) # efeito do vetor de controles no D erro &lt;- rnorm(n, 0, 5) # matriz de preditores correlacionados rho &lt;- 0.7 # correlação entre vizinhos imediatos Sigma &lt;- toeplitz(rho^(0:(k-1))) # R_{ij} = rho^{|i-j|}, variâncias = 1 mean_vector &lt;- rep(0, k) x &lt;- mvrnorm(n, mean_vector, Sigma) x_interaction &lt;- x[,10] D &lt;- rbinom(n, 1, invlogit(x%*%delta + rnorm(n))) D_num &lt;- as.numeric(D) # 0 ou 1 X &lt;- as.matrix(x_interaction) # 6 × 5 no seu exemplo # interação: cada linha multiplicada por D[i] X_int &lt;- X * D_num X_int_omitida &lt;- x_interaction*as.matrix(x[,11:20]) y &lt;- alpha + beta*D + x%*%gamma + X_int%*%theta + rowSums(X_int_omitida) + erro df_sim &lt;- data.frame(y, D, x, x_interaction) lista_df[[i]] &lt;- df_sim fit &lt;- lm(y ~ D*x_interaction + x[,-10], data = df_sim) beta_hat[i] &lt;- coef(summary(fit))[2] vec_p_values[i] &lt;- summary(fit)$coefficients[,4][2] theta_hat[i] &lt;- coef(summary(fit))[3] } df_final &lt;- data.frame(beta = beta_hat, p_values = vec_p_values, theta_hat = theta_hat) return(list(df_final = df_final, lista_df = lista_df)) } result_sim &lt;- sim_pvalue_dl() my_p_values_beta &lt;- result_sim$df_final lista_df &lt;- result_sim$lista_df hist(my_p_values_beta$p_values, breaks = 30, main = &quot;Teste de signific. de D&quot;, xlab = &quot;p-valor&quot;) abline(v = 0.05, col = &quot;red&quot;, lwd = 1, lty = 1) text(0.1, par(&quot;usr&quot;)[4] * 0.75, &quot;0.05&quot;, col = &quot;red&quot;, pos = 3, cex=.5) hist(my_p_values_beta$beta, breaks = 30, main = &quot;Teste de signific. de D&quot;, xlab = &quot;p-valor&quot;) # percentual p-valor menor que 5% sum(my_p_values_beta$p_values &lt;= .05)/1000 ## [1] 0.05 mean(my_p_values_beta$beta) ## [1] -0.0199413 mean(my_p_values_beta$theta_hat) ## [1] -0.07478368 Nós rejeitamos a hipótese nula aproximadamente 50% do tempo. E se usarmos LASSO (single LASSO)? # Instalar e carregar o pacote glmnet, se necessário library(glmnet) ## Loaded glmnet 4.1-9 # Vetor para armazenar se x foi selecionado pelo LASSO lasso_selected_D &lt;- numeric() # Loop de simulação for (i in 1:1000) { y &lt;- lista_df[[i]]$y X &lt;- cbind(lista_df[[i]]$D, lista_df[[i]]$x) # Preparando os dados para o LASSO # Matriz de preditores (sem o intercepto) # Ajustando o modelo LASSO com validação cruzada lasso_model &lt;- cv.glmnet(X, y, alpha = 1) # alpha = 1 para LASSO # Extraindo os coeficientes no valor de lambda que minimiza o erro lasso_coefs &lt;- coef(lasso_model, s = &quot;lambda.min&quot;) # Verificando se a variável x foi selecionada pelo LASSO (coeficiente diferente de zero) lasso_selected_D[i] &lt;- ifelse(lasso_coefs[&quot;V1&quot;, 1] != 0, 1, 0) } # Analisando os resultados hist(lasso_selected_D, breaks = 40, main = &quot;Seleção de x pelo LASSO&quot;, xlab = &quot;x selecionado (1 = sim, 0 = não)&quot;) sum(lasso_selected_D &lt;= .05)/1000 ## [1] 0.75 Também não funciona, mais ou menos mesma taxa de erro. 12.2.3 Outras soluções ineficazes Bootstrap (não funciona) Clássico: suponha que a covariável não é relevante Conservador: sempre inclua quantos controles puder (pode gerar Collider Bias). DL lida com essa situação fazendo uma modelagem dupla, tanto do tratamento quanto da resposta. Daí o nome, Double Lasso. 12.3 DL - Algoritmo Passo 1. Inclua controle se ele for preditor significativo da resposta \\(y_i\\) por um teste conservador (teste t, LASSO etc.) Passo 2. Inclua controle se ele for preditor significativo do tratamento \\(D_i\\) por um teste conservador (teste t, LASSO etc.). Passo 3. Ajuste o modelo com as variáveis selecionadas e o tratamento. Esse passo é chamado de Pós MQO (Post OLS). No R, podemos usar o pacote “hdm” para fazer a implementação em uma linha. library(hdm) library(knitr) d_s_vec &lt;- numeric() for ( i in 1:1000) { my_double_selection &lt;- rlassoEffects(y~. , I=~x + D, data=lista_df[[i]]) d_s_vec[i] &lt;- summary(my_double_selection)$coefficients[&quot;D&quot;, &quot;Pr(&gt;|t|)&quot;] } hist(d_s_vec, breaks = 40, main = &quot;Seleção de D pelo Double LASSO&quot;, xlab = &quot;p-valor&quot;) abline(v = 0.05, col = &quot;red&quot;, lwd = 1, lty = 1) text(0.1, par(&quot;usr&quot;)[4] * 0.75, &quot;0.05&quot;, col = &quot;red&quot;, pos = 3, cex=.5) sum(d_s_vec &lt;= .05)/1000 ## [1] 0.04 Como vemos, aproximadamente 5% das vezes nós rejeitamos a hipótese nula erradamente, que é o esperado do p-valor de 5%. 12.4 Termos de Interação Blackwell &amp; Olson (2022) argumentam que incluir um termo de interação com o tratamento, mas não com os controles, pode viesar as estimativas. Como eles falam: ” If the relationship between the covariates and the outcome also depends on the moderator [termo de interação], a naive application of the single-interaction model can lead to what we call omitted interaction bias, a form of model misspecification that can be severe” (p. 2). A solução é usar o Double LASSO para escolher quais variáveis com termos de interação devem ser mantidas, e quais devem ser dropadas da regressão de especificação. 12.5 Aplicação Alguns exemplos que encontrei em ciência política de aplicação do Double LASSO foram o artigo (working paper) de Dahlum et al. (2024) e Dutt &amp; Tsetlin (2021). O Double LASSO resolve o problema de seleção de variáveis para inferência causal. Uma abordagem mais geral, que permite o uso de qualquer método de Machine Learning para estimar os parâmetros de nuisance, é o Double/Debiased Machine Learning. 12.6 DML A estratégia de identificação canônica em nosso curso tem girado sempre em torno de suposições críveis de identificação do efeito de um tratamento (em geral binário) \\(D\\) sobre a variável resposta (em geral contínua) \\(Y\\). E com frequência precisamos empregar controles para garantir a identificação causal e fechar as portas abertas (back-doors). Nesse contexto, as variáveis de controle são o que chamamos de nuisance variables, isto é, variáveis que não são de interesse para a pergunta de pesquisa, mas que precisam ser levadas em consideração para que possamos estimar sem viés o parâmetro de interesse. Considere o modelo de regressão padrão em um estudo observacional: \\(y_i = \\alpha + \\beta_1D_i + BX + e_i\\), em que \\(D_i\\) é o tratamento (binário) e \\(X\\) é um vetor de \\(p\\) potenciais variáveis de confusão: \\(\\mathbf{X} = (x_1, x_2, \\ldots, x_p)\\) e \\(B\\) o vetor de parâmetros das variáveis de controle. Dado que a regressão está aproximando uma esperança condicional \\(\\mathbb{E}[Y|D=d, \\mathbf{X}= \\mathbf{x}]\\), ela pode ser escrita como: \\(\\mathbb{E}[Y|D=d, \\mathbf{X}= \\mathbf{x}] = \\eta_0(\\mathbf{X}) + \\theta_0(\\mathbf{X})d\\), em que \\(\\eta_0 = \\mathbb{E}[Y|D=0, \\mathbf{X}= \\mathbf{x}]\\) é um functional nuisance e \\(\\theta_0 = \\mathbb{E}[Y|D=1, \\mathbf{X}= \\mathbf{x}] - \\mathbb{E}[Y|D=0, \\mathbf{X}= \\mathbf{x}]\\) é o funcional de interesse. Tipicamente, quando usamos regressão linear, estamos assumindo uma forma funcional específica para a função de nuisance. Se houver erro de especificação, iremos introduzir um viés na estimativa do parâmetro de interesse. Aí é que entra o Double/Debiased Machine Learning. 12.7 Double Debiasing O chamado Double/Debiased Machine Learning (DML) foi desenvolvido por Chernozhukov et al. (2018). Sua inspiração vem do teorema de Frisch-Waugh-Lovell (FWL). Vamos começar por ele. Suponha o seguinte modelo de regressão múltipla: \\[ Y = \\beta_0 + \\beta_1X + \\beta_2W_1 + \\dots + \\beta_{k+1}W_k + \\epsilon \\] Em que \\(X\\) é a variável causal de interesse (tratamento) e os \\(W\\) são variáveis de controle. São as nuisance variables. O teorema de FWL diz que posso estimar \\(\\beta_1\\) rodando diretamente a regressão acima, ou então pelos seguintes passos: Rodo uma regressão em que o tratamento é a VD, e os controles as VIs. \\[ X = \\alpha_0 + \\alpha_1W_1 + \\dots + \\alpha_{k}W_k + \\epsilon \\] Calculo os resíduos \\(\\tilde{X} = X - \\hat{X}\\), em que \\(\\hat{X} = \\hat{\\alpha}_0 + \\hat{\\alpha}_1W_1 + \\dots + \\hat{\\alpha}_{k}W_k\\). Rodo uma regressão de \\(Y\\) nos controles \\(W\\) e obtenho os resíduos \\(\\tilde{Y} = Y - \\hat{Y}\\). Finalmente, rodo a regressão \\(\\tilde{Y} = \\beta_1 \\tilde{X} + \\epsilon\\) para obter \\(\\hat{\\beta}_1\\). A ideia do DML é usar ML para estimar os dois resíduos como no teorema de FWL, e então rodar uma regressão linear para estimar o efeito causal do tratamento. E Chernozhukov et al. (2018) mostram que usar ML gera resíduos ortogonais e, portanto, permite estimar o efeito causal. Um ingrediente técnico essencial do DML é o cross-fitting, que evita overfitting na estimação dos parâmetros de nuisance. 12.8 Cross-fitting Uma questão importante para nós é como fazer a validação cruzada em um contexto de TSCS. De acordo com Ahrens et al. (2025), devemos sortear as partições entre unidades \\(i = 1, 2, \\dots, n\\), mantendo todas as séries temporais por unidades juntas. 12.9 Questões Práticas Para usar DML, precisamos fazer escolhas (não-óbvias) sobre três aspectos do processo: Qual modelo de ML usar para estimar o nuisance parameter. Isso inclui escolher o parâmetro de fine-tuning, típico de aplicações de ML. Quantas partições realizar na amostra (aka, valor de \\(k\\)). Como fazer a divisão das amostras em folds. Um exemplo de aplicação em que o DML é útil é em DiD. Nós sabemos que a suposição de tendências paralelas, condicional a controles, depende de uma suposição da forma paramétrica dessa relação (em geral linear). Se a forma paramétrica não for corretamente especificada, a estimativa será viesada. Ao usar DML, nós ganhamos a flexibilidade de estimar o nuisance parameter corretamente e estimar o efeito causal de interesse. 12.10 Resumo e próximos passos Neste capítulo, vimos como técnicas de Machine Learning podem ser adaptadas para inferência causal. O Double LASSO resolve o problema de seleção de variáveis de confusão, enquanto o DML generaliza essa ideia permitindo o uso de qualquer método de ML para estimar os parâmetros de nuisance. Ambos se baseiam na lógica do teorema FWL: residualizar tanto o tratamento quanto a resposta antes de estimar o efeito causal. Estas ferramentas são especialmente úteis quando combinadas com outros métodos de identificação causal vistos no curso (como DiD ou IV), pois permitem maior flexibilidade na modelagem da forma funcional dos controles. 12.11 Referências Ahrens, A., Chernozhukov, V., Hansen, C., Kozbur, D., Schaffer, M., &amp; Wiemann, T. (2025). An Introduction to Double/Debiased Machine Learning. arXiv preprint arXiv:2504.08324. Belloni, A., Chernozhukov, V., &amp; Hansen, C. (2014). High-dimensional methods and inference on structural and treatment effects. Journal of Economic Perspectives, 28(2), 29-50. Blackwell, M., &amp; Olson, M. P. (2022). Reducing model misspecification and bias in the estimation of interactions. Political Analysis, 30(4), 495-514. Dutt, P., &amp; Tsetlin, I. (2021). Income distribution and economic development: Insights from machine learning. Economics &amp; Politics, 33(1), 1-36. Chernozhukov, Victor; Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, James Robins, Double/debiased machine learning for treatment and structural parameters, The Econometrics Journal, Volume 21, Issue 1, 1 February 2018, Pages C1–C68, https://doi.org/10.1111/ectj.12097 Dahlum, S., Hanson, T., Johnsen, Å., Kotsadam, A., &amp; Wuttke, A. (2024). “Is Support for Authoritarian Rule Contagious? Evidence from Field and Survey Experiments.” CESifo Working Paper Series No. 11490. White, A. (2019). Misdemeanor disenfranchisement? The demobilizing effects of brief jail spells on potential voters. American Political Science Review, 113(2), 311-324. "],["resumo-1.html", "Capítulo 13 Resumo 13.1 Matching 13.2 IV 13.3 RDD 13.4 DiD 13.5 SCM 13.6 DiD Sintético 13.7 Double LASSO 13.8 DML", " Capítulo 13 Resumo 13.1 Matching Selling point: evitar viés da extrapolação de OLS baseado na forma funcional (overlapping). Estimação não paramétrica do ATT (mais robusto). Estimando: ATT (em geral) Suposição de identificação chave: selection on observables (conditional ignorability) Suposição de identificação testável: balancing de covariáveis Questões de estimação: ?? Status: difícil convencer que conditional ignorability é satisfeita. 13.2 IV Selling point: Mais fácil obter ignorability do que selection on observables em regressão ou matching. Estimando: LATE (com heterogeneidade). Supõe monotonicidade. Suposição de identificação chave: exclusion restriction Suposição de identificação testável: Testes de sobreidentificação (Sargan–Hansen) para múltiplos instrumentos. Questões de estimação: IV fraca (estatística F &gt; 23) Status: difícil convencer que temos IV boa 13.3 RDD Selling point: Intuitivo e mais crível de obter ignorability que outros métodos Estimando: LATE Suposição de identificação chave: continuidade do resultado potencial dos não tratados ao redor do ponto de corte Suposição de identificação testável: não-manipulação ao redor do ponto de corte (teste de McCrary etc.) Questões de estimação: Correção de viés de banda larga e construção de intervalos de confiança robustos. Ordem do polinômio e sensibilidade à forma funcional (geralmente recomenda-se local linear). Status: N. 1. Mas cuidado com Politician characteristic regression discontinuity (PCRD). Não será mais crível. 13.4 DiD Selling point: Suposições transparentes? Não depende de ignorability, mas tendências paralelas (mais fácil de obter?). Estimando: ATT Suposição de identificação chave: tendências paralelas e, em casos dinâmicos, comparação correta com grupo controle adequado. Suposição de identificação testável: tendências paralelas pré-exposição ao tratamento. Event studies. Questões de estimação: Tendências paralelas dependem da mensuração da VD (log? etc.). Depende de forma funcional paramétrica. Status: N. 2? 13.4.1 TSCS Selling point: Todo mundo usa e “entende” Estimando: ATT Suposição de identificação chave: tendências paralelas, exogeneidade estrita ou exogeneidade contemporânea (random effects). Suposição de identificação testável: ? Questões de estimação: Em RE, usar correção de Mundlak. Status: Benchmark? Usar para generalização de efeito estimado por outro método local? 13.5 SCM Selling point: Ótimo para efeito causal de um caso Estimando: ATT Suposição de identificação chave: Controle sintético aproxima bem resultado potencial? Suposição de identificação testável: Controle sintético aproxima bem controle pré-exposição Questões de estimação: Erro padrão e p-valor com randomization test. Seleção de conjunto de doadores e covariáveis preditoras (pouca teoria aqui). Status: ??? 13.6 DiD Sintético Selling point: Mais robusto a violações de tendências paralelas que DiD Estimando: ATT Suposição de identificação chave: tendências paralelas Suposição de identificação testável: tendências paralelas pré-exposição Questões de estimação: ? Status: Ninguém entende direito. 13.7 Double LASSO Selling point: Seleção automática de variáveis de controle sem viés de regularização, mesmo com muitas covariáveis. Estimando: ATE (com ignorability condicional) Suposição de identificação chave: Ignorability condicional Suposição de identificação testável: ? Questões de estimação: Definição de penalização (λ) e folds para cross-validation. Status: Potencialmente útil em contextos em que ignorability condicional é satisfeita, como experimentos ou DiD? 13.8 DML Selling point: Resolve o problema de má especificação da forma funcional dos controles Estimando: Depende da aplicação. De ATE, a ATT e LATE. Suposição de identificação chave: Ignorability condicional Suposição de identificação testável: ? Questões de estimação: Muitas. Sensível a qual ML usar, sensível ao número de folds, estrutura dependente pode dificultar cross-validação (dados de rede?), como escolher fine-tuning de parâmetros, qual métrica usar. Status: Promissor para complementar outras técnicas (IV, DiD etc.), mas ainda em desenvolvimento. Seu uso sinaliza sofisticação metodológica. "],["shift-share.html", "Capítulo 14 Shift-share 14.1 Introdução 14.2 Exemplos da Política 14.3 Variação temporal 14.4 O instrumento shift-share como variável instrumental 14.5 Duas estratégias de identificação 14.6 O problema de inferência 14.7 Implementação em R 14.8 Aplicações em Ciência Política 14.9 Aplicações em Relações Internacionais 14.10 Referências", " Capítulo 14 Shift-share 14.1 Introdução O termo “shift-share” surgiu no contexto de análises que procuravam decompor uma variável econômica em subcomponentes. Até onde eu sei, isso não era comum na ciência política, talvez por não ser uma questão “natural” para nós, mas vou tentar explicar a lógica dessas decomposições com exemplos da política. Mas comecemos com os primeiros exemplos na economia. Digamos que queremos decompor o PIB per capita de um estado. Seja \\(D_{ij}\\) o PIB per capita do estado \\(i\\) na indústria \\(j\\), isto é, o valor adicionado do setor \\(j\\) no estado \\(i\\) dividido pelo número de trabalhadores nesse setor. Seja \\(w_{ij}\\) a parcela (share) do emprego da indústria \\(j\\) no estado \\(i\\), ou seja, a fração dos trabalhadores do estado \\(i\\) empregados no setor \\(j\\). Então, o PIB per capita do estado \\(i\\), \\(X_i\\), pode ser decomposto por: \\[X_i = \\sum_j w_{ij}D_{ij}\\] Essa identidade vale porque a soma das parcelas de emprego ponderadas pela produtividade setorial reconstitui a produtividade total do estado. Agora, vamos aplicar um truque algébrico que será recorrente neste capítulo: somar e subtrair o mesmo termo. Somamos e subtraímos \\(\\sum_j w_{ij}\\bar{D}_{j}\\), onde \\(\\bar{D}_{j}\\) é a média nacional do PIB per capita no setor \\(j\\): \\[\\begin{equation} \\begin{aligned} X_i &amp;= \\sum_j w_{ij}D_{ij} \\\\ &amp;= \\sum_j w_{ij}D_{ij} \\color{blue}{+ \\sum_j w_{ij}\\bar{D}_{j}} \\color{red}{- \\sum_j w_{ij}\\bar{D}_{j}} \\\\ &amp;= \\sum_j w_{ij}\\bar{D}_{j} + \\sum_j w_{ij}(D_{ij} - \\bar{D}_{j}) \\end{aligned} \\tag{14.1} \\end{equation}\\] O resultado é a decomposição shift-share básica: \\[\\begin{equation} X_i = \\underbrace{\\sum_j w_{ij}\\bar{D}_{j}}_{\\text{PIB esperado}} + \\underbrace{\\sum_j w_{ij}(D_{ij} - \\bar{D}_{j})}_{\\text{choque regional no PIB}} \\tag{14.2} \\end{equation}\\] O primeiro componente é o PIB esperado: quanto o estado \\(i\\) produziria se cada setor tivesse a produtividade média nacional, dada a estrutura setorial do estado. O segundo componente é o choque regional: quanto o estado se desvia dessa expectativa porque seus setores são mais (ou menos) produtivos que a média nacional. 14.1.1 Aplicação: PIB por estado e setor Vamos aplicar essa decomposição a dados reais simplificados do IBGE. Consideramos cinco estados brasileiros representativos e três grandes setores (Agropecuária, Indústria e Serviços). Os dados abaixo são valores aproximados do Valor Adicionado Bruto e da estrutura de emprego. library(knitr) # Parcelas de emprego por setor (shares) — dados aproximados IBGE pib_shares &lt;- data.frame( Estado = c(&quot;SP&quot;, &quot;MT&quot;, &quot;RJ&quot;, &quot;BA&quot;, &quot;AM&quot;), Agropecuaria = c(0.04, 0.30, 0.02, 0.15, 0.10), Industria = c(0.22, 0.12, 0.15, 0.11, 0.25), Servicos = c(0.74, 0.58, 0.83, 0.74, 0.65) ) # PIB per capita setorial (R$ mil por trabalhador) — dados aproximados pib_prod &lt;- data.frame( Estado = c(&quot;SP&quot;, &quot;MT&quot;, &quot;RJ&quot;, &quot;BA&quot;, &quot;AM&quot;), Agropecuaria = c(40, 100, 35, 25, 20), Industria = c(80, 60, 85, 50, 70), Servicos = c(65, 50, 60, 40, 35) ) kable(pib_shares, caption = &quot;Parcelas de emprego por setor (shares)&quot;, col.names = c(&quot;Estado&quot;, &quot;Agropecuária&quot;, &quot;Indústria&quot;, &quot;Serviços&quot;)) Table 14.1: Parcelas de emprego por setor (shares) Estado Agropecuária Indústria Serviços SP 0.04 0.22 0.74 MT 0.30 0.12 0.58 RJ 0.02 0.15 0.83 BA 0.15 0.11 0.74 AM 0.10 0.25 0.65 kable(pib_prod, caption = &quot;PIB per capita setorial (R$ mil por trabalhador)&quot;, col.names = c(&quot;Estado&quot;, &quot;Agropecuária&quot;, &quot;Indústria&quot;, &quot;Serviços&quot;)) Table 14.1: PIB per capita setorial (R$ mil por trabalhador) Estado Agropecuária Indústria Serviços SP 40 80 65 MT 100 60 50 RJ 35 85 60 BA 25 50 40 AM 20 70 35 Agora aplicamos a decomposição. O PIB per capita de cada estado é \\(X_i = \\sum_j w_{ij}D_{ij}\\), e calculamos a média nacional \\(\\bar{D}_j\\) para cada setor: # Médias nacionais por setor (média simples dos 5 estados) D_bar &lt;- colMeans(pib_prod[, -1]) # PIB per capita total de cada estado pib_total &lt;- rowSums(pib_shares[, -1] * pib_prod[, -1]) # Componente 1: PIB esperado (shares × média nacional) pib_esperado &lt;- as.numeric(as.matrix(pib_shares[, -1]) %*% D_bar) # Componente 2: Choque regional choque_regional &lt;- pib_total - pib_esperado resultado_pib &lt;- data.frame( Estado = pib_shares$Estado, PIB_total = round(pib_total, 1), PIB_esperado = round(pib_esperado, 1), Choque_regional = round(choque_regional, 1) ) kable(resultado_pib, caption = &quot;Decomposição shift-share do PIB per capita (R$ mil)&quot;, col.names = c(&quot;Estado&quot;, &quot;PIB total&quot;, &quot;PIB esperado&quot;, &quot;Choque regional&quot;)) Table 14.2: Decomposição shift-share do PIB per capita (R$ mil) Estado PIB total PIB esperado Choque regional SP 67.3 53.9 13.4 MT 66.2 50.5 15.7 RJ 63.2 52.7 10.5 BA 38.9 51.2 -12.3 AM 42.2 54.1 -11.9 A tabela mostra que estados como São Paulo e Rio de Janeiro têm choques regionais positivos (seus setores são mais produtivos que a média), enquanto estados como Bahia e Amazonas ficam abaixo do esperado. Mato Grosso se destaca porque sua agropecuária é muito mais produtiva que a média nacional, compensando a menor produtividade nos demais setores. 14.2 Exemplos da Política Agora vamos considerar exemplos da política. Um exemplo que me parece “natural” é o voto por estado, que pode ser decomposto por partido. A lógica é análoga à decomposição econômica: cada estado tem uma “estrutura” de composição partidária, e podemos perguntar quanto do resultado eleitoral se deve à tendência nacional dos partidos e quanto se deve a fatores regionais. Formalmente, se definirmos \\(w_{ij}\\) como a parcela de votos do partido \\(j\\) no estado \\(i\\) e \\(\\bar{V}_j\\) como a votação média nacional do partido \\(j\\), podemos construir uma “votação esperada” para cada estado: \\[\\begin{equation} \\hat{X}_i = \\sum_j w_{ij}\\bar{V}_{j} \\tag{14.3} \\end{equation}\\] A diferença entre o resultado observado e o esperado revela o choque regional — o quanto aquele estado se desvia do padrão nacional, dada sua composição partidária. A gente poderia pensar que o poder de um país poderia ser um exemplo em RI. Tipicamente ele é decomposto em componentes militares, econômicos e culturais. Contudo, não é apropriado porque os componentes se misturam, isto é, aumentar a economia ajuda a aumentar os outros componentes, por exemplo, o aspecto cultural, e vice-versa. Para que a decomposição funcione, é preciso que sejam ortogonais. Um exemplo mais apropriado é volume de comércio internacional. Ele pode ser decomposto em volumes por indústria (como na economia), ou por parceiros comerciais. O aspecto crucial aqui a ser notado é que é necessário que exista uma variável que pode ser decomposta em subunidades formadas por categorias mutuamente excludentes. Neste exemplo, o voto do partido exclui voto em outro partido necessariamente. No exemplo original da economia, a renda per capita ou PIB per capita de uma indústria exclui a de todas as outras. É curioso que não tenha havido maior utilização desse tipo de variável instrumental na ciência política e RI, na medida em que temos várias medidas potencialmente decompostas em subunidades formadas por categorias excludentes. 14.3 Variação temporal Para construir o instrumento de shift-share, é preciso adicionar uma dimensão temporal. Suponha que a parcela \\(w_{ij}\\) de votos no partido \\(j\\) no estado \\(i\\) varia no tempo. Isso é razoável: o PT, por exemplo, vai ter variação na sua votação por estado ao longo do tempo. Vamos chamar \\(w_{ijt}\\) a parcela \\(w_{ij}\\) no tempo \\(t=0, 1, ...\\). Assim, podemos expressar \\(w_{ijt}\\) como a soma da parcela inicial \\(w_{ij0}\\) e a mudança ao longo do tempo \\((w_{ijt} - w_{ij0})\\): \\[w_{ijt} = w_{ij0} + (w_{ijt} - w_{ij0})\\] e decompor \\(X_{it}\\) separando a parcela inicial da variação: \\[\\begin{equation} \\begin{aligned} X_{it} &amp;= \\sum_j w_{ijt}D_{ijt} \\\\ &amp;= \\sum_j \\left[w_{ij0} + (w_{ijt} - w_{ij0})\\right] D_{ijt} \\\\ &amp;= \\sum_j w_{ij0} \\, D_{ijt} + \\sum_j (w_{ijt} - w_{ij0}) \\, D_{ijt} \\end{aligned} \\tag{14.4} \\end{equation}\\] E agora aplicamos nosso truque usual de somar e subtrair o mesmo termo, no caso relativo à média \\(\\bar{D}_{jt}\\), mais especificamente \\(w_{ij0}\\bar{D}_{jt}\\): \\[\\begin{equation} \\begin{aligned} X_{it} &amp;= \\sum_j w_{ij0} \\, D_{ijt} + \\sum_j (w_{ijt} - w_{ij0}) \\, D_{ijt} \\\\ &amp;= \\sum_j w_{ij0} \\, D_{ijt} \\color{blue}{+ \\sum_j w_{ij0}\\bar{D}_{jt}} \\color{red}{- \\sum_j w_{ij0}\\bar{D}_{jt}} + \\sum_j (w_{ijt} - w_{ij0}) \\, D_{ijt} \\\\ &amp;= \\color{orange}{\\underbrace{\\sum_j w_{ij0}\\bar{D}_{jt}}_{\\text{A: votação esperada}}} + \\color{purple}{\\underbrace{\\sum_j w_{ij0}(D_{ijt} - \\bar{D}_{jt})}_{\\text{B: choque partidário}}} + \\color{teal}{\\underbrace{\\sum_j (w_{ijt} - w_{ij0}) \\, D_{ijt}}_{\\text{C: choque temporal}}} \\end{aligned} \\tag{14.5} \\end{equation}\\] A interpretação de cada componente é: Componente \\(A\\) (votação esperada): reflete a tendência ou média de votação dos partidos no estado \\(i\\) no ano \\(t\\), levando em conta a composição inicial da distribuição de votos por partido \\(w_{ij0}\\). É o que esperaríamos se o estado mantivesse sua estrutura inicial e cada partido tivesse o desempenho médio nacional. Componente \\(B\\) (choque partidário): reflete a mudança na distribuição de votos por partido por estado. Cada termo \\(w_{ij0}(D_{ijt} - \\bar{D}_{jt})\\) mede quanto a votação do partido \\(j\\) no estado \\(i\\) se desviou da referência média \\(\\bar{D}_{jt}\\) naquele ano. Se \\(D_{ijt} - \\bar{D}_{jt}\\) for positivo, significa que o partido \\(j\\) teve um desempenho acima do esperado no estado \\(i\\) (um choque positivo ali), contribuindo para aumentar \\(X_{it}\\). Se for negativo, o partido \\(j\\) foi pior que a média no estado (choque negativo), reduzindo \\(X_{it}\\) em relação ao esperado. Importante: esses desvios são ponderados por \\(w_{ij0}\\) (quão importante era o partido \\(j\\) no estado \\(i\\) inicialmente), de modo que choques em partidos que tinham grande presença inicial no estado impactam mais o total \\(X_{it}\\) do que choques em partidos com pouca presença inicial. Este componente é chamado de shift porque reflete as mudanças no desempenho dos partidos no nível nacional/setorial afetando o estado conforme sua composição inicial. Componente \\(C\\) (choque temporal): representa o impacto das mudanças na participação dos partidos no próprio estado \\(i\\) ao longo do tempo. Aqui consideramos a diferença \\(w_{ijt} - w_{ij0}\\), ou seja, o quanto a participação do partido \\(j\\) mudou no estado \\(i\\) desde o período inicial. Esse termo mede os choques locais ou regionais na composição dos votos. Por exemplo, se um partido \\(j\\) ganhou espaço no estado \\(i\\) (aumentou sua fatia \\(w_{ijt}\\) em relação à inicial \\(w_{ij0}\\)), isso adiciona votos ao total \\(X_{it}\\) (já que \\(D_{ijt}\\) é multiplicado por um \\(\\Delta w\\) positivo). Por outro lado, se um partido perdeu participação no estado, o termo será negativo, indicando que o estado \\(i\\) teve um desempenho pior por mudança na composição dos votos entre partidos. Em suma, este componente reflete alterações estruturais próprias do estado — realinhamentos políticos regionais, vantagens competitivas locais, etc. — independentemente da tendência geral dos partidos. Em conjunto, esses três componentes (A, B e C) formam a decomposição shift-share completa. Eles nos permitem entender \\(X_{it}\\) da seguinte forma: (A) o que seria esperado dada a tendência geral; (B) o quanto o estado ganhou ou perdeu devido a shifts no desempenho dos partidos; e (C) o quanto se deve a mudanças internas do próprio estado na distribuição de votos (share regional). 14.3.1 Aplicação: Eleições presidenciais 2014→2018 Vamos aplicar a decomposição temporal a dados reais da política brasileira, usando os resultados do primeiro turno das eleições presidenciais de 2014 (Dilma Rousseff, PT) e 2018 (Fernando Haddad, PT). A queda do PT entre essas duas eleições — de cerca de 41% para 29% dos votos válidos nacionalmente — é um dos maiores realinhamentos eleitorais recentes no Brasil, impulsionado pela crise econômica e pela Operação Lava-Jato. Agrupamos os candidatos em três blocos: PT, PSDB e Outros. # Dados aproximados do TSE: votação 1º turno por UF (% votos válidos) # 2014: Dilma (PT), Aécio (PSDB), Marina+outros # 2018: Haddad (PT), Alckmin (PSDB), Bolsonaro+Ciro+outros eleicoes &lt;- data.frame( UF = c(&quot;AC&quot;,&quot;AL&quot;,&quot;AM&quot;,&quot;AP&quot;,&quot;BA&quot;,&quot;CE&quot;,&quot;DF&quot;,&quot;ES&quot;,&quot;GO&quot;,&quot;MA&quot;, &quot;MG&quot;,&quot;MS&quot;,&quot;MT&quot;,&quot;PA&quot;,&quot;PB&quot;,&quot;PE&quot;,&quot;PI&quot;,&quot;PR&quot;,&quot;RJ&quot;,&quot;RN&quot;, &quot;RO&quot;,&quot;RR&quot;,&quot;RS&quot;,&quot;SC&quot;,&quot;SE&quot;,&quot;SP&quot;,&quot;TO&quot;), PT_2014 = c(55,64,62,54,66,62,36,44,33,65, 47,36,36,56,63,62,63,33,40,61, 35,42,37,26,57,31,50), PSDB_2014 = c(27,18,22,25,15,20,40,37,48,17, 34,44,44,26,20,20,19,49,39,21, 45,36,44,55,24,49,31), Outros_2014 = c(18,18,16,21,19,18,24,19,19,18, 19,20,20,18,17,18,18,18,21,18, 20,22,19,19,19,20,19), PT_2018 = c(35,53,43,40,60,55,15,25,14,55, 33,17,16,44,52,47,54,14,21,50, 14,22,19,10,48,16,33), PSDB_2018 = c(5,3,5,4,2,3,7,6,7,2, 7,6,5,4,3,3,2,8,5,3, 6,6,6,7,3,8,4), Outros_2018 = c(60,44,52,56,38,42,78,69,79,43, 60,77,79,52,45,50,44,78,74,47, 80,72,75,83,49,76,63) ) # Mostrar tabela resumo para estados selecionados estados_sel &lt;- c(&quot;SP&quot;,&quot;RJ&quot;,&quot;MG&quot;,&quot;BA&quot;,&quot;CE&quot;,&quot;RS&quot;,&quot;PR&quot;,&quot;PA&quot;,&quot;PE&quot;,&quot;MT&quot;) tab_sel &lt;- eleicoes[eleicoes$UF %in% estados_sel, ] tab_sel &lt;- tab_sel[match(estados_sel, tab_sel$UF), ] kable(tab_sel, row.names = FALSE, caption = &quot;Votação 1º turno (% votos válidos) — estados selecionados&quot;, col.names = c(&quot;UF&quot;, &quot;PT 2014&quot;, &quot;PSDB 2014&quot;, &quot;Outros 2014&quot;, &quot;PT 2018&quot;, &quot;PSDB 2018&quot;, &quot;Outros 2018&quot;)) Table 14.3: Votação 1º turno (% votos válidos) — estados selecionados UF PT 2014 PSDB 2014 Outros 2014 PT 2018 PSDB 2018 Outros 2018 SP 31 49 20 16 8 76 RJ 40 39 21 21 5 74 MG 47 34 19 33 7 60 BA 66 15 19 60 2 38 CE 62 20 18 55 3 42 RS 37 44 19 19 6 75 PR 33 49 18 14 8 78 PA 56 26 18 44 4 52 PE 62 20 18 47 3 50 MT 36 44 20 16 5 79 A queda do PT e o colapso do PSDB são visíveis em todos os estados, mas com intensidade muito diferente. No Nordeste (BA, CE, PE), o PT manteve boa parte dos votos; no Sul e Sudeste (SP, RS, PR), a queda foi drástica. Essa variação regional é exatamente o que a decomposição shift-share nos ajuda a entender. Primeiro, construímos o instrumento Bartik: a mudança esperada na votação de cada estado, com base na composição partidária inicial (2014) e nas tendências nacionais de cada bloco. # Shares: composição partidária de 2014 (em fração) shares_2014 &lt;- eleicoes[, c(&quot;PT_2014&quot;,&quot;PSDB_2014&quot;,&quot;Outros_2014&quot;)] / 100 # Shifts: mudança nacional na votação de cada bloco (média dos 27 estados) media_2014 &lt;- colMeans(eleicoes[, c(&quot;PT_2014&quot;,&quot;PSDB_2014&quot;,&quot;Outros_2014&quot;)]) media_2018 &lt;- colMeans(eleicoes[, c(&quot;PT_2018&quot;,&quot;PSDB_2018&quot;,&quot;Outros_2018&quot;)]) shifts &lt;- (media_2018 - media_2014) / 100 # em pontos percentuais / 100 # Instrumento Bartik para cada estado bartik &lt;- as.numeric(as.matrix(shares_2014) %*% shifts) # Mudança real na votação do PT mudanca_real_pt &lt;- (eleicoes$PT_2018 - eleicoes$PT_2014) / 100 resultado_elec &lt;- data.frame( UF = eleicoes$UF, Mudanca_PT = round(mudanca_real_pt * 100, 1), Bartik = round(bartik * 100, 1), Residuo = round((mudanca_real_pt - bartik) * 100, 1) ) tab_elec &lt;- resultado_elec[resultado_elec$UF %in% estados_sel, ] tab_elec &lt;- tab_elec[match(estados_sel, tab_elec$UF), ] kable(tab_elec, row.names = FALSE, caption = &quot;Mudança na votação PT 2014→2018 vs. predição Bartik (pp)&quot;, col.names = c(&quot;UF&quot;, &quot;Mudança real PT&quot;, &quot;Predição Bartik&quot;, &quot;Resíduo&quot;)) Table 14.4: Mudança na votação PT 2014→2018 vs. predição Bartik (pp) UF Mudança real PT Predição Bartik Resíduo SP -15 -9.6 -5.4 RJ -19 -7.8 -11.2 MG -14 -8.4 -5.6 BA -6 -6.1 0.1 CE -7 -7.2 0.2 RS -18 -9.6 -8.4 PR -19 -10.8 -8.2 PA -12 -8.0 -4.0 PE -15 -7.2 -7.8 MT -20 -9.0 -11.0 O resíduo captura fatores regionais específicos — por exemplo, estados onde a Lava-Jato teve impacto particularmente forte ou onde lideranças locais do PT mantiveram sua base eleitoral. library(ggplot2) ggplot(resultado_elec, aes(x = Bartik, y = Mudanca_PT)) + geom_point(size = 2) + geom_abline(intercept = 0, slope = 1, linetype = &quot;dashed&quot;, color = &quot;gray50&quot;) + geom_text(aes(label = UF), vjust = -0.7, size = 3) + labs(x = &quot;Predição Bartik (pp)&quot;, y = &quot;Mudança real na votação PT (pp)&quot;, title = &quot;Decomposição shift-share das eleições 2014-2018&quot;) + theme_minimal() Figure 14.1: Mudança na votação do PT (2014→2018): observada vs. predição Bartik O gráfico mostra que estados próximos à linha tracejada (45°) tiveram mudanças bem explicadas pela estrutura nacional; estados distantes da linha tiveram choques regionais importantes. Agora aplicamos a decomposição completa nos três componentes A, B e C: # Shares em 2014 (t=0) e 2018 (t=1) — em fração w_0 &lt;- eleicoes[, c(&quot;PT_2014&quot;,&quot;PSDB_2014&quot;,&quot;Outros_2014&quot;)] / 100 w_t &lt;- eleicoes[, c(&quot;PT_2018&quot;,&quot;PSDB_2018&quot;,&quot;Outros_2018&quot;)] / 100 # D_{ijt}: votação em 2018 (usamos os mesmos dados como proxy de intensidade) D_t &lt;- eleicoes[, c(&quot;PT_2018&quot;,&quot;PSDB_2018&quot;,&quot;Outros_2018&quot;)] # Média nacional de D_{jt} em 2018 D_bar_t &lt;- colMeans(D_t) # Componente A: votação esperada = sum_j w_{ij0} * D_bar_{jt} comp_A &lt;- as.numeric(as.matrix(w_0) %*% D_bar_t) # Componente B: choque partidário = sum_j w_{ij0} * (D_{ijt} - D_bar_{jt}) desvios &lt;- sweep(as.matrix(D_t), 2, D_bar_t) comp_B &lt;- rowSums(as.matrix(w_0) * desvios) # Componente C: choque temporal = sum_j (w_{ijt} - w_{ij0}) * D_{ijt} delta_w &lt;- as.matrix(w_t) - as.matrix(w_0) comp_C &lt;- rowSums(delta_w * as.matrix(D_t)) temporal &lt;- data.frame( UF = eleicoes$UF, A_esperado = round(comp_A, 1), B_choque_part = round(comp_B, 1), C_choque_temp = round(comp_C, 1) ) # Tabela para estados selecionados tab_temp &lt;- temporal[temporal$UF %in% estados_sel, ] tab_temp &lt;- tab_temp[match(estados_sel, tab_temp$UF), ] kable(tab_temp, row.names = FALSE, caption = &quot;Decomposição temporal A, B, C — estados selecionados&quot;, col.names = c(&quot;UF&quot;, &quot;A: esperado&quot;, &quot;B: choque partidário&quot;, &quot;C: choque temporal&quot;)) Table 14.5: Decomposição temporal A, B, C — estados selecionados UF A: esperado B: choque partidário C: choque temporal SP 25.1 -1.0 36.9 RJ 28.2 -2.3 33.5 MG 29.1 0.2 18.1 BA 34.6 12.6 3.4 CE 32.8 9.4 5.7 RS 26.2 -2.3 36.3 PR 24.5 -1.9 40.9 PA 31.1 3.9 11.5 PE 32.8 5.9 8.4 MT 26.5 -2.8 41.5 library(tidyr) # Preparar dados para gráfico de barras (estados selecionados) plot_data &lt;- temporal[temporal$UF %in% estados_sel, ] plot_data &lt;- plot_data[match(estados_sel, plot_data$UF), ] plot_long &lt;- pivot_longer(plot_data, cols = -UF, names_to = &quot;Componente&quot;, values_to = &quot;Valor&quot;) plot_long$Componente &lt;- factor(plot_long$Componente, levels = c(&quot;A_esperado&quot;,&quot;B_choque_part&quot;,&quot;C_choque_temp&quot;), labels = c(&quot;A: Votação esperada&quot;,&quot;B: Choque partidário&quot;,&quot;C: Choque temporal&quot;)) ggplot(plot_long, aes(x = UF, y = Valor, fill = Componente)) + geom_col(position = &quot;dodge&quot;) + labs(x = &quot;Estado&quot;, y = &quot;Valor do componente&quot;, title = &quot;Decomposição shift-share das eleições 2018&quot;, fill = &quot;Componente&quot;) + scale_fill_manual(values = c(&quot;orange&quot;,&quot;purple&quot;,&quot;#008080&quot;)) + theme_minimal() + theme(axis.text.x = element_text(angle = 0)) Figure 14.2: Componentes shift-share da votação 2018 por estado O gráfico ilustra como o resultado eleitoral de 2018 em cada estado se decompõe nos três componentes. O componente A (votação esperada) é relativamente estável; as maiores diferenças entre estados vêm dos componentes B (choque partidário — refletindo o colapso diferencial do PSDB e a ascensão de Bolsonaro) e C (choque temporal — refletindo realinhamentos regionais como a resistência do PT no Nordeste). 14.4 O instrumento shift-share como variável instrumental A decomposição acima é útil descritivamente, mas o verdadeiro poder do shift-share está no seu uso como variável instrumental. Vamos formalizar a construção e entender as condições de identificação. 14.4.1 Construção formal Considere \\(N\\) estados (indexados por \\(i\\)) e \\(K\\) partidos (indexados por \\(k\\)). Para cada estado \\(i\\), observamos a parcela (share) de votos do partido \\(k\\) em um período-base \\(t_0\\): \\[\\begin{equation} w_{ik} = \\frac{V_{ik,t_0}}{V_{i,t_0}} \\tag{14.6} \\end{equation}\\] onde \\(V_{ik,t_0}\\) é o total de votos no partido \\(k\\) no estado \\(i\\) no período-base, e \\(V_{i,t_0}\\) é o total de votos válidos no estado \\(i\\). Note que \\(\\sum_k w_{ik} = 1\\). Observamos também um choque (shift) agregado no nível do partido \\(k\\), denotado \\(g_k\\). Por exemplo, \\(g_k\\) pode ser a variação nacional na votação do partido \\(k\\): \\[\\begin{equation} g_k = \\frac{\\Delta V_k^{\\text{Nacional}}}{V_{k,t_0}^{\\text{Nacional}}} \\tag{14.7} \\end{equation}\\] O instrumento shift-share (ou instrumento Bartik) para o estado \\(i\\) é definido como: \\[\\begin{equation} B_i = \\sum_{k=1}^{K} w_{ik} \\cdot g_k \\tag{14.8} \\end{equation}\\] Este instrumento calcula a média ponderada dos choques partidários nacionais, usando as shares pré-determinadas como pesos. A intuição é que estados com composição partidária diferente serão diferencialmente afetados pelas mesmas tendências nacionais. Por exemplo, um estado com alta concentração inicial de votos no PT será mais afetado por uma queda nacional do PT do que um estado onde o PT era minoritário. Embora aqui ilustremos com votos e partidos, a mesma lógica se aplica a setores econômicos e emprego (a aplicação clássica de Bartik 1991), a parceiros comerciais e comércio, ou a qualquer variável decomponível em subunidades excludentes. 14.4.2 Voltando ao exemplo: construindo \\(w_{ik}\\), \\(g_k\\) e \\(B_i\\) com dados eleitorais Podemos agora mapear cada elemento da construção formal nos dados das eleições 2014→2018 já analisados. Nossos “setores” (\\(k\\)) são os três blocos partidários (PT, PSDB, Outros) e nossas “regiões” (\\(i\\)) são os 27 estados. As shares \\(w_{ik}\\) são a composição partidária de cada estado em 2014 (o período-base \\(t_0\\)): # w_{ik} = fração de votos do partido k no estado i em 2014 tab_shares &lt;- data.frame( UF = eleicoes$UF, w_PT = round(shares_2014$PT_2014, 2), w_PSDB = round(shares_2014$PSDB_2014, 2), w_Outros = round(shares_2014$Outros_2014, 2) ) tab_shares_sel &lt;- tab_shares[tab_shares$UF %in% c(&quot;BA&quot;,&quot;CE&quot;,&quot;MG&quot;,&quot;SP&quot;,&quot;RS&quot;), ] tab_shares_sel &lt;- tab_shares_sel[match(c(&quot;BA&quot;,&quot;CE&quot;,&quot;MG&quot;,&quot;SP&quot;,&quot;RS&quot;), tab_shares_sel$UF), ] kable(tab_shares_sel, row.names = FALSE, caption = &quot;Shares $w_{ik}$: composição partidária em 2014 (fração dos votos válidos)&quot;, col.names = c(&quot;Estado (i)&quot;, &quot;$w_{i,PT}$&quot;, &quot;$w_{i,PSDB}$&quot;, &quot;$w_{i,Outros}$&quot;)) Table 14.6: Shares \\(w_{ik}\\): composição partidária em 2014 (fração dos votos válidos) Estado (i) \\(w_{i,PT}\\) \\(w_{i,PSDB}\\) \\(w_{i,Outros}\\) BA 0.66 0.15 0.19 CE 0.62 0.20 0.18 MG 0.47 0.34 0.19 SP 0.31 0.49 0.20 RS 0.37 0.44 0.19 A Bahia tem \\(w_{BA,PT} = 0{,}66\\): dois terços dos votos foram para o PT em 2014. Já São Paulo tem \\(w_{SP,PT} = 0{,}31\\). Essa diferença na composição inicial é o que gera variação no instrumento. Os shifts \\(g_k\\) são as mudanças nacionais na votação de cada bloco entre 2014 e 2018: tab_shifts &lt;- data.frame( Partido = c(&quot;PT&quot;, &quot;PSDB&quot;, &quot;Outros&quot;), g_k = round(shifts * 100, 1) ) kable(tab_shifts, row.names = FALSE, caption = &quot;Shifts $g_k$: mudança nacional na votação de cada bloco (pp)&quot;, col.names = c(&quot;Partido ($k$)&quot;, &quot;$g_k$ (pp)&quot;)) Table 14.7: Shifts \\(g_k\\): mudança nacional na votação de cada bloco (pp) Partido (\\(k\\)) \\(g_k\\) (pp) PT -15.2 PSDB -27.4 Outros 42.6 O PT caiu cerca de 16pp nacionalmente, o PSDB desmoronou ~26pp, e o bloco Outros (liderado por Bolsonaro e Ciro) subiu ~43pp. Esses choques são os mesmos para todos os estados — são tendências nacionais. Finalmente, o instrumento Bartik \\(B_i = \\sum_k w_{ik} \\cdot g_k\\) combina as shares iniciais com os shifts nacionais: tab_bartik &lt;- data.frame( UF = eleicoes$UF, Bartik = round(bartik * 100, 1) ) tab_bartik_sel &lt;- tab_bartik[tab_bartik$UF %in% c(&quot;BA&quot;,&quot;CE&quot;,&quot;MG&quot;,&quot;SP&quot;,&quot;RS&quot;), ] tab_bartik_sel &lt;- tab_bartik_sel[match(c(&quot;BA&quot;,&quot;CE&quot;,&quot;MG&quot;,&quot;SP&quot;,&quot;RS&quot;), tab_bartik_sel$UF), ] kable(tab_bartik_sel, row.names = FALSE, caption = &quot;Instrumento Bartik $B_i$ para cada estado (pp)&quot;, col.names = c(&quot;Estado ($i$)&quot;, &quot;$B_i$ (pp)&quot;)) Table 14.8: Instrumento Bartik \\(B_i\\) para cada estado (pp) Estado (\\(i\\)) \\(B_i\\) (pp) BA -6.1 CE -7.2 MG -8.4 SP -9.6 RS -9.6 Observe que os shifts \\(g_k\\) são idênticos para todos os estados — o que diferencia os \\(B_i\\) entre si são exclusivamente as shares \\(w_{ik}\\). A Bahia, com 66% de votos no PT em 2014, é muito mais exposta à queda nacional do PT do que São Paulo, com 31%. É essa variação cross-sectional no instrumento, gerada pela composição inicial, que permite a identificação. 14.4.3 O modelo estrutural e o IV O objetivo típico é estimar o efeito causal de uma variável endógena \\(X_i\\) sobre uma variável de resultado \\(Y_i\\). O modelo estrutural é: \\[\\begin{equation} Y_i = \\alpha + \\beta X_i + \\varepsilon_i \\tag{14.9} \\end{equation}\\] onde \\(X_i\\) é endógena (por exemplo, crescimento do emprego local ou mudança na votação, que é tanto causa quanto consequência de outros fatores locais). OLS é inconsistente porque \\(\\text{Cov}(X_i, \\varepsilon_i) \\neq 0\\). Primeiro estágio (first stage): O instrumento \\(B_i\\) prevê \\(X_i\\): \\[\\begin{equation} X_i = \\gamma_0 + \\gamma_1 B_i + \\nu_i \\tag{14.10} \\end{equation}\\] A condição de relevância exige \\(\\gamma_1 \\neq 0\\): as shares combinadas com os shifts devem efetivamente prever a variável endógena. Segundo estágio (second stage): Substitui-se \\(X_i\\) por \\(\\hat{X}_i\\): \\[\\begin{equation} Y_i = \\alpha + \\beta \\hat{X}_i + \\eta_i \\tag{14.11} \\end{equation}\\] A condição de exclusão exige \\(\\text{Cov}(B_i, \\varepsilon_i) = 0\\): o instrumento só afeta \\(Y_i\\) através de \\(X_i\\). 14.4.4 Interpretando o modelo com o exemplo eleitoral Vamos dar concretude ao modelo acima usando nosso exemplo. Suponha que queremos estimar o efeito causal da mudança na votação do PT (\\(X_i\\) = queda do PT em pp no estado \\(i\\)) sobre alguma variável de resultado político \\(Y_i\\) — por exemplo, o nível de abstenção, o gasto público municipal ou a ocorrência de protestos. O problema é que a queda do PT em cada estado não é aleatória: ela está correlacionada com fatores locais não observados (\\(U_i\\)), como a força de lideranças locais, o nível de desemprego estadual, a cobertura midiática da Lava-Jato, entre outros. Esses mesmos fatores podem afetar \\(Y_i\\) diretamente. Por isso, OLS é inconsistente. Primeiro estágio: O instrumento Bartik \\(B_i\\) prevê a queda do PT no estado \\(i\\). A lógica é que estados com maior concentração inicial de votos no PT (\\(w_{i,PT}\\) alto) estão mecanicamente mais expostos à tendência nacional de queda do PT. O primeiro estágio estima: \\[X_i = \\gamma_0 + \\gamma_1 B_i + \\nu_i\\] Se \\(\\gamma_1\\) é significativamente diferente de zero, o instrumento é relevante — as tendências nacionais, filtradas pela composição inicial, efetivamente preveem a mudança local. No nosso exemplo, o gráfico da seção anterior (mudança real vs. predição Bartik) já mostrou que essa relação é forte: estados onde o Bartik prevê queda maior de fato tiveram queda maior. Segundo estágio: Substituímos \\(X_i\\) por seu valor predito \\(\\hat{X}_i\\) — a parte da mudança local que é explicada apenas pelas tendências nacionais interagidas com a composição inicial: \\[Y_i = \\alpha + \\beta \\hat{X}_i + \\eta_i\\] A estimativa \\(\\hat{\\beta}\\) captura o efeito causal de \\(X_i\\) sobre \\(Y_i\\), desde que o instrumento satisfaça a restrição de exclusão. Intuitivamente, ao usar \\(\\hat{X}_i\\) em vez de \\(X_i\\), estamos “limpando” a variação endógena (fatores locais) e ficando apenas com a variação exógena (exposição a tendências nacionais via composição inicial). 14.4.5 Por que o instrumento seria válido? Uma discussão intuitiva Podemos visualizar a estrutura causal do instrumento shift-share com um DAG: Figure 14.3: DAG do instrumento shift-share. O instrumento \\(B_i\\) é construído a partir das shares iniciais (\\(w\\)) e dos choques nacionais (\\(g\\)). A restrição de exclusão exige que não haja caminho direto de \\(B\\) para \\(Y\\) que não passe por \\(X\\). No DAG acima, \\(g\\) representa os choques nacionais (\\(g_k\\)), \\(w\\) as shares iniciais (\\(w_{ik}\\)), \\(B\\) o instrumento Bartik (\\(B_i\\)), \\(X\\) a variável endógena (\\(X_i\\)), \\(U\\) os confundidores não observados (\\(U_i\\)) e \\(Y\\) o resultado (\\(Y_i\\)). O confundidor \\(U\\) cria um backdoor entre \\(X\\) e \\(Y\\), tornando OLS inconsistente. O instrumento \\(B\\) é válido se o único caminho de \\(B\\) para \\(Y\\) passa por \\(X\\). A restrição de exclusão seria violada se houvesse uma seta direta de \\(B\\) para \\(Y\\) (ou, equivalentemente, de \\(w\\) ou \\(g\\) para \\(Y\\) por canais que não passam por \\(X\\)). No nosso exemplo eleitoral, isso aconteceria se: A composição partidária inicial (\\(w_{ik}\\)) afetasse \\(Y_i\\) diretamente. Por exemplo, se estados mais “petistas” em 2014 fossem sistematicamente mais pobres ou mais urbanizados, e essas características afetassem \\(Y_i\\) (abstenção, protestos etc.) por canais que não passam pela mudança na votação do PT, o instrumento seria inválido. Os choques nacionais (\\(g_k\\)) refletissem fatores que também afetassem \\(Y_i\\) diretamente. Por exemplo, se a Lava-Jato afetasse tanto os votos (via \\(X_i\\)) quanto os protestos (via um canal direto), a restrição seria violada. É importante reconhecer que o nosso exemplo hipotético de IV — usar a mudança eleitoral como instrumento para algum outcome estadual como abstenção, gasto público ou protestos — enfrenta desafios reais de identificação. Primeiro, com \\(N = 27\\) estados, o número de observações é muito pequeno para estimação IV confiável (instrumentos fracos, inferência imprecisa). Segundo, as shares e os shifts operam no mesmo nível geográfico que o outcome: tendências nacionais por partido afetam os estados, e os outcomes também são estaduais, dificultando a separação entre o canal causal de interesse e outros canais. Terceiro, fatores como a mudança de governador entre 2014 e 2018 são parte do próprio mecanismo político que liga tendências nacionais a resultados locais, confundindo o canal causal. Uma solução para esses problemas é explorar variação cross-level — usar choques de um nível geográfico (por exemplo, tendências estaduais) para prever outcomes em outro nível (por exemplo, municipal). Quando os shifts são computados em um nível mais agregado do que a unidade de observação, a separação entre instrumento e confundidores locais se torna mais plausível. Além disso, o leave-out design — excluir a própria unidade ao computar o shift agregado — elimina a correlação mecânica entre o instrumento e choques locais não observados. Xu (2025, Journal of Politics) oferece um exemplo concreto e bem-sucedido de como resolver esses problemas em uma aplicação de SSIV na ciência política brasileira, usando variação cross-level entre eleições estaduais e outcomes municipais combinada com um leave-out design. Discutimos esse estudo em detalhe na seção de aplicações em ciência política. A questão crucial que emerge é: de onde, exatamente, vem a exogeneidade do instrumento? Das shares? Dos shifts? De ambos? Essa pergunta tem duas respostas formais distintas, que correspondem a duas estratégias de identificação com implicações muito diferentes para diagnósticos e credibilidade. É exatamente isso que a próxima seção formaliza. 14.5 Duas estratégias de identificação Uma revolução metodológica recente (2018-2025) esclareceu que há duas maneiras distintas de justificar a exogeneidade do instrumento shift-share. A referência pedagógica central é Borusyak, Hull &amp; Jaravel (2025), publicada no Journal of Economic Perspectives. 14.5.1 Estratégia 1: Exogeneidade das shares (GPSS 2020) Goldsmith-Pinkham, Sorkin &amp; Swift (2020) demonstram um resultado de equivalência fundamental. Para entender essa equivalência, é útil primeiro ter uma intuição sobre GMM (Método Generalizado dos Momentos). Intuição sobre GMM. O estimador de MQO (OLS) pode ser entendido como a solução de uma condição de momento: encontrar \\(\\beta\\) tal que \\(\\mathbb{E}[X_i&#39; \\varepsilon_i] = 0\\), ou seja, os resíduos são não correlacionados com os regressores. Quando temos instrumentos \\(Z_i\\), o estimador de IV impõe a condição \\(\\mathbb{E}[Z_i&#39; \\varepsilon_i] = 0\\). Quando há exatamente tantos instrumentos quanto variáveis endógenas (identificação exata), existe uma única solução. Mas quando há mais instrumentos que variáveis endógenas — o caso de sobreidentificação — o sistema tem mais equações que incógnitas, e em geral não existe \\(\\beta\\) que satisfaça todas as condições simultaneamente. O GMM resolve esse problema encontrando o \\(\\beta\\) que melhor satisfaz todas as condições de momento ao mesmo tempo, atribuindo pesos ótimos a cada condição. No caso shift-share, cada share \\(w_{ik}\\) (para \\(k = 1, ..., K\\)) pode ser vista como um instrumento separado, gerando \\(K\\) condições de momento — uma situação típica de sobreidentificação. A equivalência demonstrada por GPSS é que o estimador IV usando \\(B_i = \\sum_k w_{ik} g_k\\) como instrumento único é numericamente idêntico a um estimador GMM que usa cada share \\(w_{ik}\\) como instrumento separado, com os shifts \\(g_k\\) servindo apenas como pesos na combinação ótima: \\[\\begin{equation} \\hat{\\beta}^{IV} = \\sum_k \\hat{\\alpha}_k \\hat{\\beta}_k \\tag{14.12} \\end{equation}\\] onde \\(\\hat{\\beta}_k\\) é a estimativa just-identified usando apenas \\(w_{ik}\\) como instrumento (para o partido \\(k\\)), e \\(\\hat{\\alpha}_k\\) é o peso de Rotemberg que mede a influência relativa do partido \\(k\\) na estimativa global. Os pesos de Rotemberg satisfazem \\(\\sum_k \\hat{\\alpha}_k = 1\\) mas podem ser negativos, o que é um sinal de alerta. Em outras palavras: usar o instrumento Bartik \\(B_i\\) é matematicamente equivalente a usar todas as \\(K\\) shares como instrumentos separados via GMM. A escolha entre os dois é uma questão de conveniência, não de substância. Hipótese de identificação: As shares iniciais \\(w_{ik}\\) são exógenas — isto é, não correlacionadas com fatores não observados que afetam \\(Y_i\\): \\[\\begin{equation} \\mathbb{E}[w_{ik} \\cdot \\varepsilon_i] = 0 \\quad \\forall k \\tag{14.13} \\end{equation}\\] Os shifts \\(g_k\\) não precisam ser exógenos; eles apenas afetam a ponderação e a relevância do instrumento. Diagnósticos: Calcular os Rotemberg weights \\(\\hat{\\alpha}_k\\) para identificar quais partidos (ou setores) mais influenciam a estimativa. Testar balanceamento das shares mais influentes contra covariáveis pré-determinadas. 14.5.2 Estratégia 2: Exogeneidade dos shifts (BHJ 2022) Borusyak, Hull &amp; Jaravel (2022) oferecem um framework alternativo. A regressão IV no nível regional é numericamente equivalente a uma regressão IV no nível do choque (partido/setor), onde a variável de resultado e o tratamento são agregados ao nível do choque usando as shares como pesos: \\[\\begin{equation} \\bar{Y}_k = \\sum_i s_{ik} Y_i, \\quad \\bar{X}_k = \\sum_i s_{ik} X_i \\tag{14.14} \\end{equation}\\] onde \\(s_{ik} = w_{ik} / \\sum_i w_{ik}\\) normaliza os pesos. A regressão no nível do choque: \\[\\begin{equation} \\bar{Y}_k = \\alpha + \\beta \\bar{X}_k + \\bar{\\varepsilon}_k \\tag{14.15} \\end{equation}\\] instrumentada por \\(g_k\\), produz exatamente a mesma estimativa \\(\\hat{\\beta}\\) que a regressão regional com \\(B_i\\). Hipótese de identificação: Os choques \\(g_k\\) são quase aleatoriamente atribuídos — isto é, não correlacionados com a média ponderada (por shares) dos fatores não observados regionais: \\[\\begin{equation} \\mathbb{E}[g_k \\cdot \\bar{\\varepsilon}_k] = 0 \\quad \\forall k \\tag{14.16} \\end{equation}\\] As shares \\(w_{ik}\\) podem ser endógenas. A identificação vem inteiramente da aleatoriedade dos choques, dado que há muitos choques independentes (\\(K \\to \\infty\\)). Diagnósticos: Testes de pré-tendências e balanceamento no nível do choque. Verificar se \\(g_k\\) correlaciona-se com \\(\\bar{\\varepsilon}_k\\) pré-tratamento. 14.5.3 Resumo das duas estratégias Shares exógenas (GPSS 2020) Shifts exógenos (BHJ 2022) Hipótese-chave \\(\\mathbb{E}[w_{ik} \\cdot \\varepsilon_i] = 0\\) \\(\\mathbb{E}[g_k \\cdot \\bar{\\varepsilon}_k] = 0\\) Shares podem ser endógenas? Não Sim Shifts podem ser endógenos? Sim (só afetam pesos) Não N. de choques necessário Pode funcionar com poucos Precisa de muitos (\\(K\\) grande) Diagnósticos Rotemberg weights, balanceamento nas shares Pré-tendências e balanceamento no nível do choque Aplicações típicas Elasticidades de oferta de trabalho, especialização histórica exógena Imigração (enclave), comércio (China Shock) 14.6 O problema de inferência Adão, Kolesár &amp; Morales (2019) identificam um problema crítico: erros-padrão convencionais (incluindo clustered por região ou estado) são severamente subestimados em regressões shift-share. Em exercícios de placebo, testes ao nível nominal de 5% rejeitam a hipótese nula verdadeira até 55% das vezes. O problema surge porque resíduos \\(\\hat{\\varepsilon}_i\\) são correlacionados entre regiões com composição setorial similar, independentemente de proximidade geográfica. Duas regiões \\(i\\) e \\(j\\) com shares parecidos (\\(w_{ik} \\approx w_{jk}\\)) compartilham exposição aos mesmos choques setoriais, induzindo correlação em \\(\\hat{\\varepsilon}_i\\) e \\(\\hat{\\varepsilon}_j\\) que não é capturada por clustering geográfico. Na prática, os intervalos de confiança corrigidos por AKM são substancialmente mais largos que os convencionais. Alternativa BHJ: Em vez de corrigir os erros-padrão no nível regional, rodar a regressão diretamente no nível do choque (via ssaggregate) e usar erros-padrão convencionais (heteroscedasticidade-robustos) no nível do choque. Se os choques são independentes, a inferência convencional é válida. 14.7 Implementação em R 14.7.1 Construção do instrumento O instrumento \\(B_i = \\sum_k w_{ik} g_k\\) é uma simples multiplicação matricial: # shares: matriz N x K de exposure shares (cada linha soma 1) # shocks: vetor K x 1 de choques setoriais bartik_instrument &lt;- shares %*% shocks 14.7.2 Estimação IV Diversos pacotes R permitem estimar 2SLS. O fixest é recomendado por sua velocidade e suporte a efeitos fixos: library(fixest) # Construir instrumento dados$bartik &lt;- as.numeric(shares %*% shocks) # IV com efeitos fixos de estado modelo &lt;- feols(y ~ controles | estado | x_endogeno ~ bartik, data = dados) summary(modelo) 14.7.3 Erros-padrão corrigidos: pacote ShiftShareSE O pacote ShiftShareSE, de Michal Kolesár, está disponível no CRAN e implementa os erros-padrão AKM (Adão, Kolesár &amp; Morales, 2019): install.packages(&quot;ShiftShareSE&quot;) library(ShiftShareSE) # IV com SEs corrigidos para shift-share resultado &lt;- ivreg_ss(y ~ x_endogeno | bartik, X = shares_matrix, # matriz N x K de shares data = dados) summary(resultado) Este pacote é essencial porque, como demonstrado por AKM, erros-padrão convencionais (mesmo clusterizados por geografia) são severamente subestimados em designs shift-share. 14.7.4 Agregação ao nível do choque: pacote ssaggregate O pacote ssaggregate, de Kyle Butts, implementa a agregação ao nível do choque de Borusyak, Hull &amp; Jaravel (2022). Está disponível apenas no GitHub: # install: remotes::install_github(&quot;kylebutts/ssaggregate&quot;) library(ssaggregate) # Agregar dados regionais para o nível do choque dados_choque &lt;- ssaggregate( data = dados_long, # formato longo: região x setor shares = &quot;share&quot;, n = &quot;regiao&quot;, s = &quot;setor&quot;, t = &quot;ano&quot;, y = c(&quot;y&quot;, &quot;x_endogeno&quot;) ) # Agora rodar IV convencional no nível do choque feols(y ~ 1 | x_endogeno ~ g_k, data = dados_choque) 14.7.5 Ecossistema R vs. Stata Uma comparação do ecossistema de software para shift-share revela diferenças importantes: Funcionalidade Stata R Status R Agregação BHJ ssaggregate (Borusyak et al.) ssaggregate (Kyle Butts) GitHub apenas SEs AKM ShiftShareSE (pacote .ado) ShiftShareSE (Kolesár) No CRAN Rotemberg weights bartik_weight (GPSS) Nenhum pacote Lacuna principal IV básico ivregress, ivreg2 fixest, ivreg, estimatr Excelente A principal lacuna no R é a ausência de um pacote para calcular Rotemberg weights — o diagnóstico central da abordagem GPSS (2020). Em Stata, o comando bartik_weight de Goldsmith-Pinkham, Sorkin &amp; Swift calcula automaticamente esses pesos. Em R, o pesquisador precisa adaptar o código de replicação disponível no GitHub dos autores (github.com/paulgp/bartik-weight) ou implementar manualmente, o que envolve rodar \\(K\\) regressões just-identified (uma por setor). Essa lacuna pode desencorajar o uso de diagnósticos adequados, distorcer a escolha metodológica em favor da abordagem BHJ (que tem melhor suporte em R via ssaggregate), e criar uma barreira de entrada para pesquisadores de CP e RI que tipicamente usam R. 14.8 Aplicações em Ciência Política O instrumento shift-share tem sido cada vez mais utilizado em ciência política, especialmente para estudar os efeitos políticos de choques comerciais. 14.8.1 Comércio e voto nos EUA Baccini &amp; Weymouth (2021, APSR) mostram que, em condados dos EUA afetados pela desindustrialização via importações chinesas, brancos votaram mais em republicanos e negros mais em democratas — sugerindo que a desindustrialização ameaça o status do grupo dominante. Feigenbaum &amp; Hall (2015, Journal of Politics) encontram que choques de importação chinesa fazem legisladores votarem de forma mais protecionista em projetos de comércio, mas sem efeito em outras votações nem na reeleição. Margalit (2011, APSR) mostra que eleitores são mais sensíveis a demissões por competição estrangeira do que por outros fatores, e que a compensação governamental (via Trade Adjustment Assistance) mitiga o backlash político. 14.8.2 Comércio e nacionalismo na Europa Colantone &amp; Stanig publicaram dois artigos seminais: em 2018 no APSR, mostram que o voto Leave no Brexit foi sistematicamente maior em regiões mais expostas à competição chinesa (um desvio-padrão no choque = ~2pp a mais de Leave); e no mesmo ano no AJPS, encontram que maior exposição ao choque chinês aumentou apoio a partidos nacionalistas e de extrema-direita em 15 países europeus (1988-2007). Hays, Lim &amp; Spoon (2019, Electoral Studies) confirmam esse padrão para o populismo de direita na Europa, e Rommel &amp; Walter (2022, Comparative Political Studies) estendem para offshoring, mostrando que regiões mais expostas tiveram aumento no apoio a partidos de direita radical. 14.8.3 Valores autoritários Ballard-Rosa, Malik, Rickard &amp; Scheve (2021, Comparative Political Studies) mostram que regiões britânicas mais afetadas por importações chinesas têm valores significativamente mais autoritários, via mecanismo de frustração-agressão. Ballard-Rosa, Jensen &amp; Scheve (2022, International Studies Quarterly) replicam o achado para os EUA: competição chinesa em regiões diversas gera valores mais autoritários, afetando a identidade social de grupos dominantes. 14.8.4 Welfare state histórico Scheve &amp; Serlin (2023, APSR) usam um shift-share histórico para mostrar que importações alemãs na Grã-Bretanha (1880-1910) pioraram o mercado de trabalho e mudaram crenças sobre o “merecimento” dos pobres, contribuindo para o surgimento do welfare state britânico. 14.8.5 Automação e redistribuição Thewissen &amp; Rueda (2019, Comparative Political Studies) mostram que trabalhadores mais expostos à automação expressam preferências mais fortes por redistribuição, com o efeito mediado pelo contexto institucional. 14.8.6 Brasil Campello &amp; Urdinez (2021, Comparative Political Studies) é uma das poucas aplicações fora dos EUA/Europa. Mostram que municípios brasileiros afetados por importações chinesas veem a China como risco, mas municípios beneficiados por exportações não veem como oportunidade — as perdas moldam percepções de política externa mais que os ganhos. 14.8.7 Competição política e desmatamento Xu (2025, Journal of Politics) — “Bureaucratic Packing in the Brazilian Amazon” — é uma aplicação de SSIV em ciência política brasileira que exemplifica como resolver os problemas de identificação discutidos na seção sobre exclusion restriction. A pergunta central é: competição política local causa desmatamento na Amazônia? O problema de endogeneidade é severo. Municípios com mais desmatamento podem ter economias baseadas em extração ilegal de madeira, o que afeta a competição política local (causalidade reversa). Além disso, fatores não observados — como capacidade institucional, presença de ONGs ambientais ou interesses de grandes proprietários — podem afetar simultaneamente competição e desmatamento. A estratégia de identificação. Xu adapta o método de Shaukat (2019) para construir um instrumento shift-share que prevê competição política municipal a partir de tendências eleitorais estaduais. A construção tem três componentes: Shares (\\(z_{p,m,s}\\)): a votação do partido \\(p\\) no município \\(m\\) do estado \\(s\\) na eleição estadual de 1998, o período-base. Essas shares capturam a composição partidária inicial do município. Shifts (\\(g_{p,s,t}^{-m}\\)): a mudança na votação do partido \\(p\\) no nível estadual entre 1998 e a eleição \\(t\\), excluindo o próprio município \\(m\\) do cálculo (leave-out). Esses shifts capturam tendências partidárias estaduais que são plausivamente exógenas ao município individual. Predicted vote share: \\(\\hat{s}_{p,m,s,t} = z_{p,m,s} + g_{p,s,t}^{-m}\\). O instrumento combina a composição inicial do município com a tendência estadual para prever a votação de cada partido no município. A partir dos vote shares preditos, Xu constrói uma medida de competição política predita: \\(1 - |\\hat{s}_{winner} - \\hat{s}_{runner-up}|\\), onde valores mais altos indicam margens menores entre os dois candidatos mais votados (mais competição). Por que essa estratégia funciona? Três elementos-chave garantem a identificação: Variação cross-level: Os shifts vêm de eleições estaduais, mas os outcomes (desmatamento) são municipais. Ao usar tendências de um nível geográfico mais agregado para prever outcomes em um nível mais desagregado, a separação entre o instrumento e confundidores locais não observados se torna mais plausível. Isso contrasta com o nosso exemplo hipotético anterior, onde shifts e outcomes operavam no mesmo nível estadual. Leave-out design: Ao excluir o próprio município \\(m\\) do cálculo do shift estadual \\(g_{p,s,t}^{-m}\\), elimina-se a correlação mecânica entre o instrumento e choques locais não observados. Se um choque local afeta tanto o desmatamento quanto a votação no município \\(m\\), esse choque não contamina o shift estadual porque \\(m\\) foi excluído. Nonmonotonicity: Um partido ganhando popularidade estadual aumenta a competição em municípios onde era fraco, mas diminui a competição onde já era forte. Essa propriedade gera variação rica no instrumento e torna improvável que tendências estaduais afetem o desmatamento municipal por um canal direto uniforme. Resultado. Xu encontra que maior competição política leva a mais desmatamento. O mecanismo identificado é o bureaucratic packing: prefeitos em eleições competitivas nomeiam mais funcionários comissionados para construir máquinas eleitorais, deslocando recursos da fiscalização ambiental. O enfraquecimento da capacidade de enforcement local facilita o desmatamento ilegal. Conexão com as estratégias de identificação. O design de Xu/Shaukat aposta fundamentalmente na exogeneidade dos shifts — as tendências estaduais de votação partidária, excluindo o município. Isso o alinha à estratégia BHJ (2022): a identificação vem da quase-aleatoriedade dos choques, não da exogeneidade das shares iniciais. A combinação de variação cross-level com leave-out design oferece um modelo replicável para aplicações de SSIV em ciência política comparada, especialmente em contextos onde a unidade de tratamento (município) está aninhada em unidades políticas maiores (estado). 14.9 Aplicações em Relações Internacionais O shift-share também tem sido publicado em periódicos de RI, especialmente International Organization e International Studies Quarterly. 14.9.1 Comércio e política externa Jensen, Quinn &amp; Weymouth (2017, International Organization) mostram que importações reduzem o voto no incumbente presidencial nos EUA enquanto exportações aumentam, com swing states de manufatura de baixa qualificação especialmente vulneráveis. Broz, Frieden &amp; Weymouth (2021, International Organization 75(1): 76-103) encontram que regiões simultaneamente expostas a importações e automação tiveram o maior aumento no voto populista (Trump 2016), com a interação dos dois choques mais poderosa que cada um isoladamente. 14.9.2 Comportamento legislativo em política comercial Kuk, Seligsohn &amp; Zhang (2018, Journal of Contemporary China) mostram que, após 2003 (pós-acessão da China à OMC), legisladores americanos de distritos afetados por importações chinesas tornaram-se sistematicamente mais hostis à China em votos de política externa — mais hostis do que após o massacre de Tiananmen. Owen (2017, International Studies Quarterly) mostra que congressistas de distritos mais expostos a offshoring votaram mais contra o acordo DR-CAFTA. 14.9.3 Temas com potencial inexplorado em RI A metodologia shift-share tem aplicações potenciais em diversos temas de RI que permanecem pouco explorados: Sanções internacionais: Exposição diferencial de países a sanções, usando shares de parceiros comerciais e shifts de sanções impostas. Cooperação internacional: Efeitos de choques econômicos sobre apoio a organizações internacionais e tratados. Conflito: Na interface com economia, Dube &amp; Vargas (2013, Review of Economic Studies) oferecem um exemplo elegante usando preços de commodities e conflito na Colômbia com dois mecanismos opostos (custo de oportunidade vs. rapacidade), e Gallea (2023, Journal of Development Economics) usa transferências de armas e conflito na África, mas essas aplicações foram publicadas em periódicos de economia, não de RI. China Shock no Sul Global: Além de Campello &amp; Urdinez (2021) sobre o Brasil, há pouquíssimas aplicações do China Shock político em países em desenvolvimento. 14.10 Referências Adão, Rodrigo, Michal Kolesár, and Eduardo Morales. 2019. “Shift-Share Designs: Theory and Inference.” Quarterly Journal of Economics 134(4): 1949-2010. Baccini, Leonardo, and Stephen Weymouth. 2021. “Gone For Good: Deindustrialization, White Voter Backlash, and US Presidential Voting.” American Political Science Review 115(2): 550-567. Ballard-Rosa, Cameron, Amalie Jensen, and Kenneth Scheve. 2022. “Economic Decline, Social Identity, and Authoritarian Values in the United States.” International Studies Quarterly 66(1). Ballard-Rosa, Cameron, Mashail Malik, Stephanie Rickard, and Kenneth Scheve. 2021. “The Economic Origins of Authoritarian Values.” Comparative Political Studies 54(13): 2321-2353. Bartik, Timothy J. 1991. Who Benefits from State and Local Economic Development Policies? Kalamazoo, MI: W.E. Upjohn Institute. Borusyak, Kirill, Peter Hull, and Xavier Jaravel. 2022. “Quasi-Experimental Shift-Share Research Designs.” Review of Economic Studies 89(1): 181-213. Borusyak, Kirill, Peter Hull, and Xavier Jaravel. 2025. “A Practical Guide to Shift-Share Instruments.” Journal of Economic Perspectives 39(1): 181-204. Broz, J. Lawrence, Jeffry Frieden, and Stephen Weymouth. 2021. “Populism in Place: The Economic Geography of the Globalization Backlash.” International Organization 75(1): 76-103. Campello, Daniela, and Francisco Urdinez. 2021. “Voter and Legislator Responses to Localized Trade Shocks from China in Brazil.” Comparative Political Studies 54(7): 1131-1162. Colantone, Italo, and Piero Stanig. 2018. “Global Competition and Brexit.” American Political Science Review 112(2): 201-218. Colantone, Italo, and Piero Stanig. 2018. “The Trade Origins of Economic Nationalism.” American Journal of Political Science 62(4): 936-953. Dube, Oeindrila, and Juan Vargas. 2013. “Commodity Price Shocks and Civil Conflict: Evidence from Colombia.” Review of Economic Studies 80(4): 1384-1421. Feigenbaum, James, and Andrew Hall. 2015. “How Legislators Respond to Localized Economic Shocks.” Journal of Politics 77(4). Gallea, Quentin. 2023. “Weapons and War: The Effect of Arms Transfers on Internal Conflict.” Journal of Development Economics 160. Goldsmith-Pinkham, Paul, Isaac Sorkin, and Henry Swift. 2020. “Bartik Instruments: What, When, Why, and How.” American Economic Review 110(8): 2586-2624. Hays, Jude, Junghyun Lim, and Jae-Jae Spoon. 2019. “The Path from Trade to Right-Wing Populism in Europe.” Electoral Studies 57: 181-196. Jensen, J. Bradford, Dennis Quinn, and Stephen Weymouth. 2017. “Winners and Losers in International Trade.” International Organization 71(3): 423-457. Kuk, John Seungmin, Deborah Seligsohn, and Jiakun Jack Zhang. 2018. “From Tiananmen to Outsourcing.” Journal of Contemporary China 27(109). Margalit, Yotam. 2011. “Costly Jobs: Trade-related Layoffs, Government Compensation, and Voting in U.S. Elections.” American Political Science Review 105(1): 166-188. Owen, Erica. 2017. “Exposure to Offshoring and the Politics of Trade Liberalization.” International Studies Quarterly 61(2): 297-311. Rommel, Tobias, and Stefanie Walter. 2022. “The Electoral Consequences of Offshoring.” Comparative Political Studies 55(5): 829-864. Scheve, Kenneth, and Theo Serlin. 2023. “The German Trade Shock and the Rise of the Neo-Welfare State.” American Political Science Review 117(2): 557-574. Shaukat, Maryam. 2019. “Political Competition and Economic Policy: Estimating the Effect of Electoral Competitiveness on Policy Outcomes.” Ph.D. Dissertation, London School of Economics. Thewissen, Stefan, and David Rueda. 2019. “Automation and the Welfare State.” Comparative Political Studies 52(1): 141-174. Xu, Alice Z. 2025. “Bureaucratic Packing in the Brazilian Amazon: How Political Competition Drives Deforestation.” Journal of Politics 87(4): 1350-1363. "],["interferência-spillover-e-dinâmica.html", "Capítulo 15 Interferência, spillover e dinâmica 15.1 Suposições simplificadoras 15.2 PO com tratamento de múltiplos valores (multi-valued) 15.3 Dinâmica 15.4 Interferência", " Capítulo 15 Interferência, spillover e dinâmica Agora iremos relaxar algumas simplificações do modelo de Resultados potenciais que vimos até agora. 15.1 Suposições simplificadoras Tratamento binário Único período de tempo (um tratamento “within unit”) SUTVA 15.2 PO com tratamento de múltiplos valores (multi-valued) 15.2.1 Multi-valued discreto Vamos estender o modelo de tratamento binário começando por tratamentos discretos. Digamos que temos \\(D_i \\in \\{0, 1, ..., d\\}\\), isto é, tratamentos ordenados. Por exemplo, múltiplas categorias de uma política pública (100 reais, 200 reais, 300 reais etc.). Definimos o resultado potencial da unidade \\(i\\) para qualquer \\(d \\in D\\) como \\(Y_i(d)\\). Nós vamos precisar da suposição de ignorability forte. \\(\\tau_i(D, D&#39;) = Y_i(d) - Y_i(d&#39;)\\), ou seja, o efeito causal entre dois níveis do tratamento. Como antes, podemos computar a esperança: \\(\\mathbb{E}[\\tau_i(D, D&#39;)] = \\mathbb{E}[Y_i(d) - Y_i(d&#39;)]\\). E se ignorability forte vale, então \\(\\mathbb{E}[\\tau_i(D, D&#39;)] = \\mathbb{E}[Y_i|D_i = d] - \\mathbb{E}[Y_i|D_i = d&#39;]\\) Se quisermos, podemos trabalhar também com tratamentos não-ordenados. Por exemplo, dois tratamentos binários. Por exemplo, um tratamento é informação sobre corrupção de um candidato (recebe ou não a informação) e outro tratamento é informação sobre a raça do candidato (é branco ou não). \\(D_i \\in \\{0,1\\}^2\\). Podemos modelar os resultados potenciais como dependendo do status dos dois tratamentos: \\(Y_i(D_{i1}, D_{i2})\\) que geram quatro possibilidades ou resultados potenciais: \\(Y(0,0)\\), \\(Y(1,0)\\), \\(Y(0,1)\\), \\(Y(1,1)\\). Exemplo onde mesmo com atribuição aleatória, há efeitos não-identificados. Aleatoriamente atribuir \\(D_1\\) e, para os que receberam \\(D_1\\), aleatoriamente atribuir \\(D_2\\). Onde isso poderia acontecer? Primeira e segunda dose de vacina! Por definição, a segunda dose só é dada para quem recebeu a primeira dose. Nunca é possível estimar efeito relativo a \\(Y_i(0,1)\\), isto é, o resultado potencial de quem não recebeu a primeira dose, mas recebeu a segunda. Essa é uma pessoa que recebeu a primeira dose quando a segunda estava sendo aplicada. 15.3 Dinâmica Considere que agora nós observamos \\(T\\) períodos de tempo para uma unidade: \\(Y_i = (Y_{i1}, Y_{i2}, \\ldots, Y_{iT})\\). Para cada período, há um tratamento \\(D_{it} \\in \\{0,1\\}\\), isto é, sempre binário. Chamamos de \\(\\mathbf{D_i} = (D_{i1}, D_{i2}, ..., D_{iT})\\) o vetor de tratamentos em todos os \\(T\\) períodos. Implicitamente, muitas pessoas abordam modelos dinâmicos supondo que podemos olhar apenas para o resultado potencial para a unidade \\(i\\) no período \\(t\\), ou seja, \\(Y_{it}(D_{it})\\). Porém, isso significa que apenas o tratamento do período \\(t\\) impacta o resultado potencial do período \\(t\\). De maneira mais geral, teríamos: \\(\\mathbf{D_i} = (D_{i1}, D_{i2}, ..., D_{iT})\\) e definiríamos o resultado potencial no período \\(t\\) como \\(Y_{it}(\\mathbf{D_i})\\). \\(Y(\\mathbf{D})\\). Nesse caso, fomos para o lado oposto: tratamentos futuros impactando o resultado potencial do presente. Isso não necessariamente significa que o futuro afeta o passado. Pode ocorrer por antecipação de tratamentos futuros. De todo modo, também parece extremo. Ainda assim, continuamos evitando a possibilidade de spillovers. Uma suposição comum, portanto, é a de não-antecipação, que pode ser representada por: \\(Y_{it}(d_1, d_2, ..., d_t, d_{t+1}, ..., d_T) = Y_{it}(d_1, d_2, ..., d_t)\\). Ou seja, os resultados potenciais até \\(t\\) não dependem dos tratamentos após essa data. Outra suposição comum é: ausência de efeitos dinâmicos: \\[Y_{it}(d_1, d_2, ..., d_t) = Y_{it}(d_t)\\] Em palavras, essa suposição requer que o resultado potencial do presente não dependa dos tratamentos passados. Essa suposição é também chamada de “no carry-over-effects hypothesis”. Ela é bem restritiva. Mesmo um desenho em que a aleatorização é executada a cada período de maneira independente pode ter “carry-over-effects” se o resultado do período anterior impactar o resultado do período presente. Modelos de “impulse response function” estão interessados em estimar justamente “carry over effects”. ver https://donskerclass.github.io/CausalEconometrics/TimeSeries.html Considere um modelo de regressão tradicional para dados dinâmicos: \\(y_{it} = \\alpha + \\beta x_{it} + e_{it}\\). Nós já sabemos que uma forma de pensar a identificação causal é imaginar um experimento aleatório controlado. O que significa, em primeiro lugar, escolher aleatoriamente o tratamento nesse caso? Uma possibilidade é imaginar que a cada período o tratamento é aleatoriamente atribuído, independentemente dos períodos anteriores. No fundo, é como um multi-valued treatment. Qual condição de ignorability estamos satisfazendo nesse caso? Se apenas o tratamento presente impacta o resultado potencial, isto é, \\(Y_{it}(D_{it})\\), então temos: Baseline randomization: \\(Y(D_{it}) \\perp D_{it}\\). Ou seja, o resultado potencial no período \\(t\\) é independente do mecanismo de atribuição do tratamento. Essa suposição implica exogeneidade estrita. Ignorability sequencial (Sequential Unconfoundedness). Assume que, conditional à história passada observada de tratamentos e covariáveis, o tratamento corrente é independente de resultados potenciais. Nós iremos aprofundar essas questões nas aulas sobre DiD e Efeitos Fixos. Por ora, quero notar que no fundo estamos falando de spillovers no tempo, isto é, tratamento no tempo \\(t\\) impactando resultados potenciais de períodos futuros \\(t+(1:k)\\), em que \\(k &gt;0\\). 15.4 Interferência Interferência ocorre quando o resultado potencial de uma unidade depende do tratamento de outra unidade. Tipicamente, em ciências sociais, spillovers podem envolver: Efeitos de pares Spillovers espaciais Interações políticas (restrições orçamentárias) Para modelar interferência, é necessário enriquecer nosso framework, introduzindo definições adicionais e alterando os pressupostos chave. Tipicamente nós modelamos com a suposição de que a interferência ocorre apenas em um subgrupo de unidades, isto é, o resultado potencial não depende do status de tratamento de todas as unidades, mas tão somente de um grupo específico. Além disso, também é comum ser necessária a suposição de anonimidade, isto é, os pares de um grupo importam, mas não quem são os pares, no sentido de que cada par teria um efeito específico e único sobre uma unidade. Essa é uma área de pesquisa ativa na inferência causal, mas ainda pouco incorporada na ciência política, em particular nas RIs, mas não só. Referências chave são: Charles F Manski. Identification of treatment response with social interactions. The Econometrics Journal, 16(1):S1–S23, 2013. Peter M Aronow and Cyrus Samii. Estimating average causal effects under general interference, with application to a social network experiment. Annals of Applied Statistics, 11(4):1912–1947, 2017. Bowers J, Fredrickson MM, Panagopoulos C. Reasoning about Interference Between Units: A General Framework. Political Analysis. 2013;21(1):97-124. doi:10.1093/pan/mps038 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
