[["index.html", "Curso de Inferência Causal Capítulo 1 Introdução 1.1 Revisão de Regressão 1.2 Inferência 1.3 Referências", " Curso de Inferência Causal Manoel Galdino 2025-06-03 Capítulo 1 Introdução Aqui pretendo guardar minhas notas de aula para meu curso de causalidade na pós-graduação. É uma forma de organizar e sistematizar meu estudo sobre o tema. 1.1 Revisão de Regressão Comecemos pelo modelo de regressão populacional dado por: \\[y = \\beta_0 + \\beta_1 x + u\\] As suposições básicas do modelo são: Média do erro é zero (sem perda de generalidade): \\(\\mathbb{E}[u] = 0\\) Independência na média do erro: \\(\\mathbb{E}[u|x] = \\mathbb{E}[u]\\). Essa é a suposição mais consequente do modelo de regressão. Como é sobre o termo de erro, não é testável. Um exemplo é útil para entender o que significa essa suposição. Suponha que estamos interessados no efeito do gasto de campanha (\\(x\\)) sobre o voto (\\(y\\)). O termo de erro \\(e\\) seria a qualidade da candidata, não observável. A suposição implica então que a qualidade média das candidatas que gastam 100 mil reais é a mesma das que gastam 500 mil e um milhão (e assim por diante). Se candidatas melhores arrecadam mais dinheiro e, portanto, gastam mais, a suposição foi violada. Conectando 1 e 2, temos: \\(\\mathbb{E}[u|x] = 0\\). Essa suposição é chamada de “média condicional zero” ou “esperança condicional zero” do termo de erro. Ela implica que: \\(\\mathbb{E}[y|x] = \\beta_0 + \\beta_1 x\\). Essa equação é chamada de Conditional Expectation Function, ou CEF. De posse de uma amostra aleatória simples, podemos derivar os estimadores de mínimos quadrados (MQO ou OLS na sigla em inglês). Vou pular os passos da derivação. Para nós, o importante é lembrar a fórmula do \\(\\hat{\\beta_1}\\): \\(\\hat{\\beta_1} = \\frac{\\text{covariância amostral}}{\\text{variância amostral}} = \\frac{\\sum_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n(x_i - \\bar{x})^2}\\) E \\(\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x}\\). Podemos então demonstrar que o estimador é não-viesado. Para isso, é necessário supor que o modelo é linear nos parâmetros (não nas variáveis), temos uma amostra aleatória simples da população, existe variância no preditor (para não dividir por zero na fórmula do estimador de OLS) e a média condicional zero. 1.1.1 Teorema da Anatomia da Regressão Esse teorema, também conhecido como teorema de Frisch, Waugh e Lovell ou Frisch-Waugh-Lovell, é útil para ajudar a entender regressão múltipla. Suponha que nosso modelo possui \\(2\\) preditores: \\(y_i=\\beta_0+\\beta_1 x_{1i}+ \\beta_2 x_{2i}+ e_i\\). Agora, suponha que, em vez de rodar a regressão acima, eu rodo uma regressão (chamada de auxiliar) em que \\(x_1\\) é a variável dependente, e \\(x_2\\) o único preditor. \\(x_{1i}=\\gamma_0+\\gamma_{1}x_{2i} + f_i\\). E os resíduos são dados por: \\(\\tilde{x}{1i}=x{1i} - \\widehat{x}{1i}\\). Então, é possível mostrar que: \\(\\beta_1 = \\frac{C(y_i, \\tilde{x}{1i})}{V(\\tilde{x}_{1i})}\\). O que essa fórmula nos diz é que o efeito de \\(\\beta_1\\) é a covariância entre a variável dependente e o resíduo da regressão auxiliar, isto é, a parte de \\(x_1\\) não explicada pelos demais preditores. Vamos visualizar essa relação com um exemplo do livro do Scott Cunningham: library(tidyverse) library(haven) read_data &lt;- function(df) { full_path &lt;- paste0(&quot;https://github.com/scunning1975/mixtape/raw/master/&quot;, df) haven::read_dta(full_path) } auto &lt;- read_data(&quot;auto.dta&quot;) %&gt;% mutate(length = length - mean(length)) lm1 &lt;- lm(price ~ length, auto) lm2 &lt;- lm(price ~ length + weight + headroom + mpg, auto) lm_aux &lt;- lm(length ~ weight + headroom + mpg, auto) auto &lt;- auto %&gt;% mutate(length_resid = residuals(lm_aux)) lm2_alt &lt;- lm(price ~ length_resid, auto) coef_lm1 &lt;- lm1$coefficients coef_lm2_alt &lt;- lm2_alt$coefficients resid_lm2 &lt;- lm2$residuals y_single &lt;- tibble(price = coef_lm2_alt[1] + coef_lm1[2]*auto$length_resid, length_resid = auto$length_resid) y_multi &lt;- tibble(price = coef_lm2_alt[1] + coef_lm2_alt[2]*auto$length_resid, length_resid = auto$length_resid) auto %&gt;% ggplot(aes(x=length_resid, y = price)) + geom_point() + geom_smooth(data = y_multi, color = &quot;blue&quot;) + geom_smooth(data = y_single, color = &quot;red&quot;) ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; 1.2 Inferência Como sabemos, inferência lida com a generalização da amostra para a população e, portanto, com a variabilidade inerente de amostra para amostra. Eu não vou revisar aqui os cálculos para derivar o erro padrão. Quero apenas enfatizar dois pontos que não são usualmente abordados em cursos de regressão. Em primeiro lugar, generalização da amostra para a população é diferente de generalização causal, também conhecida como validade externa. Esse ponto foi confundido por muitos autores, em particular o livro conhecido como KKV, e levou muitos pesquisadores a acreditarem que uma regressão possuía maior capacidade de generalização causal do que estudos de caso. Uma regressão (supondo que o erro padrão foi calculado corretamente) permite generalizar as estimativas para uma população. Porém, o que significa falar em generalização quando temos o universo de casos (por exemplo, todos os deputados, ou todos os candidatos, ou todos os municípios)? Quando temos o universo, não é diferente de estudos de caso que possuem todos os casos relevantes e, portanto, a noção de generalização da amostra para população não se aplica. O que me leva ao segundo ponto: na inferência causal, em particular nesses casos em que temos o universo dos casos, ainda assim há incerteza. O trabalho de Abadie et. al (2020) discute a ideia de design-based inference. Nós vamos explicar no curso em mais detalhes o que é uma pesquisa design-based (em oposição a model-based). A ideia desse tipo de incerteza (e seu correspondente erro-padrão) é a seguinte. Imagine que estamos interessados em estimar o efeito causal da reeleição de prefeitos sobre a corrupção municipal. Suponha que tenho todos os municípios na amostra. Por fim, suponha que temos um experimento natural de forma que podemos supor que (talvez condicional a algumas variáveis) a reeleição é aleatória. Não há incerteza amostral para a população, mas há incerteza sobre o que aconteceria com a corrupção para os prefeitos reeleitos, caso não fossem reeleitos (e para os que perderam, como seria a corrupção caso fossem reeleitos). Em particular, se acreditamos que a reeleição foi aleatória, então uma nova rodada de amostragem (em um universo alternativo?) produziria outra configuração de prefeitos reeleitos e não-reeleitos e alguma variação na estimativa do efeito causal. Isso antecipa nossa discussão sobre causalidade da próxima aula, mas o ponto é que existe incerteza na variação do efeito causal, que não deriva de variação amostral propriamente, mas da aleatoriedade da intervenção. Nas palavras dos autores: “it will be useful to distinguish between descriptive estimands, where uncertainty stems solely from not observing all units in the population of interest, and causal estimands, where the uncertainty stems, at least partially, from unobservability of some of the potential outcome” (p. 267). Meu ponto é que KKV e cia confundiram incerteza de estimandos descritivos com estimandos causais. O que me leva de volta ao ponto anterior sobre a comparação entre estudos de caso e métodos quantitativos, quando o objetivo é inferência causal. A incerteza inerente é sobre o efeito da intervenção, não sobre variações amostrais. Além disso, em ambos os casos não sabemos (a princípio) se os estudos possuem validade externa, isto é, se os resultados valem para outras populações, no tempo e espaço. É preciso avançar nessa agenda, tanto em métodos quali como quanti. É um problema em aberto e que tem atraído muitas pesquisas novas, que não iremos cobrir no curso (até por desconhecimento meu de boa parte dessa literatura). 1.3 Referências Abadie, Alberto, Susan Athey, Guido W. Imbens, and Jeffrey M. Wooldridge. 2020. “Sampling-Based Versus Design-Based Uncertainty in Regression Analysis.” Econometrica 88 (0): 265–96. "],["resultados-potenciais.html", "Capítulo 2 Resultados Potenciais 2.1 Causalidade e o Método Comparativo 2.2 Potential Outcomes 2.3 Notação 2.4 Problema Fundamental da Inferência Causal 2.5 Estimando 2.6 Estimandos Mais Comuns 2.7 Nota sobre estimandos 2.8 Exercício - Qual o estimando e o estimador (se possível)? 2.9 Identificação 2.10 Identificação do ATE 2.11 Equações estruturais 2.12 Modelo versus Desenho 2.13 Exercício em sala 2.14 Referências", " Capítulo 2 Resultados Potenciais Durante muito tempo, inferência causal com regressão era caracterizada por recomendações vagas, ad hoc e inconsistências. O debate sobre o efeito causal do cigarro sobre câncer de pulmão é ilustrativo a esse respeito. Durante décadas, pesquisadores enfrentaram dificuldades para diferenciar correlação de causalidade em estudos epidemiológicos sobre tabagismo. Muitos estudos iniciais baseados apenas em correlação eram contestados por não apresentarem mecanismos claros ou critérios objetivos para validar inferências causais. Fisher (1958), por exemplo, questionou os resultados iniciais que ligavam o cigarro ao câncer por falta de critérios explícitos para identificar uma relação causal, argumentando que a correlação observada poderia decorrer de fatores confundidores, causalidade reversa ou problemas de mensuração. A situação mudou gradualmente com contribuições metodológicas importantes, como os critérios de causalidade propostos por Hill (1965). Os critérios de Bradford Hill ofereceram uma lista explícita e sistemática para avaliar a plausibilidade causal em estudos observacionais: O efeito deveria ser grande reproduzível em estudos independentes possuir uma relação monotônica com “dose” (isto é, aumento na dose não pode reduzir o efeito se o efeito é positivo e vice-versa se for negativo). corresponde a um “experimento natural”” se comporta apropriadamente quando a causa é aplicada, removida e então reinstalada. é consistente com o conhecimento especializado do tema é, por exemplo, predita por alguma teoria bem estabelecida. Nós temos amplas evidências de que muitas intervenções são causais, mesmo na ausência de qualquer experimento aleatório controlado. Sabemos, por exemplo, que defribilação, manobra de Heimlinch e uso de paraquedas são eficazes para prevenir mortes [@howick_etal_2009]. Em um artigo clássico dos primórdios da estatística escrito por Yule [@yule_1989], temos um dos primeiros exemplos de utilização da regressão para estudar o efeito causal do efeito de uma política (ajuda sobre pobreza). E a despeito do título do artigo falar em causalidade (“An investigation into the causes of changes in pauperism in england, chiefly during the last two intercensal decades”), a certa altura ele diz, em nota de rodapé, que “due to” deve ser lido como “associated to”. Quase cem anos depois, o grande estatístico Cox afirmaria em um artigo sobre causalidade: “it is remarkable how relatively little causality is mentioned in the general statistics literature, except in a social science context”[@cox_1992, p. 292]. Exemplo da perspectiva de que falava Cox quando, por exemplo, @muthen_1987 chegou a afirmar que “It would be very healthy if more researchers abandon thinking of and using terms such as cause and effect” (p. 180). Algo ecoado em uma entrevista com um dos líderes da evolução causal desde os anos 70/80, Jamie Robins, que relata que seus papers (en journals de estatística) eram rejeitados por usar linguagem causal, algo rejeitado na época [@robins_2022]. Então parece bastante seguro dizer que a sensação geral na estatística até os anos 80 é que não se deveria usar linguagem causal fora de estudos experimentais, isto é, em estudos não-observacionais. 2.1 Causalidade e o Método Comparativo A ideia de causalidade é bastante presente na ciência política na literatura de polític comparada qualitativa. Empregando os métodos advogados por Stuart Mill, a ideia de causalidade sempre estive presente e associada a ideias de relações necessárias e ou suficientes. Nesse sentido, causalidade seria determiniística. A moderna forma de pensar causalidade abandona esse paradigma de relações necessárias e/ou suficientes, para pensar em termos de contrafactual, o que no fundo é próximo do que a pesquisa comparada fazia. Tomemos um exemplo clássico dessa literatura. [inserirautor] estava interessado em estudar o efeito ccausal de [inserir variável de tratamento] sobre [variável de resultado], e comparou [unidade de tratamento] com [unidade de controle]. 2.2 Potential Outcomes Objetivos de aporendizado da aula: Aprender a diferença entre esimando, estimador e estimativa. Aprender as condições de identificação do ATE (Average Treatment Effect) 2.3 Notação Vamos assumir que existe um tratamento binário, que recebe o valor \\(1\\) se a unidade \\(i\\) recebe o tratamento, e \\(0\\) caso contrário, dado por: \\(D_i \\in \\{1,0\\}\\). Suponha que eu tenha \\(N\\) unidades que podem receber o tratamento ou controle. Então, o resultado potencial para a unidade \\(i\\) é \\(Y_i(\\mathbf{D})\\), ou seja, o resultado (potencial) da unidade \\(i\\) dado o conjunto de tratamento recebido por todas as \\(N\\) unidades. Em outras palavras, o resultado potencial depende do status de tratamento de todas as unidades. O que nos leva à primeira suposição simplificadoras: Assumption 1 (Stable Unit Treatment Value Assumption) Se \\(D_i = D{&#39;}_i\\), então \\(Y_i(\\mathbf{D}) = Y_i(\\mathbf{D}^{&#39;})\\). Em palavras, se mudarmos o tratamento de \\(i\\) de \\(D\\) para \\(D&#39;\\), então o resultado potencial depende apenas dessa mudança, e não dos demais tratamentos. Ou seja, o resultado potencial depende apenas do próprio tratamento, não dos demais. Essa suposição també é chamada de não-interferência. Então podemos escrever o resultado potencial apenas como função de \\(D_i\\): \\(Y_i(D_i)\\). Entretanto, os resultados potenciais não são observáveis. O que nós observamos é o resultado se a pessoa foi ou não tratada. O que nos leva à “switching equation”: \\(Y_i = Y_i(1)D_i + (1-D_i)Y_i(0)\\) Podemos agora definir o efeito causal do tratamento ao nível da unidade: \\(\\tau_i = Y_i(1) - Y_i(0)\\) A switching equation conecta o observado aos resultados potenciais e vice-versa. Esse modelo é chamado de Modelo Causal de Neyman-Rubin. 2.4 Problema Fundamental da Inferência Causal Barizado por Holland (1986) de Problema Fundamental da Inferência Causal (PFIC) diz que não podemos observar, simultanemente, ambos os resultados potenciais \\(Y_i(1)\\) e \\(Y_i(0)\\). Possívels soluções para o PFIC: Assumir homogeneidade temporal (comparação antes de depois da mesma unidade) Assumir homogeneidade da unidade (comparar dois indivíduos, um tratado, outro no controle) Método estatístico (foco na esperança) 2.5 Estimando O que nós estamos interessados em estimar é o nosso Estimando. Lundberg et al. (2021), definem de maneira bem completa o que é um estimando. Informalmente, é a quantidade causal que queremos estimar. Os autores separam o estimando teórico do estimando estatístico. O estimando teórico especifica a unidade teórica de interesse (ex.: o efeito de instituicões inclusivas sobre o desenvolvimento economômico do país \\(i\\); “A Dilma teria sofrido impeachment se a lava-jato não existisse?”). O segundo componente é a população-alvo. Se formos agregar essa unidade, é sobre quem ou quê? No primeiro caso, é a categoria de países em desenvolvimento em 1990? Todos os países independentes do globo no seçulo XX? No segundo caso, é mais difícil pensar qual é a população alvo. Talv ez já seja a população e, nesse caso, nao cabe se perguntar sobre qume agregaríamos a quantidade. Ou talvez a pergunta de pesquisa seja sobre crises econômicas e impeachment, e o Brasil é só um caso. Daí a população alvo pode ser, talvez, países latino-americanos. Nesse caso, a pesquisadora deverá argumentar sobre como o estudo de caso é informativo sobre a população-alvo. Estimando estatístico ou empírico é a quantidade que pode ser estimada estatisticamente (a princípio). Estimativa: a aproximação do estimando usando uma amostra finita de dados Estimador: o método ou fórmula para se chegar a uma estimativa para um estimando. 2.6 Estimandos Mais Comuns 2.6.1 ATE Vamos definir o ATE e mostrar condições suficientes para identificação desse estimando. O ATT é simplesmente o efeito causal médio entre todos os indivíduos de uma população. Às vezes chamado de PATE, de Populational Averate Treatment Effect. Definição 2.1. Chamamos de ATE na população: \\[\\tau_{\\text{ATE}} = \\mathbb{E}[\\tau_i] = \\mathbb{E}[Y_i(1) - Y_i(0)] = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)]\\] O ATE nos dá o efeito do tratamento em toda a população de interesse. 2.6.2 ATT Definição 2.2. Chamamos de Average Treatment Effect on the Treated (ATT): \\[\\tau_{\\text{ATT}} = \\mathbb{E}[\\tau_i|D_i=1] = \\mathbb{E}[Y_i(1) - Y_i(0)|D_i=1] = \\underbrace{\\mathbb{E}[Y_i(1)|D_i=1]}_{\\text{observado}} - \\mathbb{E}[Y_i(0)|D_i=1]\\] Note que \\(\\mathbb{E}[Y_i(1)|D_i=1]\\) é um resultado potencial que podemos observar, já que é igual ao resultado realizado dos tratados. Esse estimando estima o efeito do tratamento apenas entre os tratados. Essa quantidade é, tipicamente, a mais relevante em políticas públicas. Considere a política pública de vacinação. O que é mais importante, saber o efeito causal da vacina em toda a população, ou em toda a população que tomaria a vacina (tratados)? Ou para dar um exemplo mais claro ainda. Não é relevante o efeito do bolsa-famnília sobre redução da pobreza em toda a população, nem mesmo se considerarmos que a população alvo é toda a população pobre. Pessoas que não vão participar do programa não importam muito. Importam as que efetivamente irão receber o programa. 2.6.3 CATE Vamos definir o Conditional Average Treatment Effect (CATE). Seja \\(X_i\\) um conjunto de co-variáveis pré-determinadas (não causadas pelo tratamento). Então, podemos definir o CATE como: \\[\\tau_{\\text{CATE}} = \\mathbb{E}[\\tau_i|X_i=x] = \\mathbb{E}[Y_i(1) - Y_i(0)|X_i=x] = \\mathbb{E}[Y_i(1) - \\mathbb{E}[Y_i(1)|X_i=x]\\] Retornando ao nosso exemplo da introdução da urna eletrônica em um município sobre a pobreza municipal. ATE: O efeito médio de um município ter urna eletrônica sobre a pobreza municipal comparado a voto em papel. ATT: O efeito médio da urna eletrônica nos municípios que receberam urna eletrônica sobre a pobreza municial comparado a voto em papel. CATE: O efeito médio de urna eletrônica sobre a pobreza municipal, em um determinado grupos de municípios (ex. do semiá-rido do Nordeste), comparado a voto em papel. Se \\(X\\) for discreto, podemos estabelecer a seguinte relação entre ATE e CATE: \\[\\tau_{\\text{ATE}} = \\sum_{x \\in X} \\tau_{\\text{CATE}}(x) p(X_i = x)\\] Há outros estimandos possíveis, mas esses são os mais comuns. 2.7 Nota sobre estimandos A rigor, podemos caracterizar ao nível da população dois contrastes: a distribuição de probabilidade de resultados potenciais do tratamento com a do controle, para um dado conjunto de covariáeis de pré-tratamento \\(\\mathbf{X}\\). Formalmente, sejam \\(f(Y(1)|\\mathbf{X})\\) e \\(f(Y(0)|\\mathbf{X})\\) as densidades dos dois resultados potenciais, então \\(f(Y(1)|\\mathbf{X} - f(Y(0)|\\mathbf{X})\\) configura uma nova distribuição, da diferença entre os dois resultados potenciais. Nossa ênfase na esperança, portanto, é tanto uma questão de conveniência matemática quanto potencial interesse de pesquisa em um estimando em torno da média da diferença dessas duas distribuições, mas nada impede, a princípio, que estimarmos toda a distribuição da diferença. Outra observação: como veremos mais para frente no curso, dados longitudinais não possuem estimandos claros. Alguns pesquisadores mais rigorosos em política comparada, por exemplo, falam em efeito de país-ano, pois esta é a unidade de análise e o estimando é definido nesse nível. Como veremos também mais para frente (e é um tema de pesquisa meu), também é complicado definir as condições de identificação em dados longitudinais. Voltaremos a isso. 2.8 Exercício - Qual o estimando e o estimador (se possível)? Abstract 1 Abstract 2 Abstract 3 2.9 Identificação “Econometric identification really means just one thing: model parameters or features being uniquely determined from the observable population that generates the data”(Lwebel, apud Paul GP). Ou seja, se você tiver acesso a uma amostra infinita, isto é, não há problemas inferenciais de amostra pequena, é possível estimar precisamente o parâmetro de interesse? Dizemos que, nesse caso, o estimando é identificável. O que seria um estimando não-identificável? Digamos que estou interessado em estimar o efeito causal da segunda dose de uma vacina sobre internação por uma doença. Para a pessoa receber a segunda dose, obviamente ela precisa receber a primeira. Suponha que a primeira dose ajuda a reduzir a internação. É impossível estimar o efeito causal da segunda dose. Para mostrar que o ATE é identificado, vamos supor o que chamamos de ignorabilidade forte (strong ignorability). Definição. Dizemos que \\(D_i\\) é fortemente ignorável condicional a um vetor \\(\\mathbf{X_i}\\) se: 1. \\(Y_i(1), Y_i(0) \\perp D_i\\) 2. \\(\\exists \\epsilon &gt; 0 \\text{ tal que } \\epsilon &lt; Pr(D_i = 1 | \\mathbf{X_i}) &lt; 1 - \\epsilon\\) Em palavras, a primeira condição diz que os resultados potenciais são independentes de receber ou não o tratamento. Quando pensamos em modelos com seres humanos ou unidades com agência, a principal preocupação é que as unidades não se auto-selecionam no tratamento que lhes é mais benéfico (ou que acreditam sê-lo). Às vezes na literatura essa condição aparece como permutabilidade (exchangeability): Como dizem Hernan e Robins em seu livro, “the treated and the untreated are exchangeable because the treated, had they remained untreated, would have experienced the same average outcome as the untreated did, and vice versa.”(p. 29). A segunda condição, conhecida como commmon support ou overlaping condition, diz que não existe unidade que não possa receber o tratamento ou controle. Essa condição é mais forte do que a positividade (toda unidade tem probabilidade positiva de receber o tratamento). Quero explorar aqui essa condição por meio de uma simulação. Vamos supor que um efeito causal \\(\\tau_i\\) tem distribuição normal com média \\(2\\) e desvio-padrão \\(2\\). E vamos supor que pessoas com \\(\\tau_i &gt;6\\) não podem receber o tratatamento, apenas o controle. Veremos que o efeito causal para esse subgrupo não é identificado e mesmo o ATE não é identificado. ## d1 ## d 0 1 ## 0 5019 0 ## 1 396 4585 ## [1] 2.013731 ## [1] 1.37696 Um último comentário: ignorability às vezes aparece como “tratamento é exógeno”. Porém, exogeneidade ignora a segunda condição e trata apenas da primeira. Em uma audiência de ciência política, dizemos que o tratamento é condicionalmente aleatório ou exógeno (o que é impreciso). 2.10 Identificação do ATE Teorema 1: Se \\(D_i\\) é fortemente ignorável condicional a \\(\\mathbf{X_i}\\), então: \\[\\mathbb{E}[\\tau_i] = \\sum_{x \\in X}(\\mathbb{E}[(Y_i|D_i=1, \\mathbf{X_i} = x)] - \\mathbb{E}[(Y_i|D_i=0, \\mathbf{X_i} = x)])Pr(\\mathbf{X_i = x})\\] Prova: O ATE foi definido como: \\[\\mathbb{E}[\\tau_{\\text{ATE}}] = \\mathbb{E}[\\tau_i] = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)]\\] Pela LIE, temos que: \\[\\mathbb{E}[Y_i(1)] = \\mathbb{E}[\\mathbb{E}[Y_i(1)|\\mathbf{X_i}]\\] \\[\\mathbb{E}[Y_i(0)] = \\mathbb{E}[\\mathbb{E}[Y_i(0)|\\mathbf{X_i}]\\] Com ignorabilidade forte, \\(\\mathbb{E}[(Y_i(0)|\\mathbf{X_i}] = \\mathbb{E}[Y_i(0)|D_i=0, \\mathbf{X_i}] = \\mathbb{E}[Y_i|D_i=0, \\mathbf{X_i}]\\). Similarmente, \\(\\mathbb{E}[(Y_i(1)|\\mathbf{X_i}] = \\mathbb{E}[Y_i(1)|D_i=1, \\mathbf{X_i}] = \\mathbb{E}[Y_i|D_i=1, \\mathbf{X_i}]\\). Juntando tudo, chegamos à proposição do teorema. Ou seja, com ignorabilidade forte, podemos estimar o ATE não-parametricamente apenas a partir de observáveis. O CATE também é identificado, como corolário. 2.11 Equações estruturais Normalmente nós temos um modelo que queremos estimar o efeito causal, e não algo sobre o mecanismo de assignment do tratamento. Vamos conectar as duas abordagens. Seja o modelo: \\(Y_i = \\alpha + \\beta D_i + \\epsilon_i\\). Nós intrepretamos \\(\\beta\\) como a diferença média no \\(y\\) de uma unidade no tratamento, formalmente: \\(\\mathbb{E}[Y|D_i=1] - \\mathbb{E}[Y|D_i=0] = \\mathbb{E}[\\alpha + \\beta D_i + \\epsilon_i|D_i=1] - \\mathbb{E}[\\alpha + \\beta D_i + \\epsilon_i|D_i=0] = \\beta + \\mathbb{E}[\\epsilon_i|D_i=1] - \\mathbb{E}[\\epsilon_i|D_i=0]\\). E dizemos que, sob a suposição de esperança condicional zero do erro, ou seja, \\(\\mathbb{E}[\\epsilon_i|D_i=1] = \\mathbb{E}[\\epsilon_i|D_i=0] = 0\\). Portanto, temos que \\(\\mathbb{E}[Y|D_i=1] - \\mathbb{E}[Y|D_i=0] = \\beta\\). E o estimador de MQO é não-viesado. E de forma geral, temos que \\(\\mathbb{E}[Y|D_i] = \\alpha + \\beta\\), sob a suposição de esperança condicional zero do erro. Vamos mapeá-lo ao modelo de resultados potenciais com a switching equation. \\[ \\begin{aligned} Y_i &amp;= Y_i(0)(1-D_i) + Y_i(1)D_i \\\\ &amp;= Y_i(0) + \\tau_i D_i \\\\ &amp;= Y_i(0) + \\tau_i D_i + \\tau D_i - \\tau D_i\\\\ &amp;= Y_i(0) + \\tau D_i + (\\tau_i - \\tau)D_i \\\\ &amp;= \\mathbb{E}[Y_i(0)|D_i=0] - \\mathbb{E}[Y_i(0)|D_i=0] + Y_i(0) + \\tau D_i + (\\tau_i - \\tau)D_i \\\\ &amp;= \\underbrace{\\mathbb{E}[Y_i(0)|D_i=0]}_{\\alpha} + \\underbrace{\\tau}_{\\beta} D_i + \\underbrace{(\\tau_i - \\tau)D_i + (Y_i(0) - \\mathbb{E}[Y_i(0)|D_i=0])}_{\\epsilon_i} \\\\ \\end{aligned} \\] Nós sabemos que em uma regressão estamos estimando \\(\\mathbb{E}[Y_i|D_i]\\). Podemos agora ver com clareza o que de fato estamos estimamos em termos causais. \\[ \\begin{aligned} \\mathbb{E}[Y_i|D_i=1] &amp;= \\alpha + \\tau + \\mathbb{E}[\\epsilon_i|D_i=1] \\\\ \\mathbb{E}[Y_i|D_i=0] &amp;= \\alpha + \\mathbb{E}[\\epsilon_i|D_i=0] \\\\ \\mathbb{E}[\\epsilon_i|D_i=1] &amp;= \\mathbb{E}[(\\tau_i - \\tau)D_i + (Y_i(0) - \\mathbb{E}[Y_i(0)|D_i=0])|D_i=1] \\\\ &amp;= \\mathbb{E}[(\\tau_i - \\tau)D_i|D_i=1] + \\mathbb{E}[(Y_i(0) - \\mathbb{E}[Y_i(0)|D_i=0])|D_i=1] \\\\ &amp;= \\mathbb{E}[\\tau_i D_i|D_i=1] -\\tau\\mathbb{E}[ D_i|D_i=1] + \\mathbb{E}[Y_i(0)|D_i=1] - \\mathbb{E}[\\mathbb{E}[Y_i(0)|D_i=0]|D_i=1] \\\\ &amp;= (\\mathbb{E}[\\tau_i|D_i=1] -\\tau) + \\mathbb{E}[Y_i(0)|D_i=1] - \\mathbb{E}[Y_i(0)|D_i=0] \\\\ \\mathbb{E}[\\epsilon_i|D_i=0] &amp;= \\mathbb{E}[(\\tau_i - \\tau)D_i + (Y_i(0) - \\mathbb{E}[Y_i(0)|D_i=0])|D_i=1] \\\\ &amp;= \\mathbb{E}[Y_i(0)|D_i=0] - \\mathbb{E}[\\mathbb{E}[Y_i(0)|D_i=0]|D_i=0] \\\\ &amp;= 0 \\end{aligned} \\] Portanto, \\(\\mathbb{E}[Y_i|D_i=1] - \\mathbb{E}[Y_i|D_i=0] = \\tau + (\\mathbb{E}[\\tau_i|D_i=1] -\\tau) + \\mathbb{E}[Y_i(0)|D_i=1] - \\mathbb{E}[Y_i(0)|D_i=0]\\) Em palavras, estimamos o efeito causal médio, \\(\\tau\\), mais um componente que tem a ver com os efeitos causais heterogêneos mais um componente que é a diferença no resultado potencial do controle entre os tratados e o controle. Se \\(\\mathbb{E}[Y_i(0)|D_i=1] - \\mathbb{E}[Y_i(0)|D_i=0] \\neq 0\\), o efeito estimado é viesado. Similarmente, se \\(\\mathbb{E}[\\tau_i|D_i=1] \\neq \\tau\\), também teremos viés, ou seja, se o efeito causal dos tratados for diferente do efeito médio da população, também temos uma estimativa viesada do ATE. Porém, nesse caso, note que estamos viesando para estimar o efeito médio dos tratados, que é o ATT. Para ver isso, suponha que não há diferença nos resultados potenciais de não receber o tratamento entre os tratados e os no grupo controle, de modo que \\(\\mathbb{E}[Y_i(0)|D_i=1] - \\mathbb{E}[Y_i(0)|D_i=0] = \\tau + (\\mathbb{E}[\\tau_i|D_i=1] -\\tau) = \\mathbb{E}[\\tau_i|D_i=1]\\), que é o ATT. 2.12 Modelo versus Desenho Há na literatura (mais de economia) uma distinção entre estimando baseado em modelos e baseado em designs (desenho). Model-based: O estimando é identificado a partir de um modelo dos resultados potenciais, condicional ao tratamento e co-variáveis. O exemplo arquetípico é modelo de diferença em diferenças ou controle sintético, em que estimamos o efeito causal a partir de estimativa do contrafactual a partir de dados observados. Design-based: O estimando é identificado a partir de suposições sobre o mecanismo de atribuição do tratamento e co-variáveis. O exemplo arquetípico desse tipo de pesquisa é o experimento aleatório controlado. 2.13 Exercício em sala Na década de 1970, houve um programa de treinamento e emprego conhecido como National Supported Work (NSW). Este programa temporário visava ajudar trabalhadores desfavorecidos e sem habilidades básicas a ingressarem no mercado de trabalho, oferecendo experiência profissional e orientação em um ambiente protegido. Um aspecto inovador do NSW foi a seleção aleatória de candidatos qualificados para os treinamentos, garantindo que o grupo de tratamento recebesse todos os benefícios do programa, enquanto o grupo de controle não tinha suporte. Os participantes do grupo de tratamento tinham emprego garantido por 9 a 18 meses, dependendo do grupo-alvo e do local. Eles trabalhavam em equipes de 3 a 5 pessoas, reunindo-se frequentemente com um orientador para discutir questões do programa e desempenho. Embora recebessem salários inferiores aos de um emprego regular, havia possibilidade de aumento conforme o desempenho e a frequência. Ao término do período, os participantes precisavam procurar emprego regular. O programa também coletou dados de renda e informações demográficas de ambos os grupos, realizando entrevistas periódicas, o que gerou diferentes tamanhos de amostra entre os estudos. O NSW utilizava um desenho experimental aleatório. Lalonde (1986) comparou os resultados experimentais com dados observacionais. Para isso, substituiu os dados do grupo controle atribuídos aleatoriamente, com dados de três amostras do Current Population Survey (CPS) e do Panel Survey of Income Dynamics (PSID). E usou as técnicas econométricas usuais para isso. O resultado não foi bom para a econometria. Voltaremos a isso mais pra frente. Por hora, vamos estimar efeitos causais com os dados experimentais. O exercício a seguir é adaptado do exercício disponibilizado por Paul GP em seu github, no seu curso de métodos. Esta análise utilizará a amostra de Dehejia e Wahba do conjunto de dados Lalonde do experimento NSW. O conjunto de dados é “lalonde nsw.csv”. A variável de resultado é “re78” (rendimento real em 1978). O indicador de tratamento é “treat”. As demais variáveis são potenciais covariáveis. Para os fins deste conjunto de problemas, assuma que “treat” é atribuído de forma aleatória. Calcule o efeito médio do tratamento da política, \\(\\mathbb{E}[\\tau_i]\\), utilizando uma simples diferença de médias. Calcule o efeito médio do tratamento sobre os tratados da política, \\(\\mathbb{E}[\\tau_i|treat=1]\\). Como ele se compara à parte (a)? ## [1] 1794.342 ## [1] 1794.342 2.14 Referências Lalonde, Robert. 1986. “Evaluating the Econometric Evaluations of Training Programs with Experimental Data.” American Economic Review 76 (4): 604–20. Rajeev Dehejia and Sadek Wahba, “Causal Effects in Non-Experimental Studies: Reevaluating the Evaluation of Training Programs,” Journal of the American Statistical Association, Vol. 94, No. 448 (December 1999), pp. 1053-1062. Rajeev Dehejia and Sadek Wahba, “Propensity Score Matching Methods for Non-Experimental Causal Studies,” Review of Economics and Statistics, Vol. 84, (February 2002), pp. 151-161. Robert Lalonde, “Evaluating the Econometric Evaluations of Training Programs,” American Economic Review, Vol. 76 (1986), pp. 604-620. Lundberg, I., Johnson, R., &amp; Stewart, B. M. (2021). What is your estimand? Defining the target quantity connects statistical evidence to theory. American Sociological Review, 86(3), 532-565. Paul W Holland. Statistics and causal inference. Journal of the American statistical Association, 81(396):945–960, 1986. "],["dags.html", "Capítulo 3 DAGs 3.1 Causalidade 3.2 Introdução 3.3 Os Tipos Básicos de DAGs 3.4 Simulação no R: Ilustrando o Collider Bias 3.5 Definições 3.6 Controle e Ajuste 3.7 Fatorização da Probabilidade Conjunta 3.8 Fatorização e DAGs 3.9 Fatorização, DAGs e Causalidade", " Capítulo 3 DAGs 3.1 Causalidade 3.2 Introdução Uma das principais abordagens para fazer inferência causal utiliza diagramas causais chamados de Directed Acyclic Graphs (DAG). Ela foi desenvolvida na ciência da computação entre os anos 80 e 90 e é associada com o trabalho pioneiro de Judea Pearl. Veja o livro The Book of Why para uma história de como surgiu essa abordagem. Abaixo temos um exemplo simples de um DAG: Eles são chamados de DAGs porque os gráficos são direcionados (apontam em uma direção), acyclic porque não permitem ciclos (isto é, se A causa B, B não pode causar A) e graphs porque, como você pode imaginar, são grafos. No exemplo acima, o DAG é formado por três variáveis {y, x, z} que são, em geral, variáveis aleatórias. E as flechas indicam direção de causalidade. Ou seja, \\(x\\) causa \\(y\\) e \\(z\\) causa \\(x\\). É importante saber que DAGs são não paramétricos. Eles podem ser interpretados como: \\(y = f(x, z)\\). Ou seja, qualquer função de x e z são igualmente possíveis. Eis alguns exemplos compatíveis com o DAG acima: \\(y = x + z\\) \\(y = 10 + x + z + x*z\\) \\(y = 3*x^z\\) \\(y = \\pi*z/x + x^2 + 1/(z^3)\\) A razão porque não escrevemos DAGs como equações é porque \\(y = f(x, z)\\) não expressa adequadamente a relação de causalidade pois, em matemática, é indiferente escrever \\(f(x, z) = y\\) ou \\(y = f(z, x)\\). Porém, dizer que \\(x\\) e \\(z\\) causam \\(y\\) é muito diferente de dizer que \\(y\\) causa \\(x\\) e \\(z\\). E com o DAG as flechas indicam a direção da causalidade. 3.3 Os Tipos Básicos de DAGs 3.3.1 1. Chains Em uma chain, x causa w que, por sua vez, causa y. Aqui, w pode ser considerado o mediador do efeito de x sobre y. Exemplo: O desempenho econômico de um país pode aumentar a popularidade do presidente, o que leva a mais votos. Representação: 3.3.2 2. Forks Em um fork, uma variável w causa ambos x e y. Dessa forma, w é uma causa comum que pode gerar correlação espúria entre x e y. Exemplo: A qualidade de um candidato pode fazer com que ele arrecade mais dinheiro para a campanha e, ao mesmo tempo, obtenha mais votos. Representação: 3.3.3 3. Colliders Em um collider, x causa w e y também causa w. Esse tipo de estrutura é também chamado de “fork invertido”. Apesar de x e y não terem relação causal direta, controlar para w (ou um de seus descendentes) pode introduzir uma correlação espúria entre x e y. Exemplo: Imagine que você organiza uma festa e convida apenas pessoas que fazem ciência política ou são canhotas. Na população geral pode não haver relação entre essas características, mas na festa pode surgir uma correlação: se uma pessoa é canhota, ela pode ter maior probabilidade de fazer ciência política. 3.4 Simulação no R: Ilustrando o Collider Bias Vamos rodar uma simulação para ilustrar o collider bias. Suponha que 10% das pessoas fazem ciência política e 5% são canhotas. library(dplyr) set.seed(4) # Gerando as variáveis cp &lt;- rbinom(1000, 1, p = 0.1) # 10% fazem ciência política canhoto &lt;- rbinom(1000, 1, p = 0.05) # 5% são canhotos # Definindo a condição da festa: convida se faz ciência política ou é canhoto festa &lt;- ifelse(cp == 1, 1, ifelse(canhoto == 1, 1, 0)) tabela &lt;- data.frame(cp, canhoto, festa) # Correlação na população geral cor_geral &lt;- round(cor(cp, canhoto), 2) print(cor_geral) ## [1] -0.02 # Correlação entre os que foram à festa cor_festa &lt;- tabela %&gt;% filter(festa == 1) %&gt;% summarise(cor = round(cor(cp, canhoto), 2)) print(cor_festa) ## cor ## 1 -0.95 Na população em geral, a correlação é próxima de zero (aproximadamente -0,02). Porém, entre as pessoas que foram à festa, a correlação pode chegar a -0,95, evidenciando como condicionar em um collider (neste caso, a variável festa) pode induzir correlação espúria. 3.5 Definições Path (caminho): É uma sequência de flechas conectadas. Um directed path (caminho dirigido) é aquele em que todas as flechas seguem a mesma direção (por exemplo, \\(x \\to z \\to y\\)). 3.5.1 Relações entre Variáveis (nós): As relações são descritas usando termos da genética, como pais, filhos, ancestrais, descendentes e vizinhos. Pais e filhos referem-se a relações diretas. Ancestrais e descendentes incluem todas as variáveis em qualquer posição no caminho. Um path sem collider está aberto; um path com collider está fechado. Duas variáveis (ou conjuntos) estão d-separated se não houver caminho aberto entre elas. Caso contrário, podem ou não ser independentes, pois múltiplos caminhos abertos podem se cancelar. 3.6 Controle e Ajuste No contexto dos DAGs, controlar para variáveis pode ter diferentes significados: Experimentos: Controlar significa manipular o valor da variável pelo pesquisador. Exemplo: Um experimento em que o resultado do lançamento de uma moeda determina se um pedido de acesso à informação será feito por um homem ou mulher. Estudos Observacionais: Controlar significa condicionar (estratificar ou incluir em uma regressão). Para visualizar isso em um DAG, considere o seguinte DAG: Controlar para C, nesse DAG, significa efetuar os seguintes passos, na sequência: 1. Eliminar todas as flechas que saem de C. Se C for um collider, elimine as flechas que vão para C e conecte os parentes de C por meio de linhas tracejadas. elimine C Manipular: Determinar o valor da variável. Alterar o Gráfico: Para controlar a variável G (por exemplo, se relacionada a C): Eliminar as flechas que saem de G. Eliminar as flechas do collider (no caso, c e u, parentes de G) e criar relação bi-direcional espúria. Remover G do gráfico. Em resumo, se C depende de A e B de forma independente, condicionar em C pode criar uma relação espúria entre A e B. Por exemplo, se A e B são binárias e \\(C = A + B\\), para \\(C = 1\\) saber o valor de A determina automaticamente o valor de B, e vice-versa. De modo geral, condicionar em um collider inverte o status dos caminhos: caminhos que estavam abertos podem se fechar e vice-versa. Além disso, condicionar em um descendente de um collider também pode alterar os efeitos, atenuando ou abrindo caminhos que originalmente estavam fechados. 3.7 Fatorização da Probabilidade Conjunta Toda distribuição de probabilidade obedece à regra da cadeia de probabilidades (nenhuma suposição adicional). Lembremos: \\(Pr(X,Y) = Pr(Y|X) Pr(X) = Pr(X|Y) Pr(Y)\\) Similarmente, \\(Pr(X,Y,Z) = Pr(Y|X,Z) Pr(X|Z) Pr(Z) = Pr(X|Y,Z) Pr(Y|Z) Pr(Z) = Pr(Z|Y,X) Pr(X|Y) Pr(X) = \\cdots\\) De maneira geral, se temos \\(n\\) variáveis marginais, temos no total \\(n!\\) maneiras distintas de fatorar a distribuição conjunta. A lógica é assim&gt; Seja uma pmf conjunta \\(Pr(x_1, x_2, ..., x_k)\\). Então, podemos usar a regra do produto: \\(Pr(x_1, x_2, ..., x_k) = Pr(x_1) Pr(x_2, ..., x_k|x_1)\\) Aplicando a regra iterativamente, \\(Pr(x_2, ..., x_k|x_1) = Pr(x_2|x_1)Pr(x_3, ..., x_k|x_1, x_2)\\), de forma que: \\(Pr(x_1, x_2, ..., x_k) = Pr(x_1) Pr(x_2|x_1)Pr(x_3, ..., x_k|x_1, x_2)\\) E assim por diante, até: \\(Pr(x_1, x_2, ..., x_k) = Pr(x_1) Pr(x_2|x_1) Pr(x_3| x_2, x_1) \\cdots Pr(x_k|x_1, x_2, x_3, ... , x_{k-1})\\) A Regra do produto pode ser aplicada em qualquer ordem, gerando fatorizações distintas. 3.8 Fatorização e DAGs Existem teoremas que mostram que existe uma relação entre DAGs e fatorização de probabilidades conjuntas. Dado um DAG, em que um nós é independente condicional a outro nó, isso implica a fatorização da probabilidade conjunta de acordo com essa relação, e vice-versa. Dois exemplos abaixo ilustram essa propriedade. Considere o DAG abaixo: Nós sabemos que, condicional a X, Y é independente de Z, W e M. Similarmente, X é independente de M, condicional a Z e W. Podemos então fatorar a distribuição conjunta da seguinte maneira: \\[Pr(M, W, X, X, Y) = Pr(M) Pr(Z|M) Pr(W|M) Pr(X|W,Z) Pr(Y|X)\\] Ou seja, basta escrever a probabilidade condicional nas variáveis que tornam cada nós independente para descrever a distribuição de probabilidade conjunta. 3.9 Fatorização, DAGs e Causalidade De volta à causalidade, um DAG em que não há confouding, isto é, sem back-door aberto, como o DAG abaixo, implica que a fatorização observacional é igual à fatorização intervencional: \\[Pr(Y = y |do (X = x)) = Pr(Y|X)\\] Logo, é verdade que \\[Pr(Y,X) = P(X)Pr(Y|X) = Pr(X)Pr(Y = y |do (X = x))\\]. O operador “do” aqui é uma inovação do Pearl, e diz que fizemos uma cirurgia no gráfico e determinamos, exogenamente, por assim dizer, que o valro de \\(X\\) é \\(x\\). Referências Hernán MA, Robins JM (2019). Causal Inference. Boca Raton: Chapman &amp; Hall/CRC. Disponível temporariamente em: https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/ Greenland, S., &amp; Pearl, J. (2014). Causal diagrams. Wiley StatsRef: Statistics Reference Online, 1-10. "],["experimentos.html", "Capítulo 4 Experimentos 4.1 Introdução 4.2 Experimentos aleatórios 4.3 Restrição de Exclusão 4.4 Tipos de experimentos 4.5 Estimador ATE 4.6 Key Takeways 4.7 Declare Design 4.8 Exercício", " Capítulo 4 Experimentos 4.1 Introdução Um experimento é o desenho de pesquisa no qual a pesquisadora controla o mecanismo de atribuição do tratamento e controle Seja \\(p_i = P(T_i=1)\\). Então \\(p_i\\) é conhecido e controlado pela pesquisadora. Em contraposição, um estudo observacional é quando a pesquisadora não controla o mecanismo (natureza ou realidade social) Quando uma quantidade potencial (estimando) pode ser descrita em função da distribuição de dados observáveis, dizemos que o estimando é identificável. De outro modo, não identificado. Veremos porque experimentos produzem desenhos críveis de identificação causal Vamos supor experimentos ideais (sem attrition ou non-compliance) Nós já vimos que uma suposição crítica é a SUTVA. Stable Unit Treatment Values Assumption Não interferência e sem varição escondida no tratamento PO não varia com o tratamento atribuiído a outra unidades PO de uma unidade não é impactado pelo nível de tratamento de outras unidades Para cada unidade, não há formas distintas ou versões de cada nível de tratamento Definição não-ambígua do tratamento Supondo SUTVA, Diferença Simples de Média pode ser decomposta em ATE + viés de seleção \\(\\underbrace{\\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0]}_{\\text{Simple Difference in Outcomes (SDO)}} = \\mathbb{E}[Y_i^1|T_i=1] - \\mathbb{E}[Y_i^0|T_i=0]\\) Podemos adicionar e subtrair os resultados contrafactuais para os tratados \\(= \\mathbb{E}[Y_i^1|T_i=1] - \\color{blue}{\\mathbb{E}[Y_i^0|T_i=1]} + \\color{red}{\\mathbb{E}[Y_i^0|T_i=1]} - \\mathbb{E}[Y_i^0|T_i=0]\\) \\(= \\underbrace{\\mathbb{E}[Y_i^1 - Y_i^0|T_i=1]}_{\\text{ATT}} + \\underbrace{\\mathbb{E}[Y_i^0|T_i=1] - \\mathbb{E}[Y_i^0|T_i=0]}_{\\text{Viés de Seleção}}\\) 4.2 Experimentos aleatórios Mecanismo de atribuição de tratamento é probabilístico (Positividade): \\(0 &lt; p_i &lt; 1\\). Unconfoundedness ou Permutabilidade (ou assignment mechanism–ignorability): \\(P(T_i=1|y^1, y^0) = P(T_i)\\). O que é Permutabilidade (uncounfoudedness)? A distribuição dos resultados potenciais é independente do tratamento. \\(\\mathbb{E}[Y^1|T=1] = \\mathbb{E}[Y^1|T=0]\\) \\(\\mathbb{E}[Y^0|T=1] = \\mathbb{E}[Y^0|T=0]\\) Resultados potenciais são independentes do tratamento, dadas as covariáveis. Se a condição de tratamento fosse hipoteticamente trocada, os resultados esperados permaneceriam os mesmos. Isso significa que em um experimento com permutabilidade, não temos viés de seleção (Por quê?). Independência entre tratamento e resultados potenciais implica que \\(\\mathbb{E}[Y^0_i|T_i=1] = \\mathbb{E}[Y^0_i|T_i=0] = \\mathbb{E}[Y^0_i]\\) Portanto, o viés de seleção, dado por \\(\\mathbb{E}[Y_i^0|T_i=1] - \\mathbb{E}[Y_i^0|T_i=0]\\), fica: \\(\\mathbb{E}[Y_i^0|T_i=1] - \\mathbb{E}[Y_i^0|T_i=0] = \\mathbb{E}[Y_i^0] - \\mathbb{E}[Y_i^0] = 0\\) Ou seja, SDO estima o ATE (via ATT). \\(\\underbrace{\\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0]}_{\\text{Simple Difference in Outcomes (SDO)}} = \\underbrace{\\mathbb{E}[Y_i^1 - Y_i^0|T_i=1]}_{\\text{ATT}} = ATE\\) 4.3 Restrição de Exclusão Formalmente, podemos separar a alocação do tratamento e o tratamento efetivamente recebido. Seja \\(Z_i\\) a alocação do tratamento e \\(T_i\\) o tratamento recebido. Então, a restrição de exclusão quer dizer que o que importa é o tratamento efetivamente recebido \\(T_i\\), e não a variável que aloca o tratamento \\(Z_i\\). Formalmente, isso quer dizer que: \\(Y^{1,z=1, T}_i = Y^{1,z=0, T}_i = Y^{1,T}_i\\) e similarmente, \\(Y^{0,z=0,T}_i = Y^{0,z=0,T}_i = Y^{0,T}_i\\) Quando não ocorre isso? Se o mecanismo de atribuição do tratamento dispara outras causas Suponha que um experimento é sobre efeito de transferência de dinheiro em bem-estar Se ongs, sabendo do experimento, forem ajudar quem não tiver sido alocado para receber dinheiro Se houver erro de mensuração assimétrico? Pesquisadores distintos entrevistam recipientes e não-recipientes da transferência de dinheiro, com habilidades distintas Ou questionários diferentes. Erro de mensuração assimétrico Nova switching equation. Seja \\(e_{i1}\\) o erro de mensuração cometido se uma observação é atribuída para o tratamento, e, analogamente, \\(e_{i0}\\) o erro para o controle. De \\(Y_i = T_iY^1_i + (1- T_i)Y^0_i\\) para \\(Y_i = T_i(Y^1_i + e_{i1}) + (1- T_i))(Y^0_i + e_{i0})\\). Novo SDO: \\(\\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0] = \\mathbb{E}[Y^1_i + e_{i1}|T_i=1] - \\mathbb{E}[Y^0_i + e_{i0}|T_i=0] = \\mathbb{E}[Y^1_i|T_i=1] + \\mathbb{E}[e_{i1}|T_i=1] - \\mathbb{E}[Y^0_i|T_i=0] - \\mathbb{E}[e_{i0}|T_i=0]\\) Novo SDO pode se rearranjado: \\(\\underbrace{\\mathbb{E}[Y^1_i|T_i=1] - \\mathbb{E}[Y^0_i|T_i=0]}_{\\text{antigo SDO}} + \\underbrace{\\mathbb{E}[e_{i1}|T_i=1] - \\mathbb{E}[e_{i0}|T_i=0]}_{\\text{Dif média no erro de mensuração}}\\) Se \\(\\mathbb{E}[e_{i1}|T_i=1] \\neq \\mathbb{E}[e_{i0}|T_i=0]\\), então SDO será viesado. Como Garantir a restrição de Exclusão? Double blindness (duplo cego) Paralelismo na administração do experimento (mesmo questionário e mesmos entrevistadores) Na pior das hipóteses, aleatorização dos entrevistadores. 4.4 Tipos de experimentos 4.4.1 Aleatorização de Bernoulli É o experimento com aleatorização simples (basicamente, lançamento de moeda) Matematicamente, \\(p_i(T_i=1) = p\\). Problema: Possível “má aleratorização” (todo mundo no controle ou tratamento) ps.: toda aleatorização realizada é matematicamente equivalente. Possui \\(2^n\\) configurações possíveis de alocação entre tratamento e controle set.seed(10) n &lt;- 50 hist(replicate(1000, sum(rbinom(n, 1, 0.5))), main = &quot;aleatorização de Bernoulli&quot;, xlab = &quot;Número de tratados&quot;, col = &quot;lightblue&quot;) + xlim(0,50) 4.4.2 Aleatorização Completa Seleciono aleatoriamente um número fixo de pessoas para tratamento e controle Ex.: 25 para tratamento e 25 para controle Basta numerar cada unidade (de 1 a 50) e amostrar 25 aleatoriamente para tratamento (e restante para controle) Vantagem: garanto número de obs em cada condição Possui \\({N \\choose \\frac{n}{2}}\\) configurações possíveis de alocação entre tratamento e controle. Intuição: estamos jogando fora as aleatorizações “indesejáveis”. Cálculo da variância é mais complexo 4.4.3 Aleatorização Condicional (Block Random Assigment) Definição: Experimento é condicionalmente aleatório se a aleatorização depende de variáveis pré-tratamento \\(X\\). Exemplo Binário: Duas moedas, uma para \\(X=1\\) e outra para \\(X=0\\). Aleatorização Marginal vs. Condicional: Marginal: Aleatorização uniforme para todos os indivíduos. Condicional: Aleatorização depende de \\(X\\), gerando permutabilidade condicional a \\(X\\). Permutabilidade Condicional: \\((Y^1, Y^0 | X=x) \\indep T\\). Não gera permutabilidade (não-condicional). Permutabilidade condicional a \\(X\\) é crucial para inferência em contextos com variáveis pré-tratamento. 4.4.4 Pensando aleatorização em bloco Ex.: digamos que em um amostra de 100 pessoas, queremos 25 homens e 25 mulheres no tratamento e controle Sorteio 25 homens para tramento e depois 25 mulheres. Cada bloco possui tamanho 25, neste exemplo. Blocos de tamanho \\(2\\) são chamados de pair-matched design. Em geral, estudos com matching em muitas variáveis Útil para amostras pequenas 4.4.5 ATE com Aleatorização Condicional (Bloco) Estratitificação Efeito heterogêneo por estrato? Podemos calcular o ATE por estrato, já que é aleatório no interior de cada estrato. Efeito geral na população. Podemos calcular ponderando os ATEs. Seja \\(J\\) o número de estratos, indixados por \\(j\\). Seja \\(N\\) o número de unidades e \\(N_j\\) o número de unidades no bloco \\(j\\). Então: \\(ATE = \\sum_{j=1}^J \\frac{N_j}{N}ATE_j\\) 4.4.6 Aleatorização em bloco – Pela Lei dos Grandes números, tende a gerar balanceamento entre blocos – Balanceamento quer dizer que blocos são similares – Em variáveis observadas e não-observadas – Probabilidade de tratamento pode variar por bloco. – Chamada de propensity score. 4.4.7 Precisão da aleatorização em bloco Em geral a precisão aumenta (erro padrão diminui) com aleatorização em bloco. Intuição é que removemos parte da variância (amostras possíveis), condicionando nos estratos Vamos checar uma simulação no R para ver um exemplo do ganho na precisão Lembrem-se que se \\(X\\) e \\(Y\\) são independentes, então \\(Var(aX + bY) = a^2Var(x) + b^2Var(Y)\\). # Set up Potential outcomes and units and blocks n1 &lt;- 10 n2 &lt;- 16 N &lt;- n1+n2 J &lt;- 2 index_block &lt;- c(rep(2, n2), rep(1, n1)) set.seed(12) # potential outcome control y0 &lt;- c(rnorm(n1, 2, 1),rnorm(n2, 6, 1)) y1 &lt;- y0 + 1.5 # potential outcome treatment # block assignment t_bloco1 &lt;- sample(1:n1, n1/2) c_bloco1 &lt;- (1:n1)[!(1:n1 %in% t_bloco1)] t_bloco2 &lt;- sample((n1+1):(n1+n2), n2/2) c_bloco2 &lt;- ((n1+1):(n1+n2))[!((n1+1):(n1+n2) %in% t_bloco2)] y1_obs_bloco1 &lt;- y1[t_bloco1] y1_obs_bloco2 &lt;- y1[t_bloco2] y0_obs_bloco1 &lt;- y0[c_bloco1] y0_obs_bloco2 &lt;- y0[c_bloco2] # random assignment units_simple_treatment &lt;- c(t_bloco1, t_bloco2) units_simple_control &lt;- c(c_bloco1, c_bloco2) y1_obs &lt;- y1[units_simple_treatment] y0_obs &lt;- y0[units_simple_control] # erro padrão erro_pad_simple &lt;- t.test(y1_obs, y0_obs)$stderr simple_p_value &lt;- t.test(y1_obs, y0_obs)$p.value my_t &lt;- mean(y1_obs - y0_obs)/erro_pad_simple erro_pad1 &lt;- t.test(y1_obs_bloco1, y0_obs_bloco1)$stderr erro_pad2 &lt;- t.test(y1_obs_bloco2, y0_obs_bloco2)$stderr erro_padrao_geral &lt;- sqrt(erro_pad1^2*(n1/N)^2 + erro_pad2^2*(n2/N)^2) ate1 &lt;- mean(y1_obs_bloco1 - y0_obs_bloco1)*(n1/N) ate2 &lt;- mean(y1_obs_bloco2 - y0_obs_bloco2)*(n2/N) ate &lt;- ate1 + ate2 my_t &lt;- ate/erro_padrao_geral p_value &lt;- 2*(1 - pt(abs(my_t), df = 23.76567)) print(erro_pad1) ## [1] 0.646563 print(erro_pad1) ## [1] 0.646563 print(erro_padrao_geral) ## [1] 0.3723061 print(p_value) ## [1] 0.0006818314 4.4.8 Comparação de SEs library(knitr) comparison_table &lt;- data.frame( Method = c(&quot;Simple Randomization&quot;, &quot;Block 1&quot;, &quot;Block 2&quot;, &quot;General Block Randomization&quot;), Standard_Error = c(erro_pad_simple, erro_pad1, erro_pad2, erro_padrao_geral) ) knitr::kable(comparison_table, caption = &quot;Comparação de Erros padrão&quot;, align = &#39;c&#39;, format = &quot;latex&quot;) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) 4.4.9 Cluster randomization Quando aleatorizo o cluster, em vez das unidades. Ex.: Se não for possível aleatorizar um tratamento entre estudantes, aleatorizo escolas No interior de cada escola, todo mundo é tratado ou não-tratado. Não há variação within escolas, apenas entre (between) escolas. Grande perda de variabilidade nos dados, reduzindo precisão (aumento no erro padrão) Às vezes é a única aleatorização possível. ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) 4.4.10 Tabelas em artigos 4.5 Estimador ATE estimativa: \\(\\frac{\\sum_{i=1}^{n}Y_iT_i}{n_1} - \\frac{\\sum_{i=1}^{n}Y_i(1-T_i)}{n_0} = .0608 - .0353 = 0.0255\\) Erro padrão: \\(\\sqrt{\\frac{\\hat{\\sigma_1^2}}{n_1} + \\frac{\\hat{\\sigma_0^2}}{n_0}} = \\sqrt{\\frac{.0608\\cdot(1-.0608)}{1217} + \\frac{.0353\\cdot (1-.0353)}{1217}} = 0.00865\\) Pequena diferença com os coeficientes da tabela Typo? Alguma informação não reproduz exatamente? Fizemos algo errado? treatment &lt;- c(rep(1, 74), rep(0, 1217 - 74)) control &lt;- c(rep(1, 43), rep(0, 1217 - 43)) var_treat &lt;- var(treatment) var_control &lt;- var(control) erro_padrao &lt;- sqrt(var_treat/1217 + var_control/1217) round(erro_padrao, 5) ## [1] 0.00866 t.test(treatment, control) ## ## Welch Two Sample t-test ## ## data: treatment and control ## t = 2.9414, df = 2286.3, p-value = 0.0033 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.008490408 0.042454539 ## sample estimates: ## mean of x mean of y ## 0.06080526 0.03533279 4.6 Key Takeways Experimento (sob SUTVA) elimina o viés de seleção Depende de restrição de exclusão e simetria Vários tipos de experimentos: block aumenta precisão Com N grande, diferença diminui Sempre supomos condições ideais (sem attrition, compliance perfeito etc.) 4.7 Declare Design Uma ferramenta muito útil para experimentos (mas também para estudos observacionais) é o pacote do R Declare Design. Blair, Coppock e Humphreys criaram um framework para definir e avaliar um desenho de pesquisa. Com oresultado, escreveram um livro “Research Design in the Social Sciences”, e um pacote no R para implementar os conceitos desenvolvidos no livro, chamado “DeclareDesign. Para instalar (junto com os datasets usados no livro), basta rodar . O frameowrk é baseado no acrônimo MIDA, que contempla os quatro elementos básicos de um desenho de pesquisa: models, inquiries, data strategies, and answer strategies. Ou seja, você deve especificar um modelo, qual pergunta de pesquisa (aka estimando), quais dados vai utilizar e como vai estimar o estimando. Um modelo descreve o que causa o que e como. Tipicamente especifica a as unidades, o tamanho da amostra e a equação de resultados potenciais. Suponha que quero rodar um experimento aleatório com um tratamento e controle (two-arm randomized experiment). Assim, podemos declarar um modelo com: library(DeclareDesign) model &lt;- declare_model( N = 500, X = rep(c(0, 1), each = N / 2), # tratamento e controle U = rnorm(N, sd = 0.25), # heterogeneidade exógena potential_outcomes(Y ~ 0.2 * Z + X + U) ) Vamos entender o que fizemos. Declaramos que nossa população terá \\(500\\) observações: . Nesse exemplo, a amostra será igual a populacão, mas poderíamos amostrar da população se quiséssemos. Declaramos que \\(X\\), uma covariável, pode assumir dois valores (0,1), e atribuimos a priemria metade pra \\(0\\) e a outra metade para \\(1\\): . Declaramos que existe uma variável \\(U\\) que tem distribuição normal, com \\(N\\) observações e média \\(0\\) e desvio-padrão \\(.25\\):. Declaramos que os resultados potenciais diferem em \\(20\\%\\) entre tratamento e controle (\\(Z\\)) para cada unidade. Uma forma alternativa e talvez mais clara de declarar a relação entre tratamento/controle e resultados potenciais seria escrever . 4.1. Além disso, \\(X\\) tem efeito de \\(1\\) para todas as unidades. Vamos passar agora ao nosso estimando ou inquiry. inquiry &lt;- declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) Se estamos interessados no ATE, é só declarar que é a média da diferença entre os resultados potenciais. Podemos também usar a função Outras possibilidaes incluem o ATT e CATE: , por exemplo. Formulação equivalente para o ATT seria . Estratégia de dados data &lt;- declare_assignment(Z = complete_ra(N = N, m = 250)) + # assigment mechanism declare_measurement(Y = reveal_outcomes(Y ~ Z)) # reveal_outcomes é a switching equation estimator &lt;- declare_estimator(Y ~ Z, inquiry = &quot;ATE&quot;) two_arm_trial &lt;- model + inquiry + data + estimator # Draw a simulated dataset head(draw_data(two_arm_trial), 10) ## ID X U Y_Z_0 Y_Z_1 Z Y ## 1 001 0 0.013136040 0.013136040 0.21313604 1 0.213136040 ## 2 002 0 0.306059991 0.306059991 0.50605999 0 0.306059991 ## 3 003 0 0.248393137 0.248393137 0.44839314 1 0.448393137 ## 4 004 0 0.037319115 0.037319115 0.23731912 0 0.037319115 ## 5 005 0 0.352668514 0.352668514 0.55266851 0 0.352668514 ## 6 006 0 0.364146534 0.364146534 0.56414653 1 0.564146534 ## 7 007 0 0.366437409 0.366437409 0.56643741 1 0.566437409 ## 8 008 0 -0.280273943 -0.280273943 -0.08027394 1 -0.080273943 ## 9 009 0 -0.007617163 -0.007617163 0.19238284 0 -0.007617163 ## 10 010 0 0.195182802 0.195182802 0.39518280 1 0.395182802 Após declarar um desenho de pesquisa, podemos diagnosticar se nosso desenho de pesquisa pode ser respondido adequadamente (isto é, se é identificável, se possui poder para estimar com precisão o efeito de interesse etc.). Podemos inclusive modificar o desenho para responder a outras perguntas (é generalizável para outras populações, diferentes estimadores pdesempenham melhor etc.) Eis um exemplo de diagnóstico: diagnose_design(two_arm_trial, sims = 100) ## ## Research design diagnosis based on 100 simulations. Diagnosis completed in 0 secs. Diagnosand estimates with bootstrapped standard errors in parentheses (100 replicates). ## ## Design Inquiry Estimator Outcome Term N Sims Mean Estimand Mean Estimate Bias SD Estimate RMSE Power ## two_arm_trial ATE estimator Y Z 100 0.20 0.20 0.00 0.05 0.05 0.99 ## (0.00) (0.00) (0.00) (0.00) (0.00) (0.01) ## Coverage ## 0.95 ## (0.02) Podemos ajustar o desenh ode pesquisa designs &lt;- redesign(two_arm_trial, N = c(100, 200, 300, 400, 500)) diagnose_design(designs) ## ## Research design diagnosis based on 500 simulations. Diagnosis completed in 8 secs. Diagnosand estimates with bootstrapped standard errors in parentheses (100 replicates). ## ## Design N Inquiry Estimator Outcome Term N Sims Mean Estimand Mean Estimate Bias SD Estimate RMSE Power ## design_1 100 ATE estimator Y Z 500 0.20 0.20 -0.00 0.05 0.05 0.97 ## (0.00) (0.00) (0.00) (0.00) (0.00) (0.01) ## design_2 200 ATE estimator Y Z 500 0.20 0.20 0.00 0.05 0.05 0.98 ## (0.00) (0.00) (0.00) (0.00) (0.00) (0.01) ## design_3 300 ATE estimator Y Z 500 0.20 0.20 -0.00 0.05 0.05 0.97 ## (0.00) (0.00) (0.00) (0.00) (0.00) (0.01) ## design_4 400 ATE estimator Y Z 500 0.20 0.20 -0.00 0.05 0.05 0.98 ## (0.00) (0.00) (0.00) (0.00) (0.00) (0.01) ## design_5 500 ATE estimator Y Z 500 0.20 0.20 -0.00 0.05 0.05 0.98 ## (0.00) (0.00) (0.00) (0.00) (0.00) (0.01) ## Coverage ## 0.94 ## (0.01) ## 0.95 ## (0.01) ## 0.95 ## (0.01) ## 0.95 ## (0.01) ## 0.96 ## (0.01) 4.8 Exercício O exercício abaixo é uma tradução de questões que estavam presentes no exame de qualificação (prelims) da área de métodos do programa de doutorado em ciência política de Yale. 4.8.1 Experimento com envio de cartões-postais e participação eleitoral Você conduz um experimento aleatório para testar o efeito de um cartão-postal sobre a participação eleitoral, sorteando independentemente uma moeda para cada sujeito com probabilidade \\(0 &lt; p &lt; 1\\) de receber o tratamento. Assuma o pressuposto de SUTVA (Stable Unit Treatment Value Assumption). Você estima o seguinte modelo por Mínimos Quadrados Ordinários (OLS): \\[ Y_i = \\beta_0 + \\beta_1 T_i + \\beta_2 S_i + \\beta_3 T_i S_i + u_i \\] em que: - \\(Y_i\\) indica se o indivíduo votou (variável dependente); - \\(T_i\\) é o indicador binário de tratamento (receber ou não o cartão-postal); - \\(S_i\\) é um indicador binário que vale 1 se o indivíduo vive em um estado eleitoralmente competitivo (battleground state) e 0 caso contrário; - \\(T_i S_i\\) é a interação entre o tratamento e o contexto competitivo. 4.8.1.1 (a) Interprete os quatro coeficientes \\(\\beta\\) \\(\\beta_0\\): média de \\(Y_i\\) (taxa de votação) para o grupo controle (\\(T_i = 0\\)) em estados não competitivos (\\(S_i = 0\\)). \\(\\beta_1\\): efeito médio do tratamento (cartão-postal) em estados não competitivos. Como o tratamento foi atribuído aleatoriamente, \\(\\beta_1\\) tem interpretação causal. \\(\\beta_2\\): diferença na taxa média de votação entre estados competitivos e não competitivos no grupo controle. Não tem interpretação causal. \\(\\beta_3\\): diferença no efeito do tratamento entre estados competitivos e não competitivos. Se \\(\\beta_3 \\neq 0\\), o efeito do cartão-postal depende do tipo de estado. Como o tratamento é aleatório, \\(\\beta_3\\) também tem interpretação causal. 4.8.1.2 (b) Como testar a hipótese de que o efeito do tratamento é igual entre os dois tipos de estado? Testa-se a hipótese nula \\(H_0: \\beta_3 = 0\\). Isso pode ser feito diretamente a partir do resultado da regressão usando um teste t para o coeficiente da interação \\(T_i S_i\\). 4.8.2 Experimento com anúncios de TV e participação eleitoral Você quer testar se anúncios de TV aumentam a participação eleitoral. O experimento pode ser conduzido em até 16 mercados de mídia, dos quais até 8 podem ser sorteados para o grupo de tratamento. Os anúncios só podem ser exibidos para o mercado de mídia como um todo. Você tem informações individuais para todos os eleitores elegíveis nesses mercados: mercado de mídia, idade, sexo, raça/etnia e participação nas duas eleições anteriores. Após a eleição, você receberá os dados atualizados sobre participação no pleito atual. 4.8.2.1 (a) Como alocar aleatoriamente os mercados ao tratamento? Sorteie aleatoriamente 8 dos 16 mercados de mídia para o grupo de tratamento. Como o tratamento é atribuído no nível do mercado, essa é a unidade de aleatorização. Recomenda-se balancear o sorteio usando pareamento ou estratificação com base em características agregadas dos mercados (por exemplo, participação passada, composição demográfica), se houver variação relevante entre eles. 4.8.2.2 (b) Como analisar esse experimento? A análise deve ser feita no nível do mercado de mídia, que é a unidade de tratamento. Uma abordagem válida é calcular a média da taxa de votação em cada mercado e rodar uma regressão simples: \\[ \\bar{Y}_j = \\alpha + \\tau D_j + \\varepsilon_j \\] em que: - \\(\\bar{Y}_j\\) é a média da taxa de votação no mercado \\(j\\); - \\(D_j\\) é um indicador de tratamento para o mercado; - \\(\\tau\\) estima o efeito médio do tratamento. É possível incluir covariáveis no nível do mercado para aumentar a precisão, mas não é necessário para validade causal. 4.8.3 Exclusão de participantes em experimentos de survey Pesquisadores às vezes excluem participantes de um experimento de survey por: 1. Não passarem em uma checagem de atenção pré-tratamento; 2. Não passarem em uma checagem de atenção pós-tratamento; 3. Completarem o survey muito rapidamente (por exemplo, 3 desvios-padrão abaixo da média de tempo). 4.8.3.1 (a) Se o interesse é no efeito médio do tratamento entre os sujeitos que não foram excluídos, qual dessas estratégias é não-viesada? Todas essas estratégias podem fornecer estimativas não viesadas para o efeito médio do tratamento entre os sujeitos que permanecem na amostra, desde que os critérios de exclusão sejam pré-tratamento ou não afetem diferencialmente os grupos de tratamento e controle. A exclusão baseada em variáveis observadas antes do tratamento (como checagem pré-tratamento ou tempo de resposta) é menos problemática. Já a exclusão com base em comportamentos após o tratamento (como falha em atenção pós-tratamento) pode introduzir viés, pois pode estar correlacionada com a resposta ao tratamento. 4.8.3.2 (b) Se o interesse é no efeito médio do tratamento entre todos os participantes que iniciaram o experimento, qual dessas estratégias é não-viesada? Nenhuma das exclusões garante uma estimativa não viesada nesse caso. Excluir participantes com base em qualquer critério — mesmo que relacionado à atenção ou tempo de resposta — altera a composição da amostra em relação ao universo original. Para estimar o efeito médio para todos os participantes que começaram o experimento, é necessário manter todos os sujeitos, independentemente do desempenho em checagens ou tempo de resposta. "],["propensity-score-e-matching.html", "Capítulo 5 Propensity Score e Matching 5.1 Introdução 5.2 Propensity Score 5.3 Matching 5.4 Suposições de identificação 5.5 Matching 5.6 Matching exato 5.7 Matching aproximado 5.8 Estimando 5.9 Declare Design e Matching 5.10 Recomendações Práticas sobre Matching 5.11 Referências", " Capítulo 5 Propensity Score e Matching 5.1 Introdução Na aula de hoje, iremos aprender sobre a principal estratégia de “seleção em observáveis”, que é matching. Mas antes, vamos falar de subclassificação ,que é uma técnica mais simples e é útil para introduzir a ideia de matching. 5.2 Propensity Score O propensity score nada mais é que a probabilidade de uma unidade ser tratada, dada as covariáveis, ou seja, \\(Pr(D_i = 1| X_i)\\). A ideia chave para propensity-score vem de um paper de Rosenbaum-Rubin (1983) em que eles mostram que, se a condição 1 de ignorabilidade forte (isto é, \\(Y_i(1), Y_i(0) \\perp D_i|X_i\\)) for satisfeita, então também é verdade que a condição \\(Y_i(1), Y_i(0) \\perp D_i|\\pi(X_i)\\) também é satisfeita. E por que isso é importante? Nós nunca sabemos o verdadeiro modelo que relaciona as convariáveis \\(X_i\\) com \\(D_i\\) e \\(Y_i\\), de modo que podemos ter algum problema de modelo mal especificado (por exemplo, supomos um modelo linear, quando na verdade é não-linear). Então, em vez de estimar dezenas de modelos, posso condicionar (“controlar”) apenas pelo propensity score \\(\\pi(X_i)\\). A intuição é que o propensity score cria balanceamento entre tratados e não-tratados. Para ilustrar o poder desse reusltado, vamos considerar um exemplo simulado, em que ignorability forte é satisfeita, mas um modelo mal-especificado gera amostras não-balanceadas e, portanto, estimativas viesadas. library(knitr) library(tidyverse) library(ggdag) library(arm) # true DGP dag &lt;- dagify( y ~ D + w1, D ~ w1 ) ggdag(dag) O DAG acima ilustra bem qual a relação causal entre variáveis. Para estimar o ATE de \\(D\\) sobre \\(Y\\), precisamos fechar o backdoor de \\(w_1\\). A forma usual como fazemos isso é com regressão. O problema que estamos abordando aqui é quando a amostra é não-balanceada entre tratados e não-tratados, isto é. Vamos visualizar dois tipos de relações (uma linear e outra não-linear) entre a variável de controle \\(w_1\\) e a resposta \\(Y\\) para ilustrar o problema do desbalanceamento: library(ggplot2) set.seed(202) n &lt;- 1e4 w1 &lt;- rnorm(n) # único confundidor tau &lt;- 3 # efeito causal verdadeiro # GERAMOS UM PROPENSITY SCORE NÃO‐LINEAR p &lt;- plogis(-0.5 + 2 * w1) D &lt;- rbinom(n, 1, p) # GERAÇÃO DOS RESULTADOS POTENCIAIS linear (apenas função de w1, forte ignorabilidade): y0 &lt;- 5 * w1 + rnorm(n) y1 &lt;- y0 - tau # efeito constante y &lt;- ifelse(D == 1, y1, y0) df &lt;- data.frame(y=y, D=D, w1=w1) df %&gt;% mutate( D = factor(D, levels = c(0,1), labels = c(&quot;Controle (D = 0)&quot;, &quot;Tratado (D = 1)&quot;)) ) %&gt;% ggplot(aes(x = w1, y = y, colour = D)) + geom_point(alpha = 0.6) + scale_colour_manual( name = &quot;Tratamento (binário)&quot;, values = c(&quot;Controle (D = 0)&quot; = &quot;steelblue&quot;, &quot;Tratado (D = 1)&quot; = &quot;firebrick&quot;) ) + theme_bw() No primeiro gráfico, o efeito causal (ATE) do tratamento é \\(-3\\) e podemos ver nos dados que de fato em média a resposta é menor entre tratados que no controle. Além disso, vemos também que o efeito é basicamente linear. Mas o pontpo importante aqui é que existem duas regiões dos dados em que praticamente só temos unidades no controle (\\(w_1 &lt; -2\\)) e ou no tratamento (\\(w_1 &gt; -2\\)). Isso significa que para que a regressão possa estimar o efeito causal deve extrapolar a estimativa da região em que ambos tratamento e controle estão presentes nos dados para uma região em que não estão presentes. Como o efeito é constante para todas as regiões de \\(w_1\\), isso não causa problema e a regressão consegue recuperar o ATE sem viés. O gráfico abaixo ilustra o que a regressão está fazendo: df %&gt;% mutate( D = factor(D, levels = c(0,1), labels = c(&quot;Controle (D = 0)&quot;, &quot;Tratado (D = 1)&quot;)) ) %&gt;% ggplot(aes(x = w1, y = y, colour = D)) + geom_point(alpha = 0.6) + geom_smooth(method = &quot;lm&quot;) + scale_colour_manual( name = &quot;Tratamento (binário)&quot;, values = c(&quot;Controle (D = 0)&quot; = &quot;steelblue&quot;, &quot;Tratado (D = 1)&quot; = &quot;firebrick&quot;) ) + theme_bw() O gráfico mostra duas retas de regressão ajustadas, uma para o controle (em azul) e outra para o tratamento (em vermelho). Efetivamente, temos de estender as duas retas para as regiões em que não há dados, por meio de extrapolação, que no caso significa continuar a linha reta. Assim, temos uma estimativa dos resultados potenciais nessas regiões e podemos computar o efeito causal médio. Como a extrapolação é razoável, não há problema. Vejamos agora uma situação em que o efeito de \\(w_1\\) é não linear sobre \\(Y\\). set.seed(202) n &lt;- 1e4 w1 &lt;- rnorm(n) # único confundidor tau &lt;- 3 # efeito causal verdadeiro # GERAMOS UM PROPENSITY SCORE NÃO‐LINEAR p &lt;- plogis(-0.5 + 2 * w1) D &lt;- rbinom(n, 1, p) # GERAÇÃO DOS RESULTADOS POTENCIAIS não-linear (apenas função de w1, forte ignorabilidade): y0 &lt;- 5 * w1^2 + rnorm(n) y1 &lt;- y0 - tau # efeito constante y &lt;- ifelse(D == 1, y1, y0) df &lt;- data.frame(y=y, D=D, w1=w1) df %&gt;% mutate( D = factor(D, levels = c(0,1), labels = c(&quot;Controle (D = 0)&quot;, &quot;Tratado (D = 1)&quot;)) ) %&gt;% ggplot(aes(x = w1, y = y, colour = D)) + geom_point(alpha = 0.6) + scale_colour_manual( name = &quot;Tratamento (binário)&quot;, values = c(&quot;Controle (D = 0)&quot; = &quot;steelblue&quot;, &quot;Tratado (D = 1)&quot; = &quot;firebrick&quot;) ) + theme_bw() Aqui, vemos que o efeito é não-linear de \\(w_1\\) sobre \\(Y\\) e também o desbalanceamento na amostra. Vamos ver o mesmo gráfico com as duas retas ajustadas para entender como a extrapolação pode ficar bem ruim nesse caso. df %&gt;% mutate( D = factor(D, levels = c(0,1), labels = c(&quot;Controle (D = 0)&quot;, &quot;Tratado (D = 1)&quot;)) ) %&gt;% ggplot(aes(x = w1, y = y, colour = D)) + geom_point(alpha = 0.6) + geom_smooth(method = &quot;lm&quot;) + scale_colour_manual( name = &quot;Tratamento (binário)&quot;, values = c(&quot;Controle (D = 0)&quot; = &quot;steelblue&quot;, &quot;Tratado (D = 1)&quot; = &quot;firebrick&quot;) ) + theme_bw() Um problema óbvio do modelo é que o efeito de w1 é quadrático, então podemos tentar corrigir isso incluindo um termo quadrático. reg_sq &lt;- lm(y ~ D + w1 + w1^2, data = df) summary(reg_sq) ## ## Call: ## lm(formula = y ~ D + w1 + w1^2, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.567 -4.180 -2.347 1.646 73.841 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.2689 0.1041 40.995 &lt; 2e-16 *** ## D -1.2953 0.1804 -7.181 7.44e-13 *** ## w1 -0.7960 0.0890 -8.943 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 7.052 on 9997 degrees of freedom ## Multiple R-squared: 0.03237, Adjusted R-squared: 0.03217 ## F-statistic: 167.2 on 2 and 9997 DF, p-value: &lt; 2.2e-16 O efeito causal é negativo, o que é bom, pois está na direção certa, mas ainda está distante do efeito verdadeiro. Isso ilustra também como a estimativa é dependente do modelo, o que é bem ruim, pois não sabemos qual o modelo certo. Em resumo, quando há desbalancamento, causamos dependência do modelo, o que é problemático. Agora, vamos comparar com o propensity score: library(knitr) library(tidyverse) library(ggdag) # true DGP reg_aux&lt;- glm(D ~ w1, family = binomial, data=df) p_score &lt;- reg_aux$fitted.values reg1 &lt;- lm(y ~ D + p_score) summary(reg1) ## ## Call: ## lm(formula = y ~ D + p_score) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.921 -4.258 -2.462 1.647 70.708 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.2799 0.1179 36.307 &lt; 2e-16 *** ## D -2.9562 0.1858 -15.910 &lt; 2e-16 *** ## p_score 1.6681 0.2917 5.718 1.11e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 7.069 on 9997 degrees of freedom ## Multiple R-squared: 0.02781, Adjusted R-squared: 0.02761 ## F-statistic: 143 on 2 and 9997 DF, p-value: &lt; 2.2e-16 w &lt;- ifelse(D == 1, 1/p_score, 1/(1-p_score)) # pesos IPTW reg2 &lt;- lm(y ~ D , weights = w) summary(reg2) ## ## Call: ## lm(formula = y ~ D, weights = w) ## ## Weighted Residuals: ## Min 1Q Median 3Q Max ## -15.95 -5.52 -2.87 2.04 324.89 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.67183 0.09553 48.90 &lt;2e-16 *** ## D -2.57016 0.13452 -19.11 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.499 on 9998 degrees of freedom ## Multiple R-squared: 0.03523, Adjusted R-squared: 0.03513 ## F-statistic: 365.1 on 1 and 9998 DF, p-value: &lt; 2.2e-16 Conseguimos recuperar o ATE sem problemas. E não precisei especificar corretamente a forma funcional da variáveil de controle \\(w_1\\) no modelo principal, pois usei o propensity score. Note que precisei modelar corretamente a regreessão que calcula o propensity score. É útil ver como o pscore está distribuído entre os grupos de tratamento e controle: library(knitr) library(tidyverse) library(ggdag) # true DGP df &lt;- df %&gt;% mutate(pscore = p_score) df %&gt;% ggplot(aes(pscore, group=D)) + geom_boxplot() df %&gt;% mutate(D = as.factor(D)) %&gt;% ggplot()+ geom_density(aes(x=pscore, group=D, colour = D)) Há desbalanceamento e falta de overlap ou suporte comum, o que leva à extrapolação. 5.3 Matching A Ideia do matching pode ser ilustrada se notarmos o seguinte. A projeção da reta vermelha para pontos abaixo de \\(-2\\) é de um \\(y\\) médio muito baixo, enquanto que o \\(y\\) médio é muito alto para o controle. O oposto é verificado para a região em que \\(w_1 &gt; 2\\). Portanto, se eu restringir (excluir os casos) a análise para uma região onde a necessidade de extrapolação é menor, o resultado tende a ser aproximar do ATE library(knitr) library(tidyr) library(broom) library(kableExtra) reg_sub &lt;- lm(y ~ D + w1, data = df) reg_sub %&gt;% tidy() %&gt;% kable(digits = c(0, 2, 3, 2, 3)) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) term estimate std.error statistic p.value (Intercept) 4.27 0.104 41.00 0 D -1.30 0.180 -7.18 0 w1 -0.80 0.089 -8.94 0 reg_sub &lt;- lm(y ~ D + w1, data = subset(df, w1 &gt; -2 &amp; w1 &lt; 2)) reg_sub %&gt;% tidy() %&gt;% kable(digits = c(0, 2, 3, 2, 3)) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) term estimate std.error statistic p.value (Intercept) 3.46 0.069 50.52 0 D -1.99 0.119 -16.70 0 w1 -0.35 0.066 -5.32 0 reg_sub &lt;- lm(y ~ D + w1, data = subset(df, w1 &gt; -1.5 &amp; w1 &lt; 1.5)) reg_sub %&gt;% tidy() %&gt;% kable(digits = c(0, 2, 3, 2, 3)) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) term estimate std.error statistic p.value (Intercept) 2.57 0.047 55.02 0 D -2.48 0.080 -30.78 0 w1 -0.21 0.053 -3.88 0 reg_sub &lt;- lm(y ~ D + w1, data = subset(df, w1 &gt; -1 &amp; w1 &lt; 1)) reg_sub %&gt;% tidy() %&gt;% kable(digits = c(0, 2, 3, 2, 3)) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) term estimate std.error statistic p.value (Intercept) 1.41 0.029 49.57 0 D -2.77 0.048 -57.27 0 w1 -0.17 0.043 -3.93 0 reg_sub &lt;- lm(y ~ D + w1, data = subset(df, w1 &gt; -1 &amp; w1 &lt; 1)) reg_sub %&gt;% tidy() %&gt;% kable(digits = c(0, 2, 3, 2, 3)) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) term estimate std.error statistic p.value (Intercept) 1.41 0.029 49.57 0 D -2.77 0.048 -57.27 0 w1 -0.17 0.043 -3.93 0 A ideia do matching é um pouco diferente do que fizemos acima, pois estamos excluindo as observações que estão no tratamento e que não possuem controle correspondente, e do controle que não possuem tratamento correspondente. Não há erro em excluir os dois tipos de observações, mas sempre temos de nos perguntar qual é o estimando de interesse. Se faço esse procedimento, o meu estimando não é nenhum dos usuais ATT ou ATE. No matchingf, nós nos concentramos em estimar o ATT, de forma que procuramos achar observações no controle que são próximas das tratadas, ou seja, excluímos os controles que não são um match para as observações tratadas. 5.4 Suposições de identificação Supondo para simplificar um tratamento binário \\(T\\), e uma covariável categórica \\(X\\), temos: \\((Y^1, Y^0) \\perp T|X \\text{ (Independência Condicional)}\\) \\(0 &lt; P(T=1|A) &lt; 1 \\text{ (Suporte comum)}\\) Temos então a seguinte derivação (usando o fato de os resultados potenciais são independentes do treatment assignment, condicional à covariável) e a switching equation no último passo: \\[\\begin{align} \\mathbb{E}[Y^1-Y^0|X] &amp; = \\mathbb{E}[Y^1 - Y^0 | X, T=1] \\\\ &amp; = \\mathbb{E}[Y^1| X, T=1] - \\mathbb{E}[Y^0| X,T=0] \\\\ &amp; = \\mathbb{E}[Y| X, D=1] - \\mathbb{E}[Y| X, D=0] \\end{align}\\] E o estimador que usamos pode ser representado (supondo suporte comum) como: \\(\\widehat{\\delta_{ATE}} = \\sum_{x\\in X}{(\\mathbb{E}[Y| X=x, D=1] - \\mathbb{E}[Y| X=x, D=0])P(X=x)}\\) E o que estamos fazendo é computar a média do efeito do tratamento condicional ponderado pela distribuição de \\(X\\). Para identificar o ATE, nós precisamos supor independência condicional a ambos os resultados potenciais. Se porém isso for crível apenas para \\(Y^0\\), podemos estimar o ATT. Basta lembrarmos que \\(\\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0] = \\mathbb{E}[Y_i^1 - Y_i^0|T_i=1] + \\mathbb{E}[Y_i^0|T_i=1] - \\mathbb{E}[Y_i^0|T_i=0]\\) 5.5 Matching A técnica de matching trata os resultados potenciais como missing data. Assim, pudermos supor CIA com credibilidade, pelo menos com relação a \\(Y^0\\), então podemos imputar esses resultados potenciais e estimar o ATT. A ideia é achar uma unidade a mais similar possível a unidade tratada para servir como contrafactual. Assim, poderíamos computar “diretamente” o ATT, já que teríamos os \\(Y^1\\) e \\(Y^0\\) para cada unidade, este último imputado. Há dois grandes grupos de métodos de matching: exato e aproximado. 5.6 Matching exato Nesse método, nós achamos uma unidade (ou mais) que tenham um valor exatamente igual nas covariáveis (ou no propensity score), e imputamos o controle. 5.7 Matching aproximado Para aproximar o matching, utilizamos alguma noção de distância entre variáveis. Para mais de uma variável, podemos utilizar algumas métricas de distância. A primeira é a distância euclidiana (supondo \\(K\\) variáveis). \\[ \\lVert X_i - X_j \\rVert = \\sqrt{(X_i - X_j)&#39;(X_i - X_j)} \\] \\[ \\lVert X_i - X_j \\rVert = \\sqrt{\\sum_{n=1}^k(X_{ni} - X_{nj})} \\] A distância euclidiana utiliza a escala das próprias variáveis, então é comum usar a distância euclidiana normalizada: \\[ \\lVert X_i - X_j \\rVert = \\sqrt{\\sum_{n=1}^k(\\frac{X_{ni} - X_{nj})}{\\hat{\\sigma}_n^2}} \\] Outra métrica é a distância de Mahalanobis, que basicamente divide pela covariância (amostral) entre as variáveis em vez da variância. Mas na prática a gente usa a euclidiana. 5.8 Estimando Uma vez que fizemos o matching entre unidades, qual nosso estimador? Lemrbando que o estimando é o ATT. \\[ \\widehat{\\delta}_{ATT} = \\dfrac{1}{N_T} \\sum_{D_i=1} (Y_i - Y_{j(i)}) \\] library(MatchIt) result_0 &lt;- matchit(D ~ w1, data = df, method = NULL, distance = &#39;glm&#39;) summary(result_0) ## ## Call: ## matchit(formula = D ~ w1, data = df, method = NULL, distance = &quot;glm&quot;) ## ## Summary of Balance for All Data: ## Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max ## distance 0.6549 0.2493 1.5714 1.2566 0.3685 0.5761 ## w1 0.7004 -0.5362 1.6030 0.9132 0.3685 0.5761 ## ## Sample Sizes: ## Control Treated ## All 5806 4194 ## Matched 5806 4194 ## Unmatched 0 0 ## Discarded 0 0 5.9 Declare Design e Matching Pode ser útil usar o declare design para investigar o uso de matching. Vamos fazer isso para o dataset lalonde. Esse é um banco de dados famoso na economia, pois o pesquisador Lalonde (1986) foi investigar se aplicação de métodos (então) tradicionais de modelagem econométrica eram capaz de recuperar o efeito causal de um estudo experimental chamada National Supported Work Demonstration (NSW), um programa de emprego temporário para dar experiência de trabalho. Ele coletou dados de um survey “representativo” de trabalhadores americanos (PSID) e elencou esses trabalhadores como grupo controle e empregou métodos econométricos para tentat estimar o efeito causal. Os resultados foram desastrosos, no sentido de altamente variáveis dependendo do modelo e subconjunto de dados e longe da estimativa experimental (incluindo com sinal errado). Vamos replicar esse trabalho, usando matching e pscore. A variável resposta do banco de dados é re78 (real earnings in 1978). O tratamento é a variável treat. As demais variáveis são covariáveis. library(tidyverse) library(data.table) library(here, quietly=TRUE) library(fixest) here() ## [1] &quot;/Users/manoelgaldino/Documents/DCP/Cursos/Causalidade/Causalidade&quot; set.seed(1234) lalonde &lt;- fread(here(&quot;Dados&quot;, &quot;lalonde_nsw.csv&quot;)) dt &lt;- lalonde[, .(re78, treat)] %&gt;% rename(Y = re78, D = treat) dt %&gt;% group_by(D) %&gt;% sample_n(3) %&gt;% kableExtra::kable(digits = 0, col.names = c(&quot;Income&quot;, &quot;Treatment&quot;)) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Income Treatment 0 0 290 0 7010 0 13830 1 0 1 60308 1 dt %&gt;% group_by(D) %&gt;% summarize(mean(Y)) %&gt;% kableExtra::kable(digits = 0, col.names = c(&quot;Treatment&quot;, &quot;Income&quot;)) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Treatment Income 0 4555 1 6349 y1 = dt[dt$D == 1, Y] y0 &lt;- dt[dt$D == 0, Y] tau &lt;- mean(y1) - mean(y0) A diferença simples na média é 1794. 5.9.1 Matching e Propensity scores Usando age, education, hispanic, black, married, nodegree, RE74 e RE75, vamos moelar o propensity score usando o grupo dos tratados em lalonde_nsw.csv e a amostra de controle de lalonde_psid.csv. Report the average p-score for the treated and control samples, and plot the propensity score densities for the treatment and control groups. nsw_data &lt;- lalonde psid_data &lt;- fread(here(&quot;Dados&quot;, &quot;lalonde_psid.csv&quot;)) nsw_treat &lt;- nsw_data[nsw_data$treat == 1, ] psid_control &lt;- psid_data[psid_data$treat == 0, ] dw_data &lt;- rbind(nsw_treat, psid_control) library(MatchIt) m.out1 &lt;- matchit(treat ~ age + education + hispanic + black + married + nodegree + re74 + re75, data = dw_data, method = &quot;nearest&quot;, distance = &quot;glm&quot;) ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred summary(m.out1) ## ## Call: ## matchit(formula = treat ~ age + education + hispanic + black + ## married + nodegree + re74 + re75, data = dw_data, method = &quot;nearest&quot;, ## distance = &quot;glm&quot;) ## ## Summary of Balance for All Data: ## Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max ## distance 0.6364 0.0270 2.1674 8.0268 0.4816 0.8817 ## age 25.8162 34.8506 -1.2627 0.4696 0.2317 0.3771 ## education 10.3459 12.1169 -0.8808 0.4255 0.1091 0.4029 ## hispanic 0.0595 0.0325 0.1139 . 0.0269 0.0269 ## black 0.8432 0.2506 1.6301 . 0.5926 0.5926 ## married 0.1892 0.8663 -1.7287 . 0.6771 0.6771 ## nodegree 0.7081 0.3052 0.8862 . 0.4029 0.4029 ## re74 2095.5737 19428.7458 -3.5471 0.1329 0.4684 0.7292 ## re75 1532.0553 19063.3377 -5.4458 0.0561 0.4695 0.7736 ## ## Summary of Balance for Matched Data: ## Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max Std. Pair Dist. ## distance 0.6364 0.2934 1.2200 1.4702 0.0432 0.5568 1.2200 ## age 25.8162 30.4811 -0.6520 0.4149 0.1196 0.1784 1.3561 ## education 10.3459 10.3784 -0.0161 0.4745 0.0407 0.0919 1.3281 ## hispanic 0.0595 0.0649 -0.0229 . 0.0054 0.0054 0.5257 ## black 0.8432 0.7568 0.2379 . 0.0865 0.0865 0.9515 ## married 0.1892 0.4595 -0.6901 . 0.2703 0.2703 1.0213 ## nodegree 0.7081 0.6216 0.1902 . 0.0865 0.0865 0.9036 ## re74 2095.5737 4499.8428 -0.4920 1.1020 0.0722 0.4162 0.8667 ## re75 1532.0553 3204.3968 -0.5195 0.7389 0.0605 0.2973 0.9044 ## ## Sample Sizes: ## Control Treated ## All 2490 185 ## Matched 185 185 ## Unmatched 2305 0 ## Discarded 0 0 plot(summary(m.out1)) m.data &lt;- match_data(m.out1) head(m.data) ## treat age education black hispanic married nodegree re74 re75 re78 distance weights subclass ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;fctr&gt; ## 1: 1 37 11 1 0 1 1 0 0 9930.0459 0.3773454 1 1 ## 2: 1 22 9 0 1 0 1 0 0 3595.8940 0.8849355 1 2 ## 3: 1 30 12 1 0 0 0 0 0 24909.4492 0.7201238 1 3 ## 4: 1 27 11 1 0 0 1 0 0 7506.1460 0.8717413 1 4 ## 5: 1 33 8 1 0 0 1 0 0 289.7899 0.7896888 1 5 ## 6: 1 22 9 1 0 0 1 0 0 4056.4939 0.9030698 1 6 library(&quot;marginaleffects&quot;) fit &lt;- lm(re78 ~ treat * (age + education + black + married + nodegree + re74 + re75), data = m.data, weights = weights) avg_comparisons(fit, variables = &quot;treat&quot;, vcov = ~subclass, newdata = subset(treat == 1)) ## ## Estimate Std. Error z Pr(&gt;|z|) S 2.5 % 97.5 % ## 1881 879 2.14 0.0325 4.9 157 3605 ## ## Term: treat ## Type: response ## Comparison: 1 - 0 library(MatchIt) library(DeclareDesign) exact_matching &lt;- function(data) { matched &lt;- matchit(D ~ X, method = &quot;exact&quot;, data = data) match.data(matched) } declaration_16.2 &lt;- declare_model( N = 100, U = rnorm(N), X = rbinom(N, 1, prob = 0.5), D = rbinom(N, 1, prob = 0.25 + 0.5 * X), Y_D_0 = 0.2 * X + U, Y_D_1 = Y_D_0 + 0.5 ) + declare_inquiry(ATT = mean(Y_D_1[D == 1] - Y_D_0[D == 1])) + declare_step(handler = exact_matching) + declare_measurement(Y = reveal_outcomes(Y ~ D)) + declare_estimator(Y ~ D, weights = weights, .method = difference_in_means, inquiry = &quot;ATT&quot;, label = &quot;Matched difference-in-means&quot;) + declare_estimator(Y ~ D, .method = difference_in_means, inquiry = &quot;ATT&quot;, label = &quot;Raw difference-in-means&quot;) library(MatchIt) m.out0 &lt;- matchit(treat ~ age + education + hispanic + black + married + nodegree + re74 + re75, data = dw_data, method = NULL, distance = &quot;glm&quot;) ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred # Checking balance prior to matching summary(m.out0) ## ## Call: ## matchit(formula = treat ~ age + education + hispanic + black + ## married + nodegree + re74 + re75, data = dw_data, method = NULL, ## distance = &quot;glm&quot;) ## ## Summary of Balance for All Data: ## Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max ## distance 0.6364 0.0270 2.1674 8.0268 0.4816 0.8817 ## age 25.8162 34.8506 -1.2627 0.4696 0.2317 0.3771 ## education 10.3459 12.1169 -0.8808 0.4255 0.1091 0.4029 ## hispanic 0.0595 0.0325 0.1139 . 0.0269 0.0269 ## black 0.8432 0.2506 1.6301 . 0.5926 0.5926 ## married 0.1892 0.8663 -1.7287 . 0.6771 0.6771 ## nodegree 0.7081 0.3052 0.8862 . 0.4029 0.4029 ## re74 2095.5737 19428.7458 -3.5471 0.1329 0.4684 0.7292 ## re75 1532.0553 19063.3377 -5.4458 0.0561 0.4695 0.7736 ## ## Sample Sizes: ## Control Treated ## All 2490 185 ## Matched 2490 185 ## Unmatched 0 0 ## Discarded 0 0 library(MatchIt) m.out1 &lt;- matchit(treat ~ age + education + hispanic + black + married + nodegree + re74 + re75, data = dw_data, method = &quot;nearest&quot;, distance = &quot;glm&quot;) ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred # Full matching on a probit PS m.out2 &lt;- matchit(treat ~ age + education + black + married + nodegree + re74 + re75, data = lalonde, method = &quot;full&quot;, distance = &quot;glm&quot;, link = &quot;probit&quot;) m.data &lt;- match_data(m.out2) library(&quot;marginaleffects&quot;) fit &lt;- lm(re78 ~ treat * (age + education + black + married + nodegree + re74 + re75), data = m.data, weights = weights) avg_comparisons(fit, variables = &quot;treat&quot;, vcov = ~subclass, newdata = subset(treat == 1)) ## ## Estimate Std. Error z Pr(&gt;|z|) S 2.5 % 97.5 % ## 2064 679 3.04 0.00238 8.7 733 3396 ## ## Term: treat ## Type: response ## Comparison: 1 - 0 full_matching &lt;- function(data) { matched &lt;- matchit(treat ~ age + education + hispanic + black + married + nodegree + re74 + re75, method = &quot;full&quot;, data = data) match.data(matched) } declaration_16.2 &lt;- declare_model( N = 1000, U = rnorm(N), X = rbinom(N, 1, prob = 0.5), D = rbinom(N, 1, prob = 0.25 + 0.5 * X), Y_D_0 = 0.2 * X + U, Y_D_1 = Y_D_0 + 0.5 ) + declare_inquiry(ATT = mean(Y_D_1[D == 1] - Y_D_0[D == 1])) + declare_step(handler = exact_matching) + declare_measurement(Y = reveal_outcomes(Y ~ D)) + declare_estimator(Y ~ D, weights = weights, .method = difference_in_means, inquiry = &quot;ATT&quot;, label = &quot;Matched difference-in-means&quot;) + declare_estimator(Y ~ D, .method = difference_in_means, inquiry = &quot;ATT&quot;, label = &quot;Raw difference-in-means&quot;) 5.10 Recomendações Práticas sobre Matching Rotina ou algoritmo: Defina o que é proximidade: alguma distância de medida para determinar se um caso é um bom match e quais variáveis utilizar. Em geral, distância euclidiana. Implemente o método do match. Avalie a qualidade do método, por meio do balanceamento antes e depois do match. Se necessário, altere o passo 1 ou 2 e itere. Faça a inferência sobre o efeito causal do tratamento sobre a resposta, dado o matching feito em 3. ### Avaliação do matching feito É melhor usar matching exato ou aproximado do que propensity score matching, pois o poder do teste é melhor (cf. King &amp; Nielsen, 2019). Não devemos fazer teste de hipótese para checar que o balanceamento após matching é melhor do que antes (amostra menor reduz o poder do teste de detectar desbalanceamento. Além disso, não há superpopulação alvo da inferência, pois balanceamento é uma propriedade de uma amostra em particular). Cf. Austin 2009. Além de comparar médias, é recomendado comparar variâncias ou desvios-padrão (Austin 2009). Por exemplo, razão de variâncias. Jamais use a variável resposta para fazer o matching. Matching com reposição gera dificuldades para calcular o erro padrão, já que as observações não são independentes. 5.11 Referências Austin, P. C. (2009). Balance diagnostics for comparing the distribution of baseline covariates between treatment groups in propensity‐score matched samples. Stat Med. King, G., &amp; Nielsen, R. (2019). Why propensity scores should not be used for matching. Political analysis, 27(4), 435-454. Stuart, E. A. (2010). Matching methods for causal inference: A review and a look forward. Statistical science: a review journal of the Institute of Mathematical Statistics, 25(1), 1. "],["variáveis-instrumentais.html", "Capítulo 6 Variáveis Instrumentais 6.1 Introdução 6.2 IV com modelo estrutural 6.3 MQO em 2 Estágios 6.4 Principais usos de IV 6.5 Restrição de Exclusão 6.6 Monoticidade 6.7 Estimação (aka estatística F) 6.8 Referências", " Capítulo 6 Variáveis Instrumentais 6.1 Introdução Considere o seguinte DAG canônico de Variáveis Instrumentais: Nós vemos que o efeito causal do tratamento \\(T\\) é confundido pela variável não observada \\(U\\), já que temos um backdoor aberto. Porém, a variável \\(Z\\) não tem nenhum caminho aberto para \\(Y\\) exceto via \\(T\\), isto é, \\(T\\) é um mediador do efeito causal de \\(Z\\). Do ponto de vista não paramétrico (DAGs), dizemos que a variável \\(Z\\) é uma candidata a variável instrumental (IV) se: \\(Z\\) está conectado a X no grafo original. Condição de relevância. No grafo em que a seta de \\(T\\) para \\(y\\) é removida, \\(Z\\) é d-separado de \\(Y\\). Exclusion Restriction. A variável instrumental \\(Z\\) não compartilha causa comum com \\(y\\), incluindo, portanto, não ser descendente de \\(T\\). Causa comum. Remark: Pode acontecer de ser necessário controlar para uma conjunto de covariáveis \\(X\\) para que a segunda condição seja satisfeita. Chamamos isso de IV condicional. Remark 2: Dizemos que uma variável \\(Z\\) é candidata a ser VI porque as três condições acima, ainda que necessárias, não são suficientes para uma variável ser considerada VI. Veremos mais à frente porque isso acontece e o que mais é necessário para uma variável ser considerada VI. Considere o DAG abaixo. Remark 3: A literatura econométrica não costuma deixar muito clara a condição 3. Às vezes falam que \\(Z\\) deve causar \\(T\\) (o que implica que não há causa comum em um DAG). Porém, isso não é correto, como o DAG abaixo mostra, em que, controlando para \\(V_3\\), que é um collider, induzimos correlação entre \\(Z\\) e \\(T\\) para a condição de relevância ser satisfeita, e \\(Z\\) é uma VI candidata. Do mesmo jeito, se \\(V_3\\) for causa comum de \\(Z\\) e \\(T\\), não controlar para ela torna a \\(Z\\) admissível como VI. Será que \\(Z\\) pode ser uma IV no DAG abaixo? Vamos verificar as condições. É fácil ver que \\(Z\\) está conectado a \\(T\\), já que temos dois caminhos abertos, um via \\(W\\) e outro via \\(L\\) (e ainda um via \\(W\\) via \\(L\\)). Portanto, a primeira condição está satisfeita. Note que se eu controlar simultaneamente para \\(W\\) e \\(L\\), então eu fecho todos os caminhos abertos. Com relação à segunda condição, Remover a flecha de \\(T\\) para \\(Y\\) é, efetivamente, ter um novo DAG: Por fim, \\(Z\\) não compartilha causa comum com \\(Y\\). Nesse DAG, \\(Z\\) não está d-separado de \\(Y\\), pois existe um caminho aberto para \\(Y\\) via \\(L\\). Portanto, controlando para \\(L\\) (mas não \\(W\\)), tenho um instrumento que passa nas duas condições. 6.2 IV com modelo estrutural \\(y_i = \\beta D_i + \\delta_2 U + e_i\\) \\(D_i = \\delta_1 U + \\gamma z_i + u_i\\) As duas equações são estruturais, no sentido de que representam relações causais. A restrição de exclusão do tratamento \\(D_i\\) é que \\(\\mathbb{E}[D_i|e_i] = 0\\). Sabemos que não é verdade porque \\(D_i\\) é endógeno, ou seja, há um viés de variável omitida, \\(U\\). Já a restrição de exclusão da variável instrumental é que \\(\\mathbb{E}[z_i|u_i] = 0\\) Vamos supor, para simplificar, que tanto \\(D_i\\) quanto \\(Z_i\\) são binários. Considere o seguinte exemplo: Nós sabemos que diferença simples de média identifica o ATE da segunda equação: \\(\\gamma = \\frac{\\sum_{i=1}^n z_i}{n} - \\frac{\\sum_{i=1}^n (1-z_i)}{n}\\). 6.3 MQO em 2 Estágios Considere novamente o DAG canônico para IV. Como poderíamos estimar o efeito causal de \\(T\\) sobre \\(Y\\)? Uma possibilidade é a chamada forma reduzida, que pode ser derivada a partir da suposição de independência. Antes, vamos introduzir uma notação: A notação \\(Y^{T=t,Z=z}\\) indica o resultado potencial para um nível do tratamento \\(t\\) efetivamente recebido, que pode ser \\(0\\) ou \\(1\\), e para um nível do treatment assignment, que pode ser \\(0\\) ou \\(1\\), para um instrumento binário. E também temos um status potencial do tratamento (em oposição ao tratamento observado): \\(T^1_i\\) é o status do tratamento quando \\(Z=1\\). Similarmente, \\(T^0_i\\) é o status do tratamento quando \\(Z=0\\). E aqui temos uma nova switching equation: \\(T_i = T^0_i + (T^1_i - T^0_i)Z_i\\) \\[\\begin{align} E\\big[Y_i\\mid Z_i=1\\big]-E\\big[Y_i\\mid Z_i=0\\big] &amp; = E\\big[Y_i(D_i^1,1)\\mid Z_i=1\\mid]- E\\big[Y_i(D_i^0,0)\\mid Z_i=0\\big] \\\\ &amp; = E[Y_i(D_i^1,1)] - E[Y_i(D_i^0,0)] \\end{align}\\] O estimador é o efeito causal (total) de \\(Z\\) sobre \\(Y\\). Em um experimento, isso é chamado de intent to treat, pois se a aleatorização é o instrumento, então é o efeito causal da intenção de tratar. library(stargazer) n &lt;- 100000 set.seed(123) z &lt;- rnorm(n) u &lt;- rnorm(n, 0 , 3) treatment &lt;- rbinom(n, 1, plogis(z - u + rnorm(n, 0, 2))) y &lt;- 2*treatment + u reg_vies &lt;- lm(y ~ treatment) summary(reg_vies) Call: lm(formula = y ~ treatment) Residuals: Min 1Q Median 3Q Max -11.4112 -1.6433 0.0048 1.6470 10.8586 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 1.75964 0.01096 160.56 &lt;2e-16 treatment -1.49476 0.01551 -96.35 &lt;2e-16 — Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1 Residual standard error: 2.453 on 99998 degrees of freedom Multiple R-squared: 0.08495, Adjusted R-squared: 0.08494 F-statistic: 9283 on 1 and 99998 DF, p-value: &lt; 2.2e-16 reg_1s &lt;- lm(treatment ~ z) reg_2s &lt;- lm(y ~ fitted(reg_1s)) stargazer(reg_vies, reg_1s, reg_2s, type = &quot;html&quot;, title=&quot;OLS e 2SLS&quot;) OLS e 2SLS Dependent variable: y treatment y (1) (2) (3) treatment -1.495*** (0.016) z 0.095*** (0.002) fitted(reg_1s) 1.916*** (0.085) Constant 1.760*** 0.499*** 0.058 (0.011) (0.002) (0.043) Observations 100,000 100,000 100,000 R2 0.085 0.036 0.005 Adjusted R2 0.085 0.036 0.005 Residual Std. Error (df = 99998) 2.453 0.491 2.558 F Statistic (df = 1; 99998) 9,283.268*** 3,739.184*** 505.426*** Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 Uma regra de bolso, baseada em um artigo de Stock &amp; Yogo (2002), diz que a estatística F da regressão do primeiro estágio deve ser maior que 10. library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.4 ✔ readr 2.1.5 ## ✔ forcats 1.0.0 ✔ stringr 1.5.1 ## ✔ ggplot2 3.5.1 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.3 ✔ tidyr 1.3.1 ## ✔ purrr 1.0.4 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors library(ggplot2) simulate_and_fit &lt;- function(n) { z &lt;- rnorm(n) u &lt;- rnorm(n, 0, 3) treatment &lt;- rbinom(n, 1, plogis(z - u + rnorm(n, 0, 2))) y &lt;- 2 * treatment + u # Naive regression reg_vies &lt;- lm(y ~ treatment) # 2SLS reg_1s &lt;- lm(treatment ~ z) predicted_treatment &lt;- predict(reg_1s) reg_2s &lt;- lm(y ~ predicted_treatment) # Return coefficients tibble( naive_coef = coef(reg_vies)[2], tsls_coef = coef(reg_2s)[2] ) } # Sample sizes to simulate sample_sizes &lt;- seq(1000, 100000, by = 1000) # Use map to apply the function to each sample size results &lt;- tibble(sample_size = sample_sizes) %&gt;% mutate( simulation_results = map(sample_size, simulate_and_fit) ) %&gt;% unnest(cols = c(simulation_results)) results %&gt;% pivot_longer(cols = c(naive_coef, tsls_coef), names_to = &quot;method&quot;, values_to = &quot;coefficient&quot;) %&gt;% ggplot(aes(x = sample_size, y = coefficient, color = method)) + geom_line() + geom_smooth(data = . %&gt;% filter(method == &quot;2sls_coef&quot;), method = &quot;lm&quot;, se = FALSE, color = &quot;red&quot;) + labs( title = &quot;Convergence of Regression Coefficients with Increasing Sample Size&quot;, x = &quot;Sample Size&quot;, y = &quot;Estimated Coefficient&quot;, color = &quot;Method&quot; ) + theme_minimal() + scale_color_manual(values = c(&quot;naive_coef&quot; = &quot;blue&quot;, &quot;tsls_coef&quot; = &quot;red&quot;)) + theme( plot.title = element_text(hjust = 0.5), legend.title = element_blank() ) 6.4 Principais usos de IV 6.4.1 Experimentos Quando pesquisadores utilizam o processo de assignment como instrumento para lidar com problema de non-compliance. Estimativas do Local Average Treatment Effect são críveis. Contraposição a intent-to-treat estimates. 6.4.2 Regras com variação quasi-aleatória Kin (2019) utiliza uma regra na Suécia que obriga cidades com poplução acima de certo nível a adotar democracia direta. Dinas (2014) utiliza idade para votar no momento da eleição como instrumento para comparecimento eleitoral do eleitor. 6.4.3 Teoria Quando a restrição de exclusão é baseada em teoria ou conhecimento substantivo. Aqui estão os instrumentos baseados em geografia ou clima (por exemplo, proximidade a faculdade como instrumento para ensino superior) ou (Zhu, 2017) que usou proximidade geográfica de cinco centros comerciais fora da China (ponderados pelo PIB dos centros comerciais) como instrumento para presença de multinacional (que causaria corrupção). Há o clássico instrumento de chuva como instrumento para, por exemplo, comparecimento eleitoral de eleitores democratas. Mellon (2023) revisou 289 estudos e concluiu que 195 variáveis distintas foram conectadas com chuva, o que significa que podem ser potenciais violações da restrição de exclusão. Cinelli and Hazlett Freidman et. al (2000) usaram origem legal (francesa, inglesa, sueca etc.) como instrumento para qualidade das instituições. Djankov et al. (2003) usaram origem legal como instrumento para grau de formalismo de instituições. Glaeser et al. (2004) usaram origem legal como instrumento para restrições ao executivo (“executive constraints”). Henderson and Brooks, 2016, usam chuva ao redor do dia da eleição como instrumento para votação de candidatos democratas, e concluem que aumento da chuva reduz comparecimento que causa democratas terem comportamento legislativo mais direitoso. ##Efeito heterogêneo Se houver efeito heretogêneo (apenas mulheres mudam comportamento em razão do instrumento, por exemplo), então estamos estimando o efeito apenas para aquele subgrupo (são os compliers com o instrumento). Se o instrumento explicar pouco da variação no Tratamento, então teremos pouca variação no tratamento para explicar a variação em Y. Ou seja, o sinal é fraco. Isso se traduz em baixo poder estatístico. Para discutir efeito casual heterogêneo, vamos utilizar um estudo em ciência política (White, 2019). Qual o efeito de misdemeanor (algo como contravenção penal) sobre comparecimento eleitoral? O aturo argumenta que o efeito deve variar por raça (maior para negros que brancos), de modo que o efeito causla é heterogêneo. Segundo o autor, casos são atribuídos aleatoriamente para diferentes cortes judiciais, e elas variam em sua leniência (ou severidade). Aqui, o tratamento é a condenação (\\(1\\) se condenado, \\(0\\) se não), e temos uma variável instrumental, o sorteio do juiz mais ou menos leniente. Alguns acusados têm tantas evidências que serão condenados não importa para que tipo de corte são enviados. Outros, podem sersempre absolvidos, não importa o juiz. Há os !azarados”, que só serão condenados se enviados para a corte severa. O que não faz sentido é ter alguém que só é condenado se enviado para um juiz leniente e absolvido se enviado para um severo. Nós iremos agrupar esses quatro tipos (incluindo o último) em quatro tipos: Os primeiros são chamado de always-takers. Sempre recebem o tratamento (são presos), não importa o que foi atribuído a eles pelo mecanismo de atribuição. O segundo são os never takers, que nunca recebem o tratamento. Por fim, o terceiro grupo são os compliers, que seguem o tratamernto prescrito e o quarto grupo são os defiers, aqueles que fazem o contrário do prescrito. Nesse caso, não faz muito sentido imaginar que existem os defiers, mas teoricamente é possível. Digmos que o efeito causal do tratamento é heterogêneo, isto é, \\(\\delta_i = Y^1_i - Y^0_i\\). Nesse caso, não podemos mais estimar o efeito causal geral (ATE), pois o efeito causla é heterogêneo e o instrumento só explica a variação no tratamento para os compliers. 6.4.4 Suposições para estimar o LATE Além das suposições que já discutimos, vale sempre lembrar que temos também a SUTVA. Resultados potenciais para unidade \\(i\\) não estão relacionadas ao tratamento que \\(j\\) recebe. Claramente existe potencial para SUTVA ser violada no estudo de encarceramento e voto. Se dois irmãos (indivíduo \\(i\\) e \\(j\\)) são acusados e um deles é preso, é possível que o tratamento de um deles impacte a probabilidade de voto do outro e vice-versa. Salvo engano, White não discute essa possibilidade de violação da suposição, o que é problemático. Mas vamos supor que SUTVA está garantido. Vale lembrar também que Independência é diferetne da restrição de exclusão Também chamada de as good as random assignment e no confounding for the effect of Z on Y. Afirma que a IV é independente dos resultados potenciais e das potenciais atribuições de tratamento. Em termos de nosso DAG, quer dizer que \\(Z\\) não compartilha causa comum com \\(Y\\). Essa suposição parece tranquilamente satisfeita no estudo em questão, já que a atribuição da corte é aleatória e parece difícil imaginar que algo que causa a leniência da corte ser causado por alguma variável que também causa o comparecimento. Aqui o DAG: 6.5 Restrição de Exclusão 6.6 Monoticidade Por fim, precisamos assumir monoticidade. Ela requer que a variável instrumental opera (fracamente) em todas as direções para todos os indivíduos. Ou seja, todo mundo que é afetado pelo instrumento é afetado da mesma maneira. Em outras palavras, o instrumento apenas move as pessoas do controle para o tratamento (ou não move a pessoa), mas nunca o contrário. Ou seja, estamos assumindo que não há defiers na nossa população. Matematicamente e de maneira geral, dizemos que a monoticidade é válida quando \\(T^{Z=1} &gt;= T^{Z=0}\\) para todas as unidades. Com essas suposições, nós estiamos o LATE: Local Average Treatment Effect of T on Y. Isso porque nosso estimador é: \\[\\begin{align} \\mathbb{E}[Y(Z=1) - Y(Z=0)] = \\\\ =&amp; \\mathbb{E}[Y(Z=1) - Y_i(Z=0)|T^1 = 1, T^0 = 1]P(T^1 = 1, T^0 = 1) \\text{ always-takers} \\\\ +&amp; \\mathbb{E}[Y(Z=1) - Y_i(Z=0)|T^1 = 0, T^0 = 0]P(T^1 = 0, T^0 = 0) \\text{ never-takers} \\\\ +&amp; \\mathbb{E}[Y(Z=1) - Y_i(Z=0)|T^1 = 1, T^0 = 0]P(T^1 = 1, T^0 = 0) \\text{ compliers} \\\\ +&amp; \\mathbb{E}[Y(Z=1) - Y_i(Z=0)|T^1 = 0, T^0 = 1]P(T^1 = 0, T^0 = 1) \\text{ defiers} \\end{align}\\] Porém, sabemos que o instrumento não tem efeito causal sobre always-takers nem never-takers, então o efeito causal é zero para esses grupos. E a proporção de defiers é zero, de modo que ficamos apenas com a parte dos compliers. E nesse grupo, \\(Z = T\\), de modo que o efeito do instrumento é o efeito do tratamento. Então podemos reescrever como: \\[\\delta_{IV,LATE} = \\mathbb{E}[Y(1) - Y^0)|T^1 - T^0 = 1]\\] Vejam que o denominador nos dá a proporção da população que mudou seu status por causa do instrumento. 6.7 Estimação (aka estatística F) Considere nosso modelo em que as variáveis estão centradas (sem constante) e não há controle. \\(y_i = \\beta D_i + e_i\\) \\(D_i = \\pi z_i + u_i\\) Posso reescrever a equação de resultado como: \\(y_i = \\beta (\\pi z_i + u_i) + e_i = \\underbrace{\\beta \\pi}_{\\delta} z_i + \\beta u_i + e_i\\) Essa equação é chamada de forma reduzida. Lembrando que nosso estimador \\(\\hat{\\beta}_{2sls} = \\frac{\\hat{\\delta}}{\\hat{\\pi}}\\) Ou seja, o estimador de 2sls é a razão da forma reduzida e o primeiro estágio O que acontece se \\(Cov(D_i, z_i)\\) for muito pequeno? Pequenas variações podem impactar bastante as estimativas. É possível mostrar (supondo homocedasticidade) como o viés do nosso estimaodr em dois estágio se releciona com a estatística F: \\[ \\mathbb{E}[\\hat{\\beta_{2sls}} - \\beta] \\approx \\underbrace{\\frac{Cov(u,e)}{Var(u)}}_{\\text{OVB}} \\frac{k}{F + 1} \\] Se a estatística F é zero, ou seja, o poder do teste é zero, então o viés é igual ao de MQO normal, ou seja, a estimativa com IV é a mesma de OLS/MQO. Quanto maior a estatística F, menor o viés. E por fim, quanto maior o número de instrumentos (isso não está explícito, mas entra na fórmula), maior o viés em amostras finitas. É por essa razão que a literatura se concentrou em uma heurística para a estatística F, que vimos é ser maior que 10. Que basicamente é dizer que será no máximo 10% do viés com 95% de certeza. 6.7.1 F stat A estatística F do primeiro estágio é a parcela explicada no primeiro estágio, relativo ao ruído no primeiro estágio. Quanto maior a estatística F, menor o viés. Se o poder é zero, \\(F = 0\\) e IV é apenas a estimativa de MQO. Ponto chave: quando existem muitos instrumentos, o viés aumenta. This is the approach initially developed by Staiger and Stock (1997) and Stock and Yogo (2005). - Typical rule of thumb: first-stage F-statistic above 10 means that bias won’t be larger than 10% with size of 5%. Very popular! - Suposição chave: homecedasticidade! Montiel Olea and Pfluger( 2013) desenvolveram um teste robusto a heterocedasticidade, com uma estatística F mais apropriada a (allows for clustering, autocorrelation, etc.) - O novo ponto de corte é mais como 23.1 O patoce ivDiag computa essa estatística F. Função eff_F. Alternativa é computar um invervalo de confiança de Anderson-Rubin, que é válido mesmo com instrumento fraco. Novamente, ivDiag computa esse IC. 6.8 Referências Henderson, J., &amp; Brooks, J. (2016). Mediating the electoral connection: The information effects of voter signals on legislative behavior. The Journal of Politics, 78(3), 653-669. Mellon, J. (2023). Rain, Rain, Go Away: 195 Potential Exclusion-Restriction Violations for Studies Using Weather as an Instrumental Variable. Available at SSRN 3715610. White, A. (2019). Misdemeanor disenfranchisement? The demobilizing effects of brief jail spells on potential voters. American Political Science Review, 113(2), 311-324. "],["desenho-de-regresão-discontínua.html", "Capítulo 7 Desenho de Regresão Discontínua 7.1 Outline da aula 7.2 Características-chave da RDD 7.3 Fuzzy RDD 7.4 Suposição de continuidade 7.5 Suposições na RDD 7.6 Testabilidade da Suposição de não-Manipulação 7.7 Estimação em RDD 7.8 Métodos de Estimação 7.9 Trade-off de Viés-Variância 7.10 Regras arbitrárias 7.11 Simulação 7.12 Simulação - Potential Outcomes Y0 7.13 Simulação - Potential Outcomes Y1 7.14 Simulação - Potential Outcomes Y1 e Y0 7.15 Simulação - Y observado 7.16 Quando o RDD funciona? 7.17 Raw Data versus Bin 7.18 Permutation tests (balancing) 7.19 McCray test 7.20 Robustez 7.21 Densidade descontínua - results 7.22 Regressão RDD 7.23 Placebo Tests 7.24 PCRD 7.25 Checlist para um paper 7.26 Referências", " Capítulo 7 Desenho de Regresão Discontínua 7.1 Outline da aula Na aula de hoje, iremos aprender sobre identificação causal do do aspecto mais simples da RD e como funciona Em seguida, estimação e checagem. Falaremos rapidamente de extensões. 7.2 Características-chave da RDD A Regressão Discontínua (RDD) é caracterizada por uma variável contínua \\(X_i\\), que determina quem recebe tratamento, denotado por \\(T_i\\) (1 se tratado). Por convenção, \\(X\\) é chamada de “running variable”, “assignment variable” ou “forcing variable”. 7.2.1 Determinação do Tratamento Em um desenho RDD sharp, uma unidade é tratada se \\(X_i \\geq c\\) e não tratada se \\(X_i &lt; c\\). Assim, \\(T_i\\) é uma função determinística de \\(X_i\\): \\(T_i = f(X_i)\\). A running variable determina completamente quem recebe tratamento. 7.3 Fuzzy RDD Pode acontecer do ponto de corte não determinar quem recebe ou não o tratamento, mas apenas a probabilidade de receber o tratamento. Nesse caso, a regra serve como variável instrumental ao redor do ponto de corte. Ex.: regra de voto determina número de cadeiras. Mas migração partidária altera o número. Então quem fica abaixo do número mínimo em um distrito pode ter cadeiras naquele distrito via migração partidária. 7.3.1 Observação e Corte É essencial observar \\(X\\) e conhecer o ponto de corte ou limiar \\(c\\). Uma das suposições da RDD é que ela requer a continuidade da variável \\(X\\) para identificação, embora, na prática, alguns estudos de RDD tenham usado running variables discretas. A continuidade de \\(X\\) é necessária porque a identificação ocorre no limite. Mas a suposiçao chave é que os resultados potenciais devem ser contínuos ao redor do ponto de corte. Como sempre, essa suposição é intestável, devido ao problema fundamental da inferência causal. Lee (2008), em um artigo clássico, mostrou que uma condição mais restritiva é suficiente para identificação causal: que as unidades podem controlar a running varibale, exceto ao redor do ponto de corte. Isso implica também que as covariáveis de pré-tratamento são contínuas no cutoff. Isso é potencialmente testável, pelo menos nas variáveis observadas e em geral olhando para a média das variáveis, o que não é a mesma coisa que olhar para outros momentos, que podem ser descontínuos. 7.3.2 Estimativa dos Efeitos do Tratamento A comparação de \\(\\lim_{x \\uparrow c} E[Y_i | X_i = x]\\) com \\(\\lim_{x \\downarrow c} E[Y_i | X_i = x]\\) fornece uma estimativa dos efeitos do tratamento (note a direção das setas). Esta comparação é equivalente a: \\(\\lim_{x \\uparrow c} E[Y_i | X_i = x, T_i=0]\\) e \\(\\lim_{x \\downarrow c} E[Y_i | X_i = x, T_i=1]\\), uma vez que, neste exemplo, à direita de \\(c\\) todos recebem tratamento; à esquerda, ninguém recebe. Portanto: \\(\\lim_{x \\uparrow c} E[Y_i | X_i = x] \\approx E[Y_{0i} | X_i = c]\\) \\(\\lim_{x \\downarrow c} E[Y_i | X_i = x] \\approx E[Y_{1i} | X_i = c]\\) Se fôssemos usar regressão linear, o modelo seria: \\(y_i = \\alpha + \\beta_1 (x_i &gt; c) + \\beta_2 x_i + \\beta_3 x (x_i &gt; c) + e_i\\), em que \\(c\\) é o ponto de corte, e \\(x\\) é a running variable. 7.4 Suposição de continuidade A suposição de continuidade é tão crítica que vale discutirmos um pouco mais sobre ela. Se há continuidade, isso significa que, na auência do ponto de corte \\(c\\), x (e outras covariáveis) não devem apresentar descontinuidade. Ex.: Suponha que estamos interessados em estudar o efeito da incumbência sobre a chance de reeleição futura ou riqueza futura desses políticos. Habilidades e carisma são variáveis que devem influenciar tanto a chance de serem incumbentes como os resultados de interesse. Em um RDD, podemos usar close elections para estimar o efeito. E a suposição de continuidade requer que carisma e habilidades não tenham descontinuidade no cut off de 50%. Na verdade, apenas o resultado eleitoral é descontínuo no cut off, que vai de não-eleito para eleito. 7.5 Suposições na RDD 7.5.1 Suposição de Não-manipulação com Precisão A identificação dos efeitos do tratamento na RDD baseia-se na premissa de que \\(X\\) atua como um aleatorizador ao redor de \\(c\\). Imagine que \\(X\\) seja uma variável aleatória uniforme usada para atribuir tratamento. Se \\(X \\geq c\\), uma unidade recebe tratamento. Na RDD, \\(X\\) tem o mesmo papel, exceto que não assumimos que \\(X\\) é independente do resultado \\(Y\\). Na maioria das aplicações, \\(X\\) e \\(Y\\) são correlacionados de alguma forma. 7.5.2 Problemas de Manipulação No entanto, se \\(c\\) não for arbitrário ou tiver uma relação determinística com \\(Y\\), ou se as unidades puderem — com precisão — determinar seus escores \\(X\\) e, assim, escolher receber tratamento ou não, então \\(X\\) ao redor de \\(c\\) não se comporta mais como um aleatorizador — há alguma forma de auto-seleção que poderia depender de variáveis não observáveis. 7.6 Testabilidade da Suposição de não-Manipulação Em parte, isso é testável. As unidades não pareceriam semelhantes perto de \\(c\\) e haveria um “acúmulo” próximo a \\(c\\). No entanto, não podemos descartar a manipulação com precisão apenas com dados — devemos argumentar isso com conhecimento do assunto (é uma restrição de exclusão). 7.7 Estimação em RDD 7.7.1 Problema de Complete Overlapping Um problema chave na estimação em RDD estrita é a completa falta de sobreposição. Em matching, dicustimos como a ausência de sobreposição gerava problemas de extrapolação. Sobreposição requer que \\(0 &lt; P(D_i = 1 | X_i) &lt; 1\\) para o domínio de \\(X_i\\). No domínio da running vairable \\(X_i\\), isso claramente não é satisfeito. Em RDD estrita, temos \\(P(D_i = 1 | X_i &lt; c) = 0\\) e \\(P(D_i = 1 | X_i \\geq c) = 1\\). 7.7.2 Dependência de Extrapolação Devido à falta de sobreposição, dependemos de extrapolação para estimar os efeitos do tratamento. Dito de outra forma, podemos não ser capazes de estimar corretamente os efeitos do tratamento se errarmos a forma funcional \\(Y_i = f(X_i)\\). Novamente, essa foi uma motivação para usar matching. O problema é que nunca sabemos se acertamos, então a especificação do modelo é uma questão chave na estimação RDD. 7.8 Métodos de Estimação O problema sugere a necessidade de um método de estimação não paramétrico. Utilizaremos métodos paramétricos, não paramétricos (ou semiparamétricos) para tentar abordar essas questões. 7.8.1 Identificação no Limite A identificação dos efeitos do tratamento ocorre no limite, à medida que \\(X_i \\rightarrow c\\). Quanto mais usarmos observações distantes de \\(c\\) em \\(X\\), mais dependeremos de extrapolação e das suposições sobre a forma funcional. 7.9 Trade-off de Viés-Variância Mais perto de c: Melhor em termos de precisão, mas pode haver uma amostra insuficiente. Resulta em menos viés, mas mais variância. Mais distante de c: Dependemos menos de extrapolação, mas introduzimos mais viés, mesmo com menor variância. 7.9.1 Métodos de Largura de Banda Ótima A ideia é restringir a estimativa a uma janela ao redor de \\(X_i = c\\), que pode ter tamanhos diferentes à esquerda ou à direita. Estes métodos buscam equilibrar a precisão das estimativas minimizando viés e variância conforme a proximidade do ponto de corte \\(c\\). 7.10 Regras arbitrárias Atribuição de “coisas” a partir de regras com pontos de cortes Bolsa família: a partir de certa renda Educação: aprovação no ensino superior a partir de certa nota de corte Espacial: polítia pública para donos de áreas abaixo ou acima de certas áreas. Data: regras para aposentadoria, idade para entrar na escola, data para perdão de dívida: Desenrola: “…cujas dívidas tenham sido incluídas no cadastro de inadimplentes no período entre 1º de janeiro de 2019 e 31 de dezembro de 2022”. Política: regras de número de vereadores, regras de população para ter segundo turno, regras para ter biometria etc. 7.11 Simulação ## Basic RD Model set.seed(123) N &lt;- 1000 # number of observations X &lt;- runif (N , -5,5) Y0 &lt;- rnorm ( n =N , mean =X , sd=1) # control potential outcome Y1 &lt;- rnorm ( n =N , mean = X+2, sd=1) # treatment potential outcome #You only get treatment if X&gt;0 Treatment &lt;- ( X &gt;= 0) # What we observe Y = Y1* Treatment + Y0*(1- Treatment ) 7.12 Simulação - Potential Outcomes Y0 7.13 Simulação - Potential Outcomes Y1 7.14 Simulação - Potential Outcomes Y1 e Y0 ## Warning: No shared levels found between `names(values)` of the manual scale and the data&#39;s colour values. 7.15 Simulação - Y observado 7.16 Quando o RDD funciona? A suposição chave para o RDD é que tenha descontinuidade ao redor do ponto de corte, e que não haja descontinuidade ao redor do ponto de corte em outra variável omitida. Vamos ver o que isso significa, comparando quator gráficos, três em que a estimativa do RDD é válida, mas com diferentes validades “externas” e uma em que é inválida. ## [1] 3.965471 ## [1] 0.1726892 7.17 Raw Data versus Bin Como escolher os bins? 1. Espaçamentos iguais ou quantis? 2. Quantos bins? No exemplo, escolhi espaçamento igual e 20 bins. Podemos usar quantis. Não faz muita diferença neste exemplo, mas usar quantis é mais transparente e mais crível retoricamente, pois não mascara a densidade. Sobre o número de bins, Cattaneo et. al (2020) discutem o tema e sugerem duas abordagens: 1. IMSE-minimizing (proporcional a \\(n^{1/3}\\)) 2. Mimmicking-variance (proporcional a \\(n/log(n)^2\\)) E usamos o pacote rdplot para implementar isso automaticamente 7.18 Permutation tests (balancing) Para checar balancing, podemos usar testes de permutação. library(RATest) df &lt;- df_u head(df) ## y x treatment y0 y1 u ## 1 -4.9108800 -2.8126930 FALSE -4.9108800 0.24201180 -0.56047565 ## 2 -3.4521053 -3.2945724 FALSE -3.4521053 0.06456756 -0.23017749 ## 3 3.3243805 -5.0368128 FALSE 3.3243805 -10.37746355 1.55870831 ## 4 1.5797551 0.1039258 TRUE -0.4349002 1.57975508 0.07050839 ## 5 0.6339174 -0.1709231 FALSE 0.6339174 2.58972091 0.12928774 ## 6 1.3680416 -0.5215457 FALSE 1.3680416 1.57907203 1.71506499 resultado &lt;- RDperm( W = &quot;u&quot;, # Substitua pelos nomes das suas covariáveis z = &quot;x&quot;, # Substitua pelo nome da sua variável de corte data = df, # Substitua pelo seu data frame cutoff = 0 # Substitua pelo valor do ponto de corte, se diferente de 0 ) summary(resultado) ## ## ********************************************************** ## ** RD Distribution Test using permutations ** ## ********************************************************** ## Running Variable: x ## Cutoff: 0 ## q: Defined by User ## Test Statistic: CvM ## Number of Permutations: 499 ## Number of Obs: 1000 ## ## ********************************************************** ## H0: &#39;Continuity of the baseline covariates at the cutoff&#39; ## ********************************************************** ## ## Estimates: ## T(Sn) Pr(&gt;|z|) q ## u 0.01 0.92 10 ## --- ## Signif. codes: 0.01 &#39;***&#39; 0.05 &#39;**&#39; 0.1 &#39;*&#39; plot(resultado, w=&quot;u&quot;, &quot;cdf&quot;) Canay&amp; Kamat (2018) utiolizaram esse teste pars revisitar o trabalho de Lee (2008) e descobrem que havia problema de balanceamento. Caughey and Sekhon (2011) na political analysis mostraram que de fato havia problemas de balanceamento no estudo de Lee (2008). Do paper da PA: Houve um debate na ciência política sobre isso. Erikson &amp; Rader (2017) e Cuesta &amp; Imai (2016) argumentam que o RDD é identificado. Até onde eu sei, cientistas políticos não revisitaram a controvérsia com os novos metodos desenvolvidos pelos economistas. De todo modo, as evidências de De Magalhães et. al (2025) sugerem que a recomendação que estou adotando no curso de quais práticas usar são as melhores e mais robustas. 7.19 McCray test Um dos principais desafios à identificação causal em RDDs é a possibilidade de manipulação por parte dos agentes sobre ficar acima ou abaixo do ponto de corte. A lógica esperada é que se o tratamento é desejável, indivíduos tentarão receber o tratanto, levando a um gap justamente abaixo do ponte de corte. Se o tratamento é indesejável (efeitos negativos), indivíduos vão evitar o tratamento, levando a um gap justamente acima do ponto de corte. O exemplo mais evidente para nós cientistas políticos é a aprovação de um projeto de lei no legislativo. Nós sabemos que os legisladores agem estrategicamente retirando propostas que não vão ser aprovadas ou postergando a votação, até terem a maioria, ainda que por margem mínima. Nesse caso, a aplicação de RDD nesse caso produirá estimativas viesadas. McCray, em um artigo de 2008, argumentou que tais casos apareceriam como descontinuidade na densidade da running variable ao redor do ponto de corte. Eis o gráfico feito por McCray em seu estudo original: Para formalizar essa ideia, McCray estima os limites da densidade pela esquerda e pela direita e avalia se a diferença (do logaritmo) das estimativas é estatisticamente significante diferente de zero. Portanto, rejeitar a hipótese nula é encontrar evidências de que há manipulação. Cattaneo, Jansson, &amp; Ma 2018; 2020 introduziram uma versão alternativa do teste, com espírito similar. Na prática, de um ponto de vista retórico, o que pesquisadores querem é falhar em rejeitar a nula. Como o teste tem baixo poder de rejeitar a nula, ausência de evidência não quer dizer evidência de ausência. library(rdd) # Simulated data without discontinuity DCdensity(df$x, 0) # No discontinuity ## [1] 0.6885203 Cattaneo Density Test (Improved Version) library(rddensity) # Simulated continuous density rdd &lt;- rddensity(X = df$x, vce = &quot;jackknife&quot;) summary(rdd) ## ## Manipulation testing using local polynomial density estimation. ## ## Number of obs = 1000 ## Model = unrestricted ## Kernel = triangular ## BW method = estimated ## VCE method = jackknife ## ## c = 0 Left of c Right of c ## Number of obs 484 516 ## Eff. Number of obs 136 229 ## Order est. (p) 2 2 ## Order bias (q) 3 3 ## BW est. (h) 1.63 2.095 ## ## Method T P &gt; |T| ## Robust 0.6125 0.5402 ## ## ## P-values of binomial tests (H0: p=0.5). ## ## Window Length &lt;c &gt;=c P&gt;|T| ## 0.174 + 0.174 20 20 1.0000 ## 0.336 + 0.349 34 45 0.2604 ## 0.498 + 0.523 52 60 0.5085 ## 0.659 + 0.697 65 82 0.1868 ## 0.821 + 0.872 81 96 0.2926 ## 0.983 + 1.046 96 116 0.1918 ## 1.145 + 1.220 109 133 0.1391 ## 1.306 + 1.395 122 153 0.0702 ## 1.468 + 1.569 128 173 0.0111 ## 1.630 + 1.743 136 189 0.0039 Essa é uma área ativa de pesquisa, com novos testes sendo desenvolvidos, por exemplo, Fitzgerald (2025), que é um working paper. 7.20 Robustez Mostrar várias estimativas, para várias escolhas de estimações (bandwith etc.) Uma possibilidade é simplesmente apresentar várias estimativas, como faremos abaixo. Ou então, uma tabela. Mas o mais simples seria um gráfico dos efeitos com seus respectivos ICs, em que cada entrada no eixo x é uma estimação, e no y temos o efeito. Abaixo apresento duas dessas possbilidades para ilustrar como a última é a melhor. df1 &lt;- data.frame( estimate = vec_estimate, se = se_estimate, lower = vec_estimate - 2 * se_estimate, upper = vec_estimate + 2 * se_estimate, h = c(&quot;Aut&quot; , &quot;h=1&quot;, &quot;h=.5&quot; , &quot;h=.1&quot;) # ou names(vec_estimate) se o vetor for nomeado ) # 2) Plote com pontos e barras de erro ggplot(df1, aes(x = h, y = estimate)) + geom_point(size = 2) + geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.1) + labs( x = &quot;h&quot;, y = &quot;Estimativa&quot;, title = &quot;Efeitos estimados com IC (±2×SE)&quot; ) + theme_minimal() 7.21 Densidade descontínua - results 7.22 Regressão RDD library(rdrobust) # Assuming the cutoff is at x=0 basic_model &lt;- rdrobust(y = df$y, x = df$x, c = 0) summary(basic_model) ## Sharp RD estimates using local polynomial regression. ## ## Number of Obs. 1000 ## BW type mserd ## Kernel Triangular ## VCE method NN ## ## Number of Obs. 484 516 ## Eff. Number of Obs. 124 152 ## Order est. (p) 1 1 ## Order bias (q) 2 2 ## BW est. (h) 1.375 1.375 ## BW bias (b) 2.375 2.375 ## rho (h/b) 0.579 0.579 ## Unique Obs. 484 516 ## ## ============================================================================= ## Method Coef. Std. Err. z P&gt;|z| [ 95% C.I. ] ## ============================================================================= ## Conventional 2.221 0.305 7.283 0.000 [1.623 , 2.818] ## Robust - - 6.539 0.000 [1.630 , 3.025] ## ============================================================================= 7.23 Placebo Tests Testando descontinuidade em covariáveis predeterminadas: covariáveis que não devem ser afetadas pelo tratamento não devem apresentar salto no ponto de corte. Testando descontinuidades em outros pontos: verificar a existência de descontinuidades em pontos arbitrários ao longo da variável de ordenação. Uso de VDs placebos: se uma variável dependente que não deveria ser afetada pelo tratamento apresentar descontinuidade significativa, isso levanta dúvidas sobre a validade do desenho RD. Avaliação de sensibilidade às covariáveis: as estimativas de RD não devem ser altamente sensíveis à inclusão ou exclusão de covariáveis. 7.24 PCRD Marhsall (2024) na AJPS introduz a nomenclatura do desenho de pesquisa Politician characteristic regression discontinuity (PCRD). Basicamente, o argumento é que RDD não permite identificar efeito de características de políticos (como gênero, profissão, raça, ideologia, alinhamento com govenro federal etc.) “In contrast, the treatment in PCRD designs — which instead seek to estimate the LATE of an elected politician characteristic — is defined by possessing (or not) predetermined characteristic X, conditional on narrowly winning an election. (…) restricting attention to close elections entails conditioning on candidate vote shares that may be affected by X. (…) [It] generally introduce bias — even when X is independent of other predetermined variables and the weak continuity assumption underpinning standard RD designs holds.” (p. 495) Basicamente, Marshall está dizendo que nesses casos, close election é um collider, e isso abre as portas para viéses de variáveis que causem \\(y\\) e se a eleição é apertada. 7.25 Checlist para um paper Teste de balancemaneto de variáveis de pré-tratamento (não impactadas pelo tratamento) Teste de permutação no cuttoff (outra forma de olhar balanceamento) Densidade da running variable (teste de McCrary) Testes de placebo (cutoffs arbitrários. Estimativa não muda) Gráfico com a descontinuidade Estimativas baseadas em bandwith ótimos, e local linear regression Análise de robustez junto com a escolha do bandwith (apresente graficamente) Ordem preferida: primeiro estabelecer a validade da estratégia, depois detalhes da estimação. 7.26 Referências Canay, I. A., &amp; Kamat, V. (2018). Approximate permutation tests and induced order statistics in the regression discontinuity design. The Review of Economic Studies, 85(3), 1577-1608. Cattaneo, M. D., Idrobo, N., &amp; Titiunik, R. (2024). A practical introduction to regression discontinuity designs: Extensions. Cambridge University Press. Cattaneo, M. D., Idrobo, N., &amp; Titiunik, R. (2019). A Practical Introduction to Regression Discontinuity Designs: Foundations. Elements in Quantitative and Computational Methods for the Social Sciences. Cattaneo, M. D., &amp; Titiunik, R. (2022). Regression discontinuity designs. Annual Review of Economics, 14(1), 821-851. De Magalhães, L., Hangartner, D., Hirvonen, S., Meriläinen, J., Ruiz, N. A., &amp; Tukiainen, J. (2025). When Can We Trust Regression Discontinuity Design Estimates from Close Elections? Evidence from Experimental Benchmarks. Political Analysis, 1-8. Fitzgerald, J. (2025). Manipulation Tests in Regression Discontinuity Design: The Need for Equivalence Testing. Gelman, A., &amp; Imbens, G. (2019). Why high-order polynomials should not be used in regression discontinuity designs. Journal of Business &amp; Economic Statistics, 37(3), 447-456. Marshall, J. (2024). Can close election regression discontinuity designs identify effects of winning politician characteristics?. American Journal of Political Science, 68(2), 494-510. Erikson, R. S., &amp; Rader, K. (2017). Much ado about nothing: rdd and the incumbency advantage. Political Analysis, 25(2), 269-275. De la Cuesta, B., &amp; Imai, K. (2016). Misunderstandings about the regression discontinuity design in the study of close elections. Annual Review of Political Science, 19(1), 375-396. Marshall, J. (2024). Can close election regression discontinuity designs identify effects of winning politician characteristics?. American Journal of Political Science, 68(2), 494-510. Tutorial: https://congressdata.joshuamccrain.com/regression_discontinuity.html "],["diferença-em-diferenças.html", "Capítulo 8 Diferença em Diferenças 8.1 Modelo básico 2x2 8.2 TWFE 8.3 Pressupostos 8.4 Aplicação 8.5 Múltiplos períodos 8.6 Tendências Paralelas 8.7 Múltiplos períodos pós-tratamento 8.8 Análise de sensibilidade em DiD 8.9 DiD generalizado 8.10 DID com adoção escalonada (staggered timing) 8.11 Paper Voter Gratitude Last Long? 8.12 Referências", " Capítulo 8 Diferença em Diferenças 8.1 Modelo básico 2x2 Vamos considerar primeiro um cenário de dois grupos \\(G \\in \\{1,2\\}\\) e dois períodos de tempo \\(T \\in \\{1,2\\}\\). A notação de resultados potenciais é: \\(Y_{gt}(0,0)\\) é o resultado potencial da unidade \\(g\\) no período \\(t\\) se não for tratada nos dois períodos. \\(Y_{gt}(0,1)\\) é o resultado potencial da unidade \\(g\\) no período \\(t\\) se for tratada no segundo período. Usualmente nós simplificamos a notação com dois períodos para \\(Y_{gt}(0)\\) e \\(Y_{gt}(1)\\). A vantagem da notação mais complexa é para manter a ideia de que o path (caminho) pode vir a ser relevante. Supondo, como usual, que temos um tratamento binário \\(D\\), e que ele é ativado (implementado) apenas no período \\(2\\) para um dos grupos, temos a seguinte tabela para descrever como usualmente se pensa as relações causais. \\(t = 0\\) \\(t = 1\\) \\(D = 0\\) \\(\\gamma_0 + \\alpha_i\\) \\(\\gamma_1 + \\alpha_i\\) \\(D = 1\\) \\(\\gamma_0 + \\alpha_i + \\tau_i\\) \\(\\gamma_1 + \\alpha_i + \\tau_i\\) A diferença para cada grupo \\(g\\) é: \\[ y_{g1} - y_{g0} = (\\lambda_1 - \\lambda_0) + \\tau_i(D_i1 - D_i0) \\] Como pode haver mudança nos resultados apenas pela passagem do tempo, o efeito causal é não-identificado. Contudo, veja que: \\[ \\mathbb{E}[y_{g1} - y_{g0}|D_{i1} - D_{i0} = 1] - \\mathbb{E}[y_{g1} - y_{g0}|D_{i1} - D_{i0} = 0] = \\mathbb{E}[\\tau_i(D_{i1} - D_{i0})|D_{i1} - D_{i0} = 1] \\] Unpacking: \\(\\mathbb{E}[y_{g1} - y_{g0}|D_i1 - D_{i0} = 1] = (\\lambda_1 - \\lambda_0) + \\mathbb{E}[\\tau_i|(D_{i1} - D_{i0})=1]\\) e \\(\\mathbb{E}[y_{g1} - y_{g0}|D_i1 - D_{i0} = 0] = (\\lambda_1 - \\lambda_0)\\), então a diferença é \\((\\lambda_1 - \\lambda_0) + \\tau_i - (\\lambda_1 - \\lambda_0) = \\mathbb{E}[\\tau_i|D_{i1}=1]\\). 8.2 TWFE É possível estimar um modelo de DiD com regressão. \\[ y_{gt} = \\alpha + \\beta_1 Post_t + \\beta_2 Treat_g + \\tau (Post_t \\times Treat_g) + e_{gt} \\] Outras parametrização é: \\[ y_{gt} = \\alpha_g + \\lambda_t + \\tau D_{it} + e_{gt} \\] A segunda parametrização é chamada de “two-way fixed effects”, pois usamos um efeito fixo de unidade e um de tempo. 8.3 Pressupostos Os pressupostos de identificação de DiD são: Tendências Paralelas.”Na ausência de tratamento, a média dos resultados potenciais teriam evoluído em paralelo”. \\(\\mathbb{E}[Y_{g2}(0) - Y_{g1}(0)|D_g=1] = \\mathbb{E}[Y_{g2}(0) - Y_{g1}(0)|D_g=0]\\) Suposição paramétrica das PT: \\(Y_{gt}(0) = \\alpha_g + \\lambda_t + e_{it}\\) Isso é na verdade um resultado: é possível mostrar que supor este modelo implica PT. Não-antecipação: tratamento não possui efeito no período anterior. \\(\\mathbb{E}[Y_{g1}(0)] = \\mathbb{E}[Y_{g1}(1)]\\) 8.4 Aplicação Vamos ver um exemplo no R, a partir de um estudo meu. Os dados são de um projeto da Transparência Brasil, chamado de Obra Transparente. O projeto consistiu em uma intervenção em 20 cidades do Sudeste, em que treinamento e informações foram dados a ongs locais para monitoramento de obras de creches e escolas. O projeto começou em maio de 2017 e terminou em junho de 2019. Os dados trazem informações sobre as obras nas cidades do projeto e nas demais cidades onde havia obras similares nos mesmos estados. library(here, quietly=TRUE) library(knitr) data_ot &lt;- readRDS(here(&quot;Dados&quot;, &quot;obra_transparente.RDS&quot;)) head(data_ot) %&gt;% kable() id municipio concluida group_treated periodo time_treated1 post_treat 1366 Conchas 1 0 1 0 0 1367 Itararé 1 0 1 0 0 1391 Brotas 1 0 1 0 0 1392 Buritizal 1 0 1 0 0 1393 Caconde 1 0 1 0 0 1400 Porteirinha 1 0 1 0 0 Como o gráfico abaixo mostra, o grupo controle possui percentual mais elevado de obras concluídas em comparação ao grupo de tratamento, mesmo antes do projeto ter se iniciado. Olhando para outras covariáveis (não mostradas aqui), de fato os dois grupos eram bastante desbalanceados. Porém, apesar da diferença de nível, as mudanças (evolução temposal) são similares. Isso sugere um dif in dif como uma metodologia adequada para estimar o efeito causal. A partir do período 4 o tratamento já poderia fazer efeito, mas ele é muito pequeno (leve mudança na inclinação) e o efeito é relevante apenas após o período 5. Temos portando efeitos dinâmicos.Vamos inicialmente ajustar um modelo estático, considerando apenas o período 1 e 5. library(estimatr) library(modelsummary) library(fixest) data_ot_reg &lt;- data_ot %&gt;% filter(periodo %in% c(1,5)) %&gt;% mutate(post = ifelse(periodo == 5, 1, 0)) did &lt;- lm_robust(concluida ~ post + group_treated + post*group_treated, data=data_ot_reg, clusters = municipio) msummary(did, stars = c(&#39;*&#39; = .1, &#39;**&#39; = .05, &#39;***&#39; = .01)) /* tinytable css entries after */ .table td.tinytable_css_83y0azwaq1kosw772g9g, .table th.tinytable_css_83y0azwaq1kosw772g9g { text-align: center; border-bottom: solid #d3d8dc 0.1em; } .table td.tinytable_css_sn4wt5ll3o1wjtnt3dxi, .table th.tinytable_css_sn4wt5ll3o1wjtnt3dxi { text-align: center; border-bottom: solid black 0.05em; } .table td.tinytable_css_shsz39eaqgv3b76e8r8j, .table th.tinytable_css_shsz39eaqgv3b76e8r8j { text-align: center; } .table td.tinytable_css_y7cl39wqj5ihl6uljuee, .table th.tinytable_css_y7cl39wqj5ihl6uljuee { text-align: center; border-top: solid #d3d8dc 0.1em; border-bottom: solid #d3d8dc 0.05em; } .table td.tinytable_css_sjztzirheanz7xcfycup, .table th.tinytable_css_sjztzirheanz7xcfycup { text-align: left; border-bottom: solid #d3d8dc 0.1em; } .table td.tinytable_css_6hbkq0v7927dzdnq8b9d, .table th.tinytable_css_6hbkq0v7927dzdnq8b9d { text-align: left; border-bottom: solid black 0.05em; } .table td.tinytable_css_88tt0mwaj59p76ewsjxe, .table th.tinytable_css_88tt0mwaj59p76ewsjxe { text-align: left; } .table td.tinytable_css_9yc4qux24a3bl91gv7ck, .table th.tinytable_css_9yc4qux24a3bl91gv7ck { text-align: left; border-top: solid #d3d8dc 0.1em; border-bottom: solid #d3d8dc 0.05em; } (1) * p (Intercept) 0.382*** (0.014) post 0.481*** (0.010) group_treated -0.224*** (0.057) post × group_treated 0.155** (0.062) Num.Obs. 9020 R2 0.258 R2 Adj. 0.258 AIC 9911.2 BIC 9946.8 RMSE 0.42 Std.Errors by: municipio did_alt &lt;- feols(concluida ~ post_treat| municipio + periodo, cluster = &quot;municipio&quot;, data = data_ot_reg) summary(did_alt) ## OLS estimation, Dep. Var.: concluida ## Observations: 9,020 ## Fixed-effects: municipio: 2,020, periodo: 2 ## Standard-errors: Clustered (municipio) ## Estimate Std. Error t value Pr(&gt;|t|) ## post_treat 0.15401 0.059179 2.60247 0.0093232 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## RMSE: 0.338161 Adj. R2: 0.376909 ## Within R2: 0.002425 8.5 Múltiplos períodos O que acontece se tivermos múltiplos períodos, isto é, \\(t&gt;2\\)? Múltiplos períodos antes do tratamento ser implementado Múltiplos períodos após o tratamento ser implementado. Precisamos escolher um período de comparação, \\(t_0\\). Nos últimos 10 anos, uma grande problematização e desenvolvimento de testes ,estimadores e entendimento do que é DiD com múltiplos períodos. Impossível cobrir tudo em uma única aula. Recomendo as vídeo-aulas do grupo de estudo em DiD. 8.6 Tendências Paralelas A suposição de tendências paralelas significa que \\(\\mathbb{E}[[Y_{i,t}(0) − Y_{g,t−1}(0)]\\) não varia entre grupos \\(g\\). Essa suposição implica que os nunca-tratados seguem um modelo de efeitos fixos duplo (Two-way fixed effects ou TWFE): \\[ \\mathbb{E}[Y_{g,t}(0)] = \\alpha_i + \\lambda_t \\] Uma outra forma de escrever essa suposição é: \\[ Y_{g,t}(0) = \\alpha_i + \\lambda_t + e_{it} \\text{, com } \\mathbb{E}[e_{it}] = 0 \\] Demonstrar equivalência é demonstrar que um implica o outro. Vamos começar mostrando que TWFE implica PT. Supondo que TWFE é verdade, então \\(\\mathbb{E}[[Y_{i,t}(0) − Y_{g,t−1}(0)] = \\alpha_i + \\lambda_t - (\\alpha_i + \\lambda_{t-1}) = \\lambda_t - \\lambda_{t-1})\\), para todo \\(g\\). Como a diferença no tempo \\(\\lambda_t - \\lambda_{t-1})\\) não depende de \\(g\\), então a PT é satisfeita. Vamos agora mostrar a otra implicação. Sem perda de generalidade, defina \\(\\lambda_1 = 0\\), isto é, o efeito do período 1 é 0. Poderia ser qualquer outro valor, mas zero vai facilitar. E vamos definir \\(\\alpha_g = \\mathbb{E}[Y_{g,1}0]\\), ou seja, Se as tendências não forem exatamente paralelas, Rambachan e Roth (2023) desenvolveram uma forma de impor restrições sobre quão diferentes as tendências podem não ser paralelas pós-tratamento em comparação com o período pré-tratamento. O pacote no R honestDiD permite implementar isso. Assim conseguimos obter identificação parcial (intervalo para as estimativas), em vez de estimação pontual. O parâmetro M controla quanto o desvio é maior em relação ao observado no pré-teste. Se M é igual a 1, temos o mesmo desvio no máximo. Se M igual a 2, duas vezes maior e assim por diante. library(HonestDiD) library(tidyverse) library(knitr) library(fixest) # Install remotes package if not installed #install.packages(&quot;remotes&quot;) # Turn off warning-error-conversion, because the tiniest warning stops installation #Sys.setenv(&quot;R_REMOTES_NO_ERRORS_FROM_WARNINGS&quot; = &quot;true&quot;) # install from github #remotes::install_github(&quot;asheshrambachan/HonestDiD&quot;) # Run model # twfe_results &lt;- feols(rating ~ i(goodr, qa) | year_month + asin, # cluster = c(&quot;asin&quot;), # data = GoodAma) # # fixest::iplot(twfe_results) # # # Save coefficients # betahat &lt;- summary(model_4)$coefficients # # # Save the covariance matrix # sigma &lt;- summary(model_4)$cov.scaled # # ## Identificação Parcial # # delta_rm_results &lt;- createSensitivityResults_relativeMagnitudes( # betahat = betahat, #coefficients # sigma = sigma, #covariance matrix # numPrePeriods = 1, #num. of pre-treatment coefs # numPostPeriods = 1, #num. of post-treatment coefs # Mbarvec = seq(0.5,2,by=0.5) #values of Mbar # ) # # delta_rm_results %&gt;% # kable() 8.7 Múltiplos períodos pós-tratamento Provavelmente, \\(\\tau\\) não é constante no tempo e entre unidades. Efeito do tratamento pode depender de quando começou. Pode depender da duração. Precisamos de um modelo mais sofisticado de regressão. O modelo que fizemos estima uma média dos efeitos. É preciso ter cuidado, pois se a amostra não for completa (não-balanceada), pode gerar problemas. A primeira extensão do modelo é considerar um did dinâmico. Como fazemos isso? \\[ Y_{g,t} = \\alpha_i + \\lambda_t + \\sum_{t=1, t \\neq t_0}^T \\delta_t D_{gt} + e_{gt} \\] Essa equação toma como referência o período \\(t_0\\), em que o tratamento foi implementado (para todas as unidades tratadas) ao mesmo tempo. Um dos coeficientes é não identificado por causa do \\(\\alpha_i\\), por isso precisamos excluir um período como categoria de referência. E todos os coeficientes medem o efeito relativo ao período \\(t_0\\) de referência. Suposição de PT foi mais forte no modelo acima: \\(Y_{g,t}(d) - Y_{g,t-k}(d) = \\lambda_t - \\lambda_{t-k}\\) para todos os \\(k\\) e \\(d\\). Podemos testar pré-tratamento. 8.8 Análise de sensibilidade em DiD \\[ y_{gt} = \\alpha_g + \\lambda_t + \\tau_{gt}D_{it} + e_{gt} \\] Podemos pensar que o \\(\\tau\\) é a média dos \\(\\tau_{gt}\\). Veja que se nós pudéssemos reescrever a equação de regressão como \\(y_{gt} -\\alpha_g - \\lambda_t = \\tau_{gt}D_{it} + e_{gt}\\), bastaria rodar um modelo de OLS tradicional e estimar essa média. Nossa vd seria \\(y_{gt} -\\alpha_g - \\lambda_t\\) e o tratamento uma variável binária indicando se o tratamento ocorreu. Acontece que não sabemos os efeitos fixos. E se nós estimarmos eles? Utilizando o torema FWL, temos: Primeiro, extraio os resíduos de uma regressão apenas com os efeitos fixos: \\[ y_{gt} = \\alpha_g + \\lambda_t + \\text{resíduos}_Y \\] Se chamar os resíduos de \\(\\tilde{y}_{gt}\\), tenho tudo de \\(y_{gt}\\) que não é explicado pelos efeitos fixos. E posso reescrever: \\(y_{gt} = \\alpha_g + \\lambda_t + \\text{resíduos}_Y\\) como \\(\\tilde{y}_{gt} = y_{gt} -\\alpha_g - \\lambda_t\\). Em seguida, residualizo o tratamento: \\[ D_{gt} = \\alpha_g + \\lambda_t + \\text{resíduos}_D \\] Novamente, vou chamar os resíduos de \\(\\tilde{D}_{gt}\\) Então, posso rodar uma regressão \\(\\tilde{y}_{gt} = \\tilde{D}_{gt} + e_{gt}\\). Ou ainda: \\[ y_{gt} - \\tilde{\\alpha}_g - \\tilde{\\lambda}_t = \\tau_{gt}\\tilde{D}_{it} + e_{gt} \\] Essa regressão estima \\(\\hat{\\tau} = \\sum w_{gt}\\tau_{gt} \\neq \\tau\\). Esses pesos podem até mesm oser negartivos e a estimativa \\(\\hat{\\tau}\\) ter sinal oposto a \\(\\tau\\). A intuição é porque estamos comparando bananas com laranjas. Há grupos que são tratados em momentos distintos, e dependendo do tamanho dos efeitos em cada momento do tempo, a média ponderada dessas comparações dá algo estranho. A solução proposta do Gardner de regressão DiD em dois estágios é justamente evitar esse problema rodando \\(y_{gt} - \\tilde{\\alpha}_g - \\tilde{\\lambda}_t = \\tau_{gt}D_{it} + e_{gt}\\). Estágio 1: Estime os efeitos fixos usando observações não tratadas ou ainda não tratadas. Estágio 2. Rode a regressão \\(y_{gt} - \\tilde{\\alpha}_g - \\tilde{\\lambda}_t = \\tau_{gt}D_{it} + e_{gt}\\). Obviamente, o cálculo do erro padrão se torna mais complexo nesse caso, pois há ruído extra introduzido na nova VD. Felizmente, o pacote {did2s} faz tudo isso pra gente. Se você olhar os papers mais recentes publicados nos top journals, eles estão usando esse tipo de estimador. 8.9 DiD generalizado Nós permitimos que cada unidade, por exemplo, tenha sua própria tendência. Ou que o resultado potencial do controle (não-tratado) dependa de covariáveis que variam no tempo, ou seja, a tendência paralela é condicional às covariáveis. A única coisa não permitida é interação entre efeitos fixos de unidade e tempo. did_din = feols(concluida ~ i(periodo, group_treated, ref=3) | id + periodo, data_ot) summary(did_din) ## OLS estimation, Dep. Var.: concluida ## Observations: 22,609 ## Fixed-effects: id: 4,530, periodo: 5 ## Standard-errors: Clustered (id) ## Estimate Std. Error t value Pr(&gt;|t|) ## periodo::1:group_treated -0.009828 0.028085 -0.349923 7.2641e-01 ## periodo::2:group_treated -0.004025 0.018226 -0.220847 8.2522e-01 ## periodo::4:group_treated 0.022207 0.015355 1.446207 1.4819e-01 ## periodo::5:group_treated 0.143744 0.033830 4.249033 2.1901e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## RMSE: 0.247446 Adj. R2: 0.685451 ## Within R2: 0.002541 8.10 DID com adoção escalonada (staggered timing) No meu exemplo, tratamento foi o mesmo para todas as unidades ao mesmo tempo. Mas é comum que não aconteça assim. Qual é o estimando quando tenho adoção escalonada no tempo? Com quem estou comparando? Digamos que quero ver o efeito da biometria sobre comparecimento eleitoral. Como ela foi escalonada no tempo, podemos adotar um modelo de DiD. Nesse caso, uma vez implementado (turned on), não volta atrás (turn off). Porém, há casos em que a política pode ser ativada ou desativada. Exemplo: política de uso de câmeras corporais pela política. Tarcísio desativou por um tempo (STF impediu). Isso cria complicações para definir o grupo de controle adequado. 8.11 Paper Voter Gratitude Last Long? library(haven) elbe1994_98 &lt;- read_dta(here(&quot;Dados&quot;, &quot;Elbe&quot;, &quot;1994_1998.dta&quot;)) elbe0 &lt;- elbe1994_98 %&gt;% dplyr::select(wkr, wkrname, year, spd_z_vs, Flooded) elbe1998_02 &lt;- read_dta(here(&quot;data&quot;, &quot;Elbe&quot;, &quot;1998_2002.dta&quot;)) elbe1 &lt;- elbe1998_02 %&gt;% dplyr::select(wkr, wkrname, year, spd_z_vs, Flooded) %&gt;% dplyr::filter(year == 2002) elbe1998_05 &lt;- read_dta(here(&quot;data&quot;, &quot;Elbe&quot;, &quot;1998_2005.dta&quot;)) elbe2 &lt;- elbe1998_05 %&gt;% dplyr::filter(year == 2005) %&gt;% dplyr::select(wkr, wkrname, year, spd_z_vs, Flooded) elbe &lt;- bind_rows(elbe0, elbe1, elbe2) did_short &lt;- feols(spd_z_vs ~ Flooded| wkr + year, cluster = &quot;wkr&quot;, data = elbe1998_02) summary(did_short) ## OLS estimation, Dep. Var.: spd_z_vs ## Observations: 598 ## Fixed-effects: wkr: 299, year: 2 ## Standard-errors: Clustered (wkr) ## Estimate Std. Error t value Pr(&gt;|t|) ## Flooded 7.14401 0.468184 15.259 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## RMSE: 1.80615 Adj. R2: 0.905029 ## Within R2: 0.255154 did_din = feols(spd_z_vs ~ i(year, Flooded, ref=1998) | wkr + year, elbe) summary(did_din) ## OLS estimation, Dep. Var.: spd_z_vs ## Observations: 1,254 ## Fixed-effects: wkr: 328, year: 4 ## Standard-errors: Clustered (wkr) ## Estimate Std. Error t value Pr(&gt;|t|) ## year::2002:Flooded 0.458643 1.52364 0.301018 0.7635917 ## year::2005:Flooded -4.806790 1.34447 -3.575220 0.0004027 *** ## ... 1 variable was removed because of collinearity (year::1994:Flooded) ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## RMSE: 4.71647 Adj. R2: 0.591674 ## Within R2: 0.017113 Sys.setenv(RGL_USE_NULL = TRUE) library(DIDmultiplegtDYN) elbe_het &lt;- elbe %&gt;% rename(Y = spd_z_vs, G = wkr, D = Flooded, T = year) did_het &lt;- did_multiplegt_dyn( df = elbe, outcome = &quot;spd_z_vs&quot;, group = &quot;wkr&quot;, time = &quot;year&quot;, treatment = &quot;Flooded&quot;, effects = 2, placebo = 2, cluster = &quot;wkr&quot; ) summary(did_het) ## ## ---------------------------------------------------------------------- ## Estimation of treatment effects: Event-study effects ## ---------------------------------------------------------------------- ## Estimate SE LB CI UB CI N Switchers ## Effect_1 0.20036 0.69213 -1.15620 1.55692 874 65 ## Effect_2 -3.75276 1.14577 -5.99843 -1.50709 557 40 ## ## Test of joint nullity of the effects : p-value = 0.0000 ## ---------------------------------------------------------------------- ## Average cumulative (total) effect per treatment unit ## ---------------------------------------------------------------------- ## Estimate SE LB CI UB CI N Switchers ## -1.47405 0.95447 -3.34478 0.39667 914 105 ## Average number of time periods over which a treatment effect is accumulated: 1.6882 ## ## ---------------------------------------------------------------------- ## Testing the parallel trends and no anticipation assumptions ## ---------------------------------------------------------------------- ## Estimate SE LB CI UB CI N Switchers ## 0.37683 0.40786 -0.42256 1.17622 546 29 ## ## ## ## ## The development of this package was funded by the European Union. ## ERC REALLYCREDIBLE - GA N. 101043899 did_short &lt;- feols(spd_z_vs ~ Flooded| wkr + year, cluster = &quot;wkr&quot;, data = elbe1998_02) summary(did_short) ## OLS estimation, Dep. Var.: spd_z_vs ## Observations: 598 ## Fixed-effects: wkr: 299, year: 2 ## Standard-errors: Clustered (wkr) ## Estimate Std. Error t value Pr(&gt;|t|) ## Flooded 7.14401 0.468184 15.259 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## RMSE: 1.80615 Adj. R2: 0.905029 ## Within R2: 0.255154 did_din = feols(spd_z_vs ~ i(year, Flooded, ref=1998) | wkr + year, elbe) summary(did_din) ## OLS estimation, Dep. Var.: spd_z_vs ## Observations: 1,254 ## Fixed-effects: wkr: 328, year: 4 ## Standard-errors: Clustered (wkr) ## Estimate Std. Error t value Pr(&gt;|t|) ## year::2002:Flooded 0.458643 1.52364 0.301018 0.7635917 ## year::2005:Flooded -4.806790 1.34447 -3.575220 0.0004027 *** ## ... 1 variable was removed because of collinearity (year::1994:Flooded) ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## RMSE: 4.71647 Adj. R2: 0.591674 ## Within R2: 0.017113 8.12 Referências de Chaisemartin, C., &amp; D’Haultfœuille, X. (2023). Credible answers to hard questions: Differences-in-differences for natural experiments. Available at SSRN. Rambachan, A., &amp; Roth, J. (2023). A more credible approach to parallel trends. Review of Economic Studies, 90(5), 2555-2591. "],["time-series-cross-section-tscs.html", "Capítulo 9 Time-Series Cross-Section (TSCS) 9.1 Introdução 9.2 OVB 9.3 Estimandos 9.4 Resultados Potenciais 9.5 Modelo AR(1) 9.6 Sequential ignorability 9.7 Resumo 9.8 Suposições para Inferência 9.9 Efeitos aleatórios 9.10 Referências", " Capítulo 9 Time-Series Cross-Section (TSCS) 9.1 Introdução Dados de Painel são definidos como consistindo de observações repetidas de uma mesma unidade \\(i = 1, \\cdot, N\\) no período \\(t = 1, \\cdot, T\\). O termo dados de painel tem origem em surveys em ondas, em que o mesmo indivíduo era rastreado ao longo do tempo. Em ciência política também chamamos esse tipo de dado de Time-Series Cross-Section, TSCS abreviado. É basicamernte a mesma coisa. A distinção foi introduzida na literatura de ciência política portque tipicamente surveys em ondas possuem \\(T\\) pequeno, enquanto dados de TSCE (país, estados municípios) típicos da política comparada e Relaçòes Internacionais possuem \\(T\\) “grande”, eventualmente maior do que \\(N\\) (exemplo, países da OCDE ao longo de 50 anos, estados brasileiros ao longo de 30 anos etc.). Uma observação de uma Vd e uma VI é dada pelo par \\((y_{it}, x_{it})\\), em que \\(i\\) indexa a unidade e \\(t\\) o tempo. Tradicionalmente a literatura categorizava os dados de painel em balanceados (mesmo período de tempo para todas as unidades) e não-balanceado (períodos de tempo diferentes para as unidades). Essa terminologia confunde com nossa ideia de balanceamento em matching, de forma que mais recentemente tem sido substituída por dados completos (todas as unidades são observadas pelo mesmo período \\(T\\)) ou incompletos (algumas observações são ausentes para alguns períodos de algumas unidades). Em TSCS, podemos ter países que deixam de existir (URSS, Yugoslávia) ou serem criados (Sérvia, Montenegro). Isso vale também para estados e municípios. Não é muito claro que pensar como dados ausente faz sentido, pois não é que não foram observados (como em um survey), mas a entidade nem existe mais (ou passou a existir apenas após um tempo). Isso cria potencialmente alguns tipos de problemas que a literatura metodológica basicamente tem ignorado. Em meu doutorado, eu estudei o efeito de regimes políticos sobre a adesão a tratados de patentes. Porém, não é muito claro se a adesão da URSS em um período \\(t^{\\star}\\) deve ser atribuída à Rússia em (\\(t &gt; t^{\\star}\\)). E no caso da Yuguslávia? Ou Sérvia e Montenegro, que posteriormente se dividiram? As consequências dessas decisões é uma questão tanto substantiva quanto metodológica. Mas, até onde sei, pouco ou nada investigada. Os dados podem ser organizados no banco de dados em dois formatos: long e wide. O formato long, que é o padrão, organizada os dados com a coluna de unidade repetindo nas linhas tantas vezes quanto observações no tempo existirem. Já o formato wide apresenta cada unidade aparecendo em uma única linha. long vs wide format. Fonte: https://tavareshugo.github.io/r-intro-tidyverse-gapminder/09-reshaping/index.html 9.1.1 Within versus Between Uma distinção importante quando se trata de dados de painel é entre variação within subject e between subject. Para entender essa discintção, contrastemos dois estudos hipotéticos. Em um estudo “within subject”, cada indivíduo é exposto às múltiplas versões do tratamento (ex. trataamento e controle) e analisamos como os indivíduos mudaram entre exposições às variações do tratamento. Em um desenho “between-subject”, aleatorizamos o tratamento e controle em dois grupos de indivíduos, os tratados e não-tratados e comparamos a diferença na variável resposta dos dois grupos. Em dados de painel, a questão retorna, pois observamos as mesmas unidades repetidamente no tempo. Isso quer dizer que podemos, potencialmente, fazer comparações entre unidades (“between) e intra-unidades (within). Imagine que tenho uma variável \\(y_{it}\\) medida para \\(N\\) indivíduos em \\(T\\) períodos, por exemplo, intenção de voto no candidato democrata. Posso então fazer os seguintes cálculos: média individual: \\(\\bar{x}_i = \\frac{1}{T}\\sum_{t=1}^T x_{it}\\). Ou seja, média de intenção de votos de cada indivíduo nos \\(T\\) períodos. média temporal: \\(\\bar{x}_t = \\frac{1}{N}\\sum_{i=1}^N x_{it}\\). Ou seja, a média de intencão de voto de cada período de tempo. Média geral: \\(\\bar{x} = \\frac{1}{NT}\\sum_{i=1}^N\\sum_{t=1}^T x_{it}\\) Podemos então definir a variação between: \\(B = \\sum_{i=1}^N n_i(\\bar{x}_i - \\bar{x})^2\\). Se o painel é completo, a fórmula simplifica para: \\(B = n\\sum_{i=1}^N(\\bar{x}_i - \\bar{x})^2\\). Veja que essa fórmula mede quanto de variação temos nos dados que se deve à variação entre unidades. Para definir a variação within, temos: Para um dado indivíduo \\(i\\), a variabilidade das suas observações ao longo do tempo, em relação à sua média \\(\\bar{x}_i\\), é dado por \\(\\sum_t (x_{it} - \\bar{x}i)^2\\). Se quisermos medir a soma total da variação within, podemos então definir: \\(W = \\sum_{i=1}^N \\sum_{t=1}^{n_i}(x_{it} - \\bar{x}_i)^2\\). A variação total, ou seja, a soma da variação em torno da média geral, é dada por: \\(\\sum_{i=1}^N\\sum_{i=1}^{n_i} (x_{it} - \\bar{x})^2 = W + B\\) 9.2 OVB Suponha o DAG abaixo, em que \\(a\\), uma variável invariante no tempo é não observada: library(ggdag) dag &lt;- dagify( y ~ x + a, x ~ a, latent = &quot;a&quot; ) ggdag(dag) Ela leva ao clássico problema de variável omitida. Dados de painel nos permite remover essa variável de confusão. Há várias formas de mostrar isso, e vou optar pela abordagem de centrar as variáveis. Suponha uma forma paramétrica do modelo estrutural dado por: \\(y_{it} = \\alpha + \\beta_0 x_{it} + a_i + e_{it}\\). Suponha, para simplificar, que o painel é completo. Agora, considerem os seguintes passos: \\[\\begin{aligned} \\bar{y}_i &amp;= \\frac{1}{T}\\sum_{t=1}^T y_{it} \\\\ &amp;= \\frac{1}{T}\\sum_{t=1}^T (\\alpha + \\beta_0 x_{it} + a_i + e_{it}) \\\\ &amp;= \\frac{1}{T}\\sum_{t=1}^T \\alpha + \\frac{1}{T}\\sum_{t=1}^T\\beta_0 x_{it} + \\frac{1}{T}\\sum_{t=1}^T a_i + \\frac{1}{T}\\sum_{t=1}^Te_{it}) \\\\ &amp;= \\alpha + \\frac{\\beta_0}{T}\\sum_{t=1}^T x_{it} + a_i + \\frac{1}{T}\\sum_{t=1}^Te_{it} \\\\ &amp;= \\alpha + \\beta_0 \\bar{x}_i + a_i + \\bar{e}_i \\end{aligned}\\] Agora, definindo \\(\\tilde{y}_{it} = y_{it} - \\bar{y}_i\\), temos: \\[\\begin{aligned} \\tilde{y}_{it}i &amp;= y_it - \\bar{y}_i \\\\ &amp;= \\alpha + \\beta_0 x_{it} + a_i + e_{it} - (\\alpha + \\beta_0 \\bar{x}_i + a_i + \\bar{e}_i) \\\\ &amp;= (\\alpha - \\alpha) + (\\beta_0 x_{it} - \\beta_0 \\bar{x}_i) + (a_i - a_i) + (e_{it} - \\bar{e}_i) \\\\ &amp;= \\beta_0(x_{it} - \\bar{x}_i) + (e_{it} - \\bar{e}_i) \\\\ &amp;= \\beta_0 \\tilde{x} + \\tilde{e}_{it} \\text{, em que } \\tilde{x} = x_{it} - \\bar{x}_i \\text{ e } \\tilde{e}_{it} = e_{it} - \\bar{e}_i \\end{aligned}\\] Temos então um modelo de regressão em que os \\(\\a_i\\) foram removidos da equação estrutural e, portanto, não podem mais causal viés de variável omitida. A pergunta para vocês agora é: qual o estimando que tal estimador estima? Pensem antes de responder… Vamos formular a questão um pouco em termos de resultados potenciais. 9.3 Estimandos Há muitos estimandos possíveis com dados TSCS. Eis alguns possíveis estimandos de interesse (baseado em Blackwell e Glynn, 2018). Antes ,vamos definir: todos os tratamentos para uma dada unidade formam a história do tratamento \\(X_i = \\{x_{i1}, x_{i2}, \\cdots, x_{iT}\\}\\). A história parcial dos tratamentos até \\(t\\) é \\(X_{i, 1:t} = \\{x_{i1}, x_{i2}, \\cdots, x_{it}\\}\\). Variáveis de controle \\(W\\) podem ser definidas de maneira similar. O efeito de uma história de tratamento. Posso estar interessado em entender o efeito de uma particular história em contraposição a outra. Digamos, um país que sempre foi democracia versus um que sempre foi ditadura. Em termos de resultados potenciais: \\(Y_{it}(X_{i, 1:t}) - Y_{it}(X^{\\prime}_{i, 1:t})\\), em que \\(\\prime\\) indica uma história alternativa. No caso, \\(Y_{it}(1, 1, \\cdots, 1)\\) versus \\(Y_{it}(0, 0, \\cdots, 0)\\). Como sempre, nosso estimando típico é uma média, isto é: \\(\\tau_{X_{i, 1:t}, X^{\\prime}_{i, 1:t}} = \\mathbb{E}[Y_{it}(X_{i, 1:t}) - Y_{it}(X^{\\prime}_{i, 1:t})]\\). Obviamente, existem muitas combinações de histórias possíveis (de fato, \\(2^t\\) se o tratamento é binário). Como vamos observar muitas histórias distintas, teremos em geral poucas ou nenhuma observação de uma dada história para estimar o efeito causal com precisão. Efeito de história parcial (recente) do tratamento. Vamos definir resultado potencial dos últimos \\(j\\) períodos \\(Y_{it}(X_{t-j:t}) = Y_{it}(X_{i,1: t-j-1}, X_{t-j:t})\\). Nós interpretamos essa quantidade como o efeito causal de observar a história até o período \\(t-j-1\\) e então fixar o valor do tratamento na história \\(X_{t-j,:t}\\). Efeito Contemporâneo do Tratamento (Contemporaneous Treatment Effect, CET): \\(\\tau_c(t) = \\mathbb{E}[Y_{it}(X_{i,1: t-j-1}, X_{t-j:1}) - Y_{it}(X_{i,1: t-j-1}, X_{t-j:0})]\\). Ou seja, deixamos as unidades terem qualqquer história, e investigamos o efeito do tratamento no último período. Veja que estamos calculando a média sobre todas as histórias até o período \\(t\\). 9.4 Resultados Potenciais Vamos considerar, inicialmente, um caso de depois períodos e em que indíviduos são tratados nos dois períodos ou não tratados nos dois períodos. Isso significa que de quatro resultados potenciais possívels \\(Y_i(0,0), Y_i(0,1), Y(1,0)_i, Y_i(1,1)\\) só observamos \\(Y_i(0,0), Y_i(1,1)\\). Digamos que estamos interessados em \\(\\mathbb{E}[Y_i(1,1) - Y_i(0,0)]\\). Se a sequência de tratamento for atribuída aleatoriamente, isto é, sorteamos que irá receber \\(x_i = (1,1)\\) e \\(x_i = (0,0)\\), então podemos utilizar os resultados observados para recuperar nosso estimando: \\(\\mathbb{E}[Y_i|x_{i1} = 1, x_{i2}=1] - \\mathbb{E}[Y_i|x_{i1} = 0, x_{i2}=0]\\). Veja que nós aleatorizamos a sequência dos tratamentos. Tal tipo de aleatorização implica que exogeneidade estrita é statisfeita, que formalizamos a seguir com resultados potenciais: \\[ Y_{it}(1), Y_{it}(0) \\perp x_{it}|\\mathbf{W}^{1:T}_i, a_i, \\mathbf{f}^{1:T}\\text{, para todo } i, t, s, \\] As variáveis em negrito indicam que são (potencialmente) um vetor de variáveis. A suposição de exogeneidade estrita implica a suposição de tendências paralelas. Em palavras, essa suposição (que é um restrição de exclusão) quer dizer que: não há time-varying confoundings; Resposta passada não causa diretamente resposta presente, isto é, sem flecha de \\(y_{t-1}\\) para \\(y_t\\); Semfeedback de variáveis causadas por tratamentos passados (resultados passados ou outras covariáveis) e o status de tratamento corrente e futuro. Ou seja, sem flechas de \\(y_{t-1}\\) para \\(x_t\\) ou de \\(w_{t-1}\\) para \\(x_t\\). Sem “carryover effects” do tratamento presente para resultados futuros, ou seja, sem flecha de \\(x_{t-1}\\) para \\(y_t\\) ou \\(y_{t+1}\\). Qualquer violação de uma ou mais condições acima implica que a suposição de exogeneidade restrita não foi satisfeita. O DAG abaixo apresena exogeneidade estrita para um caso simplificado de três períodos: Obviamente, essa restrição de exclusão é difícil de ser satisfeita na prática. Se supusermos \\(\\mathbb{E}[e_t|x_{t1}, x_{t2}, \\cdots, x_{tk}]=0\\), temos o que chamamos de exogeneidade contemporânea, ou seja, as variáveis independentes e o termo de erro são não-correlacionadas no tempo \\(t\\). Isso, porém, não garante que o estimador de OLS é não-viesado. Para obtermos um estimador não-viesado, precisamos supor exogeneidade estrita: É possível mostrar, porém, que o estimador de OLS é consistente com exogeneidade contemporânea. Vale destacar que exogeneidade estrita exclui a possibilidade de que o termo de erro no presente possa causar mudanças futuras em \\(x\\). Ou seja, não pode haver feedback do \\(y\\) para futuros valores de \\(x\\). Em outras palavras, tratamentos estritamente exógenos não podem reagir pelo que aconteceu com o \\(y\\) no passado. Considere o que a literatura chama de Distributed Lag Model (DLM), que basicamente consiste em introduzir valores defasados (além do presente) do tratamento. O modelo simples, fica: \\[ y_{it} = \\alpha + \\beta_1x_{it} + \\beta_2 x_{it-1} + \\cdots + \\beta_2 x_{it-k} + e_{it} \\] Um modelo relacionado, chamado de ADL (autoregressive distributed lag) incluida VD defasada: Se for um AR(1), temos: \\[ y_{it} = \\alpha + \\alpha_1y_{it-1} + \\beta_1x_{it} + \\beta_2 x_{it-1} + e_{it} \\] Vale a pena escrever a equação de resultado potenciais implicada por esse modelo: \\[ Y_{it}(x_{1:t}) = \\alpha + \\alpha_1 y_{it-1}(x_{1:t-1}) + \\beta_1x_{it} + \\beta_2 x_{it-1} + e_{it} \\] Nessa formulação fica claro porque é difícil interpretar o efeito causal do tratamento em \\(t-1\\), pois ele te mum efeito direto, via \\(\\beta_2\\) e um efeito indireto, via \\(y_{it-1}\\). 9.5 Modelo AR(1) Considere o modelo AR(1): \\[ y_{t} = \\beta_0 + \\beta_1 y_{t-1} + e_t \\] Suponha ademais que \\(\\mathbb{E}[e_t|y_{t-1}, y_{t-2}, ...] = 0\\). Esse pressuposto implica que \\(\\mathbb{E}y_{t}|y_{t-1}, y_{t-2}, ...] = \\mathbb{E}[\\beta_0 + \\beta_1 y_{t-1} + e_t|y_{t-1}, y_{t-2}, ...] = \\beta_0 + \\beta_1\\mathbb{E}y_{t-1}|y_{t-1}, y_{t-2}, ...] + 0 = \\beta_0 + \\beta_1 y_{t-1}\\). Portanto, \\(e_t\\) e \\(y_{t}\\) são correlacionados. O modelo AR(1), isto é, com VD defasa, viola exogeneidade estrita. 9.6 Sequential ignorability Uma suposição alternativa e menos demandante é a de ignorability sequencial (sequential ignorability). O experimento equivalente a essa suposição seria quando, em cada período, o tratamento \\(x_{it}\\) é aleatorizado condicional aos valores passados do tratamento e covariáveis variantes no tempo (incluindo valores passados da variável resposta, \\(y\\)). O DAG abaixo ilustra a suposição de ignorability sequencial. 9.7 Resumo A princípio, e de maneira mais geral, se a história importa (isto é, os estados passados, bem como sua ordem importam), o que Scott Page (200) chamou de path dependence, então precisamos escrever os resultados potenciais de um indivíduo \\(i\\) em \\(t = 1, \\cdots, T\\), para um tratamento binário \\(x_{it} \\in \\{0,1\\}\\) da seguinte forma: \\[ y(x_{i1}, x_{i2}, \\cdots, x_{it}, \\cdots x_{iT}) \\] Em que o valor de \\(x_{it} \\in \\{0,1\\}\\) determina se, naquele período, o indivíduo foi tratado ou não. Se a história importa, no sentido de path dependence, então cada sequência é substantivamente diferente. Uma outra possibilidade é que importe quantos tratamentos e controles a unidade recebeu, mas não a ordem. Nesse caso: \\[ y(x_{i1}, x_{i2}, \\cdots, x_{it}, \\cdots x_{iT}) = y(\\sum_{t=1}^T x_{it}) \\] Para uma dada unidade \\(i\\) no tempo \\(t\\), e supondo um tratamento binário \\(x_{it}\\), o resultado potencial é: \\(Y(1)_{it}\\) para o tratamento, e \\(Y(1)_{it}\\) para o controle. Uma suposição implícita na nossa derivação é que se eu denotar a sequência (ou caminho) de tratamento e controle no tempo por algo como \\(Y(1,0,..., 1)_{it^{\\star}}\\) para uma resposta em \\(t^{\\star} &gt; 1\\), a história dos resultados potenciais é irrelevante, de modo que posso simpliesmente escrever \\(Y(1)_{it^{\\star}}\\) e similarmente para o controle. Então, sabemos que \\(Y(1)_{it^{\\star}} = \\alpha + \\beta_0 x_{it^{\\star}} + a_i + e_{it^{\\star}}\\) e \\(Y(0)_{it^{\\star}} = \\alpha + a_i + e_{it^{\\star}}\\). O efeito do tratamento entre indivíduos no período t^{} é dado justamente por \\(Y(1)_{it^{\\star}} - Y(0)_{it^{\\star}} = \\alpha + \\beta_0 x_{it^{\\star}} + a_i + e_{it^{\\star}} - (\\alpha + a_i + e_{it^{\\star}}) = beta_0 x_{it^{\\star}\\). Como só posso observar um dos resultados potenciais para cada indivíduo no período t^{}, parece natual pensar que inha regressão de efeitos. 9.7.1 Remark Sob a suposição de exogeneidade contemporânea, o estimador de OLS é consistente, isto é, converge para o verdadeiro valor do parâmetro quando a amostra vai para infinito. Supondo que a série é estacionária e fracamente dependente. Formalmente, a dependência fraca implica que \\(|\\beta_1| &lt; 1\\). 9.8 Suposições para Inferência Para fazer inferência (calcular o erro padrão e fazer testes de hipótese, por exemplo), precisamos supor, além da exogeneidade estrita, a suposição de não-correlação serial. Ou seja, Conditional on X, the errors in two different time periods are uncorrelated: Corr ut,us X 5 0, for all t 2 s. 9.8.1 Remark Problemas de correlação serial impactam o cálculo do erro padrão, mas não o viés. 9.9 Efeitos aleatórios Um modelo simples de efeito aleatório é dado por: \\(y_{it} = \\beta_{0t} + \\beta_1 x_{it} + e_{it}\\), micro model \\(\\beta_{0t} = \\beta_0 + \\beta_2 z_t + \\mu_t\\), macro model Modelo completo: \\[ y_{it} = \\beta_0 + \\beta_2 z_t + \\beta_1 x_{it} + (e_{it} + \\mu_t) \\] A parte “fixa” é \\(beta_0 + \\beta_2 z_t + \\beta_1 x_{it}\\) e a parte “aleatória” é \\(e_{it} + \\mu_t\\). Tipicamente, assumimos que \\(\\mu_t \\sim N(0, \\sigma^2_{\\mu})\\) e \\(e_{it} \\sim N(0, \\sigma^2_e)\\). Isso é também chamado de partial pooling (shrinkage), pois os “varying-intercept” possuem uma distribuição comum, com variância estimada pelos dados. Vejam que, se \\(\\sigma^2_{\\mu} = 0\\), então os interceptos são todos iguais, e temos uma “pooled regression”. Se \\(\\sigma^2_{\\mu} \\to \\in \\infty\\), então cada intercepto poderia ser estimado separadamente para cada \\(t\\): “unpooled regression”. A suposição de identificação é: \\[ \\mathbb{E}[e_{it}|x_{it}, z_t] = 0 \\] e \\[ \\mathbb{E}[\\mu_{t}|x_{it}, z_t] = 0 \\] As implicações dos dois pressupostos é que \\(Cov(e_{it},x_{it}) = 0\\) e \\(Cov(\\mu_{t},x_{it}) = 0\\). Vamos comparar com o modelo de feitos fixos, mas usando outra formulação. O modelo padrão com varráveis binárias pode ser escrito como: \\[ y_{it} = \\sum_{t=1}^T \\beta_{0t} D_t + \\beta_1 x_{it} + e_{it} \\] Nós podemos estimar esse modelo diretamente, e nesse caso teremos uma estimativa para os efeitos fixos \\(\\beta_{0t}\\). Porém, tipicamente eles não são de interesse, e portanto, uma outra parametrização equivalente mostra a suposta vantagem dos efeitos fixos. Vamos centrar todas as variáveis do modelo. Primeiro, vamos definir: \\(\\bar{y}_t = \\sum_{i=1}^N y_{it}\\) \\(\\bar{x}_t = \\sum_{i=1}^N x_{it}\\) \\(\\bar{e}_t = \\sum_{i=1}^N e_{it}\\) \\(\\bar{e}_t = \\sum_{i=1}^N z_{it}\\) Defina a equação de regressão centrada na média como: \\[ \\bar{y}_t = \\frac{1}{N} \\sum_{i=1}^N y_{it} = \\frac{1}{N} \\sum_{i=1}^N (\\beta_0 + \\beta_2 z_{it} + \\beta_1 x_{it} + \\mu_t + e_it)= \\beta_0 + \\beta_2\\bar{z_{t}} + \\beta_1\\bar{x}_t + \\mu_t + \\bar{e}_t \\] Subtraindo esta equação da original, temos: \\[ y_{it} - \\bar{y_{t}} = \\beta_2 (z_t - \\bar{z_{t}}) + \\beta_1 (x_{it} - \\bar{x_{t}}) + (e_{it} - \\bar{e}_t) \\] E eliminamos o intercepto e os efeitos fixos da equação, de modo que não precisamos mais de nenhum pressuposto sobre os efeitos fixos e os termos de erro. O custo que nós pagamos é remover a variação entre unidades, ou seja, estamos estimando um modelo apenas com base na variação “within”, isto é, intra-unidades no tempo. Obviamente, não há nada especial em termos utilizado efeitos fixos de tempo. Poderíamos igualmente usar um efeito fixo de unidade, centrar e subtrair do modelo original, e obter estimativas apenas com variação entre unidades, mas não intra-unidades. O problema de OVB com efeitos aleatórios pode ser explicado da seguinte maneira (seguindo Bell e Jones, 2015). A variação no tratamento pode ser decomposta em: \\(x_{it} = x_t^B + x_{it}^W\\) No modelo de efeitos aleatórios \\(y_{it} = \\beta_0 + \\beta_2 z_t + \\beta_1 x_{it} + (e_{it} + \\mu_t)\\), implicitamente assumimos que o efeito between e within sao iguais. Quando são diferentes, \\(\\beta_1\\) é uma média ponderada dos dois processos, e isso produz justamente o OVB, porque o efeito between é omitido. Bell e Jones chamam de “heterogeneity bias”, para distinguir do clásico OVB. A solução proposta por Bell e Jones, ecoando Mundlak, é adicionar um termo que caputre o efeito between: a média temporal. A equaçao fica então: \\(y_{it} = \\beta_0 + \\beta_2 z_t + \\beta_1 x_{it} + \\beta_3 \\bar{x}_t + (e_{it} + \\mu_t)\\). Essa equação pode ser reformulada para: \\[ y_{it} = \\beta_0 + \\beta_2 z_t + \\beta_1 (x_{it} - \\bar{x}_t) + \\beta_4 \\bar{x}_t + (e_{it} + \\mu_t) \\] \\(\\beta_1\\) é o efeito within, e \\(\\beta_4\\) é o efeito between. 9.10 Referências Bell, A., &amp; Jones, K. (2015). Explaining fixed effects: Random effects modeling of time-series cross-sectional and panel data. Political Science Research and Methods, 3(1), 133-153. Blackwell, M., &amp; Glynn, A. N. (2018). How to make causal inferences with time-series cross-sectional data under selection on observables. American Political Science Review, 112(4), 1067-1082. Page, S. E. (2006). Path dependence. Quarterly Journal of Political Science, 1(1), 87-115. "],["synthetic-control.html", "Capítulo 10 Synthetic Control 10.1 Implementação no R 10.2 Synthethic DiD 10.3 Referências", " Capítulo 10 Synthetic Control Vamos começar com um exemplo, já famoso na literatura, de Controle Sintético. O estado da Califórnia implmentou uma proibição de uso de cigarro e digamso que queremos ver o efeito dessa proibição, isto é, nosso estimando é \\(\\tau_{\\text{ban}, \\text{CA}} = Y(1)_{\\text{ban}, CA} - Y(0)_{\\text{ban}, \\text{CA}}\\). Como não observamos \\(Y(0)_{\\text{ban}, \\text{CA}}\\), temos de criar uma “Califórnia sintética”. Antigamente, iremos usar alguma média dos demais estados “não-tratados”para estimar o contrafactual. Contudo, não é muito convincente. state year cigsale retprice california after_treatment 1 1970 89.8 39.6 FALSE FALSE 1 1971 95.4 42.7 FALSE FALSE 1 1972 101.1 42.3 FALSE FALSE 1 1973 102.9 42.1 FALSE FALSE 1 1974 108.2 43.1 FALSE FALSE 1 1975 111.7 46.6 FALSE FALSE Suponha que obtivemos dados para \\(J+1\\) unidades para unidades \\(j = 1, 2, ..., J+1\\), e sem perda de generalidade, a primeira unidade \\(j=1\\) é a de tratamento ou sob intervenção. O grupo de unidades para comparação (donor pool) é dado por \\(j = 2, ..., J+1\\), uma coleção de unidade não-tratadas. Os dados são observados por \\(T\\) períodos \\(1, 2, ..., t_0, t_1, t_2, ..., T\\), em que de \\(1\\) até \\(t_0\\) nenhuma unidade foi tratada ou sofreu intervenção. Para cada unidade \\(j\\), observamos também um conjunto de \\(k\\) preditores, \\(X_{1j}, X_{2j}, ..., X_{kj}\\), que pode incluir vaores pré-intervenção da variável resposta \\(y_{jt}\\). A ideia é usar com combinação linear do donor pool, com pesos apropriados, para estimar o contrafactual, isto é, o resultado potencial dos tratados. Lembrando que o estimando usual de interesse é o ATT: \\[ \\mathbb{E}[Y(1)_{it}|D_{it}=1] - \\mathbb{E}[Y(0)_{it}|D_{it}=1] \\] A dificuldade, como sempre, é que não observamos \\(\\mathbb{E}[Y(0)_{it}|D_{it}=1\\). Estimar ou imputar esse missing data a partir de uma média ponderada é o objetivo de nosso estimador. A ideia é um pouco parecida com matching, em que nós pareávamos unidades de controle com as taratdas, minimizando a distância a partir das covariáveis. Aqui, vamos fazer algo parecido, mas com uma diferença chave: vamos incluir nas covariáveis a variável resposta defasada. Esse método foi introduzido por Abadie et. al em um journal de ciência política. Vamos usar a abordagem de Doudchenko e Imbens (2018) para apresentar o médo, pois vai faciliar a introdução posterior de diferença em diferenças sintéticas. Nossos dados podem ser organizados da seguinte forma: 10.0.1 Tratamento Suponha, como no caso da proposição 99, que temos uma unidade tratada e o tratamento é absorvente. O banco de dado para o tratamento pode ser representado como: \\[\\begin{aligned} D \\;=\\; \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; \\cdots 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; \\cdots 0 &amp; 0\\\\ \\vdots \\\\ 0 &amp; 0 &amp; 0 &amp; \\cdots 0 &amp; 1\\\\ 0 &amp; 0 &amp; 0 &amp; \\cdots 0 &amp; 1\\\\ \\end{bmatrix} \\end{aligned}\\] Aqui, o estados estão nas colunas, Calinfórnia é a última coluna, e nas linhas temos os períodos de tempo. E podemos simplificar a matriz acima para apenas quatro blocos: \\[\\begin{aligned} D \\;=\\; \\begin{pmatrix} \\mathbf{0} &amp; \\mathbf{0} \\\\ \\mathbf{0} &amp; \\mathbf{1} \\end{pmatrix} \\end{aligned}\\] O que nos leva à seuinge matriz de resultados: \\[\\begin{aligned} Y \\;=\\; \\begin{pmatrix} \\mathbf{Y_{co, pre}} &amp; \\mathbf{Y_{tr, pre}} \\\\ \\mathbf{Y_{co, post}} &amp; \\mathbf{Y_{tr, post}} \\end{pmatrix} \\;=\\; \\begin{pmatrix} Y_{co, pre}(0) &amp; Y_{tr, pre}(0) \\\\ Y_{co, post}(0) &amp; Y_{tr, post}(1) \\end{pmatrix} \\end{aligned}\\] E de maneira similar para as covariáveis, mas vamos simplificar e supor que não temos nenhuma, sem perda de generalidade. Relembrando, nosso estimando é dado por: \\[ \\mathbb{E}[Y(1)_{it}|D_{it}=1] - \\mathbb{E}[Y(0)_{it}|D_{it}=1] \\] E preciso para isso estimar \\(\\mathbb{E}[Y(0)_{it}|D_{it}=1]\\), em nossa nova notação: \\(Y(0)_{it}|D_{it}=1 \\text{, p/ todo t} &gt; t_0 = Y_{tr, post}(0)\\). E nosso estimador será: \\[ Y_{tr, post}(0) = \\mu + \\sum_{i \\in co}w_iY_{i,t} \\] Em que \\(w_i\\) são os pesos do donor pool. Em ADH (2010), as restrições são: \\(\\mu = 0\\) \\(\\sum_i w_i = 1\\) \\(w_i \\geq 0 \\text{, } \\forall i\\) Restrição 1 signifca que não há diferença de nível. Suposição 2 significa que o contrafactual tem de ser contruído no suporte do donor pool. Suposição 3 A intuição para o cálculo do peso é parecida da regressão linear, em que estamos minimizando a soma da distância. A diferença é que é uma soma diferente. \\[ ||\\mathbf{X}_{tr} - \\mathbf{X}_{co}\\mathbf{W}|| \\] Lembrando que vamos incluir a VD defasada em \\(X\\). Vamos para o R para ver isso em ação. Dica: Há vários pacotes, mas o original, synth, é muito complexdo de usar e não recomendamos. augsynth/tidysynth and synthdid packages (original package is tough to use) 10.1 Implementação no R # tidysynth library(tidysynth) library(tidyverse) data(smoking) smoking %&gt;% head() %&gt;% kable() state year cigsale lnincome beer age15to24 retprice Rhode Island 1970 123.9 NA NA 0.1831579 39.3 Tennessee 1970 99.8 NA NA 0.1780438 39.9 Indiana 1970 134.6 NA NA 0.1765159 30.6 Nevada 1970 189.5 NA NA 0.1615542 38.9 Louisiana 1970 115.9 NA NA 0.1851852 34.3 Oklahoma 1970 108.4 NA NA 0.1754592 38.4 smoking_out &lt;- smoking %&gt;% # initial the synthetic control object synthetic_control(outcome = cigsale, # outcome unit = state, # unit index in the panel data time = year, # time index in the panel data i_unit = &quot;California&quot;, # unit where the intervention occurred i_time = 1988, # time period when the intervention occurred generate_placebos=T # generate placebo synthetic controls (for inference) ) %&gt;% # Generate the aggregate predictors used to fit the weights # average log income, retail price of cigarettes, and proportion of the # population between 15 and 24 years of age from 1980 - 1988 generate_predictor(time_window = 1980:1988, ln_income = mean(lnincome, na.rm = T), ret_price = mean(retprice, na.rm = T), youth = mean(age15to24, na.rm = T)) %&gt;% # average beer consumption in the donor pool from 1984 - 1988 generate_predictor(time_window = 1984:1988, beer_sales = mean(beer, na.rm = T)) %&gt;% # Lagged cigarette sales generate_predictor(time_window = 1975, cigsale_1975 = cigsale) %&gt;% generate_predictor(time_window = 1980, cigsale_1980 = cigsale) %&gt;% generate_predictor(time_window = 1988, cigsale_1988 = cigsale) %&gt;% # Generate the fitted weights for the synthetic control generate_weights(optimization_window = 1970:1988, # time to use in the optimization task margin_ipop = .02,sigf_ipop = 7,bound_ipop = 6 # optimizer options ) %&gt;% # Generate the synthetic control generate_control() # série do observado e controle sintético smoking_out %&gt;% plot_trends(time_window = 1970:2000) A quantidade causal de interesse pode ser visualizada do seguinte modo: smoking_out %&gt;% plot_differences() E é possível visulizar os pesos de cada unidade e das variáveis: smoking_out %&gt;% plot_weights() Podemos também olhar o balanceamento entre o observado e o sintético: smoking_out %&gt;% grab_balance_table() ## # A tibble: 7 × 4 ## variable California synthetic_California donor_sample ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ln_income 10.1 9.85 9.83 ## 2 ret_price 89.4 89.4 87.3 ## 3 youth 0.174 0.174 0.173 ## 4 beer_sales 24.3 24.2 23.7 ## 5 cigsale_1975 127. 127. 137. ## 6 cigsale_1980 120. 120. 138. ## 7 cigsale_1988 90.1 91.4 114. A Inferência é complicada. O método tradicional é o chamado teste placebo, cuja intuição é a de um teste de permutação, ou seja, a gente diz que um outro estado foi tratado (NY, por exemplo), e roda o modelo de novo e assim por diante para todas as unidades do donor pool. O gráfico abaixo traz isso pronto. smoking_out %&gt;% plot_placebos() 10.2 Synthethic DiD Synth DiD comebinar controle sintético com DiD, em algo novo. Então, vamos começar revisitando DiD. Nós vimos que o estimador de DiD é equivalente a uma regressão linear com efeitos fixos de unidade e tempo. Vamos aplicar nosso estimador para os dados da da proposição 99. library(fixest) smoking_did &lt;- smoking %&gt;% mutate(treatment = ifelse(state == &quot;California&quot; &amp; year &gt; 1988, 1, 0)) did &lt;- feols(cigsale ~ treatment | state + year, data = smoking_did) summary(did) ## OLS estimation, Dep. Var.: cigsale ## Observations: 1,209 ## Fixed-effects: state: 39, year: 31 ## Standard-errors: Clustered (state) ## Estimate Std. Error t value Pr(&gt;|t|) ## treatment -27.3491 2.80238 -9.75925 6.6913e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## RMSE: 11.5 Adj. R2: 0.870229 ## Within R2: 0.032671 O problema dessa. estimativa é que a suposição de tendências paralelas na média não é muito crível. df &lt;- smoking_did %&gt;% mutate(event_time = year - 1988, id = as.integer(as.factor(state))) %&gt;% group_by(state) %&gt;% mutate(g = ifelse(state == &quot;California&quot; &amp; year &gt;= 1988, 1988, 0)) # Estimação do modelo event study # model_feols &lt;- feols( # cigsale ~ i(event_time, ref = -1) | unidade + periodo, # data = df) library(did2s) out_es &lt;- event_study( data = df, idname = &quot;id&quot;, tname = &quot;year&quot;, gname = &quot;g&quot;, # coluna que indica o período de tratamento para cada i yname = &quot;cigsale&quot;, estimator = &quot;all&quot; ) ## Error in max(t) : invalid &#39;type&#39; (list) of argument ## Error in fixest::feols(sunab_formla, data = data) : ## Evaluation of the right-hand-side of the formula raises an error: ## in i(factor_var = period, f2 = cohort, f_n...: ## Argument `factor_var` must be a vector. Problem: it is of length 0, while it should have a positive length. ## Error in create_Atheta_list_for_event_study(eventTime = eventTime, g_list = g_list, : ## There are no comparison cohorts for the given eventTime plot_event_study(out_es) E se a gente combinasse controle sintético com DiD, isto é, usasse peso para criar tendências paralelas, e então aplicasse DiD? Arkhangelsky et al (2021) mostraram que podemos reescrever o estimador de controle sintético como: \\[ (\\hat{\\mu}, \\hat{\\gamma}, \\hat{\\tau}) = \\text{arg}\\,\\max\\limits_{\\mu, \\gamma, \\tau}\\ \\sum_i \\sum_t (y_{it}) - \\mu - \\gamma_t -D_{it}\\tau)^2\\hat{w}_i \\] Já o DiD é dado por: \\[ (\\hat{\\mu}, \\hat{\\alpha}, \\hat{\\gamma}, \\hat{\\tau}) = \\text{arg}\\,\\max\\limits_{\\mu, \\gamma, \\tau}\\ \\sum_i \\sum_t (y_{it}) - \\mu - \\alpha_i - \\gamma_t -D_{it}\\tau)^2 \\] A a proposta dos autores, o Synthetic DiD é dada pelo estimador: \\[ (\\hat{\\mu}, \\hat{\\alpha}, \\hat{\\gamma}, \\hat{\\tau}) = \\text{arg}\\,\\max\\limits_{\\mu, \\gamma, \\tau}\\ \\sum_i \\sum_t (y_{it}) - \\mu - \\alpha_i - \\gamma_t -D_{it}\\tau)^2\\hat{w}_i\\hat{\\lambda}_t \\] Como antes, \\(\\hat{w}_\\) são pesos para cada unidade que procuram balancear a tendência pré-exposição ao tratamento nos grupos controle e de tratamento (no exemplo, demais estados e Califórnia). E introduzem pesos \\(\\hat{\\lambda}_t\\) para os períodos de tempo \\(t\\) que procuram balancear os períodos pré-exposição com os períodos pós-exposição. Contrast o SDiD com o DiD, e a didferença são os dois pesos. Basicamente, estamos estimando regressão linear local ao colocar mais peso em unidades que são, em média, mais similares aos tratados no período pré-exposição e enfatiza períodos mais similares ao algo (período tratado). Em outras palavras, “Time weights are designed so that the average post-treatment outcome for each of the control units differs by a constant from the weighted average of the pre-treatment outcomes for the same control units”(p. 4) Esse estimador relaxa a suposição de tendências paralelas. Agora, precisamos que um fator latente seja paralelo. # devtools::install_github(&quot;synth-inference/synthdid&quot;) library(synthdid) estimators = list(did=did_estimate, sc=sc_estimate, sdid=synthdid_estimate) str(synthdid_estimate) ## function (Y, N0, T0, X = array(dim = c(dim(Y), 0)), noise.level = sd(apply(Y[1:N0, ## 1:T0], 1, diff)), eta.omega = ((nrow(Y) - N0) * (ncol(Y) - T0))^(1/4), ## eta.lambda = 1e-06, zeta.omega = eta.omega * noise.level, zeta.lambda = eta.lambda * ## noise.level, omega.intercept = TRUE, lambda.intercept = TRUE, weights = list(omega = NULL, ## lambda = NULL), update.omega = is.null(weights$omega), update.lambda = is.null(weights$lambda), ## min.decrease = 1e-05 * noise.level, max.iter = 10000, sparsify = sparsify_function, ## max.iter.pre.sparsify = 100) # converte para matriz df_sdid &lt;- df %&gt;% dplyr::select(state, year, cigsale, treatment) %&gt;% mutate(treatment = as.integer(treatment), year = as.integer(year), state = as.factor(state)) %&gt;% as.data.frame() # aparentemente panel.matrices não funciona com tibble setup &lt;- panel.matrices(df_sdid) head(setup) %&gt;% kable() 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 Alabama 89.8 95.4 101.1 102.9 108.2 111.7 116.2 117.1 123.0 121.4 123.2 119.6 119.1 116.3 113.0 114.5 116.3 114.0 112.1 105.6 108.6 107.9 109.1 108.5 107.1 102.6 101.4 104.9 106.2 100.7 96.2 Arkansas 100.3 104.1 103.9 108.0 109.7 114.8 119.1 122.6 127.3 126.5 131.8 128.7 127.4 128.0 123.1 125.8 126.0 122.3 121.5 118.3 113.1 116.8 126.0 113.8 108.8 113.0 110.7 108.7 109.5 104.8 99.4 Colorado 124.8 125.5 134.3 137.9 132.8 131.0 134.2 132.0 129.2 131.5 131.0 133.8 130.5 125.3 119.7 112.4 109.9 102.4 94.6 88.8 87.4 90.2 88.3 88.6 89.1 85.4 83.1 81.3 81.2 79.6 73.0 Connecticut 120.0 117.6 110.8 109.3 112.4 110.2 113.4 117.3 117.5 117.4 118.0 116.4 114.7 114.1 112.5 111.0 108.5 109.0 104.8 100.6 91.5 86.7 83.5 79.1 76.6 79.3 76.0 75.9 75.5 73.4 71.4 Delaware 155.0 161.1 156.3 154.7 151.3 147.6 153.0 153.3 155.5 150.2 150.5 152.6 154.1 149.6 144.0 144.5 142.4 141.0 137.1 131.7 127.2 118.8 120.0 123.8 126.1 127.2 128.3 124.1 132.8 139.5 140.7 Georgia 109.9 115.7 117.0 119.8 123.7 122.9 125.9 127.9 130.6 131.0 134.0 131.7 131.2 128.6 126.3 128.8 129.0 129.3 124.1 117.1 113.8 109.6 109.2 109.2 107.8 100.3 102.7 100.6 100.5 97.1 88.4 Idaho 102.4 108.5 126.1 121.8 125.6 123.3 125.1 125.0 122.8 117.5 115.2 114.1 111.5 111.3 103.6 100.7 96.7 95.0 84.5 78.4 90.1 85.4 85.1 86.7 93.0 78.2 73.6 75.0 78.9 75.1 66.9 Illinois 124.8 125.6 126.6 124.4 131.9 131.8 134.4 134.0 136.7 135.3 135.2 133.0 130.7 127.9 124.0 121.6 118.2 109.5 107.6 104.6 94.1 96.1 94.8 94.6 85.7 84.3 81.8 79.6 80.3 72.2 70.0 Indiana 134.6 139.3 149.2 156.0 159.6 162.4 166.6 173.0 150.9 148.9 146.9 148.5 147.7 143.0 137.8 135.3 137.6 134.0 134.0 132.5 128.3 127.2 128.2 126.8 128.2 135.4 135.1 135.3 135.9 133.3 125.5 Iowa 108.5 108.4 109.4 110.6 116.1 120.5 124.4 125.5 127.1 124.2 124.6 132.9 116.2 115.6 111.2 109.4 104.1 101.1 100.2 94.4 95.4 97.1 95.2 92.5 93.4 93.0 94.0 93.9 94.0 91.7 88.9 Kansas 114.0 102.8 111.0 115.2 118.6 123.4 127.7 127.9 127.1 126.4 127.1 132.0 130.9 127.6 121.7 115.7 109.4 105.2 103.2 96.5 94.3 91.8 90.0 89.9 89.1 90.1 88.7 89.2 87.6 83.3 79.8 Kentucky 155.8 163.5 179.4 201.9 212.4 223.0 230.9 229.4 224.7 214.9 215.3 209.7 210.6 201.1 183.2 182.4 179.8 171.2 173.2 171.6 182.5 170.4 167.6 167.6 170.1 175.3 179.0 186.8 171.3 165.3 156.2 Louisiana 115.9 119.8 125.3 126.7 129.9 133.6 139.6 140.0 142.7 140.1 143.8 144.0 143.9 133.7 128.9 125.0 121.2 116.5 110.9 103.6 101.5 107.2 108.5 106.2 105.3 105.7 106.8 105.3 103.2 101.0 104.3 Maine 128.5 133.2 136.5 138.0 142.1 140.7 144.9 145.6 143.9 138.5 141.2 138.9 139.5 135.4 135.5 127.9 119.0 125.0 125.0 122.4 117.5 116.1 114.5 108.5 101.6 102.3 100.0 101.1 94.5 85.5 82.9 Minnesota 104.3 116.4 96.8 106.8 110.6 111.5 116.7 117.2 118.9 118.3 117.7 120.8 119.4 113.2 110.8 113.0 104.3 108.8 94.1 92.3 90.7 86.2 83.8 81.6 83.4 84.1 81.7 84.1 83.2 80.7 76.0 Mississippi 93.4 105.4 112.1 115.0 117.1 116.8 120.9 122.1 124.9 123.9 127.0 125.3 125.8 122.3 116.4 115.3 113.2 110.0 109.0 108.3 101.8 105.6 103.9 105.4 106.0 107.5 106.9 106.3 107.0 103.9 97.2 Missouri 121.3 127.6 130.0 132.1 135.4 135.6 139.5 140.8 141.8 140.2 142.1 140.5 139.7 134.1 130.0 129.2 128.8 128.7 127.4 122.8 119.1 119.9 122.3 121.6 119.4 124.0 124.1 120.6 120.1 118.0 113.8 Montana 111.2 115.6 122.2 119.9 121.9 123.7 124.9 127.0 127.2 120.3 122.0 121.1 122.4 113.7 110.1 103.6 97.8 91.7 87.1 86.2 84.7 82.9 86.6 86.0 88.2 90.5 87.3 88.9 89.1 82.6 75.5 Nebraska 108.1 108.6 104.9 106.6 110.5 114.1 118.1 117.7 117.4 116.1 116.3 117.0 117.1 110.8 107.7 105.1 103.1 101.3 92.9 93.8 89.9 92.4 90.6 91.1 85.9 88.5 86.2 85.5 83.1 86.6 77.6 Nevada 189.5 190.5 198.6 201.5 204.7 205.2 201.4 190.8 187.0 183.3 177.7 171.9 165.1 159.2 136.6 146.7 142.6 147.7 141.9 137.9 137.3 115.5 110.0 108.1 105.2 100.9 99.0 95.6 102.4 103.9 93.2 New Hampshire 265.7 278.0 296.2 279.0 269.8 269.1 290.5 278.8 269.6 254.6 247.8 245.4 239.8 232.9 215.1 201.1 195.9 195.1 180.4 172.9 152.4 144.8 143.7 148.9 153.8 158.5 158.0 174.4 173.8 171.7 147.3 New Mexico 90.0 92.6 99.3 98.9 100.3 103.1 102.4 102.4 103.1 101.0 102.7 103.0 97.5 96.3 88.9 88.0 88.2 82.3 77.7 74.4 70.8 69.9 71.4 69.0 68.2 67.0 65.7 61.8 62.6 59.7 53.8 North Carolina 172.4 187.6 214.1 226.5 227.3 226.0 230.2 217.0 205.5 197.3 187.8 179.3 179.0 169.8 160.6 156.3 154.4 150.5 146.0 139.3 133.7 132.7 128.9 129.7 112.7 124.9 129.7 125.6 126.0 113.1 109.0 North Dakota 93.8 98.5 103.8 108.7 110.5 117.9 125.4 122.2 121.9 121.3 123.7 125.7 126.8 119.6 109.4 103.2 99.8 92.3 87.1 84.1 77.1 85.2 74.3 83.0 81.0 80.6 80.8 77.5 79.1 74.7 72.5 Ohio 121.6 124.6 124.4 120.5 122.1 122.5 124.6 127.3 131.3 130.9 133.5 132.8 134.0 130.0 127.1 126.7 126.3 124.6 122.4 118.6 115.5 113.2 112.3 108.9 108.6 111.7 107.6 108.6 106.4 104.0 99.9 Oklahoma 108.4 115.4 121.7 124.1 130.5 132.9 138.6 140.4 143.6 141.6 141.6 143.7 147.0 140.0 128.1 124.2 119.9 113.1 103.6 97.5 88.4 87.8 86.3 86.2 104.8 109.5 110.8 111.8 112.2 111.4 108.9 Pennsylvania 107.3 106.3 109.0 110.7 114.2 114.6 118.8 120.1 122.3 122.6 124.0 125.2 123.3 125.3 115.3 115.8 113.9 110.6 107.6 107.1 101.3 102.5 96.2 94.7 95.4 95.4 93.3 92.9 92.1 91.1 87.9 Rhode Island 123.9 123.2 134.4 142.0 146.1 154.7 150.2 148.8 146.8 145.8 149.3 151.2 146.3 135.8 136.9 133.4 136.3 124.4 138.0 120.8 101.4 103.6 100.1 94.1 91.9 90.8 87.5 90.0 88.7 86.9 83.1 South Carolina 103.6 115.0 118.7 125.5 129.7 130.5 136.8 137.2 140.4 135.7 138.3 136.1 136.0 131.1 127.0 125.4 126.6 126.6 124.4 122.4 118.6 121.5 112.8 115.2 112.2 109.2 102.9 124.5 126.9 109.4 103.9 South Dakota 92.7 96.7 103.0 103.5 108.4 113.5 116.7 115.6 116.9 117.4 114.7 115.7 113.0 109.8 105.7 104.4 97.0 95.8 91.9 87.4 88.3 91.8 93.0 91.6 94.8 98.6 92.3 88.8 88.3 83.5 75.1 Tennessee 99.8 106.3 111.5 109.7 114.8 117.4 121.7 124.6 127.3 127.2 130.4 129.1 131.4 129.0 125.1 128.7 129.0 130.6 125.3 124.7 121.8 120.6 121.0 120.8 118.8 125.4 119.2 118.9 119.7 115.6 108.7 Texas 106.4 108.9 108.6 110.4 114.7 116.0 121.4 124.2 126.6 126.4 129.7 129.0 131.2 126.4 117.2 115.9 113.7 105.8 96.5 94.5 85.6 79.4 77.2 81.3 78.8 75.2 74.6 72.6 73.2 67.6 69.3 Utah 65.5 67.7 71.3 72.7 75.6 75.8 77.9 78.0 79.6 79.1 74.8 77.6 73.6 69.0 66.3 66.5 64.4 67.7 55.0 57.0 53.4 53.5 55.0 56.2 55.8 52.0 54.0 57.0 42.3 43.9 40.7 Vermont 122.6 124.4 138.0 146.8 151.8 155.5 171.1 169.4 162.4 160.9 161.6 163.8 162.3 153.8 144.3 144.5 131.2 128.3 128.7 120.9 124.3 120.9 126.5 117.2 120.3 123.2 102.5 97.7 97.0 94.1 88.9 Virginia 124.3 128.4 137.0 143.1 149.6 152.7 158.1 157.7 155.9 151.8 148.9 149.9 147.4 144.7 136.8 134.6 135.8 133.0 129.5 122.5 118.9 109.1 108.2 105.4 106.2 106.7 104.6 108.0 105.6 102.1 96.7 West Virginia 114.5 111.5 117.5 116.6 119.9 123.2 129.7 133.9 131.6 122.1 122.3 120.5 119.8 115.7 111.9 109.1 112.1 107.5 109.1 104.0 104.1 100.1 97.9 111.0 104.2 115.2 112.7 114.5 114.6 112.4 107.9 Wisconsin 106.4 105.4 108.8 109.5 111.8 113.5 115.4 117.2 116.7 117.1 117.6 119.9 115.6 106.3 105.6 107.0 105.4 106.0 102.6 100.3 94.0 95.5 96.2 91.2 91.8 93.5 92.1 91.9 88.7 84.4 80.1 Wyoming 132.2 131.7 140.0 141.2 145.8 160.7 161.5 160.4 160.3 168.6 158.1 163.1 157.7 141.2 128.9 125.7 124.8 110.4 114.3 111.4 96.9 109.1 110.8 108.4 111.2 115.0 110.3 108.8 102.9 104.8 90.5 California 123.0 121.0 123.5 124.4 126.7 127.1 128.0 126.4 126.1 121.9 120.2 118.6 115.4 110.8 104.8 102.8 99.7 97.5 90.1 82.4 77.8 68.7 67.5 63.4 58.6 56.4 54.5 53.8 52.3 47.2 41.6 x 38 x 19 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 Alabama 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Arkansas 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Colorado 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Connecticut 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Delaware 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Georgia 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Idaho 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Illinois 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Indiana 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Iowa 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Kansas 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Kentucky 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Louisiana 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Maine 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Minnesota 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Mississippi 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Missouri 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Montana 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Nebraska 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Nevada 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 New Hampshire 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 New Mexico 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 North Carolina 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 North Dakota 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Ohio 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Oklahoma 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Pennsylvania 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Rhode Island 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 South Carolina 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 South Dakota 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Tennessee 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Texas 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Utah 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Vermont 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Virginia 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 West Virginia 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Wisconsin 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Wyoming 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 California 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 estimates &lt;- lapply(estimators, function(estimator) { estimator(setup$Y, setup$N0, setup$T0) } ) head(estimates) ## $did ## synthdid: -27.349 +- NA. Effective N0/N0 = 38.0/38~1.0. Effective T0/T0 = 19.0/19~1.0. N1,T1 = 1,12. ## ## $sc ## synthdid: -19.620 +- NA. Effective N0/N0 = 3.8/38~0.1. Effective T0/T0 = Inf/19~Inf. N1,T1 = 1,12. ## ## $sdid ## synthdid: -15.604 +- NA. Effective N0/N0 = 16.4/38~0.4. Effective T0/T0 = 2.8/19~0.1. N1,T1 = 1,12. standard.errors = mapply(function(estimate, name) { set.seed(12345) if(name == &#39;mc&#39;) { mc_placebo_se(setup$Y, setup$N0, setup$T0) } else { sqrt(vcov(estimate, method=&#39;placebo&#39;)) } }, estimates, names(estimators)) head(standard.errors) ## did sc sdid ## 17.740267 9.917426 8.367993 Plot comparando as estimativas. synthdid_plot(estimates[1:3], facet.vertical=FALSE, control.name=&#39;control&#39;, treated.name=&#39;california&#39;, lambda.comparable=TRUE, se.method = &#39;none&#39;, trajectory.linetype = 1, line.width=.75, effect.curvature=-.4, trajectory.alpha=.7, effect.alpha=.7, diagram.alpha=1, onset.alpha=.7) + theme(legend.position=c(.26,.07), legend.direction=&#39;horizontal&#39;, legend.key=element_blank(), legend.background=element_blank(), strip.background=element_blank(), strip.text.x = element_blank()) Plot comparando os pesos. synthdid_units_plot(rev(estimates[1:3]), se.method=&#39;none&#39;) 10.3 Referências Alcocer, J. J. (2025). Minority Legislators Sponsor and Cosponsor Differently from White Legislators: Causal Evidence from U.S. Congress. The Journal of Race, Ethnicity, and Politics, 1–13. doi:10.1017/rep.2025.29 Arkhangelsky, D., Athey, S., Hirshberg, D. A., Imbens, G. W., &amp; Wager, S. (2021). Synthetic difference-in-differences. American Economic Review, 111(12), 4088-4118. Arkhangelsky, D., &amp; Imbens, G. (2024). Causal models for longitudinal and panel data: A survey. The Econometrics Journal, 27(3), C1-C61. "],["llms-e-outras.html", "Capítulo 11 LLMs e outras 11.1 Google Colab", " Capítulo 11 LLMs e outras 11.1 Google Colab Para a aula de hoje, vamos usar o Google Colab, que é uma ferramenta online, gratuita, para programa e analisar dados. Ela permite escrever e rodar códigos em Python sem a necessidade de instalar nenhum programa. Além disso, é poss[ivel ter acesso a processadores poderosos, inclusive de GPUs, se necessário (mas pagando). Para usar o google colab, precisamos de uma conta google, o que nós já temos com nosso e-mail usp. Vamos acessar o endeeço: https://colab.google Vamos clicar em new notebook. Vamos renomear o arquivo para aula_llm.ipynb A teminação diz que é um notebook. Que é como se fosse um Rmarkdown no R, só que nesse caso, hospedado online. https://macartan.github.io/dd_bootcamp/dd.html#/using-a-design-1 https://macartan.github.io/dd_bootcamp/exercises.html https://gist.github.com/saudiwin/dd0edec5786c7edb393bd84615aafb45 https://www.datacamp.com/tutorial/fine-tuning-openais-gpt-4-step-by-step-guide https://community.revelo.com.br/tutorial-aplicacao-do-fine-tuning-para-treinamento-no-chatgpt/ "],["interferência-spillover-e-dinâmica.html", "Capítulo 12 Interferência, spillover e dinâmica 12.1 Suposições simplifcadoras 12.2 PO com tratamento de múltiplos valores (multi-valued) 12.3 Dinâmica 12.4 Interferência", " Capítulo 12 Interferência, spillover e dinâmica Agora iremos relaxar algumas simplifcações do modelo de Resultados potenciais que vimos até agora. 12.1 Suposições simplifcadoras Tratamento binário Único período de tempo (um tratamento “within unit” ) SUTVA 12.2 PO com tratamento de múltiplos valores (multi-valued) 12.2.1 Multi-valued discreto Vamos estender o modelo de tratamewnto binário começando por tratamentos discretos. Digamos que temos \\(D_i \\in \\{0, 1, ..., d\\}\\), isto é, tratamentos ordenados. Por exemplo, múltiplas categorias de uma política pública (100 reais, 200 reais, 300 reais etc.). Definimos o resultado potencial da unidade \\(i\\) para qualquer \\(d \\in D\\) como \\(Y_i(d)\\) Nós vamos precisar da suposição de ignorability forte. \\(\\tau_i(D, D&#39;) = Y_i(d) - Y_i(d&#39;)\\), ou seja, o efeito causal entre dois níveis do tratamento. Como antes, podemos computar a esperança: \\(\\mathbb{E}[\\tau_i(D, D&#39;)] = \\mathbb{E}[Y_i(d) - Y_i(d&#39;)]\\). E se ignorability forte vale, então \\(\\mathbb{E}[\\tau_i(D, D&#39;)] = \\mathbb{E}[Y_i|D_i = d] - \\mathbb{E}[Y_i|D_i = d&#39;]\\) Se quisermos, podemos trabalhar também com tratamentos não-ordenados. Por exemplo, dois tratamentos binários. Por exemplo, um tratamento é informação sobre corrupção de um candidato (recebe ou não a informação) e outro tratamento é informação sobre a raça do candidato (é branco ou não). \\(D_i \\in \\{0,1}^2\\}\\). Podemos modelar os resultados potenciais como dependendo do status dos dois tratamentos: \\(Y_i(D_{i1}, D_{i2})\\) que geram quatro possibilidades ou resultados potenciais: \\(Y(0,0)\\), \\(Y(1,0)\\), \\(Y(0,1)\\), \\(Y(1,1)\\). Exemplo onde mesmo com atribuição aleatória, há efeitos não-identificados. Aleatoriamente atribuir \\(D_1\\) e, para os que receberam \\(D_1\\), aleatoriamente atribui \\(D-2\\). Onde isso poderia acontecer? Primeira e segunda dose de vacina! Por definição, a segunda dose só é dada para quem recebeu a primeira dose. Nunca é possível estimar efeito relativo a \\(Y_i(0,1)\\), isto é, o resultado potencial de quem não recebeu a primeira dose, mas recebeu a segunda. Essa é uma pessoa que recebeu a primeira dose quando a segunda estava sendo aplicada. 12.3 Dinâmica Considere que agora nós observamos \\(T\\) períodos de tempo para uma unidade: \\(Y_i\\) = (Y_{i1}, Y_{i2}, …, Y_{iT}). Para cada período, há um tratamento \\(D_{it} \\in \\{0,1\\}\\), isto é, sempre binário. Chamamos de \\(\\mathbf{D_i} = (D_{i1}, D_{i2}, ..., D_{iT})\\) o vetor de tratamentos em todos os \\(T\\) períodos. Implicitamente, muitas pessoas abordam modelos dinâmicos supondo que podemos olhar apenas para o resultado pontencial para a unidade \\(i\\) no período \\(t\\), ou seja, \\(Y_{it}(D_{it})\\). Porém, isso significa que apenas o tratamento do período \\(t\\) impacta o resultado potencial do período \\(t\\). De maneira mais geral, teríamos: \\(\\mathbf{D_i} = (D_{i1}, D_{i2}, ..., D_{iT})\\) e definiríamos o resultado potencial no período \\(t\\) como \\(Y_{it}(\\mathbf{D_i})\\). \\(Y(\\mathbf{D})\\). Nesse caso, fomos para o lado oposto: tratamentos futuros impactando o resultado potencial do presente. Isso não necessariamente significa que o futuro afeta o passado. Pode ocorrer por antecipação de tratamentos futuros. De todo modo, também parece extremo. Ainda assim, continuamos evitando a possibilidade de spillovers. Uma suposição comum, portanto, é a de não-antecipação, que pode ser representada por: \\(Y_{it}(d_1, d_2, ..., d_t, d_{t+1}, ..., d_T) = Y_{it}(d_1, d_2, ..., d_t)\\). Ou seja, os resultados potenciais até \\(t\\) não dependem dos resultados potenciais após essa data. Outra suposição comum é: ausência de efeitos dinâmicos: \\[Y_{it}(d_1, d_2, ..., d_t) = Y_{it}(d_t)\\] Em palavras, essa suposição requer que o resultado potencial do presente não dependa dos tratamentos passados. Essa suposição é também chamada de “no carry-over-effects hypothesis”. Ela é bem restritiva. Mesmo um desenho em que a aleatorização é executada a cada período de maneira independente pode ter “carry-over-effects” se o resultado do período anterior impactar o resultado do período presente. Modelos de “impulse response function” estão interessados em estimar justamente “carry over effects”. ver https://donskerclass.github.io/CausalEconometrics/TimeSeries.html Considere um modelo de regressão tradicional para dados dinâmicos: \\(y_{it} = \\alpha + \\beta x_{it} + e_{it}\\). Nós já sabemos que uma forma de de pensar a identificação causal é imaginar um experimento aleatório controlado. O que significa, em primeiro lugar, escolher aleatoriamente o tratamento nesse caso? Uma possibilidade é imaginar que a cada período o tratamento é aleatoriamente atribuído, independentemente dos períodos anteriores. No fundo, é como uma multi-valued treatment. Qual condição de ignorability estamos satisfazendo nesse caso? Se apenas o tratamento presente impacta o resultado potencial, isto é, \\(Y_{it}(D_{it})\\), então temos: Baseline randomization: \\(Y(D_{it}) \\perp D_{it}\\). Ou seja, o resultado potencial no período \\(t\\) é independente do mecanismo de atribuição do tratamento. Essa suposição implica exogeneidade estrita. Ignorability sequencial (Sequential Unconfoundedness). Assume que, conditional à história passada observada de tratamentos e co-variáveis, o tratamento corrente é independente de resultados potenciais. Nós iremos aprofundar essas questões nas aulas sobre DiD e Efeitos Fixos. Por ora, quero notar que no fundo estamos falando de spillovers no tempo, isto é, tratamento no tempo \\(t\\) impatacando resultados potenciais de períodos furutos \\(t+(1:k)\\), em que \\(k &gt;0\\). 12.4 Interferência Interferência ocorre quando o resultado potencial de uma unidade depende do tratamento de outra unidade. Tipicamente, em ciências sociais, spillovers podem envolver: Efeitos de pares Spillovers espaciais Interações políticas (restrições orçamentárias) Para modelar interferência, é necessário enriquecer nosso framework, introduzindo definições adicionais e alterando os pressupostos chave. Tipicamente nós modelamos com a suposição de que a interferência ocorre apenas em um subgrupo de unidades, isto é, o resultado potencial não depende do status de tratamento de todas as unidades, mas tão somente de um grupo específico. Além disso, também é comum ser necessário a suposição de anonimidade, isto é, os pares de um grupo importam, mas não quem são os pares, no sentido de que cada par teria um efeito esepcífico e único sobre uma unidade. Essa é uma área de pesqquisa ativa na inferência causal, mas ainda pouco incorporada na ciência política, em particular nas RIs, mas não só. Referências chave são: Charles F Manski. Identification of treatment response with social interactions. The Econometrics Journal, 16(1):S1–S23, 2013. Peter M Aronow and Cyrus Samii. Estimating average causal effects under general interference, with application to a social network experiment. Annals of Applied Statistics, 11(4):1912–1947, 2017. Bowers J, Fredrickson MM, Panagopoulos C. Reasoning about Interference Between Units: A General Framework. Political Analysis. 2013;21(1):97-124. doi:10.1093/pan/mps038 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
