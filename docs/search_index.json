[["index.html", "Curso de Inferência Causal Capítulo 1 Introdução 1.1 Revisão de Regressão 1.2 Inferência 1.3 Referências", " Curso de Inferência Causal Manoel Galdino 2025-04-23 Capítulo 1 Introdução Aqui pretendo guardar minhas notas de aula para meu curso de causalidade na pós-graduação. É uma forma de organizar e sistematizar meu estudo sobre o tema. 1.1 Revisão de Regressão Comecemos pelo modelo de regressão populacional dado por: \\[y = \\beta_0 + \\beta_1 x + u\\] As suposições básicas do modelo são: Média do erro é zero (sem perda de generalidade): \\(\\mathbb{E}[u] = 0\\) Independência na média do erro: \\(\\mathbb{E}[u|x] = \\mathbb{E}[u]\\). Essa é a suposição mais consequente do modelo de regressão. Como é sobre o termo de erro, não é testável. Um exemplo é útil para entender o que significa essa suposição. Suponha que estamos interessados no efeito do gasto de campanha (\\(x\\)) sobre o voto (\\(y\\)). O termo de erro \\(e\\) seria a qualidade da candidata, não observável. A suposição implica então que a qualidade média das candidatas que gastam 100 mil reais é a mesma das que gastam 500 mil e um milhão (e assim por diante). Se candidatas melhores arrecadam mais dinheiro e, portanto, gastam mais, a suposição foi violada. Conectando 1 e 2, temos: \\(\\mathbb{E}[u|x] = 0\\). Essa suposição é chamada de “média condicional zero” ou “esperança condicional zero” do termo de erro. Ela implica que: \\(\\mathbb{E}[y|x] = \\beta_0 + \\beta_1 x\\). Essa equação é chamada de Conditional Expectation Function, ou CEF. De posse de uma amostra aleatória simples, podemos derivar os estimadores de mínimos quadrados (MQO ou OLS na sigla em inglês). Vou pular os passos da derivação. Para nós, o importante é lembrar a fórmula do \\(\\hat{\\beta_1}\\): \\(\\hat{\\beta_1} = \\frac{\\text{covariância amostral}}{\\text{variância amostral}} = \\frac{\\sum_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n(x_i - \\bar{x})^2}\\) E \\(\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x}\\). Podemos então demonstrar que o estimador é não-viesado. Para isso, é necessário supor que o modelo é linear nos parâmetros (não nas variáveis), temos uma amostra aleatória simples da população, existe variância no preditor (para não dividir por zero na fórmula do estimador de OLS) e a média condicional zero. 1.1.1 Teorema da Anatomia da Regressão Esse teorema, também conhecido como teorema de Frisch, Waugh e Lovell ou Frisch-Waugh-Lovell, é útil para ajudar a entender regressão múltipla. Suponha que nosso modelo possui \\(2\\) preditores: \\(y_i=\\beta_0+\\beta_1 x_{1i}+ \\beta_2 x_{2i}+ e_i\\). Agora, suponha que, em vez de rodar a regressão acima, eu rodo uma regressão (chamada de auxiliar) em que \\(x_1\\) é a variável dependente, e \\(x_2\\) o único preditor. \\(x_{1i}=\\gamma_0+\\gamma_{1}x_{2i} + f_i\\). E os resíduos são dados por: \\(\\tilde{x}{1i}=x{1i} - \\widehat{x}{1i}\\). Então, é possível mostrar que: \\(\\beta_1 = \\frac{C(y_i, \\tilde{x}{1i})}{V(\\tilde{x}_{1i})}\\). O que essa fórmula nos diz é que o efeito de \\(\\beta_1\\) é a covariância entre a variável dependente e o resíduo da regressão auxiliar, isto é, a parte de \\(x_1\\) não explicada pelos demais preditores. Vamos visualizar essa relação com um exemplo do livro do Scott Cunningham: library(tidyverse) library(haven) read_data &lt;- function(df) { full_path &lt;- paste0(&quot;https://github.com/scunning1975/mixtape/raw/master/&quot;, df) haven::read_dta(full_path) } auto &lt;- read_data(&quot;auto.dta&quot;) %&gt;% mutate(length = length - mean(length)) lm1 &lt;- lm(price ~ length, auto) lm2 &lt;- lm(price ~ length + weight + headroom + mpg, auto) lm_aux &lt;- lm(length ~ weight + headroom + mpg, auto) auto &lt;- auto %&gt;% mutate(length_resid = residuals(lm_aux)) lm2_alt &lt;- lm(price ~ length_resid, auto) coef_lm1 &lt;- lm1$coefficients coef_lm2_alt &lt;- lm2_alt$coefficients resid_lm2 &lt;- lm2$residuals y_single &lt;- tibble(price = coef_lm2_alt[1] + coef_lm1[2]*auto$length_resid, length_resid = auto$length_resid) y_multi &lt;- tibble(price = coef_lm2_alt[1] + coef_lm2_alt[2]*auto$length_resid, length_resid = auto$length_resid) auto %&gt;% ggplot(aes(x=length_resid, y = price)) + geom_point() + geom_smooth(data = y_multi, color = &quot;blue&quot;) + geom_smooth(data = y_single, color = &quot;red&quot;) ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; 1.2 Inferência Como sabemos, inferência lida com a generalização da amostra para a população e, portanto, com a variabilidade inerente de amostra para amostra. Eu não vou revisar aqui os cálculos para derivar o erro padrão. Quero apenas enfatizar dois pontos que não são usualmente abordados em cursos de regressão. Em primeiro lugar, generalização da amostra para a população é diferente de generalização causal, também conhecida como validade externa. Esse ponto foi confundido por muitos autores, em particular o livro conhecido como KKV, e levou muitos pesquisadores a acreditarem que uma regressão possuía maior capacidade de generalização causal do que estudos de caso. Uma regressão (supondo que o erro padrão foi calculado corretamente) permite generalizar as estimativas para uma população. Porém, o que significa falar em generalização quando temos o universo de casos (por exemplo, todos os deputados, ou todos os candidatos, ou todos os municípios)? Quando temos o universo, não é diferente de estudos de caso que possuem todos os casos relevantes e, portanto, a noção de generalização da amostra para população não se aplica. O que me leva ao segundo ponto: na inferência causal, em particular nesses casos em que temos o universo dos casos, ainda assim há incerteza. O trabalho de Abadie et. al (2020) discute a ideia de design-based inference. Nós vamos explicar no curso em mais detalhes o que é uma pesquisa design-based (em oposição a model-based). A ideia desse tipo de incerteza (e seu correspondente erro-padrão) é a seguinte. Imagine que estamos interessados em estimar o efeito causal da reeleição de prefeitos sobre a corrupção municipal. Suponha que tenho todos os municípios na amostra. Por fim, suponha que temos um experimento natural de forma que podemos supor que (talvez condicional a algumas variáveis) a reeleição é aleatória. Não há incerteza amostral para a população, mas há incerteza sobre o que aconteceria com a corrupção para os prefeitos reeleitos, caso não fossem reeleitos (e para os que perderam, como seria a corrupção caso fossem reeleitos). Em particular, se acreditamos que a reeleição foi aleatória, então uma nova rodada de amostragem (em um universo alternativo?) produziria outra configuração de prefeitos reeleitos e não-reeleitos e alguma variação na estimativa do efeito causal. Isso antecipa nossa discussão sobre causalidade da próxima aula, mas o ponto é que existe incerteza na variação do efeito causal, que não deriva de variação amostral propriamente, mas da aleatoriedade da intervenção. Nas palavras dos autores: “it will be useful to distinguish between descriptive estimands, where uncertainty stems solely from not observing all units in the population of interest, and causal estimands, where the uncertainty stems, at least partially, from unobservability of some of the potential outcome” (p. 267). Meu ponto é que KKV e cia confundiram incerteza de estimandos descritivos com estimandos causais. O que me leva de volta ao ponto anterior sobre a comparação entre estudos de caso e métodos quantitativos, quando o objetivo é inferência causal. A incerteza inerente é sobre o efeito da intervenção, não sobre variações amostrais. Além disso, em ambos os casos não sabemos (a princípio) se os estudos possuem validade externa, isto é, se os resultados valem para outras populações, no tempo e espaço. É preciso avançar nessa agenda, tanto em métodos quali como quanti. É um problema em aberto e que tem atraído muitas pesquisas novas, que não iremos cobrir no curso (até por desconhecimento meu de boa parte dessa literatura). 1.3 Referências Abadie, Alberto, Susan Athey, Guido W. Imbens, and Jeffrey M. Wooldridge. 2020. “Sampling-Based Versus Design-Based Uncertainty in Regression Analysis.” Econometrica 88 (0): 265–96. "],["resultados-potenciais.html", "Capítulo 2 Resultados Potenciais 2.1 Causalidade e o Método Comparativo 2.2 Potential Outcomes 2.3 Notação 2.4 Problema Fundamental da Inferência Causal 2.5 Estimando 2.6 Estimandos Mais Comuns 2.7 Nota sobre estimandos 2.8 Exercício - Qual o estimando e o estimador (se possível)? 2.9 Identificação 2.10 Identificação do ATE 2.11 Equações estruturais 2.12 Modelo versus Desenho 2.13 Exercício em sala 2.14 Referências", " Capítulo 2 Resultados Potenciais Durante muito tempo, inferência causal com regressão era caracterizada por recomendações vagas, ad hoc e inconsistências. O debate sobre o efeito causal do cigarro sobre câncer de pulmão é ilustrativo a esse respeito. Durante décadas, pesquisadores enfrentaram dificuldades para diferenciar correlação de causalidade em estudos epidemiológicos sobre tabagismo. Muitos estudos iniciais baseados apenas em correlação eram contestados por não apresentarem mecanismos claros ou critérios objetivos para validar inferências causais. Fisher (1958), por exemplo, questionou os resultados iniciais que ligavam o cigarro ao câncer por falta de critérios explícitos para identificar uma relação causal, argumentando que a correlação observada poderia decorrer de fatores confundidores, causalidade reversa ou problemas de mensuração. A situação mudou gradualmente com contribuições metodológicas importantes, como os critérios de causalidade propostos por Hill (1965). Os critérios de Bradford Hill ofereceram uma lista explícita e sistemática para avaliar a plausibilidade causal em estudos observacionais: O efeito deveria ser grande reproduzível em estudos independentes possuir uma relação monotônica com “dose” (isto é, aumento na dose não pode reduzir o efeito se o efeito é positivo e vice-versa se for negativo). corresponde a um “experimento natural”” se comporta apropriadamente quando a causa é aplicada, removida e então reinstalada. é consistente com o conhecimento especializado do tema é, por exemplo, predita por alguma teoria bem estabelecida. Nós temos amplas evidências de que muitas intervenções são causais, mesmo na ausência de qualquer experimento aleatório controlado. Sabemos, por exemplo, que defribilação, manobra de Heimlinch e uso de paraquedas são eficazes para prevenir mortes [@howick_etal_2009]. Em um artigo clássico dos primórdios da estatística escrito por Yule [@yule_1989], temos um dos primeiros exemplos de utilização da regressão para estudar o efeito causal do efeito de uma política (ajuda sobre pobreza). E a despeito do título do artigo falar em causalidade (“An investigation into the causes of changes in pauperism in england, chiefly during the last two intercensal decades”), a certa altura ele diz, em nota de rodapé, que “due to” deve ser lido como “associated to”. Quase cem anos depois, o grande estatístico Cox afirmaria em um artigo sobre causalidade: “it is remarkable how relatively little causality is mentioned in the general statistics literature, except in a social science context”[@cox_1992, p. 292]. Exemplo da perspectiva de que falava Cox quando, por exemplo, @muthen_1987 chegou a afirmar que “It would be very healthy if more researchers abandon thinking of and using terms such as cause and effect” (p. 180). Algo ecoado em uma entrevista com um dos líderes da evolução causal desde os anos 70/80, Jamie Robins, que relata que seus papers (en journals de estatística) eram rejeitados por usar linguagem causal, algo rejeitado na época [@robins_2022]. Então parece bastante seguro dizer que a sensação geral na estatística até os anos 80 é que não se deveria usar linguagem causal fora de estudos experimentais, isto é, em estudos não-observacionais. 2.1 Causalidade e o Método Comparativo A ideia de causalidade é bastante presente na ciência política na literatura de polític comparada qualitativa. Empregando os métodos advogados por Stuart Mill, a ideia de causalidade sempre estive presente e associada a ideias de relações necessárias e ou suficientes. Nesse sentido, causalidade seria determiniística. A moderna forma de pensar causalidade abandona esse paradigma de relações necessárias e/ou suficientes, para pensar em termos de contrafactual, o que no fundo é próximo do que a pesquisa comparada fazia. Tomemos um exemplo clássico dessa literatura. [inserirautor] estava interessado em estudar o efeito ccausal de [inserir variável de tratamento] sobre [variável de resultado], e comparou [unidade de tratamento] com [unidade de controle]. 2.2 Potential Outcomes Objetivos de aporendizado da aula: Aprender a diferença entre esimando, estimador e estimativa. Aprender as condições de identificação do ATE (Average Treatment Effect) 2.3 Notação Vamos assumir que existe um tratamento binário, que recebe o valor \\(1\\) se a unidade \\(i\\) recebe o tratamento, e \\(0\\) caso contrário, dado por: \\(D_i \\in \\{1,0\\}\\). Suponha que eu tenha \\(N\\) unidades que podem receber o tratamento ou controle. Então, o resultado potencial para a unidade \\(i\\) é \\(Y_i(\\mathbf{D})\\), ou seja, o resultado (potencial) da unidade \\(i\\) dado o conjunto de tratamento recebido por todas as \\(N\\) unidades. Em outras palavras, o resultado potencial depende do status de tratamento de todas as unidades. O que nos leva à primeira suposição simplificadoras: Assumption 1 (Stable Unit Treatment Value Assumption) Se \\(D_i = D{&#39;}_i\\), então \\(Y_i(\\mathbf{D}) = Y_i(\\mathbf{D}^{&#39;})\\). Em palavras, se mudarmos o tratamento de \\(i\\) de \\(D\\) para \\(D&#39;\\), então o resultado potencial depende apenas dessa mudança, e não dos demais tratamentos. Ou seja, o resultado potencial depende apenas do próprio tratamento, não dos demais. Essa suposição també é chamada de não-interferência. Então podemos escrever o resultado potencial apenas como função de \\(D_i\\): \\(Y_i(D_i)\\). Entretanto, os resultados potenciais não são observáveis. O que nós observamos é o resultado se a pessoa foi ou não tratada. O que nos leva à “switching equation”: \\(Y_i = Y_i(1)D_i + (1-D_i)Y_i(0)\\) Podemos agora definir o efeito causal do tratamento ao nível da unidade: \\(\\tau_i = Y_i(1) - Y_i(0)\\) A switching equation conecta o observado aos resultados potenciais e vice-versa. Esse modelo é chamado de Modelo Causal de Neyman-Rubin. 2.4 Problema Fundamental da Inferência Causal Barizado por Holland (1986) de Problema Fundamental da Inferência Causal (PFIC) diz que não podemos observar, simultanemente, ambos os resultados potenciais \\(Y_i(1)\\) e \\(Y_i(0)\\). Possívels soluções para o PFIC: Assumir homogeneidade temporal (comparação antes de depois da mesma unidade) Assumir homogeneidade da unidade (comparar dois indivíduos, um tratado, outro no controle) Método estatístico (foco na esperança) 2.5 Estimando O que nós estamos interessados em estimar é o nosso Estimando. Lundberg et al. (2021), definem de maneira bem completa o que é um estimando. Informalmente, é a quantidade causal que queremos estimar. Os autores separam o estimando teórico do estimando estatístico. O estimando teórico especifica a unidade teórica de interesse (ex.: o efeito de instituicões inclusivas sobre o desenvolvimento economômico do país \\(i\\); “A Dilma teria sofrido impeachment se a lava-jato não existisse?”). O segundo componente é a população-alvo. Se formos agregar essa unidade, é sobre quem ou quê? No primeiro caso, é a categoria de países em desenvolvimento em 1990? Todos os países independentes do globo no seçulo XX? No segundo caso, é mais difícil pensar qual é a população alvo. Talv ez já seja a população e, nesse caso, nao cabe se perguntar sobre qume agregaríamos a quantidade. Ou talvez a pergunta de pesquisa seja sobre crises econômicas e impeachment, e o Brasil é só um caso. Daí a população alvo pode ser, talvez, países latino-americanos. Nesse caso, a pesquisadora deverá argumentar sobre como o estudo de caso é informativo sobre a população-alvo. Estimando estatístico ou empírico é a quantidade que pode ser estimada estatisticamente (a princípio). Estimativa: a aproximação do estimando usando uma amostra finita de dados Estimador: o método ou fórmula para se chegar a uma estimativa para um estimando. 2.6 Estimandos Mais Comuns 2.6.1 ATE Vamos definir o ATE e mostrar condições suficientes para identificação desse estimando. O ATT é simplesmente o efeito causal médio entre todos os indivíduos de uma população. Às vezes chamado de PATE, de Populational Averate Treatment Effect. Definição 2.1. Chamamos de ATE na população: \\[\\tau_{\\text{ATE}} = \\mathbb{E}[\\tau_i] = \\mathbb{E}[Y_i(1) - Y_i(0)] = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)]\\] O ATE nos dá o efeito do tratamento em toda a população de interesse. 2.6.2 ATT Definição 2.2. Chamamos de Average Treatment Effect on the Treated (ATT): \\[\\tau_{\\text{ATT}} = \\mathbb{E}[\\tau_i|D_i=1] = \\mathbb{E}[Y_i(1) - Y_i(0)|D_i=1] = \\underbrace{\\mathbb{E}[Y_i(1)|D_i=1]}_{\\text{observado}} - \\mathbb{E}[Y_i(0)|D_i=1]\\] Note que \\(\\mathbb{E}[Y_i(1)|D_i=1]\\) é um resultado potencial que podemos observar, já que é igual ao resultado realizado dos tratados. Esse estimando estima o efeito do tratamento apenas entre os tratados. Essa quantidade é, tipicamente, a mais relevante em políticas públicas. Considere a política pública de vacinação. O que é mais importante, saber o efeito causal da vacina em toda a população, ou em toda a população que tomaria a vacina (tratados)? Ou para dar um exemplo mais claro ainda. Não é relevante o efeito do bolsa-famnília sobre redução da pobreza em toda a população, nem mesmo se considerarmos que a população alvo é toda a população pobre. Pessoas que não vão participar do programa não importam muito. Importam as que efetivamente irão receber o programa. 2.6.3 CATE Vamos definir o Conditional Average Treatment Effect (CATE). Seja \\(X_i\\) um conjunto de co-variáveis pré-determinadas (não causadas pelo tratamento). Então, podemos definir o CATE como: \\[\\tau_{\\text{CATE}} = \\mathbb{E}[\\tau_i|X_i=x] = \\mathbb{E}[Y_i(1) - Y_i(0)|X_i=x] = \\mathbb{E}[Y_i(1) - \\mathbb{E}[Y_i(1)|X_i=x]\\] Retornando ao nosso exemplo da introdução da urna eletrônica em um município sobre a pobreza municipal. ATE: O efeito médio de um município ter urna eletrônica sobre a pobreza municipal comparado a voto em papel. ATT: O efeito médio da urna eletrônica nos municípios que receberam urna eletrônica sobre a pobreza municial comparado a voto em papel. CATE: O efeito médio de urna eletrônica sobre a pobreza municipal, em um determinado grupos de municípios (ex. do semiá-rido do Nordeste), comparado a voto em papel. Se \\(X\\) for discreto, podemos estabelecer a seguinte relação entre ATE e CATE: \\[\\tau_{\\text{ATE}} = \\sum_{x \\in X} \\tau_{\\text{CATE}}(x) p(X_i = x)\\] Há outros estimandos possíveis, mas esses são os mais comuns. 2.7 Nota sobre estimandos A rigor, podemos caracterizar ao nível da população dois contrastes: a distribuição de probabilidade de resultados potenciais do tratamento com a do controle, para um dado conjunto de covariáeis de pré-tratamento \\(\\mathbf{X}\\). Formalmente, sejam \\(f(Y(1)|\\mathbf{X})\\) e \\(f(Y(0)|\\mathbf{X})\\) as densidades dos dois resultados potenciais, então \\(f(Y(1)|\\mathbf{X} - f(Y(0)|\\mathbf{X})\\) configura uma nova distribuição, da diferença entre os dois resultados potenciais. Nossa ênfase na esperança, portanto, é tanto uma questão de conveniência matemática quanto potencial interesse de pesquisa em um estimando em torno da média da diferença dessas duas distribuições, mas nada impede, a princípio, que estimarmos toda a distribuição da diferença. Outra observação: como veremos mais para frente no curso, dados longitudinais não possuem estimandos claros. Alguns pesquisadores mais rigorosos em política comparada, por exemplo, falam em efeito de país-ano, pois esta é a unidade de análise e o estimando é definido nesse nível. Como veremos também mais para frente (e é um tema de pesquisa meu), também é complicado definir as condições de identificação em dados longitudinais. Voltaremos a isso. 2.8 Exercício - Qual o estimando e o estimador (se possível)? Abstract 1 Abstract 2 Abstract 3 2.9 Identificação “Econometric identification really means just one thing: model parameters or features being uniquely determined from the observable population that generates the data”(Lwebel, apud Paul GP). Ou seja, se você tiver acesso a uma amostra infinita, isto é, não há problemas inferenciais de amostra pequena, é possível estimar precisamente o parâmetro de interesse? Dizemos que, nesse caso, o estimando é identificável. O que seria um estimando não-identificável? Digamos que estou interessado em estimar o efeito causal da segunda dose de uma vacina sobre internação por uma doença. Para a pessoa receber a segunda dose, obviamente ela precisa receber a primeira. Suponha que a primeira dose ajuda a reduzir a internação. É impossível estimar o efeito causal da segunda dose. Para mostrar que o ATE é identificado, vamos supor o que chamamos de ignorabilidade forte (strong ignorability). Definição. Dizemos que \\(D_i\\) é fortemente ignorável condicional a um vetor \\(\\mathbf{X_i}\\) se: 1. \\(Y_i(1), Y_i(0) \\perp D_i\\) 2. \\(\\exists \\epsilon &gt; 0 \\text{ tal que } \\epsilon &lt; Pr(D_i = 1 | \\mathbf{X_i}) &lt; 1 - \\epsilon\\) Em palavras, a primeira condição diz que os resultados potenciais são independentes de receber ou não o tratamento. Quando pensamos em modelos com seres humanos ou unidades com agência, a principal preocupação é que as unidades não se auto-selecionam no tratamento que lhes é mais benéfico (ou que acreditam sê-lo). Às vezes na literatura essa condição aparece como permutabilidade (exchangeability): Como dizem Hernan e Robins em seu livro, “the treated and the untreated are exchangeable because the treated, had they remained untreated, would have experienced the same average outcome as the untreated did, and vice versa.”(p. 29). A segunda condição, conhecida como commmon support ou overlaping condition, diz que não existe unidade que não possa receber o tratamento ou controle. Essa condição é mais forte do que a positividade (toda unidade tem probabilidade positiva de receber o tratamento). Quero explorar aqui essa condição por meio de uma simulação. Vamos supor que um efeito causal \\(\\tau_i\\) tem distribuição normal com média \\(2\\) e desvio-padrão \\(2\\). E vamos supor que pessoas com \\(\\tau_i &gt;6\\) não podem receber o tratatamento, apenas o controle. Veremos que o efeito causal para esse subgrupo não é identificado e mesmo o ATE não é identificado. ## d1 ## d 0 1 ## 0 5019 0 ## 1 396 4585 ## [1] 2.013731 ## [1] 1.37696 Um último comentário: ignorability às vezes aparece como “tratamento é exógeno”. Porém, exogeneidade ignora a segunda condição e trata apenas da primeira. Em uma audiência de ciência política, dizemos que o tratamento é condicionalmente aleatório ou exógeno (o que é impreciso). 2.10 Identificação do ATE Teorema 1: Se \\(D_i\\) é fortemente ignorável condicional a \\(\\mathbf{X_i}\\), então: \\[\\mathbb{E}[\\tau_i] = \\sum_{x \\in X}(\\mathbb{E}[(Y_i|D_i=1, \\mathbf{X_i} = x)] - \\mathbb{E}[(Y_i|D_i=0, \\mathbf{X_i} = x)])Pr(\\mathbf{X_i = x})\\] Prova: O ATE foi definido como: \\[\\mathbb{E}[\\tau_{\\text{ATE}}] = \\mathbb{E}[\\tau_i] = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)]\\] Pela LIE, temos que: \\[\\mathbb{E}[Y_i(1)] = \\mathbb{E}[\\mathbb{E}[Y_i(1)|\\mathbf{X_i}]\\] \\[\\mathbb{E}[Y_i(0)] = \\mathbb{E}[\\mathbb{E}[Y_i(0)|\\mathbf{X_i}]\\] Com ignorabilidade forte, \\(\\mathbb{E}[(Y_i(0)|\\mathbf{X_i}] = \\mathbb{E}[Y_i(0)|D_i=0, \\mathbf{X_i}] = \\mathbb{E}[Y_i|D_i=0, \\mathbf{X_i}]\\). Similarmente, \\(\\mathbb{E}[(Y_i(1)|\\mathbf{X_i}] = \\mathbb{E}[Y_i(1)|D_i=1, \\mathbf{X_i}] = \\mathbb{E}[Y_i|D_i=1, \\mathbf{X_i}]\\). Juntando tudo, chegamos à proposição do teorema. Ou seja, com ignorabilidade forte, podemos estimar o ATE não-parametricamente apenas a partir de observáveis. O CATE também é identificado, como corolário. 2.11 Equações estruturais Normalmente nós temos um modelo que queremos estimar o efeito causal, e não algo sobre o mecanismo de assignment do tratamento. Vamos conectar as duas abordagens. Seja o modelo: \\(Y_i = \\alpha + \\beta D_i + \\epsilon_i\\). Nós intrepretamos \\(\\beta\\) como a diferença média no \\(y\\) de uma unidade no tratamento, formalmente: \\(\\mathbb{E}[Y|D_i=1] - \\mathbb{E}[Y|D_i=0] = \\mathbb{E}[\\alpha + \\beta D_i + \\epsilon_i|D_i=1] - \\mathbb{E}[\\alpha + \\beta D_i + \\epsilon_i|D_i=0] = \\beta + \\mathbb{E}[\\epsilon_i|D_i=1] - \\mathbb{E}[\\epsilon_i|D_i=0]\\). E dizemos que, sob a suposição de esperança condicional zero do erro, ou seja, \\(\\mathbb{E}[\\epsilon_i|D_i=1] = \\mathbb{E}[\\epsilon_i|D_i=0] = 0\\). Portanto, temos que \\(\\mathbb{E}[Y|D_i=1] - \\mathbb{E}[Y|D_i=0] = \\beta\\). E o estimador de MQO é não-viesado. E de forma geral, temos que \\(\\mathbb{E}[Y|D_i] = \\alpha + \\beta\\), sob a suposição de esperança condicional zero do erro. Vamos mapeá-lo ao modelo de resultados potenciais com a switching equation. \\[ \\begin{aligned} Y_i &amp;= Y_i(0)(1-D_i) + Y_i(1)D_i \\\\ &amp;= Y_i(0) + \\tau_i D_i \\\\ &amp;= Y_i(0) + \\tau_i D_i + \\tau D_i - \\tau D_i\\\\ &amp;= Y_i(0) + \\tau D_i + (\\tau_i - \\tau)D_i \\\\ &amp;= \\mathbb{E}[Y_i(0)|D_i=0] - \\mathbb{E}[Y_i(0)|D_i=0] + Y_i(0) + \\tau D_i + (\\tau_i - \\tau)D_i \\\\ &amp;= \\underbrace{\\mathbb{E}[Y_i(0)|D_i=0]}_{\\alpha} + \\underbrace{\\tau}_{\\beta} D_i + \\underbrace{(\\tau_i - \\tau)D_i + (Y_i(0) - \\mathbb{E}[Y_i(0)|D_i=0])}_{\\epsilon_i} \\\\ \\end{aligned} \\] Nós sabemos que em uma regressão estamos estimando \\(\\mathbb{E}[Y_i|D_i]\\). Podemos agora ver com clareza o que de fato estamos estimamos em termos causais. \\[ \\begin{aligned} \\mathbb{E}[Y_i|D_i=1] &amp;= \\alpha + \\tau + \\mathbb{E}[\\epsilon_i|D_i=1] \\\\ \\mathbb{E}[Y_i|D_i=0] &amp;= \\alpha + \\mathbb{E}[\\epsilon_i|D_i=0] \\\\ \\mathbb{E}[\\epsilon_i|D_i=1] &amp;= \\mathbb{E}[(\\tau_i - \\tau)D_i + (Y_i(0) - \\mathbb{E}[Y_i(0)|D_i=0])|D_i=1] \\\\ &amp;= \\mathbb{E}[(\\tau_i - \\tau)D_i|D_i=1] + \\mathbb{E}[(Y_i(0) - \\mathbb{E}[Y_i(0)|D_i=0])|D_i=1] \\\\ &amp;= \\mathbb{E}[\\tau_i D_i|D_i=1] -\\tau\\mathbb{E}[ D_i|D_i=1] + \\mathbb{E}[Y_i(0)|D_i=1] - \\mathbb{E}[\\mathbb{E}[Y_i(0)|D_i=0]|D_i=1] \\\\ &amp;= (\\mathbb{E}[\\tau_i|D_i=1] -\\tau) + \\mathbb{E}[Y_i(0)|D_i=1] - \\mathbb{E}[Y_i(0)|D_i=0] \\\\ \\mathbb{E}[\\epsilon_i|D_i=0] &amp;= \\mathbb{E}[(\\tau_i - \\tau)D_i + (Y_i(0) - \\mathbb{E}[Y_i(0)|D_i=0])|D_i=1] \\\\ &amp;= \\mathbb{E}[Y_i(0)|D_i=0] - \\mathbb{E}[\\mathbb{E}[Y_i(0)|D_i=0]|D_i=0] \\\\ &amp;= 0 \\end{aligned} \\] Portanto, \\(\\mathbb{E}[Y_i|D_i=1] - \\mathbb{E}[Y_i|D_i=0] = \\tau + (\\mathbb{E}[\\tau_i|D_i=1] -\\tau) + \\mathbb{E}[Y_i(0)|D_i=1] - \\mathbb{E}[Y_i(0)|D_i=0]\\) Em palavras, estimamos o efeito causal médio, \\(\\tau\\), mais um componente que tem a ver com os efeitos causais heterogêneos mais um componente que é a diferença no resultado potencial do controle entre os tratados e o controle. Se \\(\\mathbb{E}[Y_i(0)|D_i=1] - \\mathbb{E}[Y_i(0)|D_i=0] \\neq 0\\), o efeito estimado é viesado. Similarmente, se \\(\\mathbb{E}[\\tau_i|D_i=1] \\neq \\tau\\), também teremos viés, ou seja, se o efeito causal dos tratados for diferente do efeito médio da população, também temos uma estimativa viesada do ATE. Porém, nesse caso, note que estamos viesando para estimar o efeito médio dos tratados, que é o ATT. Para ver isso, suponha que não há diferença nos resultados potenciais de não receber o tratamento entre os tratados e os no grupo controle, de modo que \\(\\mathbb{E}[Y_i(0)|D_i=1] - \\mathbb{E}[Y_i(0)|D_i=0] = \\tau + (\\mathbb{E}[\\tau_i|D_i=1] -\\tau) = \\mathbb{E}[\\tau_i|D_i=1]\\), que é o ATT. 2.12 Modelo versus Desenho Há na literatura (mais de economia) uma distinção entre estimando baseado em modelos e baseado em designs (desenho). Model-based: O estimando é identificado a partir de um modelo dos resultados potenciais, condicional ao tratamento e co-variáveis. O exemplo arquetípico é modelo de diferença em diferenças ou controle sintético, em que estimamos o efeito causal a partir de estimativa do contrafactual a partir de dados observados. Design-based: O estimando é identificado a partir de suposições sobre o mecanismo de atribuição do tratamento e co-variáveis. O exemplo arquetípico desse tipo de pesquisa é o experimento aleatório controlado. 2.13 Exercício em sala Na década de 1970, houve um programa de treinamento e emprego conhecido como National Supported Work (NSW). Este programa temporário visava ajudar trabalhadores desfavorecidos e sem habilidades básicas a ingressarem no mercado de trabalho, oferecendo experiência profissional e orientação em um ambiente protegido. Um aspecto inovador do NSW foi a seleção aleatória de candidatos qualificados para os treinamentos, garantindo que o grupo de tratamento recebesse todos os benefícios do programa, enquanto o grupo de controle não tinha suporte. Os participantes do grupo de tratamento tinham emprego garantido por 9 a 18 meses, dependendo do grupo-alvo e do local. Eles trabalhavam em equipes de 3 a 5 pessoas, reunindo-se frequentemente com um orientador para discutir questões do programa e desempenho. Embora recebessem salários inferiores aos de um emprego regular, havia possibilidade de aumento conforme o desempenho e a frequência. Ao término do período, os participantes precisavam procurar emprego regular. O programa também coletou dados de renda e informações demográficas de ambos os grupos, realizando entrevistas periódicas, o que gerou diferentes tamanhos de amostra entre os estudos. O NSW utilizava um desenho experimental aleatório. Lalonde (1986) comparou os resultados experimentais com dados observacionais. Para isso, substituiu os dados do grupo controle atribuídos aleatoriamente, com dados de três amostras do Current Population Survey (CPS) e do Panel Survey of Income Dynamics (PSID). E usou as técnicas econométricas usuais para isso. O resultado não foi bom para a econometria. Voltaremos a isso mais pra frente. Por hora, vamos estimar efeitos causais com os dados experimentais. O exercício a seguir é adaptado do exercício disponibilizado por Paul GP em seu github, no seu curso de métodos. Esta análise utilizará a amostra de Dehejia e Wahba do conjunto de dados Lalonde do experimento NSW. O conjunto de dados é “lalonde nsw.csv”. A variável de resultado é “re78” (rendimento real em 1978). O indicador de tratamento é “treat”. As demais variáveis são potenciais covariáveis. Para os fins deste conjunto de problemas, assuma que “treat” é atribuído de forma aleatória. Calcule o efeito médio do tratamento da política, \\(\\mathbb{E}[\\tau_i]\\), utilizando uma simples diferença de médias. Calcule o efeito médio do tratamento sobre os tratados da política, \\(\\mathbb{E}[\\tau_i|treat=1]\\). Como ele se compara à parte (a)? ## [1] 1794.342 ## [1] 1794.342 2.14 Referências Lalonde, Robert. 1986. “Evaluating the Econometric Evaluations of Training Programs with Experimental Data.” American Economic Review 76 (4): 604–20. Rajeev Dehejia and Sadek Wahba, “Causal Effects in Non-Experimental Studies: Reevaluating the Evaluation of Training Programs,” Journal of the American Statistical Association, Vol. 94, No. 448 (December 1999), pp. 1053-1062. Rajeev Dehejia and Sadek Wahba, “Propensity Score Matching Methods for Non-Experimental Causal Studies,” Review of Economics and Statistics, Vol. 84, (February 2002), pp. 151-161. Robert Lalonde, “Evaluating the Econometric Evaluations of Training Programs,” American Economic Review, Vol. 76 (1986), pp. 604-620. Lundberg, I., Johnson, R., &amp; Stewart, B. M. (2021). What is your estimand? Defining the target quantity connects statistical evidence to theory. American Sociological Review, 86(3), 532-565. Paul W Holland. Statistics and causal inference. Journal of the American statistical Association, 81(396):945–960, 1986. "],["dags.html", "Capítulo 3 DAGs 3.1 Causalidade 3.2 Introdução 3.3 Os Tipos Básicos de DAGs 3.4 Simulação no R: Ilustrando o Collider Bias 3.5 Definições 3.6 Controle e Ajuste 3.7 Fatorização da Probabilidade Conjunta 3.8 Fatorização e DAGs 3.9 Fatorização, DAGs e Causalidade", " Capítulo 3 DAGs 3.1 Causalidade 3.2 Introdução Uma das principais abordagens para fazer inferência causal utiliza diagramas causais chamados de Directed Acyclic Graphs (DAG). Ela foi desenvolvida na ciência da computação entre os anos 80 e 90 e é associada com o trabalho pioneiro de Judea Pearl. Veja o livro The Book of Why para uma história de como surgiu essa abordagem. Abaixo temos um exemplo simples de um DAG: Eles são chamados de DAGs porque os gráficos são direcionados (apontam em uma direção), acyclic porque não permitem ciclos (isto é, se A causa B, B não pode causar A) e graphs porque, como você pode imaginar, são grafos. No exemplo acima, o DAG é formado por três variáveis {y, x, z} que são, em geral, variáveis aleatórias. E as flechas indicam direção de causalidade. Ou seja, \\(x\\) causa \\(y\\) e \\(z\\) causa \\(x\\). É importante saber que DAGs são não paramétricos. Eles podem ser interpretados como: \\(y = f(x, z)\\). Ou seja, qualquer função de x e z são igualmente possíveis. Eis alguns exemplos compatíveis com o DAG acima: \\(y = x + z\\) \\(y = 10 + x + z + x*z\\) \\(y = 3*x^z\\) \\(y = \\pi*z/x + x^2 + 1/(z^3)\\) A razão porque não escrevemos DAGs como equações é porque \\(y = f(x, z)\\) não expressa adequadamente a relação de causalidade pois, em matemática, é indiferente escrever \\(f(x, z) = y\\) ou \\(y = f(z, x)\\). Porém, dizer que \\(x\\) e \\(z\\) causam \\(y\\) é muito diferente de dizer que \\(y\\) causa \\(x\\) e \\(z\\). E com o DAG as flechas indicam a direção da causalidade. 3.3 Os Tipos Básicos de DAGs 3.3.1 1. Chains Em uma chain, x causa w que, por sua vez, causa y. Aqui, w pode ser considerado o mediador do efeito de x sobre y. Exemplo: O desempenho econômico de um país pode aumentar a popularidade do presidente, o que leva a mais votos. Representação: 3.3.2 2. Forks Em um fork, uma variável w causa ambos x e y. Dessa forma, w é uma causa comum que pode gerar correlação espúria entre x e y. Exemplo: A qualidade de um candidato pode fazer com que ele arrecade mais dinheiro para a campanha e, ao mesmo tempo, obtenha mais votos. Representação: 3.3.3 3. Colliders Em um collider, x causa w e y também causa w. Esse tipo de estrutura é também chamado de “fork invertido”. Apesar de x e y não terem relação causal direta, controlar para w (ou um de seus descendentes) pode introduzir uma correlação espúria entre x e y. Exemplo: Imagine que você organiza uma festa e convida apenas pessoas que fazem ciência política ou são canhotas. Na população geral pode não haver relação entre essas características, mas na festa pode surgir uma correlação: se uma pessoa é canhota, ela pode ter maior probabilidade de fazer ciência política. 3.4 Simulação no R: Ilustrando o Collider Bias Vamos rodar uma simulação para ilustrar o collider bias. Suponha que 10% das pessoas fazem ciência política e 5% são canhotas. library(dplyr) set.seed(4) # Gerando as variáveis cp &lt;- rbinom(1000, 1, p = 0.1) # 10% fazem ciência política canhoto &lt;- rbinom(1000, 1, p = 0.05) # 5% são canhotos # Definindo a condição da festa: convida se faz ciência política ou é canhoto festa &lt;- ifelse(cp == 1, 1, ifelse(canhoto == 1, 1, 0)) tabela &lt;- data.frame(cp, canhoto, festa) # Correlação na população geral cor_geral &lt;- round(cor(cp, canhoto), 2) print(cor_geral) ## [1] -0.02 # Correlação entre os que foram à festa cor_festa &lt;- tabela %&gt;% filter(festa == 1) %&gt;% summarise(cor = round(cor(cp, canhoto), 2)) print(cor_festa) ## cor ## 1 -0.95 Na população em geral, a correlação é próxima de zero (aproximadamente -0,02). Porém, entre as pessoas que foram à festa, a correlação pode chegar a -0,95, evidenciando como condicionar em um collider (neste caso, a variável festa) pode induzir correlação espúria. 3.5 Definições Path (caminho): É uma sequência de flechas conectadas. Um directed path (caminho dirigido) é aquele em que todas as flechas seguem a mesma direção (por exemplo, \\(x \\to z \\to y\\)). 3.5.1 Relações entre Variáveis (nós): As relações são descritas usando termos da genética, como pais, filhos, ancestrais, descendentes e vizinhos. Pais e filhos referem-se a relações diretas. Ancestrais e descendentes incluem todas as variáveis em qualquer posição no caminho. Um path sem collider está aberto; um path com collider está fechado. Duas variáveis (ou conjuntos) estão d-separated se não houver caminho aberto entre elas. Caso contrário, podem ou não ser independentes, pois múltiplos caminhos abertos podem se cancelar. 3.6 Controle e Ajuste No contexto dos DAGs, controlar para variáveis pode ter diferentes significados: Experimentos: Controlar significa manipular o valor da variável pelo pesquisador. Exemplo: Um experimento em que o resultado do lançamento de uma moeda determina se um pedido de acesso à informação será feito por um homem ou mulher. Estudos Observacionais: Controlar significa condicionar (estratificar ou incluir em uma regressão). Para visualizar isso em um DAG, considere o seguinte DAG: Controlar para C, nesse DAG, significa efetuar os seguintes passos, na sequência: 1. Eliminar todas as flechas que saem de C. Se C for um collider, elimine as flechas que vão para C e conecte os parentes de C por meio de linhas tracejadas. elimine C Manipular: Determinar o valor da variável. Alterar o Gráfico: Para controlar a variável G (por exemplo, se relacionada a C): Eliminar as flechas que saem de G. Eliminar as flechas do collider (no caso, c e u, parentes de G) e criar relação bi-direcional espúria. Remover G do gráfico. Em resumo, se C depende de A e B de forma independente, condicionar em C pode criar uma relação espúria entre A e B. Por exemplo, se A e B são binárias e \\(C = A + B\\), para \\(C = 1\\) saber o valor de A determina automaticamente o valor de B, e vice-versa. De modo geral, condicionar em um collider inverte o status dos caminhos: caminhos que estavam abertos podem se fechar e vice-versa. Além disso, condicionar em um descendente de um collider também pode alterar os efeitos, atenuando ou abrindo caminhos que originalmente estavam fechados. 3.7 Fatorização da Probabilidade Conjunta Toda distribuição de probabilidade obedece à regra da cadeia de probabilidades (nenhuma suposição adicional). Lembremos: \\(Pr(X,Y) = Pr(Y|X) Pr(X) = Pr(X|Y) Pr(Y)\\) Similarmente, \\(Pr(X,Y,Z) = Pr(Y|X,Z) Pr(X|Z) Pr(Z) = Pr(X|Y,Z) Pr(Y|Z) Pr(Z) = Pr(Z|Y,X) Pr(X|Y) Pr(X) = \\cdots\\) De maneira geral, se temos \\(n\\) variáveis marginais, temos no total \\(n!\\) maneiras distintas de fatorar a distribuição conjunta. A lógica é assim&gt; Seja uma pmf conjunta \\(Pr(x_1, x_2, ..., x_k)\\). Então, podemos usar a regra do produto: \\(Pr(x_1, x_2, ..., x_k) = Pr(x_1) Pr(x_2, ..., x_k|x_1)\\) Aplicando a regra iterativamente, \\(Pr(x_2, ..., x_k|x_1) = Pr(x_2|x_1)Pr(x_3, ..., x_k|x_1, x_2)\\), de forma que: \\(Pr(x_1, x_2, ..., x_k) = Pr(x_1) Pr(x_2|x_1)Pr(x_3, ..., x_k|x_1, x_2)\\) E assim por diante, até: \\(Pr(x_1, x_2, ..., x_k) = Pr(x_1) Pr(x_2|x_1) Pr(x_3| x_2, x_1) \\cdots Pr(x_k|x_1, x_2, x_3, ... , x_{k-1})\\) A Regra do produto pode ser aplicada em qualquer ordem, gerando fatorizações distintas. 3.8 Fatorização e DAGs Existem teoremas que mostram que existe uma relação entre DAGs e fatorização de probabilidades conjuntas. Dado um DAG, em que um nós é independente condicional a outro nó, isso implica a fatorização da probabilidade conjunta de acordo com essa relação, e vice-versa. Dois exemplos abaixo ilustram essa propriedade. Considere o DAG abaixo: Nós sabemos que, condicional a X, Y é independente de Z, W e M. Similarmente, X é independente de M, condicional a Z e W. Podemos então fatorar a distribuição conjunta da seguinte maneira: \\[Pr(M, W, X, X, Y) = Pr(M) Pr(Z|M) Pr(W|M) Pr(X|W,Z) Pr(Y|X)\\] Ou seja, basta escrever a probabilidade condicional nas variáveis que tornam cada nós independente para descrever a distribuição de probabilidade conjunta. 3.9 Fatorização, DAGs e Causalidade De volta à causalidade, um DAG em que não há confouding, isto é, sem back-door aberto, como o DAG abaixo, implica que a fatorização observacional é igual à fatorização intervencional: \\[Pr(Y = y |do (X = x)) = Pr(Y|X)\\] Logo, é verdade que \\[Pr(Y,X) = P(X)Pr(Y|X) = Pr(X)Pr(Y = y |do (X = x))\\]. O operador “do” aqui é uma inovação do Pearl, e diz que fizemos uma cirurgia no gráfico e determinamos, exogenamente, por assim dizer, que o valro de \\(X\\) é \\(x\\). Referências Hernán MA, Robins JM (2019). Causal Inference. Boca Raton: Chapman &amp; Hall/CRC. Disponível temporariamente em: https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/ Greenland, S., &amp; Pearl, J. (2014). Causal diagrams. Wiley StatsRef: Statistics Reference Online, 1-10. "],["experimentos.html", "Capítulo 4 Experimentos 4.1 Introdução 4.2 Experimentos aleatórios 4.3 Restrição de Exclusão 4.4 Tipos de experimentos 4.5 Estimador ATE 4.6 Key Takeways 4.7 Declare Design 4.8 Exercício", " Capítulo 4 Experimentos 4.1 Introdução Um experimento é o desenho de pesquisa no qual a pesquisadora controla o mecanismo de atribuição do tratamento e controle Seja \\(p_i = P(T_i=1)\\). Então \\(p_i\\) é conhecido e controlado pela pesquisadora. Em contraposição, um estudo observacional é quando a pesquisadora não controla o mecanismo (natureza ou realidade social) Quando uma quantidade potencial (estimando) pode ser descrita em função da distribuição de dados observáveis, dizemos que o estimando é identificável. De outro modo, não identificado. Veremos porque experimentos produzem desenhos críveis de identificação causal Vamos supor experimentos ideais (sem attrition ou non-compliance) Nós já vimos que uma suposição crítica é a SUTVA. Stable Unit Treatment Values Assumption Não interferência e sem varição escondida no tratamento PO não varia com o tratamento atribuiído a outra unidades PO de uma unidade não é impactado pelo nível de tratamento de outras unidades Para cada unidade, não há formas distintas ou versões de cada nível de tratamento Definição não-ambígua do tratamento Supondo SUTVA, Diferença Simples de Média pode ser decomposta em ATE + viés de seleção \\(\\underbrace{\\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0]}_{\\text{Simple Difference in Outcomes (SDO)}} = \\mathbb{E}[Y_i^1|T_i=1] - \\mathbb{E}[Y_i^0|T_i=0]\\) Podemos adicionar e subtrair os resultados contrafactuais para os tratados \\(= \\mathbb{E}[Y_i^1|T_i=1] - \\color{blue}{\\mathbb{E}[Y_i^0|T_i=1]} + \\color{red}{\\mathbb{E}[Y_i^0|T_i=1]} - \\mathbb{E}[Y_i^0|T_i=0]\\) \\(= \\underbrace{\\mathbb{E}[Y_i^1 - Y_i^0|T_i=1]}_{\\text{ATT}} + \\underbrace{\\mathbb{E}[Y_i^0|T_i=1] - \\mathbb{E}[Y_i^0|T_i=0]}_{\\text{Viés de Seleção}}\\) 4.2 Experimentos aleatórios Mecanismo de atribuição de tratamento é probabilístico (Positividade): \\(0 &lt; p_i &lt; 1\\). Unconfoundedness ou Permutabilidade (ou assignment mechanism–ignorability): \\(P(T_i=1|y^1, y^0) = P(T_i)\\). O que é Permutabilidade (uncounfoudedness)? A distribuição dos resultados potenciais é independente do tratamento. \\(\\mathbb{E}[Y^1|T=1] = \\mathbb{E}[Y^1|T=0]\\) \\(\\mathbb{E}[Y^0|T=1] = \\mathbb{E}[Y^0|T=0]\\) Resultados potenciais são independentes do tratamento, dadas as covariáveis. Se a condição de tratamento fosse hipoteticamente trocada, os resultados esperados permaneceriam os mesmos. Isso significa que em um experimento com permutabilidade, não temos viés de seleção (Por quê?). Independência entre tratamento e resultados potenciais implica que \\(\\mathbb{E}[Y^0_i|T_i=1] = \\mathbb{E}[Y^0_i|T_i=0] = \\mathbb{E}[Y^0_i]\\) Portanto, o viés de seleção, dado por \\(\\mathbb{E}[Y_i^0|T_i=1] - \\mathbb{E}[Y_i^0|T_i=0]\\), fica: \\(\\mathbb{E}[Y_i^0|T_i=1] - \\mathbb{E}[Y_i^0|T_i=0] = \\mathbb{E}[Y_i^0] - \\mathbb{E}[Y_i^0] = 0\\) Ou seja, SDO estima o ATE (via ATT). \\(\\underbrace{\\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0]}_{\\text{Simple Difference in Outcomes (SDO)}} = \\underbrace{\\mathbb{E}[Y_i^1 - Y_i^0|T_i=1]}_{\\text{ATT}} = ATE\\) 4.3 Restrição de Exclusão Formalmente, podemos separar a alocação do tratamento e o tratamento efetivamente recebido. Seja \\(Z_i\\) a alocação do tratamento e \\(T_i\\) o tratamento recebido. Então, a restrição de exclusão quer dizer que o que importa é o tratamento efetivamente recebido \\(T_i\\), e não a variável que aloca o tratamento \\(Z_i\\). Formalmente, isso quer dizer que: \\(Y^{1,z=1, T}_i = Y^{1,z=0, T}_i = Y^{1,T}_i\\) e similarmente, \\(Y^{0,z=0,T}_i = Y^{0,z=0,T}_i = Y^{0,T}_i\\) Quando não ocorre isso? Se o mecanismo de atribuição do tratamento dispara outras causas Suponha que um experimento é sobre efeito de transferência de dinheiro em bem-estar Se ongs, sabendo do experimento, forem ajudar quem não tiver sido alocado para receber dinheiro Se houver erro de mensuração assimétrico? Pesquisadores distintos entrevistam recipientes e não-recipientes da transferência de dinheiro, com habilidades distintas Ou questionários diferentes. Erro de mensuração assimétrico Nova switching equation. Seja \\(e_{i1}\\) o erro de mensuração cometido se uma observação é atribuída para o tratamento, e, analogamente, \\(e_{i0}\\) o erro para o controle. De \\(Y_i = T_iY^1_i + (1- T_i)Y^0_i\\) para \\(Y_i = T_i(Y^1_i + e_{i1}) + (1- T_i))(Y^0_i + e_{i0})\\). Novo SDO: \\(\\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0] = \\mathbb{E}[Y^1_i + e_{i1}|T_i=1] - \\mathbb{E}[Y^0_i + e_{i0}|T_i=0] = \\mathbb{E}[Y^1_i|T_i=1] + \\mathbb{E}[e_{i1}|T_i=1] - \\mathbb{E}[Y^0_i|T_i=0] - \\mathbb{E}[e_{i0}|T_i=0]\\) Novo SDO pode se rearranjado: \\(\\underbrace{\\mathbb{E}[Y^1_i|T_i=1] - \\mathbb{E}[Y^0_i|T_i=0]}_{\\text{antigo SDO}} + \\underbrace{\\mathbb{E}[e_{i1}|T_i=1] - \\mathbb{E}[e_{i0}|T_i=0]}_{\\text{Dif média no erro de mensuração}}\\) Se \\(\\mathbb{E}[e_{i1}|T_i=1] \\neq \\mathbb{E}[e_{i0}|T_i=0]\\), então SDO será viesado. Como Garantir a restrição de Exclusão? Double blindness (duplo cego) Paralelismo na administração do experimento (mesmo questionário e mesmos entrevistadores) Na pior das hipóteses, aleatorização dos entrevistadores. 4.4 Tipos de experimentos 4.4.1 Aleatorização de Bernoulli É o experimento com aleatorização simples (basicamente, lançamento de moeda) Matematicamente, \\(p_i(T_i=1) = p\\). Problema: Possível “má aleratorização” (todo mundo no controle ou tratamento) ps.: toda aleatorização realizada é matematicamente equivalente. Possui \\(2^n\\) configurações possíveis de alocação entre tratamento e controle set.seed(10) n &lt;- 50 hist(replicate(1000, sum(rbinom(n, 1, 0.5))), main = &quot;aleatorização de Bernoulli&quot;, xlab = &quot;Número de tratados&quot;, col = &quot;lightblue&quot;) + xlim(0,50) 4.4.2 Aleatorização Completa Seleciono aleatoriamente um número fixo de pessoas para tratamento e controle Ex.: 25 para tratamento e 25 para controle Basta numerar cada unidade (de 1 a 50) e amostrar 25 aleatoriamente para tratamento (e restante para controle) Vantagem: garanto número de obs em cada condição Possui \\({N \\choose \\frac{n}{2}}\\) configurações possíveis de alocação entre tratamento e controle. Intuição: estamos jogando fora as aleatorizações “indesejáveis”. Cálculo da variância é mais complexo 4.4.3 Aleatorização Condicional (Block Random Assigment) Definição: Experimento é condicionalmente aleatório se a aleatorização depende de variáveis pré-tratamento \\(X\\). Exemplo Binário: Duas moedas, uma para \\(X=1\\) e outra para \\(X=0\\). Aleatorização Marginal vs. Condicional: Marginal: Aleatorização uniforme para todos os indivíduos. Condicional: Aleatorização depende de \\(X\\), gerando permutabilidade condicional a \\(X\\). Permutabilidade Condicional: \\((Y^1, Y^0 | X=x) \\indep T\\). Não gera permutabilidade (não-condicional). Permutabilidade condicional a \\(X\\) é crucial para inferência em contextos com variáveis pré-tratamento. 4.4.4 Pensando aleatorização em bloco Ex.: digamos que em um amostra de 100 pessoas, queremos 25 homens e 25 mulheres no tratamento e controle Sorteio 25 homens para tramento e depois 25 mulheres. Cada bloco possui tamanho 25, neste exemplo. Blocos de tamanho \\(2\\) são chamados de pair-matched design. Em geral, estudos com matching em muitas variáveis Útil para amostras pequenas 4.4.5 ATE com Aleatorização Condicional (Bloco) Estratitificação Efeito heterogêneo por estrato? Podemos calcular o ATE por estrato, já que é aleatório no interior de cada estrato. Efeito geral na população. Podemos calcular ponderando os ATEs. Seja \\(J\\) o número de estratos, indixados por \\(j\\). Seja \\(N\\) o número de unidades e \\(N_j\\) o número de unidades no bloco \\(j\\). Então: \\(ATE = \\sum_{j=1}^J \\frac{N_j}{N}ATE_j\\) 4.4.6 Aleatorização em bloco – Pela Lei dos Grandes números, tende a gerar balanceamento entre blocos – Balanceamento quer dizer que blocos são similares – Em variáveis observadas e não-observadas – Probabilidade de tratamento pode variar por bloco. – Chamada de propensity score. 4.4.7 Precisão da aleatorização em bloco Em geral a precisão aumenta (erro padrão diminui) com aleatorização em bloco. Intuição é que removemos parte da variância (amostras possíveis), condicionando nos estratos Vamos checar uma simulação no R para ver um exemplo do ganho na precisão Lembrem-se que se \\(X\\) e \\(Y\\) são independentes, então \\(Var(aX + bY) = a^2Var(x) + b^2Var(Y)\\). # Set up Potential outcomes and units and blocks n1 &lt;- 10 n2 &lt;- 16 N &lt;- n1+n2 J &lt;- 2 index_block &lt;- c(rep(2, n2), rep(1, n1)) set.seed(12) # potential outcome control y0 &lt;- c(rnorm(n1, 2, 1),rnorm(n2, 6, 1)) y1 &lt;- y0 + 1.5 # potential outcome treatment # block assignment t_bloco1 &lt;- sample(1:n1, n1/2) c_bloco1 &lt;- (1:n1)[!(1:n1 %in% t_bloco1)] t_bloco2 &lt;- sample((n1+1):(n1+n2), n2/2) c_bloco2 &lt;- ((n1+1):(n1+n2))[!((n1+1):(n1+n2) %in% t_bloco2)] y1_obs_bloco1 &lt;- y1[t_bloco1] y1_obs_bloco2 &lt;- y1[t_bloco2] y0_obs_bloco1 &lt;- y0[c_bloco1] y0_obs_bloco2 &lt;- y0[c_bloco2] # random assignment units_simple_treatment &lt;- c(t_bloco1, t_bloco2) units_simple_control &lt;- c(c_bloco1, c_bloco2) y1_obs &lt;- y1[units_simple_treatment] y0_obs &lt;- y0[units_simple_control] # erro padrão erro_pad_simple &lt;- t.test(y1_obs, y0_obs)$stderr simple_p_value &lt;- t.test(y1_obs, y0_obs)$p.value my_t &lt;- mean(y1_obs - y0_obs)/erro_pad_simple erro_pad1 &lt;- t.test(y1_obs_bloco1, y0_obs_bloco1)$stderr erro_pad2 &lt;- t.test(y1_obs_bloco2, y0_obs_bloco2)$stderr erro_padrao_geral &lt;- sqrt(erro_pad1^2*(n1/N)^2 + erro_pad2^2*(n2/N)^2) ate1 &lt;- mean(y1_obs_bloco1 - y0_obs_bloco1)*(n1/N) ate2 &lt;- mean(y1_obs_bloco2 - y0_obs_bloco2)*(n2/N) ate &lt;- ate1 + ate2 my_t &lt;- ate/erro_padrao_geral p_value &lt;- 2*(1 - pt(abs(my_t), df = 23.76567)) print(erro_pad1) ## [1] 0.646563 print(erro_pad1) ## [1] 0.646563 print(erro_padrao_geral) ## [1] 0.3723061 print(p_value) ## [1] 0.0006818314 4.4.8 Comparação de SEs library(knitr) comparison_table &lt;- data.frame( Method = c(&quot;Simple Randomization&quot;, &quot;Block 1&quot;, &quot;Block 2&quot;, &quot;General Block Randomization&quot;), Standard_Error = c(erro_pad_simple, erro_pad1, erro_pad2, erro_padrao_geral) ) knitr::kable(comparison_table, caption = &quot;Comparação de Erros padrão&quot;, align = &#39;c&#39;, format = &quot;latex&quot;) 4.4.9 Cluster randomization Quando aleatorizo o cluster, em vez das unidades. Ex.: Se não for possível aleatorizar um tratamento entre estudantes, aleatorizo escolas No interior de cada escola, todo mundo é tratado ou não-tratado. Não há variação within escolas, apenas entre (between) escolas. Grande perda de variabilidade nos dados, reduzindo precisão (aumento no erro padrão) Às vezes é a única aleatorização possível. 4.4.10 Tabelas em artigos 4.5 Estimador ATE estimativa: \\(\\frac{\\sum_{i=1}^{n}Y_iT_i}{n_1} - \\frac{\\sum_{i=1}^{n}Y_i(1-T_i)}{n_0} = .0608 - .0353 = 0.0255\\) Erro padrão: \\(\\sqrt{\\frac{\\hat{\\sigma_1^2}}{n_1} + \\frac{\\hat{\\sigma_0^2}}{n_0}} = \\sqrt{\\frac{.0608\\cdot(1-.0608)}{1217} + \\frac{.0353\\cdot (1-.0353)}{1217}} = 0.00865\\) Pequena diferença com os coeficientes da tabela Typo? Alguma informação não reproduz exatamente? Fizemos algo errado? treatment &lt;- c(rep(1, 74), rep(0, 1217 - 74)) control &lt;- c(rep(1, 43), rep(0, 1217 - 43)) var_treat &lt;- var(treatment) var_control &lt;- var(control) erro_padrao &lt;- sqrt(var_treat/1217 + var_control/1217) round(erro_padrao, 5) ## [1] 0.00866 t.test(treatment, control) ## ## Welch Two Sample t-test ## ## data: treatment and control ## t = 2.9414, df = 2286.3, p-value = 0.0033 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.008490408 0.042454539 ## sample estimates: ## mean of x mean of y ## 0.06080526 0.03533279 4.6 Key Takeways Experimento (sob SUTVA) elimina o viés de seleção Depende de restrição de exclusão e simetria Vários tipos de experimentos: block aumenta precisão Com N grande, diferença diminui Sempre supomos condições ideais (sem attrition, compliance perfeito etc.) 4.7 Declare Design Uma ferramenta muito útil para experimentos (mas também para estudos observacionais) é o pacote do R Declare Design. Blair, Coppock e Humphreys criaram um framework para definir e avaliar um desenho de pesquisa. Com oresultado, escreveram um livro “Research Design in the Social Sciences”, e um pacote no R para implementar os conceitos desenvolvidos no livro, chamado “DeclareDesign. Para instalar (junto com os datasets usados no livro), basta rodar . O frameowrk é baseado no acrônimo MIDA, que contempla os quatro elementos básicos de um desenho de pesquisa: models, inquiries, data strategies, and answer strategies. Ou seja, você deve especificar um modelo, qual pergunta de pesquisa (aka estimando), quais dados vai utilizar e como vai estimar o estimando. Um modelo descreve o que causa o que e como. Tipicamente especifica a as unidades, o tamanho da amostra e a equação de resultados potenciais. Suponha que quero rodar um experimento aleatório com um tratamento e controle (two-arm randomized experiment). Assim, podemos declarar um modelo com: library(DeclareDesign) model &lt;- declare_model( N = 500, X = rep(c(0, 1), each = N / 2), # tratamento e controle U = rnorm(N, sd = 0.25), # heterogeneidade exógena potential_outcomes(Y ~ 0.2 * Z + X + U) ) Vamos entender o que fizemos. Declaramos que nossa população terá \\(500\\) observações: . Nesse exemplo, a amostra será igual a populacão, mas poderíamos amostrar da população se quiséssemos. Declaramos que \\(X\\), uma covariável, pode assumir dois valores (0,1), e atribuimos a priemria metade pra \\(0\\) e a outra metade para \\(1\\): . Declaramos que existe uma variável \\(U\\) que tem distribuição normal, com \\(N\\) observações e média \\(0\\) e desvio-padrão \\(.25\\):. Declaramos que os resultados potenciais diferem em \\(20\\%\\) entre tratamento e controle (\\(Z\\)) para cada unidade. Uma forma alternativa e talvez mais clara de declarar a relação entre tratamento/controle e resultados potenciais seria escrever . 4.1. Além disso, \\(X\\) tem efeito de \\(1\\) para todas as unidades. Vamos passar agora ao nosso estimando ou inquiry. inquiry &lt;- declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) Se estamos interessados no ATE, é só declarar que é a média da diferença entre os resultados potenciais. Podemos também usar a função Outras possibilidaes incluem o ATT e CATE: , por exemplo. Formulação equivalente para o ATT seria . Estratégia de dados data &lt;- declare_assignment(Z = complete_ra(N = N, m = 250)) + # assigment mechanism declare_measurement(Y = reveal_outcomes(Y ~ Z)) # reveal_outcomes é a switching equation estimator &lt;- declare_estimator(Y ~ Z, inquiry = &quot;ATE&quot;) two_arm_trial &lt;- model + inquiry + data + estimator # Draw a simulated dataset head(draw_data(two_arm_trial), 10) ## ID X U Y_Z_0 Y_Z_1 Z Y ## 1 001 0 0.013136040 0.013136040 0.21313604 1 0.213136040 ## 2 002 0 0.306059991 0.306059991 0.50605999 0 0.306059991 ## 3 003 0 0.248393137 0.248393137 0.44839314 1 0.448393137 ## 4 004 0 0.037319115 0.037319115 0.23731912 0 0.037319115 ## 5 005 0 0.352668514 0.352668514 0.55266851 0 0.352668514 ## 6 006 0 0.364146534 0.364146534 0.56414653 1 0.564146534 ## 7 007 0 0.366437409 0.366437409 0.56643741 1 0.566437409 ## 8 008 0 -0.280273943 -0.280273943 -0.08027394 1 -0.080273943 ## 9 009 0 -0.007617163 -0.007617163 0.19238284 0 -0.007617163 ## 10 010 0 0.195182802 0.195182802 0.39518280 1 0.395182802 Após declarar um desenho de pesquisa, podemos diagnosticar se nosso desenho de pesquisa pode ser respondido adequadamente (isto é, se é identificável, se possui poder para estimar com precisão o efeito de interesse etc.). Podemos inclusive modificar o desenho para responder a outras perguntas (é generalizável para outras populações, diferentes estimadores pdesempenham melhor etc.) Eis um exemplo de diagnóstico: diagnose_design(two_arm_trial, sims = 100) ## ## Research design diagnosis based on 100 simulations. Diagnosis completed in 1 secs. Diagnosand estimates with bootstrapped standard errors in parentheses (100 replicates). ## ## Design Inquiry Estimator Outcome Term N Sims Mean Estimand Mean Estimate Bias SD Estimate RMSE Power Coverage ## two_arm_trial ATE estimator Y Z 100 0.20 0.20 0.00 0.05 0.05 0.95 0.92 ## (0.00) (0.01) (0.01) (0.00) (0.00) (0.02) (0.03) Podemos ajustar o desenh ode pesquisa designs &lt;- redesign(two_arm_trial, N = c(100, 200, 300, 400, 500)) diagnose_design(designs) ## ## Research design diagnosis based on 500 simulations. Diagnosis completed in 13 secs. Diagnosand estimates with bootstrapped standard errors in parentheses (100 replicates). ## ## Design N Inquiry Estimator Outcome Term N Sims Mean Estimand Mean Estimate Bias SD Estimate RMSE Power Coverage ## design_1 100 ATE estimator Y Z 500 0.20 0.20 -0.00 0.05 0.05 0.98 0.95 ## (0.00) (0.00) (0.00) (0.00) (0.00) (0.01) (0.01) ## design_2 200 ATE estimator Y Z 500 0.20 0.20 -0.00 0.05 0.05 0.97 0.96 ## (0.00) (0.00) (0.00) (0.00) (0.00) (0.01) (0.01) ## design_3 300 ATE estimator Y Z 500 0.20 0.20 -0.00 0.05 0.05 0.97 0.94 ## (0.00) (0.00) (0.00) (0.00) (0.00) (0.01) (0.01) ## design_4 400 ATE estimator Y Z 500 0.20 0.20 0.00 0.05 0.05 0.98 0.95 ## (0.00) (0.00) (0.00) (0.00) (0.00) (0.01) (0.01) ## design_5 500 ATE estimator Y Z 500 0.20 0.20 -0.00 0.05 0.05 0.97 0.93 ## (0.00) (0.00) (0.00) (0.00) (0.00) (0.01) (0.01) 4.8 Exercício O exercício abaixo é uma tradução de questões que estavam presentes no exame de qualificação (prelims) da área de métodos do programa de doutorado em ciência política de Yale. 4.8.1 Experimento com envio de cartões-postais e participação eleitoral Você conduz um experimento aleatório para testar o efeito de um cartão-postal sobre a participação eleitoral, sorteando independentemente uma moeda para cada sujeito com probabilidade \\(0 &lt; p &lt; 1\\) de receber o tratamento. Assuma o pressuposto de SUTVA (Stable Unit Treatment Value Assumption). Você estima o seguinte modelo por Mínimos Quadrados Ordinários (OLS): \\[ Y_i = \\beta_0 + \\beta_1 T_i + \\beta_2 S_i + \\beta_3 T_i S_i + u_i \\] em que: - \\(Y_i\\) indica se o indivíduo votou (variável dependente); - \\(T_i\\) é o indicador binário de tratamento (receber ou não o cartão-postal); - \\(S_i\\) é um indicador binário que vale 1 se o indivíduo vive em um estado eleitoralmente competitivo (battleground state) e 0 caso contrário; - \\(T_i S_i\\) é a interação entre o tratamento e o contexto competitivo. 4.8.1.1 (a) Interprete os quatro coeficientes \\(\\beta\\) \\(\\beta_0\\): média de \\(Y_i\\) (taxa de votação) para o grupo controle (\\(T_i = 0\\)) em estados não competitivos (\\(S_i = 0\\)). \\(\\beta_1\\): efeito médio do tratamento (cartão-postal) em estados não competitivos. Como o tratamento foi atribuído aleatoriamente, \\(\\beta_1\\) tem interpretação causal. \\(\\beta_2\\): diferença na taxa média de votação entre estados competitivos e não competitivos no grupo controle. Não tem interpretação causal. \\(\\beta_3\\): diferença no efeito do tratamento entre estados competitivos e não competitivos. Se \\(\\beta_3 \\neq 0\\), o efeito do cartão-postal depende do tipo de estado. Como o tratamento é aleatório, \\(\\beta_3\\) também tem interpretação causal. 4.8.1.2 (b) Como testar a hipótese de que o efeito do tratamento é igual entre os dois tipos de estado? Testa-se a hipótese nula \\(H_0: \\beta_3 = 0\\). Isso pode ser feito diretamente a partir do resultado da regressão usando um teste t para o coeficiente da interação \\(T_i S_i\\). 4.8.2 Experimento com anúncios de TV e participação eleitoral Você quer testar se anúncios de TV aumentam a participação eleitoral. O experimento pode ser conduzido em até 16 mercados de mídia, dos quais até 8 podem ser sorteados para o grupo de tratamento. Os anúncios só podem ser exibidos para o mercado de mídia como um todo. Você tem informações individuais para todos os eleitores elegíveis nesses mercados: mercado de mídia, idade, sexo, raça/etnia e participação nas duas eleições anteriores. Após a eleição, você receberá os dados atualizados sobre participação no pleito atual. 4.8.2.1 (a) Como alocar aleatoriamente os mercados ao tratamento? Sorteie aleatoriamente 8 dos 16 mercados de mídia para o grupo de tratamento. Como o tratamento é atribuído no nível do mercado, essa é a unidade de aleatorização. Recomenda-se balancear o sorteio usando pareamento ou estratificação com base em características agregadas dos mercados (por exemplo, participação passada, composição demográfica), se houver variação relevante entre eles. 4.8.2.2 (b) Como analisar esse experimento? A análise deve ser feita no nível do mercado de mídia, que é a unidade de tratamento. Uma abordagem válida é calcular a média da taxa de votação em cada mercado e rodar uma regressão simples: \\[ \\bar{Y}_j = \\alpha + \\tau D_j + \\varepsilon_j \\] em que: - \\(\\bar{Y}_j\\) é a média da taxa de votação no mercado \\(j\\); - \\(D_j\\) é um indicador de tratamento para o mercado; - \\(\\tau\\) estima o efeito médio do tratamento. É possível incluir covariáveis no nível do mercado para aumentar a precisão, mas não é necessário para validade causal. 4.8.3 Exclusão de participantes em experimentos de survey Pesquisadores às vezes excluem participantes de um experimento de survey por: 1. Não passarem em uma checagem de atenção pré-tratamento; 2. Não passarem em uma checagem de atenção pós-tratamento; 3. Completarem o survey muito rapidamente (por exemplo, 3 desvios-padrão abaixo da média de tempo). 4.8.3.1 (a) Se o interesse é no efeito médio do tratamento entre os sujeitos que não foram excluídos, qual dessas estratégias é não-viesada? Todas essas estratégias podem fornecer estimativas não viesadas para o efeito médio do tratamento entre os sujeitos que permanecem na amostra, desde que os critérios de exclusão sejam pré-tratamento ou não afetem diferencialmente os grupos de tratamento e controle. A exclusão baseada em variáveis observadas antes do tratamento (como checagem pré-tratamento ou tempo de resposta) é menos problemática. Já a exclusão com base em comportamentos após o tratamento (como falha em atenção pós-tratamento) pode introduzir viés, pois pode estar correlacionada com a resposta ao tratamento. 4.8.3.2 (b) Se o interesse é no efeito médio do tratamento entre todos os participantes que iniciaram o experimento, qual dessas estratégias é não-viesada? Nenhuma das exclusões garante uma estimativa não viesada nesse caso. Excluir participantes com base em qualquer critério — mesmo que relacionado à atenção ou tempo de resposta — altera a composição da amostra em relação ao universo original. Para estimar o efeito médio para todos os participantes que começaram o experimento, é necessário manter todos os sujeitos, independentemente do desempenho em checagens ou tempo de resposta. "],["propensity-score-e-matching.html", "Capítulo 5 Propensity Score e Matching 5.1 Introdução 5.2 Propensity Score 5.3 Matching 5.4 Suposições de identificação 5.5 Matching 5.6 Matching exato 5.7 Matching aproximado 5.8 Estimando 5.9 Declare Design e Matching 5.10 Recomendações Práticas sobre Matching 5.11 Referências", " Capítulo 5 Propensity Score e Matching 5.1 Introdução Na aula de hoje, iremos aprender sobre a principal estratégia de “seleção em observáveis”, que é matching. Mas antes, vamos falar de subclassificação ,que é uma técnica mais simples e é útil para introduzir a ideia de matching. 5.2 Propensity Score O propensity score nada mais é que a probabilidade de uma unidade ser tratada, dada as covariáveis, ou seja, \\(Pr(D_i = 1| X_i)\\). A ideia chave para propensity-score vem de um paper de Rosenbaum-Rubin (1983) em que eles mostram que, se a condição 1 de ignorabilidade forte (isto é, \\(Y_i(1), Y_i(0) \\perp D_i|X_i\\)) for satisfeita, então também é verdade que a condição \\(Y_i(1), Y_i(0) \\perp D_i|\\pi(X_i)\\) também é satisfeita. E por que isso é importante? Nós nunca sabemos o verdadeiro modelo que relaciona as convariáveis \\(X_i\\) com \\(D_i\\) e \\(Y_i\\), de modo que podemos ter algum problema de modelo mal especificado (por exemplo, supomos um modelo linear, quando na verdade é não-linear). Então, em vez de estimar dezenas de modelos, posso condicionar (“controlar”) apenas pelo propensity score \\(\\pi(X_i)\\). A intuição é que o propensity score cria balanceamento entre tratados e não-tratados. Para ilustrar o poder desse reusltado, vamos considerar um exemplo simulado, em que ignorability forte é satisfeita, mas um modelo mal-especificado gera amostras não-balanceadas e, portanto, estimativas viesadas. library(knitr) library(tidyverse) library(ggdag) library(arm) # true DGP dag &lt;- dagify( y ~ D + w1, D ~ w1 ) ggdag(dag) O DAG acima ilustra bem qual a relação causal entre variáveis. Para estimar o ATE de \\(D\\) sobre \\(Y\\), precisamos fechar o backdoor de \\(w_1\\). A forma usual como fazemos isso é com regressão. O problema que estamos abordando aqui é quando a amostra é não-balanceada entre tratados e não-tratados, isto é. Vamos visualizar dois tipos de relações (uma linear e outra não-linear) entre a variável de controle \\(w_1\\) e a resposta \\(Y\\) para ilustrar o problema do desbalanceamento: library(ggplot2) set.seed(202) n &lt;- 1e4 w1 &lt;- rnorm(n) # único confundidor tau &lt;- 3 # efeito causal verdadeiro # GERAMOS UM PROPENSITY SCORE NÃO‐LINEAR p &lt;- plogis(-0.5 + 2 * w1) D &lt;- rbinom(n, 1, p) # GERAÇÃO DOS RESULTADOS POTENCIAIS linear (apenas função de w1, forte ignorabilidade): y0 &lt;- 5 * w1 + rnorm(n) y1 &lt;- y0 - tau # efeito constante y &lt;- ifelse(D == 1, y1, y0) df &lt;- data.frame(y=y, D=D, w1=w1) df %&gt;% mutate( D = factor(D, levels = c(0,1), labels = c(&quot;Controle (D = 0)&quot;, &quot;Tratado (D = 1)&quot;)) ) %&gt;% ggplot(aes(x = w1, y = y, colour = D)) + geom_point(alpha = 0.6) + scale_colour_manual( name = &quot;Tratamento (binário)&quot;, values = c(&quot;Controle (D = 0)&quot; = &quot;steelblue&quot;, &quot;Tratado (D = 1)&quot; = &quot;firebrick&quot;) ) + theme_bw() No primeiro gráfico, o efeito causal (ATE) do tratamento é \\(-3\\) e podemos ver nos dados que de fato em média a resposta é menor entre tratados que no controle. Além disso, vemos também que o efeito é basicamente linear. Mas o pontpo importante aqui é que existem duas regiões dos dados em que praticamente só temos unidades no controle (\\(w_1 &lt; -2\\)) e ou no tratamento (\\(w_1 &gt; -2\\)). Isso significa que para que a regressão possa estimar o efeito causal deve extrapolar a estimativa da região em que ambos tratamento e controle estão presentes nos dados para uma região em que não estão presentes. Como o efeito é constante para todas as regiões de \\(w_1\\), isso não causa problema e a regressão consegue recuperar o ATE sem viés. O gráfico abaixo ilustra o que a regressão está fazendo: df %&gt;% mutate( D = factor(D, levels = c(0,1), labels = c(&quot;Controle (D = 0)&quot;, &quot;Tratado (D = 1)&quot;)) ) %&gt;% ggplot(aes(x = w1, y = y, colour = D)) + geom_point(alpha = 0.6) + geom_smooth(method = &quot;lm&quot;) + scale_colour_manual( name = &quot;Tratamento (binário)&quot;, values = c(&quot;Controle (D = 0)&quot; = &quot;steelblue&quot;, &quot;Tratado (D = 1)&quot; = &quot;firebrick&quot;) ) + theme_bw() O gráfico mostra duas retas de regressão ajustadas, uma para o controle (em azul) e outra para o tratamento (em vermelho). Efetivamente, temos de estender as duas retas para as regiões em que não há dados, por meio de extrapolação, que no caso significa continuar a linha reta. Assim, temos uma estimativa dos resultados potenciais nessas regiões e podemos computar o efeito causal médio. Como a extrapolação é razoável, não há problema. Vejamos agora uma situação em que o efeito de \\(w_1\\) é não linear sobre \\(Y\\). set.seed(202) n &lt;- 1e4 w1 &lt;- rnorm(n) # único confundidor tau &lt;- 3 # efeito causal verdadeiro # GERAMOS UM PROPENSITY SCORE NÃO‐LINEAR p &lt;- plogis(-0.5 + 2 * w1) D &lt;- rbinom(n, 1, p) # GERAÇÃO DOS RESULTADOS POTENCIAIS não-linear (apenas função de w1, forte ignorabilidade): y0 &lt;- 5 * w1^2 + rnorm(n) y1 &lt;- y0 - tau # efeito constante y &lt;- ifelse(D == 1, y1, y0) df &lt;- data.frame(y=y, D=D, w1=w1) df %&gt;% mutate( D = factor(D, levels = c(0,1), labels = c(&quot;Controle (D = 0)&quot;, &quot;Tratado (D = 1)&quot;)) ) %&gt;% ggplot(aes(x = w1, y = y, colour = D)) + geom_point(alpha = 0.6) + scale_colour_manual( name = &quot;Tratamento (binário)&quot;, values = c(&quot;Controle (D = 0)&quot; = &quot;steelblue&quot;, &quot;Tratado (D = 1)&quot; = &quot;firebrick&quot;) ) + theme_bw() Aqui, vemos que o efeito é não-linear de \\(w_1\\) sobre \\(Y\\) e também o desbalanceamento na amostra. Vamos ver o mesmo gráfico com as duas retas ajustadas para entender como a extrapolação pode ficar bem ruim nesse caso. df %&gt;% mutate( D = factor(D, levels = c(0,1), labels = c(&quot;Controle (D = 0)&quot;, &quot;Tratado (D = 1)&quot;)) ) %&gt;% ggplot(aes(x = w1, y = y, colour = D)) + geom_point(alpha = 0.6) + geom_smooth(method = &quot;lm&quot;) + scale_colour_manual( name = &quot;Tratamento (binário)&quot;, values = c(&quot;Controle (D = 0)&quot; = &quot;steelblue&quot;, &quot;Tratado (D = 1)&quot; = &quot;firebrick&quot;) ) + theme_bw() Um problema óbvio do modelo é que o efeito de w1 é quadrático, então podemos tentar corrigir isso incluindo um termo quadrático. reg_sq &lt;- lm(y ~ D + w1 + w1^2, data = df) summary(reg_sq) ## ## Call: ## lm(formula = y ~ D + w1 + w1^2, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.567 -4.180 -2.347 1.646 73.841 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.2689 0.1041 40.995 &lt; 2e-16 *** ## D -1.2953 0.1804 -7.181 7.44e-13 *** ## w1 -0.7960 0.0890 -8.943 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 7.052 on 9997 degrees of freedom ## Multiple R-squared: 0.03237, Adjusted R-squared: 0.03217 ## F-statistic: 167.2 on 2 and 9997 DF, p-value: &lt; 2.2e-16 O efeito causal é negativo, o que é bom, pois está na direção certa, mas ainda está distante do efeito verdadeiro. Isso ilustra também como a estimativa é dependente do modelo, o que é bem ruim, pois não sabemos qual o modelo certo. Em resumo, quando há desbalancamento, causamos dependência do modelo, o que é problemático. Agora, vamos comparar com o propensity score: library(knitr) library(tidyverse) library(ggdag) # true DGP reg_aux&lt;- glm(D ~ w1, family = binomial, data=df) p_score &lt;- reg_aux$fitted.values reg1 &lt;- lm(y ~ D + p_score) summary(reg1) ## ## Call: ## lm(formula = y ~ D + p_score) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.921 -4.258 -2.462 1.647 70.708 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.2799 0.1179 36.307 &lt; 2e-16 *** ## D -2.9562 0.1858 -15.910 &lt; 2e-16 *** ## p_score 1.6681 0.2917 5.718 1.11e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 7.069 on 9997 degrees of freedom ## Multiple R-squared: 0.02781, Adjusted R-squared: 0.02761 ## F-statistic: 143 on 2 and 9997 DF, p-value: &lt; 2.2e-16 w &lt;- ifelse(D == 1, 1/p_score, 1/(1-p_score)) # pesos IPTW reg2 &lt;- lm(y ~ D , weights = w) summary(reg2) ## ## Call: ## lm(formula = y ~ D, weights = w) ## ## Weighted Residuals: ## Min 1Q Median 3Q Max ## -15.95 -5.52 -2.87 2.04 324.89 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.67183 0.09553 48.90 &lt;2e-16 *** ## D -2.57016 0.13452 -19.11 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.499 on 9998 degrees of freedom ## Multiple R-squared: 0.03523, Adjusted R-squared: 0.03513 ## F-statistic: 365.1 on 1 and 9998 DF, p-value: &lt; 2.2e-16 Conseguimos recuperar o ATE sem problemas. E não precisei especificar corretamente a forma funcional da variáveil de controle \\(w_1\\) no modelo principal, pois usei o propensity score. Note que precisei modelar corretamente a regreessão que calcula o propensity score. É útil ver como o pscore está distribuído entre os grupos de tratamento e controle: library(knitr) library(tidyverse) library(ggdag) # true DGP df &lt;- df %&gt;% mutate(pscore = p_score) df %&gt;% ggplot(aes(pscore, group=D)) + geom_boxplot() df %&gt;% mutate(D = as.factor(D)) %&gt;% ggplot()+ geom_density(aes(x=pscore, group=D, colour = D)) Há desbalanceamento e falta de overlap ou suporte comum, o que leva à extrapolação. 5.3 Matching A Ideia do matching pode ser ilustrada se notarmos o seguinte. A projeção da reta vermelha para pontos abaixo de \\(-2\\) é de um \\(y\\) médio muito baixo, enquanto que o \\(y\\) médio é muito alto para o controle. O oposto é verificado para a região em que \\(w_1 &gt; 2\\). Portanto, se eu restringir (excluir os casos) a análise para uma região onde a necessidade de extrapolação é menor, o resultado tende a ser aproximar do ATE library(knitr) library(tidyr) library(broom) library(kableExtra) reg_sub &lt;- lm(y ~ D + w1, data = df) reg_sub %&gt;% tidy() %&gt;% kable(digits = c(0, 2, 3, 2, 3)) term estimate std.error statistic p.value (Intercept) 4.27 0.104 41.00 0 D -1.30 0.180 -7.18 0 w1 -0.80 0.089 -8.94 0 reg_sub &lt;- lm(y ~ D + w1, data = subset(df, w1 &gt; -2 &amp; w1 &lt; 2)) reg_sub %&gt;% tidy() %&gt;% kable(digits = c(0, 2, 3, 2, 3)) term estimate std.error statistic p.value (Intercept) 3.46 0.069 50.52 0 D -1.99 0.119 -16.70 0 w1 -0.35 0.066 -5.32 0 reg_sub &lt;- lm(y ~ D + w1, data = subset(df, w1 &gt; -1.5 &amp; w1 &lt; 1.5)) reg_sub %&gt;% tidy() %&gt;% kable(digits = c(0, 2, 3, 2, 3)) term estimate std.error statistic p.value (Intercept) 2.57 0.047 55.02 0 D -2.48 0.080 -30.78 0 w1 -0.21 0.053 -3.88 0 reg_sub &lt;- lm(y ~ D + w1, data = subset(df, w1 &gt; -1 &amp; w1 &lt; 1)) reg_sub %&gt;% tidy() %&gt;% kable(digits = c(0, 2, 3, 2, 3)) term estimate std.error statistic p.value (Intercept) 1.41 0.029 49.57 0 D -2.77 0.048 -57.27 0 w1 -0.17 0.043 -3.93 0 reg_sub &lt;- lm(y ~ D + w1, data = subset(df, w1 &gt; -1 &amp; w1 &lt; 1)) reg_sub %&gt;% tidy() %&gt;% kable(digits = c(0, 2, 3, 2, 3)) term estimate std.error statistic p.value (Intercept) 1.41 0.029 49.57 0 D -2.77 0.048 -57.27 0 w1 -0.17 0.043 -3.93 0 A ideia do matching é um pouco diferente do que fizemos acima, pois estamos excluindo as observações que estão no tratamento e que não possuem controle correspondente, e do controle que não possuem tratamento correspondente. Não há erro em excluir os dois tipos de observações, mas sempre temos de nos perguntar qual é o estimando de interesse. Se faço esse procedimento, o meu estimando não é nenhum dos usuais ATT ou ATE. No matchingf, nós nos concentramos em estimar o ATT, de forma que procuramos achar observações no controle que são próximas das tratadas, ou seja, excluímos os controles que não são um match para as observações tratadas. 5.4 Suposições de identificação Supondo para simplificar um tratamento binário \\(T\\), e uma covariável categórica \\(X\\), temos: \\((Y^1, Y^0) \\perp T|X \\text{ (Independência Condicional)}\\) \\(0 &lt; P(T=1|A) &lt; 1 \\text{ (Suporte comum)}\\) Temos então a seguinte derivação (usando o fato de os resultados potenciais são independentes do treatment assignment, condicional à covariável) e a switching equation no último passo: \\[\\begin{align} \\mathbb{E}[Y^1-Y^0|X] &amp; = \\mathbb{E}[Y^1 - Y^0 | X, T=1] \\\\ &amp; = \\mathbb{E}[Y^1| X, T=1] - \\mathbb{E}[Y^0| X,T=0] \\\\ &amp; = \\mathbb{E}[Y| X, D=1] - \\mathbb{E}[Y| X, D=0] \\end{align}\\] E o estimador que usamos pode ser representado (supondo suporte comum) como: \\(\\widehat{\\delta_{ATE}} = \\sum_{x\\in X}{(\\mathbb{E}[Y| X=x, D=1] - \\mathbb{E}[Y| X=x, D=0])P(X=x)}\\) E o que estamos fazendo é computar a média do efeito do tratamento condicional ponderado pela distribuição de \\(X\\). Para identificar o ATE, nós precisamos supor independência condicional a ambos os resultados potenciais. Se porém isso for crível apenas para \\(Y^0\\), podemos estimar o ATT. Basta lembrarmos que \\(\\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0] = \\mathbb{E}[Y_i^1 - Y_i^0|T_i=1] + \\mathbb{E}[Y_i^0|T_i=1] - \\mathbb{E}[Y_i^0|T_i=0]\\) 5.5 Matching A técnica de matching trata os resultados potenciais como missing data. Assim, pudermos supor CIA com credibilidade, pelo menos com relação a \\(Y^0\\), então podemos imputar esses resultados potenciais e estimar o ATT. A ideia é achar uma unidade a mais similar possível a unidade tratada para servir como contrafactual. Assim, poderíamos computar “diretamente” o ATT, já que teríamos os \\(Y^1\\) e \\(Y^0\\) para cada unidade, este último imputado. Há dois grandes grupos de métodos de matching: exato e aproximado. 5.6 Matching exato Nesse método, nós achamos uma unidade (ou mais) que tenham um valor exatamente igual nas covariáveis (ou no propensity score), e imputamos o controle. 5.7 Matching aproximado Para aproximar o matching, utilizamos alguma noção de distância entre variáveis. Para mais de uma variável, podemos utilizar algumas métricas de distância. A primeira é a distância euclidiana (supondo \\(K\\) variáveis). \\[ \\lVert X_i - X_j \\rVert = \\sqrt{(X_i - X_j)&#39;(X_i - X_j)} \\] \\[ \\lVert X_i - X_j \\rVert = \\sqrt{\\sum_{n=1}^k(X_{ni} - X_{nj})} \\] A distância euclidiana utiliza a escala das próprias variáveis, então é comum usar a distância euclidiana normalizada: \\[ \\lVert X_i - X_j \\rVert = \\sqrt{\\sum_{n=1}^k(\\frac{X_{ni} - X_{nj})}{\\hat{\\sigma}_n^2}} \\] Outra métrica é a distância de Mahalanobis, que basicamente divide pela covariância (amostral) entre as variáveis em vez da variância. Mas na prática a gente usa a euclidiana. 5.8 Estimando Uma vez que fizemos o matching entre unidades, qual nosso estimador? Lemrbando que o estimando é o ATT. \\[ \\widehat{\\delta}_{ATT} = \\dfrac{1}{N_T} \\sum_{D_i=1} (Y_i - Y_{j(i)}) \\] library(MatchIt) result_0 &lt;- matchit(D ~ w1, data = df, method = NULL, distance = &#39;glm&#39;) summary(result_0) ## ## Call: ## matchit(formula = D ~ w1, data = df, method = NULL, distance = &quot;glm&quot;) ## ## Summary of Balance for All Data: ## Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max ## distance 0.6549 0.2493 1.5714 1.2566 0.3685 0.5761 ## w1 0.7004 -0.5362 1.6030 0.9132 0.3685 0.5761 ## ## Sample Sizes: ## Control Treated ## All 5806 4194 ## Matched 5806 4194 ## Unmatched 0 0 ## Discarded 0 0 5.9 Declare Design e Matching Pode ser útil usar o declare design para investigar o uso de matching. Vamos fazer isso para o dataset lalonde. Esse é um banco de dados famoso na economia, pois o pesquisador Lalonde (1986) foi investigar se aplicação de métodos (então) tradicionais de modelagem econométrica eram capaz de recuperar o efeito causal de um estudo experimental chamada National Supported Work Demonstration (NSW), um programa de emprego temporário para dar experiência de trabalho. Ele coletou dados de um survey “representativo” de trabalhadores americanos (PSID) e elencou esses trabalhadores como grupo controle e empregou métodos econométricos para tentat estimar o efeito causal. Os resultados foram desastrosos, no sentido de altamente variáveis dependendo do modelo e subconjunto de dados e longe da estimativa experimental (incluindo com sinal errado). Vamos replicar esse trabalho, usando matching e pscore. A variável resposta do banco de dados é re78 (real earnings in 1978). O tratamento é a variável treat. As demais variáveis são covariáveis. library(tidyverse) library(data.table) library(here, quietly=TRUE) library(fixest) here() ## [1] &quot;/Users/manoelgaldino/Documents/DCP/Cursos/Causalidade/Causalidade&quot; set.seed(1234) lalonde &lt;- fread(here(&quot;Dados&quot;, &quot;lalonde_nsw.csv&quot;)) dt &lt;- lalonde[, .(re78, treat)] %&gt;% rename(Y = re78, D = treat) dt %&gt;% group_by(D) %&gt;% sample_n(3) %&gt;% kableExtra::kable(digits = 0, col.names = c(&quot;Income&quot;, &quot;Treatment&quot;)) Income Treatment 0 0 290 0 7010 0 13830 1 0 1 60308 1 dt %&gt;% group_by(D) %&gt;% summarize(mean(Y)) %&gt;% kableExtra::kable(digits = 0, col.names = c(&quot;Treatment&quot;, &quot;Income&quot;)) Treatment Income 0 4555 1 6349 y1 = dt[dt$D == 1, Y] y0 &lt;- dt[dt$D == 0, Y] tau &lt;- mean(y1) - mean(y0) A diferença simples na média é 1794. 5.9.1 Matching e Propensity scores Usando age, education, hispanic, black, married, nodegree, RE74 e RE75, vamos moelar o propensity score usando o grupo dos tratados em lalonde_nsw.csv e a amostra de controle de lalonde_psid.csv. Report the average p-score for the treated and control samples, and plot the propensity score densities for the treatment and control groups. nsw_data &lt;- lalonde psid_data &lt;- fread(here(&quot;Dados&quot;, &quot;lalonde_psid.csv&quot;)) nsw_treat &lt;- nsw_data[nsw_data$treat == 1, ] psid_control &lt;- psid_data[psid_data$treat == 0, ] dw_data &lt;- rbind(nsw_treat, psid_control) library(MatchIt) m.out1 &lt;- matchit(treat ~ age + education + hispanic + black + married + nodegree + re74 + re75, data = dw_data, method = &quot;nearest&quot;, distance = &quot;glm&quot;) ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred summary(m.out1) ## ## Call: ## matchit(formula = treat ~ age + education + hispanic + black + ## married + nodegree + re74 + re75, data = dw_data, method = &quot;nearest&quot;, ## distance = &quot;glm&quot;) ## ## Summary of Balance for All Data: ## Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max ## distance 0.6364 0.0270 2.1674 8.0268 0.4816 0.8817 ## age 25.8162 34.8506 -1.2627 0.4696 0.2317 0.3771 ## education 10.3459 12.1169 -0.8808 0.4255 0.1091 0.4029 ## hispanic 0.0595 0.0325 0.1139 . 0.0269 0.0269 ## black 0.8432 0.2506 1.6301 . 0.5926 0.5926 ## married 0.1892 0.8663 -1.7287 . 0.6771 0.6771 ## nodegree 0.7081 0.3052 0.8862 . 0.4029 0.4029 ## re74 2095.5737 19428.7458 -3.5471 0.1329 0.4684 0.7292 ## re75 1532.0553 19063.3377 -5.4458 0.0561 0.4695 0.7736 ## ## Summary of Balance for Matched Data: ## Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max Std. Pair Dist. ## distance 0.6364 0.2934 1.2200 1.4702 0.0432 0.5568 1.2200 ## age 25.8162 30.4811 -0.6520 0.4149 0.1196 0.1784 1.3561 ## education 10.3459 10.3784 -0.0161 0.4745 0.0407 0.0919 1.3281 ## hispanic 0.0595 0.0649 -0.0229 . 0.0054 0.0054 0.5257 ## black 0.8432 0.7568 0.2379 . 0.0865 0.0865 0.9515 ## married 0.1892 0.4595 -0.6901 . 0.2703 0.2703 1.0213 ## nodegree 0.7081 0.6216 0.1902 . 0.0865 0.0865 0.9036 ## re74 2095.5737 4499.8428 -0.4920 1.1020 0.0722 0.4162 0.8667 ## re75 1532.0553 3204.3968 -0.5195 0.7389 0.0605 0.2973 0.9044 ## ## Sample Sizes: ## Control Treated ## All 2490 185 ## Matched 185 185 ## Unmatched 2305 0 ## Discarded 0 0 plot(summary(m.out1)) m.data &lt;- match_data(m.out1) head(m.data) ## treat age education black hispanic married nodegree re74 re75 re78 distance weights subclass ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;fctr&gt; ## 1: 1 37 11 1 0 1 1 0 0 9930.0459 0.3773454 1 1 ## 2: 1 22 9 0 1 0 1 0 0 3595.8940 0.8849355 1 2 ## 3: 1 30 12 1 0 0 0 0 0 24909.4492 0.7201238 1 3 ## 4: 1 27 11 1 0 0 1 0 0 7506.1460 0.8717413 1 4 ## 5: 1 33 8 1 0 0 1 0 0 289.7899 0.7896888 1 5 ## 6: 1 22 9 1 0 0 1 0 0 4056.4939 0.9030698 1 6 library(&quot;marginaleffects&quot;) fit &lt;- lm(re78 ~ treat * (age + education + black + married + nodegree + re74 + re75), data = m.data, weights = weights) avg_comparisons(fit, variables = &quot;treat&quot;, vcov = ~subclass, newdata = subset(treat == 1)) ## ## Estimate Std. Error z Pr(&gt;|z|) S 2.5 % 97.5 % ## 1881 879 2.14 0.0325 4.9 157 3605 ## ## Term: treat ## Type: response ## Comparison: 1 - 0 library(MatchIt) library(DeclareDesign) exact_matching &lt;- function(data) { matched &lt;- matchit(D ~ X, method = &quot;exact&quot;, data = data) match.data(matched) } declaration_16.2 &lt;- declare_model( N = 100, U = rnorm(N), X = rbinom(N, 1, prob = 0.5), D = rbinom(N, 1, prob = 0.25 + 0.5 * X), Y_D_0 = 0.2 * X + U, Y_D_1 = Y_D_0 + 0.5 ) + declare_inquiry(ATT = mean(Y_D_1[D == 1] - Y_D_0[D == 1])) + declare_step(handler = exact_matching) + declare_measurement(Y = reveal_outcomes(Y ~ D)) + declare_estimator(Y ~ D, weights = weights, .method = difference_in_means, inquiry = &quot;ATT&quot;, label = &quot;Matched difference-in-means&quot;) + declare_estimator(Y ~ D, .method = difference_in_means, inquiry = &quot;ATT&quot;, label = &quot;Raw difference-in-means&quot;) library(MatchIt) m.out0 &lt;- matchit(treat ~ age + education + hispanic + black + married + nodegree + re74 + re75, data = dw_data, method = NULL, distance = &quot;glm&quot;) ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred # Checking balance prior to matching summary(m.out0) ## ## Call: ## matchit(formula = treat ~ age + education + hispanic + black + ## married + nodegree + re74 + re75, data = dw_data, method = NULL, ## distance = &quot;glm&quot;) ## ## Summary of Balance for All Data: ## Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max ## distance 0.6364 0.0270 2.1674 8.0268 0.4816 0.8817 ## age 25.8162 34.8506 -1.2627 0.4696 0.2317 0.3771 ## education 10.3459 12.1169 -0.8808 0.4255 0.1091 0.4029 ## hispanic 0.0595 0.0325 0.1139 . 0.0269 0.0269 ## black 0.8432 0.2506 1.6301 . 0.5926 0.5926 ## married 0.1892 0.8663 -1.7287 . 0.6771 0.6771 ## nodegree 0.7081 0.3052 0.8862 . 0.4029 0.4029 ## re74 2095.5737 19428.7458 -3.5471 0.1329 0.4684 0.7292 ## re75 1532.0553 19063.3377 -5.4458 0.0561 0.4695 0.7736 ## ## Sample Sizes: ## Control Treated ## All 2490 185 ## Matched 2490 185 ## Unmatched 0 0 ## Discarded 0 0 library(MatchIt) m.out1 &lt;- matchit(treat ~ age + education + hispanic + black + married + nodegree + re74 + re75, data = dw_data, method = &quot;nearest&quot;, distance = &quot;glm&quot;) ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred # Full matching on a probit PS m.out2 &lt;- matchit(treat ~ age + education + black + married + nodegree + re74 + re75, data = lalonde, method = &quot;full&quot;, distance = &quot;glm&quot;, link = &quot;probit&quot;) m.data &lt;- match_data(m.out2) library(&quot;marginaleffects&quot;) fit &lt;- lm(re78 ~ treat * (age + education + black + married + nodegree + re74 + re75), data = m.data, weights = weights) avg_comparisons(fit, variables = &quot;treat&quot;, vcov = ~subclass, newdata = subset(treat == 1)) ## ## Estimate Std. Error z Pr(&gt;|z|) S 2.5 % 97.5 % ## 2064 679 3.04 0.00238 8.7 733 3396 ## ## Term: treat ## Type: response ## Comparison: 1 - 0 full_matching &lt;- function(data) { matched &lt;- matchit(treat ~ age + education + hispanic + black + married + nodegree + re74 + re75, method = &quot;full&quot;, data = data) match.data(matched) } declaration_16.2 &lt;- declare_model( N = 1000, U = rnorm(N), X = rbinom(N, 1, prob = 0.5), D = rbinom(N, 1, prob = 0.25 + 0.5 * X), Y_D_0 = 0.2 * X + U, Y_D_1 = Y_D_0 + 0.5 ) + declare_inquiry(ATT = mean(Y_D_1[D == 1] - Y_D_0[D == 1])) + declare_step(handler = exact_matching) + declare_measurement(Y = reveal_outcomes(Y ~ D)) + declare_estimator(Y ~ D, weights = weights, .method = difference_in_means, inquiry = &quot;ATT&quot;, label = &quot;Matched difference-in-means&quot;) + declare_estimator(Y ~ D, .method = difference_in_means, inquiry = &quot;ATT&quot;, label = &quot;Raw difference-in-means&quot;) 5.10 Recomendações Práticas sobre Matching Rotina ou algoritmo: Defina o que é proximidade: alguma distância de medida para determinar se um caso é um bom match e quais variáveis utilizar. Em geral, distância euclidiana. Implemente o método do match. Avalie a qualidade do método, por meio do balanceamento antes e depois do match. Se necessário, altere o passo 1 ou 2 e itere. Faça a inferência sobre o efeito causal do tratamento sobre a resposta, dado o matching feito em 3. ### Avaliação do matching feito É melhor usar matching exato ou aproximado do que propensity score matching, pois o poder do teste é melhor (cf. King &amp; Nielsen, 2019). Não devemos fazer teste de hipótese para checar que o balanceamento após matching é melhor do que antes (amostra menor reduz o poder do teste de detectar desbalanceamento. Além disso, não há superpopulação alvo da inferência, pois balanceamento é uma propriedade de uma amostra em particular). Cf. Austin 2009. Além de comparar médias, é recomendado comparar variâncias ou desvios-padrão (Austin 2009). Por exemplo, razão de variâncias. Jamais use a variável resposta para fazer o matching. Matching com reposição gera dificuldades para calcular o erro padrão, já que as observações não são independentes. 5.11 Referências Austin, P. C. (2009). Balance diagnostics for comparing the distribution of baseline covariates between treatment groups in propensity‐score matched samples. Stat Med. King, G., &amp; Nielsen, R. (2019). Why propensity scores should not be used for matching. Political analysis, 27(4), 435-454. Stuart, E. A. (2010). Matching methods for causal inference: A review and a look forward. Statistical science: a review journal of the Institute of Mathematical Statistics, 25(1), 1. "],["variáveis-instrumentais.html", "Capítulo 6 Variáveis Instrumentais", " Capítulo 6 Variáveis Instrumentais "],["desenho-de-regresão-discontínua.html", "Capítulo 7 Desenho de Regresão Discontínua", " Capítulo 7 Desenho de Regresão Discontínua "],["diferença-em-diferenças.html", "Capítulo 8 Diferença em Diferenças", " Capítulo 8 Diferença em Diferenças "],["synthetic-control.html", "Capítulo 9 Synthetic Control 9.1 Implementação no R", " Capítulo 9 Synthetic Control Suponha que obtivemos dados para \\(J+1\\) unidades para unidades \\(j = 1, 2, ..., J+1\\), e sem perda de generalidade, a primeira unidade \\(j=1\\) é a de tratamento ou sob intervenção. O potencial de unidades para comparação é dado por \\(j = 2, ..., J+1\\), uma coleção de unidade não-tratadas. Os dados sõa observados por \\(T\\) períodos \\(1, 2, ..., t_0, t_1, t_2, ..., T\\), em que de \\(1\\) até \\(t_0\\) nenhuma unidade foi tratada ou sofreu intervenção. Para cada unidade \\(j\\), observamos também um conjunto de \\(k\\) preditores, \\(X_{1j}, X_{2j}, ..., X_{kj}\\), que pode incluir vaores pré-intervenção da variável resposta \\(y_{jt}\\). 9.1 Implementação no R # install.packages(&#39;scpi&#39;) https://macartan.github.io/dd_bootcamp/dd.html#/using-a-design-1 https://macartan.github.io/dd_bootcamp/exercises.html https://gist.github.com/saudiwin/dd0edec5786c7edb393bd84615aafb45 https://www.datacamp.com/tutorial/fine-tuning-openais-gpt-4-step-by-step-guide https://community.revelo.com.br/tutorial-aplicacao-do-fine-tuning-para-treinamento-no-chatgpt/ "],["interferência-spillover-e-dinâmica.html", "Capítulo 10 Interferência, spillover e dinâmica 10.1 Suposições simplifcadoras 10.2 PO com tratamento de múltiplos valores (multi-valued) 10.3 Dinâmica 10.4 Interferência", " Capítulo 10 Interferência, spillover e dinâmica Agora iremos relaxar algumas simplifcações do modelo de Resultados potenciais que vimos até agora. 10.1 Suposições simplifcadoras Tratamento binário Único período de tempo (um tratamento “within unit” ) SUTVA 10.2 PO com tratamento de múltiplos valores (multi-valued) 10.2.1 Multi-valued discreto Vamos estender o modelo de tratamewnto binário começando por tratamentos discretos. Digamos que temos \\(D_i \\in \\{0, 1, ..., d\\}\\), isto é, tratamentos ordenados. Por exemplo, múltiplas categorias de uma política pública (100 reais, 200 reais, 300 reais etc.). Definimos o resultado potencial da unidade \\(i\\) para qualquer \\(d \\in D\\) como \\(Y_i(d)\\) Nós vamos precisar da suposição de ignorability forte. \\(\\tau_i(D, D&#39;) = Y_i(d) - Y_i(d&#39;)\\), ou seja, o efeito causal entre dois níveis do tratamento. Como antes, podemos computar a esperança: \\(\\mathbb{E}[\\tau_i(D, D&#39;)] = \\mathbb{E}[Y_i(d) - Y_i(d&#39;)]\\). E se ignorability forte vale, então \\(\\mathbb{E}[\\tau_i(D, D&#39;)] = \\mathbb{E}[Y_i|D_i = d] - \\mathbb{E}[Y_i|D_i = d&#39;]\\) Se quisermos, podemos trabalhar também com tratamentos não-ordenados. Por exemplo, dois tratamentos binários. Por exemplo, um tratamento é informação sobre corrupção de um candidato (recebe ou não a informação) e outro tratamento é informação sobre a raça do candidato (é branco ou não). \\(D_i \\in \\{0,1}^2\\}\\). Podemos modelar os resultados potenciais como dependendo do status dos dois tratamentos: \\(Y_i(D_{i1}, D_{i2})\\) que geram quatro possibilidades ou resultados potenciais: \\(Y(0,0)\\), \\(Y(1,0)\\), \\(Y(0,1)\\), \\(Y(1,1)\\). Exemplo onde mesmo com atribuição aleatória, há efeitos não-identificados. Aleatoriamente atribuir \\(D_1\\) e, para os que receberam \\(D_1\\), aleatoriamente atribui \\(D-2\\). Onde isso poderia acontecer? Primeira e segunda dose de vacina! Por definição, a segunda dose só é dada para quem recebeu a primeira dose. Nunca é possível estimar efeito relativo a \\(Y_i(0,1)\\), isto é, o resultado potencial de quem não recebeu a primeira dose, mas recebeu a segunda. Essa é uma pessoa que recebeu a primeira dose quando a segunda estava sendo aplicada. 10.3 Dinâmica Considere que agora nós observamos \\(T\\) períodos de tempo para uma unidade: \\(Y_i\\) = (Y_{i1}, Y_{i2}, …, Y_{iT}). Para cada período, há um tratamento \\(D_{it} \\in \\{0,1\\}\\), isto é, sempre binário. Chamamos de \\(\\mathbf{D_i} = (D_{i1}, D_{i2}, ..., D_{iT})\\) o vetor de tratamentos em todos os \\(T\\) períodos. Implicitamente, muitas pessoas abordam modelos dinâmicos supondo que podemos olhar apenas para o resultado pontencial para a unidade \\(i\\) no período \\(t\\), ou seja, \\(Y_{it}(D_{it})\\). Porém, isso significa que apenas o tratamento do período \\(t\\) impacta o resultado potencial do período \\(t\\). De maneira mais geral, teríamos: \\(\\mathbf{D_i} = (D_{i1}, D_{i2}, ..., D_{iT})\\) e definiríamos o resultado potencial no período \\(t\\) como \\(Y_{it}(\\mathbf{D_i})\\). \\(Y(\\mathbf{D})\\). Nesse caso, fomos para o lado oposto: tratamentos futuros impactando o resultado potencial do presente. Isso não necessariamente significa que o futuro afeta o passado. Pode ocorrer por antecipação de tratamentos futuros. De todo modo, também parece extremo. Ainda assim, continuamos evitando a possibilidade de spillovers. Uma suposição comum, portanto, é a de não-antecipação, que pode ser representada por: \\(Y_{it}(d_1, d_2, ..., d_t, d_{t+1}, ..., d_T) = Y_{it}(d_1, d_2, ..., d_t)\\). Ou seja, os resultados potenciais até \\(t\\) não dependem dos resultados potenciais após essa data. Outra suposição comum é: ausência de efeitos dinâmicos: \\[Y_{it}(d_1, d_2, ..., d_t) = Y_{it}(d_t)\\] Em palavras, essa suposição requer que o resultado potencial do presente não dependa dos tratamentos passados. Essa suposição é também chamada de “no carry-over-effects hypothesis”. Ela é bem restritiva. Mesmo um desenho em que a aleatorização é executada a cada período de maneira independente pode ter “carry-over-effects” se o resultado do período anterior impactar o resultado do período presente. Modelos de “impulse response function” estão interessados em estimar justamente “carry over effects”. ver https://donskerclass.github.io/CausalEconometrics/TimeSeries.html Considere um modelo de regressão tradicional para dados dinâmicos: \\(y_{it} = \\alpha + \\beta x_{it} + e_{it}\\). Nós já sabemos que uma forma de de pensar a identificação causal é imaginar um experimento aleatório controlado. O que significa, em primeiro lugar, escolher aleatoriamente o tratamento nesse caso? Uma possibilidade é imaginar que a cada período o tratamento é aleatoriamente atribuído, independentemente dos períodos anteriores. No fundo, é como uma multi-valued treatment. Qual condição de ignorability estamos satisfazendo nesse caso? Se apenas o tratamento presente impacta o resultado potencial, isto é, \\(Y_{it}(D_{it})\\), então temos: Baseline randomization: \\(Y(D_{it}) \\perp D_{it}\\). Ou seja, o resultado potencial no período \\(t\\) é independente do mecanismo de atribuição do tratamento. Essa suposição implica exogeneidade estrita. Ignorability sequencial (Sequential Unconfoundedness). Assume que, conditional à história passada observada de tratamentos e co-variáveis, o tratamento corrente é independente de resultados potenciais. Nós iremos aprofundar essas questões nas aulas sobre DiD e Efeitos Fixos. Por ora, quero notar que no fundo estamos falando de spillovers no tempo, isto é, tratamento no tempo \\(t\\) impatacando resultados potenciais de períodos furutos \\(t+(1:k)\\), em que \\(k &gt;0\\). 10.4 Interferência Interferência ocorre quando o resultado potencial de uma unidade depende do tratamento de outra unidade. Tipicamente, em ciências sociais, spillovers podem envolver: Efeitos de pares Spillovers espaciais Interações políticas (restrições orçamentárias) Para modelar interferência, é necessário enriquecer nosso framework, introduzindo definições adicionais e alterando os pressupostos chave. Tipicamente nós modelamos com a suposição de que a interferência ocorre apenas em um subgrupo de unidades, isto é, o resultado potencial não depende do status de tratamento de todas as unidades, mas tão somente de um grupo específico. Além disso, também é comum ser necessário a suposição de anonimidade, isto é, os pares de um grupo importam, mas não quem são os pares, no sentido de que cada par teria um efeito esepcífico e único sobre uma unidade. Essa é uma área de pesqquisa ativa na inferência causal, mas ainda pouco incorporada na ciência política, em particular nas RIs, mas não só. Referências chave são: Charles F Manski. Identification of treatment response with social interactions. The Econometrics Journal, 16(1):S1–S23, 2013. Peter M Aronow and Cyrus Samii. Estimating average causal effects under general interference, with application to a social network experiment. Annals of Applied Statistics, 11(4):1912–1947, 2017. Bowers J, Fredrickson MM, Panagopoulos C. Reasoning about Interference Between Units: A General Framework. Political Analysis. 2013;21(1):97-124. doi:10.1093/pan/mps038 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
