<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 12 Machine Learning | Curso de Inferência Causal</title>
  <meta name="description" content="Capítulo 12 Machine Learning | Curso de Inferência Causal" />
  <meta name="generator" content="bookdown 0.41 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 12 Machine Learning | Curso de Inferência Causal" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 12 Machine Learning | Curso de Inferência Causal" />
  
  
  

<meta name="author" content="Manoel Galdino" />


<meta name="date" content="2025-06-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="llms-e-outras.html"/>
<link rel="next" href="termos-de-interação.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Causalidade</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introdução</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#revisão-de-regressão"><i class="fa fa-check"></i><b>1.1</b> Revisão de Regressão</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#teorema-da-anatomia-da-regressão"><i class="fa fa-check"></i><b>1.1.1</b> Teorema da Anatomia da Regressão</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#inferência"><i class="fa fa-check"></i><b>1.2</b> Inferência</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#referências"><i class="fa fa-check"></i><b>1.3</b> Referências</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html"><i class="fa fa-check"></i><b>2</b> Resultados Potenciais</a>
<ul>
<li class="chapter" data-level="2.1" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#causalidade-e-o-método-comparativo"><i class="fa fa-check"></i><b>2.1</b> Causalidade e o Método Comparativo</a></li>
<li class="chapter" data-level="2.2" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#potential-outcomes"><i class="fa fa-check"></i><b>2.2</b> Potential Outcomes</a></li>
<li class="chapter" data-level="2.3" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#notação"><i class="fa fa-check"></i><b>2.3</b> Notação</a></li>
<li class="chapter" data-level="2.4" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#problema-fundamental-da-inferência-causal"><i class="fa fa-check"></i><b>2.4</b> Problema Fundamental da Inferência Causal</a></li>
<li class="chapter" data-level="2.5" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#estimando"><i class="fa fa-check"></i><b>2.5</b> Estimando</a></li>
<li class="chapter" data-level="2.6" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#estimandos-mais-comuns"><i class="fa fa-check"></i><b>2.6</b> Estimandos Mais Comuns</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#ate"><i class="fa fa-check"></i><b>2.6.1</b> ATE</a></li>
<li class="chapter" data-level="2.6.2" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#att"><i class="fa fa-check"></i><b>2.6.2</b> ATT</a></li>
<li class="chapter" data-level="2.6.3" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#cate"><i class="fa fa-check"></i><b>2.6.3</b> CATE</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#nota-sobre-estimandos"><i class="fa fa-check"></i><b>2.7</b> Nota sobre estimandos</a></li>
<li class="chapter" data-level="2.8" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#exercício---qual-o-estimando-e-o-estimador-se-possível"><i class="fa fa-check"></i><b>2.8</b> Exercício - Qual o estimando e o estimador (se possível)?</a></li>
<li class="chapter" data-level="2.9" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#identificação"><i class="fa fa-check"></i><b>2.9</b> Identificação</a></li>
<li class="chapter" data-level="2.10" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#identificação-do-ate"><i class="fa fa-check"></i><b>2.10</b> Identificação do ATE</a></li>
<li class="chapter" data-level="2.11" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#equações-estruturais"><i class="fa fa-check"></i><b>2.11</b> Equações estruturais</a></li>
<li class="chapter" data-level="2.12" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#modelo-versus-desenho"><i class="fa fa-check"></i><b>2.12</b> Modelo versus Desenho</a></li>
<li class="chapter" data-level="2.13" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#exercício-em-sala"><i class="fa fa-check"></i><b>2.13</b> Exercício em sala</a></li>
<li class="chapter" data-level="2.14" data-path="resultados-potenciais.html"><a href="resultados-potenciais.html#referências-1"><i class="fa fa-check"></i><b>2.14</b> Referências</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="dags.html"><a href="dags.html"><i class="fa fa-check"></i><b>3</b> DAGs</a>
<ul>
<li class="chapter" data-level="3.1" data-path="dags.html"><a href="dags.html#causalidade"><i class="fa fa-check"></i><b>3.1</b> Causalidade</a></li>
<li class="chapter" data-level="3.2" data-path="dags.html"><a href="dags.html#introdução-1"><i class="fa fa-check"></i><b>3.2</b> Introdução</a></li>
<li class="chapter" data-level="3.3" data-path="dags.html"><a href="dags.html#os-tipos-básicos-de-dags"><i class="fa fa-check"></i><b>3.3</b> Os Tipos Básicos de DAGs</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="dags.html"><a href="dags.html#chains"><i class="fa fa-check"></i><b>3.3.1</b> 1. Chains</a></li>
<li class="chapter" data-level="3.3.2" data-path="dags.html"><a href="dags.html#forks"><i class="fa fa-check"></i><b>3.3.2</b> 2. Forks</a></li>
<li class="chapter" data-level="3.3.3" data-path="dags.html"><a href="dags.html#colliders"><i class="fa fa-check"></i><b>3.3.3</b> 3. Colliders</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="dags.html"><a href="dags.html#simulação-no-r-ilustrando-o-collider-bias"><i class="fa fa-check"></i><b>3.4</b> Simulação no R: Ilustrando o Collider Bias</a></li>
<li class="chapter" data-level="3.5" data-path="dags.html"><a href="dags.html#definições"><i class="fa fa-check"></i><b>3.5</b> Definições</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="dags.html"><a href="dags.html#relações-entre-variáveis-nós"><i class="fa fa-check"></i><b>3.5.1</b> Relações entre Variáveis (nós):</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="dags.html"><a href="dags.html#controle-e-ajuste"><i class="fa fa-check"></i><b>3.6</b> Controle e Ajuste</a></li>
<li class="chapter" data-level="3.7" data-path="dags.html"><a href="dags.html#fatorização-da-probabilidade-conjunta"><i class="fa fa-check"></i><b>3.7</b> Fatorização da Probabilidade Conjunta</a></li>
<li class="chapter" data-level="3.8" data-path="dags.html"><a href="dags.html#fatorização-e-dags"><i class="fa fa-check"></i><b>3.8</b> Fatorização e DAGs</a></li>
<li class="chapter" data-level="3.9" data-path="dags.html"><a href="dags.html#fatorização-dags-e-causalidade"><i class="fa fa-check"></i><b>3.9</b> Fatorização, DAGs e Causalidade</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="experimentos.html"><a href="experimentos.html"><i class="fa fa-check"></i><b>4</b> Experimentos</a>
<ul>
<li class="chapter" data-level="4.1" data-path="experimentos.html"><a href="experimentos.html#introdução-2"><i class="fa fa-check"></i><b>4.1</b> Introdução</a></li>
<li class="chapter" data-level="4.2" data-path="experimentos.html"><a href="experimentos.html#experimentos-aleatórios"><i class="fa fa-check"></i><b>4.2</b> Experimentos aleatórios</a></li>
<li class="chapter" data-level="4.3" data-path="experimentos.html"><a href="experimentos.html#restrição-de-exclusão"><i class="fa fa-check"></i><b>4.3</b> Restrição de Exclusão</a></li>
<li class="chapter" data-level="4.4" data-path="experimentos.html"><a href="experimentos.html#tipos-de-experimentos"><i class="fa fa-check"></i><b>4.4</b> Tipos de experimentos</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="experimentos.html"><a href="experimentos.html#aleatorização-de-bernoulli"><i class="fa fa-check"></i><b>4.4.1</b> Aleatorização de Bernoulli</a></li>
<li class="chapter" data-level="4.4.2" data-path="experimentos.html"><a href="experimentos.html#aleatorização-completa"><i class="fa fa-check"></i><b>4.4.2</b> Aleatorização Completa</a></li>
<li class="chapter" data-level="4.4.3" data-path="experimentos.html"><a href="experimentos.html#aleatorização-condicional-block-random-assigment"><i class="fa fa-check"></i><b>4.4.3</b> Aleatorização Condicional (Block Random Assigment)</a></li>
<li class="chapter" data-level="4.4.4" data-path="experimentos.html"><a href="experimentos.html#pensando-aleatorização-em-bloco"><i class="fa fa-check"></i><b>4.4.4</b> Pensando aleatorização em bloco</a></li>
<li class="chapter" data-level="4.4.5" data-path="experimentos.html"><a href="experimentos.html#ate-com-aleatorização-condicional-bloco"><i class="fa fa-check"></i><b>4.4.5</b> ATE com Aleatorização Condicional (Bloco)</a></li>
<li class="chapter" data-level="4.4.6" data-path="experimentos.html"><a href="experimentos.html#aleatorização-em-bloco"><i class="fa fa-check"></i><b>4.4.6</b> Aleatorização em bloco</a></li>
<li class="chapter" data-level="4.4.7" data-path="experimentos.html"><a href="experimentos.html#precisão-da-aleatorização-em-bloco"><i class="fa fa-check"></i><b>4.4.7</b> Precisão da aleatorização em bloco</a></li>
<li class="chapter" data-level="4.4.8" data-path="experimentos.html"><a href="experimentos.html#comparação-de-ses"><i class="fa fa-check"></i><b>4.4.8</b> Comparação de SEs</a></li>
<li class="chapter" data-level="4.4.9" data-path="experimentos.html"><a href="experimentos.html#cluster-randomization"><i class="fa fa-check"></i><b>4.4.9</b> Cluster randomization</a></li>
<li class="chapter" data-level="4.4.10" data-path="experimentos.html"><a href="experimentos.html#tabelas-em-artigos"><i class="fa fa-check"></i><b>4.4.10</b> Tabelas em artigos</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="experimentos.html"><a href="experimentos.html#estimador-ate"><i class="fa fa-check"></i><b>4.5</b> Estimador ATE</a></li>
<li class="chapter" data-level="4.6" data-path="experimentos.html"><a href="experimentos.html#key-takeways"><i class="fa fa-check"></i><b>4.6</b> Key Takeways</a></li>
<li class="chapter" data-level="4.7" data-path="experimentos.html"><a href="experimentos.html#declare-design"><i class="fa fa-check"></i><b>4.7</b> Declare Design</a></li>
<li class="chapter" data-level="4.8" data-path="experimentos.html"><a href="experimentos.html#exercício"><i class="fa fa-check"></i><b>4.8</b> Exercício</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="experimentos.html"><a href="experimentos.html#experimento-com-envio-de-cartões-postais-e-participação-eleitoral"><i class="fa fa-check"></i><b>4.8.1</b> Experimento com envio de cartões-postais e participação eleitoral</a></li>
<li class="chapter" data-level="4.8.2" data-path="experimentos.html"><a href="experimentos.html#experimento-com-anúncios-de-tv-e-participação-eleitoral"><i class="fa fa-check"></i><b>4.8.2</b> Experimento com anúncios de TV e participação eleitoral</a></li>
<li class="chapter" data-level="4.8.3" data-path="experimentos.html"><a href="experimentos.html#exclusão-de-participantes-em-experimentos-de-survey"><i class="fa fa-check"></i><b>4.8.3</b> Exclusão de participantes em experimentos de survey</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="propensity-score-e-matching.html"><a href="propensity-score-e-matching.html"><i class="fa fa-check"></i><b>5</b> Propensity Score e Matching</a>
<ul>
<li class="chapter" data-level="5.1" data-path="propensity-score-e-matching.html"><a href="propensity-score-e-matching.html#introdução-3"><i class="fa fa-check"></i><b>5.1</b> Introdução</a></li>
<li class="chapter" data-level="5.2" data-path="propensity-score-e-matching.html"><a href="propensity-score-e-matching.html#propensity-score"><i class="fa fa-check"></i><b>5.2</b> Propensity Score</a></li>
<li class="chapter" data-level="5.3" data-path="propensity-score-e-matching.html"><a href="propensity-score-e-matching.html#matching"><i class="fa fa-check"></i><b>5.3</b> Matching</a></li>
<li class="chapter" data-level="5.4" data-path="propensity-score-e-matching.html"><a href="propensity-score-e-matching.html#suposições-de-identificação"><i class="fa fa-check"></i><b>5.4</b> Suposições de identificação</a></li>
<li class="chapter" data-level="5.5" data-path="propensity-score-e-matching.html"><a href="propensity-score-e-matching.html#matching-1"><i class="fa fa-check"></i><b>5.5</b> Matching</a></li>
<li class="chapter" data-level="5.6" data-path="propensity-score-e-matching.html"><a href="propensity-score-e-matching.html#matching-exato"><i class="fa fa-check"></i><b>5.6</b> Matching exato</a></li>
<li class="chapter" data-level="5.7" data-path="propensity-score-e-matching.html"><a href="propensity-score-e-matching.html#matching-aproximado"><i class="fa fa-check"></i><b>5.7</b> Matching aproximado</a></li>
<li class="chapter" data-level="5.8" data-path="propensity-score-e-matching.html"><a href="propensity-score-e-matching.html#estimando-1"><i class="fa fa-check"></i><b>5.8</b> Estimando</a></li>
<li class="chapter" data-level="5.9" data-path="propensity-score-e-matching.html"><a href="propensity-score-e-matching.html#declare-design-e-matching"><i class="fa fa-check"></i><b>5.9</b> Declare Design e Matching</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="propensity-score-e-matching.html"><a href="propensity-score-e-matching.html#matching-e-propensity-scores"><i class="fa fa-check"></i><b>5.9.1</b> Matching e Propensity scores</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="propensity-score-e-matching.html"><a href="propensity-score-e-matching.html#recomendações-práticas-sobre-matching"><i class="fa fa-check"></i><b>5.10</b> Recomendações Práticas sobre Matching</a></li>
<li class="chapter" data-level="5.11" data-path="propensity-score-e-matching.html"><a href="propensity-score-e-matching.html#referências-2"><i class="fa fa-check"></i><b>5.11</b> Referências</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="variáveis-instrumentais.html"><a href="variáveis-instrumentais.html"><i class="fa fa-check"></i><b>6</b> Variáveis Instrumentais</a>
<ul>
<li class="chapter" data-level="6.1" data-path="variáveis-instrumentais.html"><a href="variáveis-instrumentais.html#introdução-4"><i class="fa fa-check"></i><b>6.1</b> Introdução</a></li>
<li class="chapter" data-level="6.2" data-path="variáveis-instrumentais.html"><a href="variáveis-instrumentais.html#iv-com-modelo-estrutural"><i class="fa fa-check"></i><b>6.2</b> IV com modelo estrutural</a></li>
<li class="chapter" data-level="6.3" data-path="variáveis-instrumentais.html"><a href="variáveis-instrumentais.html#mqo-em-2-estágios"><i class="fa fa-check"></i><b>6.3</b> MQO em 2 Estágios</a></li>
<li class="chapter" data-level="6.4" data-path="variáveis-instrumentais.html"><a href="variáveis-instrumentais.html#principais-usos-de-iv"><i class="fa fa-check"></i><b>6.4</b> Principais usos de IV</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="variáveis-instrumentais.html"><a href="variáveis-instrumentais.html#experimentos-1"><i class="fa fa-check"></i><b>6.4.1</b> Experimentos</a></li>
<li class="chapter" data-level="6.4.2" data-path="variáveis-instrumentais.html"><a href="variáveis-instrumentais.html#regras-com-variação-quasi-aleatória"><i class="fa fa-check"></i><b>6.4.2</b> Regras com variação quasi-aleatória</a></li>
<li class="chapter" data-level="6.4.3" data-path="variáveis-instrumentais.html"><a href="variáveis-instrumentais.html#teoria"><i class="fa fa-check"></i><b>6.4.3</b> Teoria</a></li>
<li class="chapter" data-level="6.4.4" data-path="variáveis-instrumentais.html"><a href="variáveis-instrumentais.html#suposições-para-estimar-o-late"><i class="fa fa-check"></i><b>6.4.4</b> Suposições para estimar o LATE</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="variáveis-instrumentais.html"><a href="variáveis-instrumentais.html#restrição-de-exclusão-1"><i class="fa fa-check"></i><b>6.5</b> Restrição de Exclusão</a></li>
<li class="chapter" data-level="6.6" data-path="variáveis-instrumentais.html"><a href="variáveis-instrumentais.html#monoticidade"><i class="fa fa-check"></i><b>6.6</b> Monoticidade</a></li>
<li class="chapter" data-level="6.7" data-path="variáveis-instrumentais.html"><a href="variáveis-instrumentais.html#estimação-aka-estatística-f"><i class="fa fa-check"></i><b>6.7</b> Estimação (aka estatística F)</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="variáveis-instrumentais.html"><a href="variáveis-instrumentais.html#f-stat"><i class="fa fa-check"></i><b>6.7.1</b> F stat</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="variáveis-instrumentais.html"><a href="variáveis-instrumentais.html#referências-3"><i class="fa fa-check"></i><b>6.8</b> Referências</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html"><i class="fa fa-check"></i><b>7</b> Desenho de Regresão Discontínua</a>
<ul>
<li class="chapter" data-level="7.1" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#outline-da-aula"><i class="fa fa-check"></i><b>7.1</b> Outline da aula</a></li>
<li class="chapter" data-level="7.2" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#características-chave-da-rdd"><i class="fa fa-check"></i><b>7.2</b> Características-chave da RDD</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#determinação-do-tratamento"><i class="fa fa-check"></i><b>7.2.1</b> Determinação do Tratamento</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#fuzzy-rdd"><i class="fa fa-check"></i><b>7.3</b> Fuzzy RDD</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#observação-e-corte"><i class="fa fa-check"></i><b>7.3.1</b> Observação e Corte</a></li>
<li class="chapter" data-level="7.3.2" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#estimativa-dos-efeitos-do-tratamento"><i class="fa fa-check"></i><b>7.3.2</b> Estimativa dos Efeitos do Tratamento</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#suposição-de-continuidade"><i class="fa fa-check"></i><b>7.4</b> Suposição de continuidade</a></li>
<li class="chapter" data-level="7.5" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#suposições-na-rdd"><i class="fa fa-check"></i><b>7.5</b> Suposições na RDD</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#suposição-de-não-manipulação-com-precisão"><i class="fa fa-check"></i><b>7.5.1</b> Suposição de Não-manipulação com Precisão</a></li>
<li class="chapter" data-level="7.5.2" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#problemas-de-manipulação"><i class="fa fa-check"></i><b>7.5.2</b> Problemas de Manipulação</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#testabilidade-da-suposição-de-não-manipulação"><i class="fa fa-check"></i><b>7.6</b> Testabilidade da Suposição de não-Manipulação</a></li>
<li class="chapter" data-level="7.7" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#estimação-em-rdd"><i class="fa fa-check"></i><b>7.7</b> Estimação em RDD</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#problema-de-complete-overlapping"><i class="fa fa-check"></i><b>7.7.1</b> Problema de Complete Overlapping</a></li>
<li class="chapter" data-level="7.7.2" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#dependência-de-extrapolação"><i class="fa fa-check"></i><b>7.7.2</b> Dependência de Extrapolação</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#métodos-de-estimação"><i class="fa fa-check"></i><b>7.8</b> Métodos de Estimação</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#identificação-no-limite"><i class="fa fa-check"></i><b>7.8.1</b> Identificação no Limite</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#trade-off-de-viés-variância"><i class="fa fa-check"></i><b>7.9</b> Trade-off de Viés-Variância</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#métodos-de-largura-de-banda-ótima"><i class="fa fa-check"></i><b>7.9.1</b> Métodos de Largura de Banda Ótima</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#regras-arbitrárias"><i class="fa fa-check"></i><b>7.10</b> Regras arbitrárias</a></li>
<li class="chapter" data-level="7.11" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#simulação"><i class="fa fa-check"></i><b>7.11</b> Simulação</a></li>
<li class="chapter" data-level="7.12" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#simulação---potential-outcomes-y0"><i class="fa fa-check"></i><b>7.12</b> Simulação - Potential Outcomes Y0</a></li>
<li class="chapter" data-level="7.13" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#simulação---potential-outcomes-y1"><i class="fa fa-check"></i><b>7.13</b> Simulação - Potential Outcomes Y1</a></li>
<li class="chapter" data-level="7.14" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#simulação---potential-outcomes-y1-e-y0"><i class="fa fa-check"></i><b>7.14</b> Simulação - Potential Outcomes Y1 e Y0</a></li>
<li class="chapter" data-level="7.15" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#simulação---y-observado"><i class="fa fa-check"></i><b>7.15</b> Simulação - Y observado</a></li>
<li class="chapter" data-level="7.16" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#quando-o-rdd-funciona"><i class="fa fa-check"></i><b>7.16</b> Quando o RDD funciona?</a></li>
<li class="chapter" data-level="7.17" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#raw-data-versus-bin"><i class="fa fa-check"></i><b>7.17</b> Raw Data versus Bin</a></li>
<li class="chapter" data-level="7.18" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#permutation-tests-balancing"><i class="fa fa-check"></i><b>7.18</b> Permutation tests (balancing)</a></li>
<li class="chapter" data-level="7.19" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#mccray-test"><i class="fa fa-check"></i><b>7.19</b> McCray test</a></li>
<li class="chapter" data-level="7.20" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#robustez"><i class="fa fa-check"></i><b>7.20</b> Robustez</a></li>
<li class="chapter" data-level="7.21" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#densidade-descontínua---results"><i class="fa fa-check"></i><b>7.21</b> Densidade descontínua - results</a></li>
<li class="chapter" data-level="7.22" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#regressão-rdd"><i class="fa fa-check"></i><b>7.22</b> Regressão RDD</a></li>
<li class="chapter" data-level="7.23" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#placebo-tests"><i class="fa fa-check"></i><b>7.23</b> Placebo Tests</a></li>
<li class="chapter" data-level="7.24" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#pcrd"><i class="fa fa-check"></i><b>7.24</b> PCRD</a></li>
<li class="chapter" data-level="7.25" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#checlist-para-um-paper"><i class="fa fa-check"></i><b>7.25</b> Checlist para um paper</a></li>
<li class="chapter" data-level="7.26" data-path="desenho-de-regresão-discontínua.html"><a href="desenho-de-regresão-discontínua.html#referências-4"><i class="fa fa-check"></i><b>7.26</b> Referências</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="diferença-em-diferenças.html"><a href="diferença-em-diferenças.html"><i class="fa fa-check"></i><b>8</b> Diferença em Diferenças</a>
<ul>
<li class="chapter" data-level="8.1" data-path="diferença-em-diferenças.html"><a href="diferença-em-diferenças.html#modelo-básico-2x2"><i class="fa fa-check"></i><b>8.1</b> Modelo básico 2x2</a></li>
<li class="chapter" data-level="8.2" data-path="diferença-em-diferenças.html"><a href="diferença-em-diferenças.html#twfe"><i class="fa fa-check"></i><b>8.2</b> TWFE</a></li>
<li class="chapter" data-level="8.3" data-path="diferença-em-diferenças.html"><a href="diferença-em-diferenças.html#pressupostos"><i class="fa fa-check"></i><b>8.3</b> Pressupostos</a></li>
<li class="chapter" data-level="8.4" data-path="diferença-em-diferenças.html"><a href="diferença-em-diferenças.html#aplicação"><i class="fa fa-check"></i><b>8.4</b> Aplicação</a></li>
<li class="chapter" data-level="8.5" data-path="diferença-em-diferenças.html"><a href="diferença-em-diferenças.html#múltiplos-períodos"><i class="fa fa-check"></i><b>8.5</b> Múltiplos períodos</a></li>
<li class="chapter" data-level="8.6" data-path="diferença-em-diferenças.html"><a href="diferença-em-diferenças.html#tendências-paralelas"><i class="fa fa-check"></i><b>8.6</b> Tendências Paralelas</a></li>
<li class="chapter" data-level="8.7" data-path="diferença-em-diferenças.html"><a href="diferença-em-diferenças.html#múltiplos-períodos-pós-tratamento"><i class="fa fa-check"></i><b>8.7</b> Múltiplos períodos pós-tratamento</a></li>
<li class="chapter" data-level="8.8" data-path="diferença-em-diferenças.html"><a href="diferença-em-diferenças.html#análise-de-sensibilidade-em-did"><i class="fa fa-check"></i><b>8.8</b> Análise de sensibilidade em DiD</a></li>
<li class="chapter" data-level="8.9" data-path="diferença-em-diferenças.html"><a href="diferença-em-diferenças.html#did-generalizado"><i class="fa fa-check"></i><b>8.9</b> DiD generalizado</a></li>
<li class="chapter" data-level="8.10" data-path="diferença-em-diferenças.html"><a href="diferença-em-diferenças.html#did-com-adoção-escalonada-staggered-timing"><i class="fa fa-check"></i><b>8.10</b> DID com adoção escalonada (staggered timing)</a></li>
<li class="chapter" data-level="8.11" data-path="diferença-em-diferenças.html"><a href="diferença-em-diferenças.html#paper-voter-gratitude-last-long"><i class="fa fa-check"></i><b>8.11</b> Paper Voter Gratitude Last Long?</a></li>
<li class="chapter" data-level="8.12" data-path="diferença-em-diferenças.html"><a href="diferença-em-diferenças.html#referências-5"><i class="fa fa-check"></i><b>8.12</b> Referências</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="time-series-cross-section-tscs.html"><a href="time-series-cross-section-tscs.html"><i class="fa fa-check"></i><b>9</b> Time-Series Cross-Section (TSCS)</a>
<ul>
<li class="chapter" data-level="9.1" data-path="time-series-cross-section-tscs.html"><a href="time-series-cross-section-tscs.html#introdução-5"><i class="fa fa-check"></i><b>9.1</b> Introdução</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="time-series-cross-section-tscs.html"><a href="time-series-cross-section-tscs.html#within-versus-between"><i class="fa fa-check"></i><b>9.1.1</b> Within versus Between</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="time-series-cross-section-tscs.html"><a href="time-series-cross-section-tscs.html#ovb"><i class="fa fa-check"></i><b>9.2</b> OVB</a></li>
<li class="chapter" data-level="9.3" data-path="time-series-cross-section-tscs.html"><a href="time-series-cross-section-tscs.html#estimandos"><i class="fa fa-check"></i><b>9.3</b> Estimandos</a></li>
<li class="chapter" data-level="9.4" data-path="time-series-cross-section-tscs.html"><a href="time-series-cross-section-tscs.html#resultados-potenciais-1"><i class="fa fa-check"></i><b>9.4</b> Resultados Potenciais</a></li>
<li class="chapter" data-level="9.5" data-path="time-series-cross-section-tscs.html"><a href="time-series-cross-section-tscs.html#modelo-ar1"><i class="fa fa-check"></i><b>9.5</b> Modelo AR(1)</a></li>
<li class="chapter" data-level="9.6" data-path="time-series-cross-section-tscs.html"><a href="time-series-cross-section-tscs.html#sequential-ignorability"><i class="fa fa-check"></i><b>9.6</b> Sequential ignorability</a></li>
<li class="chapter" data-level="9.7" data-path="time-series-cross-section-tscs.html"><a href="time-series-cross-section-tscs.html#resumo"><i class="fa fa-check"></i><b>9.7</b> Resumo</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="time-series-cross-section-tscs.html"><a href="time-series-cross-section-tscs.html#remark"><i class="fa fa-check"></i><b>9.7.1</b> Remark</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="time-series-cross-section-tscs.html"><a href="time-series-cross-section-tscs.html#suposições-para-inferência"><i class="fa fa-check"></i><b>9.8</b> Suposições para Inferência</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="time-series-cross-section-tscs.html"><a href="time-series-cross-section-tscs.html#remark-1"><i class="fa fa-check"></i><b>9.8.1</b> Remark</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="time-series-cross-section-tscs.html"><a href="time-series-cross-section-tscs.html#efeitos-aleatórios"><i class="fa fa-check"></i><b>9.9</b> Efeitos aleatórios</a></li>
<li class="chapter" data-level="9.10" data-path="time-series-cross-section-tscs.html"><a href="time-series-cross-section-tscs.html#referências-6"><i class="fa fa-check"></i><b>9.10</b> Referências</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="synthetic-control.html"><a href="synthetic-control.html"><i class="fa fa-check"></i><b>10</b> Synthetic Control</a>
<ul>
<li class="chapter" data-level="10.0.1" data-path="synthetic-control.html"><a href="synthetic-control.html#tratamento"><i class="fa fa-check"></i><b>10.0.1</b> Tratamento</a></li>
<li class="chapter" data-level="10.1" data-path="synthetic-control.html"><a href="synthetic-control.html#implementação-no-r"><i class="fa fa-check"></i><b>10.1</b> Implementação no R</a></li>
<li class="chapter" data-level="10.2" data-path="synthetic-control.html"><a href="synthetic-control.html#synthethic-did"><i class="fa fa-check"></i><b>10.2</b> Synthethic DiD</a></li>
<li class="chapter" data-level="10.3" data-path="synthetic-control.html"><a href="synthetic-control.html#referências-7"><i class="fa fa-check"></i><b>10.3</b> Referências</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="llms-e-outras.html"><a href="llms-e-outras.html"><i class="fa fa-check"></i><b>11</b> LLMs e outras</a>
<ul>
<li class="chapter" data-level="11.1" data-path="llms-e-outras.html"><a href="llms-e-outras.html#google-colab"><i class="fa fa-check"></i><b>11.1</b> Google Colab</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>12</b> Machine Learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="machine-learning.html"><a href="machine-learning.html#introdução-6"><i class="fa fa-check"></i><b>12.1</b> Introdução</a></li>
<li class="chapter" data-level="12.2" data-path="machine-learning.html"><a href="machine-learning.html#terminologia"><i class="fa fa-check"></i><b>12.2</b> Terminologia</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="machine-learning.html"><a href="machine-learning.html#lasso"><i class="fa fa-check"></i><b>12.2.1</b> LASSO</a></li>
<li class="chapter" data-level="12.2.2" data-path="machine-learning.html"><a href="machine-learning.html#double-lasso"><i class="fa fa-check"></i><b>12.2.2</b> Double Lasso</a></li>
<li class="chapter" data-level="12.2.3" data-path="machine-learning.html"><a href="machine-learning.html#outras-soluções-ineficazes"><i class="fa fa-check"></i><b>12.2.3</b> Outras soluções ineficazes</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="machine-learning.html"><a href="machine-learning.html#dl---algoritmo"><i class="fa fa-check"></i><b>12.3</b> DL - Algoritmo</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="termos-de-interação.html"><a href="termos-de-interação.html"><i class="fa fa-check"></i><b>13</b> Termos de Interação</a>
<ul>
<li class="chapter" data-level="13.1" data-path="termos-de-interação.html"><a href="termos-de-interação.html#aplicação-1"><i class="fa fa-check"></i><b>13.1</b> Aplicação</a></li>
<li class="chapter" data-level="13.2" data-path="termos-de-interação.html"><a href="termos-de-interação.html#dml"><i class="fa fa-check"></i><b>13.2</b> DML</a></li>
<li class="chapter" data-level="13.3" data-path="termos-de-interação.html"><a href="termos-de-interação.html#double-debiasing"><i class="fa fa-check"></i><b>13.3</b> Double Debiasing</a></li>
<li class="chapter" data-level="13.4" data-path="termos-de-interação.html"><a href="termos-de-interação.html#cross-fitting"><i class="fa fa-check"></i><b>13.4</b> Cross-fitting</a></li>
<li class="chapter" data-level="13.5" data-path="termos-de-interação.html"><a href="termos-de-interação.html#questões-práticas"><i class="fa fa-check"></i><b>13.5</b> Questões Práticas</a></li>
<li class="chapter" data-level="13.6" data-path="termos-de-interação.html"><a href="termos-de-interação.html#referências-8"><i class="fa fa-check"></i><b>13.6</b> Referências</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="resumo-1.html"><a href="resumo-1.html"><i class="fa fa-check"></i><b>14</b> Resumo</a>
<ul>
<li class="chapter" data-level="14.1" data-path="resumo-1.html"><a href="resumo-1.html#matching-2"><i class="fa fa-check"></i><b>14.1</b> Matching</a></li>
<li class="chapter" data-level="14.2" data-path="resumo-1.html"><a href="resumo-1.html#iv"><i class="fa fa-check"></i><b>14.2</b> IV</a></li>
<li class="chapter" data-level="14.3" data-path="resumo-1.html"><a href="resumo-1.html#rdd"><i class="fa fa-check"></i><b>14.3</b> RDD</a></li>
<li class="chapter" data-level="14.4" data-path="resumo-1.html"><a href="resumo-1.html#did"><i class="fa fa-check"></i><b>14.4</b> DiD</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="resumo-1.html"><a href="resumo-1.html#tscs"><i class="fa fa-check"></i><b>14.4.1</b> TSCS</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="resumo-1.html"><a href="resumo-1.html#scm"><i class="fa fa-check"></i><b>14.5</b> SCM</a></li>
<li class="chapter" data-level="14.6" data-path="resumo-1.html"><a href="resumo-1.html#did-sintético"><i class="fa fa-check"></i><b>14.6</b> DiD Sintético</a></li>
<li class="chapter" data-level="14.7" data-path="resumo-1.html"><a href="resumo-1.html#double-lasso-1"><i class="fa fa-check"></i><b>14.7</b> Double LASSO</a></li>
<li class="chapter" data-level="14.8" data-path="resumo-1.html"><a href="resumo-1.html#dml-1"><i class="fa fa-check"></i><b>14.8</b> DML</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="interferência-spillover-e-dinâmica.html"><a href="interferência-spillover-e-dinâmica.html"><i class="fa fa-check"></i><b>15</b> Interferência, spillover e dinâmica</a>
<ul>
<li class="chapter" data-level="15.1" data-path="interferência-spillover-e-dinâmica.html"><a href="interferência-spillover-e-dinâmica.html#suposições-simplifcadoras"><i class="fa fa-check"></i><b>15.1</b> Suposições simplifcadoras</a></li>
<li class="chapter" data-level="15.2" data-path="interferência-spillover-e-dinâmica.html"><a href="interferência-spillover-e-dinâmica.html#po-com-tratamento-de-múltiplos-valores-multi-valued"><i class="fa fa-check"></i><b>15.2</b> PO com tratamento de múltiplos valores (multi-valued)</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="interferência-spillover-e-dinâmica.html"><a href="interferência-spillover-e-dinâmica.html#multi-valued-discreto"><i class="fa fa-check"></i><b>15.2.1</b> Multi-valued discreto</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="interferência-spillover-e-dinâmica.html"><a href="interferência-spillover-e-dinâmica.html#dinâmica"><i class="fa fa-check"></i><b>15.3</b> Dinâmica</a></li>
<li class="chapter" data-level="15.4" data-path="interferência-spillover-e-dinâmica.html"><a href="interferência-spillover-e-dinâmica.html#interferência"><i class="fa fa-check"></i><b>15.4</b> Interferência</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Curso de Inferência Causal</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="machine-learning" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">Capítulo 12</span> Machine Learning<a href="machine-learning.html#machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introdução-6" class="section level2 hasAnchor" number="12.1">
<h2><span class="header-section-number">12.1</span> Introdução<a href="machine-learning.html#introdução-6" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Em estudos observacionais, como vimos, análises baseadas no pressuposto de <em>conditional ignorability</em> do tratamento e positividade permitem a estimação de quantidades causais de interesse.
As técnicas de machine learning foram desenvolvidas em geral voltadas para problema de previsão, não de inferência causal. Por isso, não são normalmente uma alternativa boa para as questões de identificação causal que temos discutido no curso. Contudo, com algumas adaptações, podem ser usadas para análise de causa e efeito.</p>
<p>Uma das abordagens mais populares é a sugerida por Belloni et. al (2014), de usar LASSO (Least Absolute Shrinkage and Selection Operator) para inferir causalidade.</p>
</div>
<div id="terminologia" class="section level2 hasAnchor" number="12.2">
<h2><span class="header-section-number">12.2</span> Terminologia<a href="machine-learning.html#terminologia" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Estatística Machine Learning</p>
<p>observações</p>
<div id="lasso" class="section level3 hasAnchor" number="12.2.1">
<h3><span class="header-section-number">12.2.1</span> LASSO<a href="machine-learning.html#lasso" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>O estimador de Mínimos Quadrados Ordinários é obtido minimizando a soma dos quadrados dos resíduos, isto é, em uma regressão <span class="math inline">\(y_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \ldots + \beta_p x_{pi} + e_i\)</span>, minimizamos <span class="math inline">\(\sum_{i=1}^n [y_i - (\alpha + \beta_1x_{1i} + \beta_2 x_{2i} + \ldots + \beta_px_{pi})]^2\)</span>. Nós podemos pensar essa minimização como uma função de custo. Quanto menor o erro total, menor o custo.</p>
<p>O estimador de LASSO adiciona uma penalidade a essa função de minimização <span class="math inline">\(\lambda \sum_{j=1}^p |\beta_j|\)</span>, ou seja, passamos a minimizar: <span class="math inline">\(\sum_{i=1}^n [y_i - (\alpha + \beta_1x_{1i} + \beta_2x_{2i} + \ldots + \beta_px_{pi})]^2 + \lambda \sum_{j=1}^p |\beta_j|\)</span></p>
<p>O termo <span class="math inline">\(\sum_{j=1}^p |\beta_j|\)</span> é chamado de norma L1. Ele envolve a soma absoluta dos parâmetros. Existem outras normas (L0, L2 etc.), isto é, outras formas de penalizar a estimação dos coeficientes. A norma L1 é conhecida como distância de Manhathan, e a intuição é que, se tenho dois pontos em Manhatan, <span class="math inline">\((x_1, y_1)\)</span> e <span class="math inline">\((x_2, y_2)\)</span>, que são ruas em esquinas opostas de uma quadra (na diagonal). Como as ruas são, em geral, em formato de grade, temos de andar uma quadra na vertical e outra na horizontal para sair de um ponto a outro. Essa distância é a norma L1. Se usássamos a norma L2, por exemplo, poderíamos ir na diagonal, que é dada pela distância euclidiana.</p>
<p>E <span class="math inline">\(\lambda\)</span> é um parâmetro não negativo que controla a força da penalização. Veja que coeficientes positivos dos <span class="math inline">\(\beta\)</span> aumentam o custo total, de modo que eles precisam ser compensados pelo ganho gerado na capacidade preditiva da variável associada (quanto maior a correlação parcial, menor o erro). Assim, ao introduzir essa penalidade, o LASSO estimula que apenas as variáveis com maior capacidade preditiva possuam coeficientes positivos, enquanto as de baixa capacidade preditiva terão coeficiente igual a zero. Nós chamamos isso de esparsividade do voetor de coeficientes, já que muitos deles serão zero. Dizemos também que a regressão foi estimada com regularização. Veja que o LASSO é o equivalente a uma regressão Bayesiana com uma priori nos parâmetros igual a um dupla exponencial, levando à interpretação de que a priori é uma forma de regularizar estimativas.</p>
<p>Quando <span class="math inline">\(\lambda \to 0\)</span>, of coeficientes convergem para os estimadores de MQO, e quando <span class="math inline">\(\lambda \to \infty\)</span> apenas o intercepto resta. Em ML, o método usual para achar <span class="math inline">\(\lambda\)</span> é validação cruzada (CV, de cross-validation), que é utilizada para favorecer previsões fora da amostra. Belloni et al. (2012) advoga escolhada baseada em teoria, também conhecido como LASSO rigoroso. Angrist &amp; Frandsen (2022) concluiram que essa abordagem rigorosa tende a favorecer modelos mais parsimoniosos (<span class="math inline">\(\lambda\)</span> maiores) do que com CV.</p>
</div>
<div id="double-lasso" class="section level3 hasAnchor" number="12.2.2">
<h3><span class="header-section-number">12.2.2</span> Double Lasso<a href="machine-learning.html#double-lasso" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>O estimador robusto mais popular é o Double Lasso. A ideia é que se eu tentar usar LASSO diretamente na equação de regressão <span class="math inline">\(y_i = \alpha + \beta_1D_i + BX + e_i\)</span>, variáveis correlacionadas entre si terão coeficientes zero, e potencialmente o tratamento será um delas, impedindo a estimação da quantidade causal de interesse. Estratégias como forçar D_i a permanecer na equação implicam que ficará fora da equação de penalização. Contudo, isso pode causar viés na estimação de <span class="math inline">\(\beta_1\)</span> (Belloni et al., 2014). Essa regularização força variáveis correlacionadas com o tratamento a serem dropadas, o que significa dropar potenciais variáveis de confusão.</p>
<p>Resumo: não use as técnicas de ML diretamente na equação de regressão.</p>
<p>Exemplo.</p>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="machine-learning.html#cb161-1" tabindex="-1"></a><span class="co"># vou rodar mil simulações com n=100</span></span>
<span id="cb161-2"><a href="machine-learning.html#cb161-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb161-3"><a href="machine-learning.html#cb161-3" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">50</span> <span class="co"># número de controles</span></span>
<span id="cb161-4"><a href="machine-learning.html#cb161-4" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span> <span class="co"># número de obs</span></span>
<span id="cb161-5"><a href="machine-learning.html#cb161-5" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> .<span class="dv">2</span> <span class="co"># intercepto</span></span>
<span id="cb161-6"><a href="machine-learning.html#cb161-6" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="dv">0</span> <span class="co"># efeito do tratamento</span></span>
<span id="cb161-7"><a href="machine-learning.html#cb161-7" tabindex="-1"></a>gamma <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="at">min=</span><span class="sc">-</span><span class="dv">1</span>, <span class="at">max=</span><span class="dv">1</span>, <span class="at">n=</span>k) <span class="co"># efeito do vetor de controles</span></span>
<span id="cb161-8"><a href="machine-learning.html#cb161-8" tabindex="-1"></a>delta <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="at">min=</span><span class="sc">-</span><span class="dv">1</span>, <span class="at">max=</span><span class="dv">1</span>, <span class="at">n=</span>k) </span>
<span id="cb161-9"><a href="machine-learning.html#cb161-9" tabindex="-1"></a>erro <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb161-10"><a href="machine-learning.html#cb161-10" tabindex="-1"></a>vec_x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n<span class="sc">*</span>k, <span class="at">mean =</span> <span class="fu">rep</span>(<span class="dv">0</span>,k)) <span class="co"># vetor de controles</span></span>
<span id="cb161-11"><a href="machine-learning.html#cb161-11" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">matrix</span>(vec_x, <span class="at">ncol=</span>k)</span>
<span id="cb161-12"><a href="machine-learning.html#cb161-12" tabindex="-1"></a>D <span class="ot">&lt;-</span> x<span class="sc">%*%</span>delta <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb161-13"><a href="machine-learning.html#cb161-13" tabindex="-1"></a>y <span class="ot">&lt;-</span> alpha <span class="sc">+</span> beta<span class="sc">*</span>D <span class="sc">+</span> x<span class="sc">%*%</span>gamma <span class="sc">+</span> erro</span>
<span id="cb161-14"><a href="machine-learning.html#cb161-14" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span>D <span class="sc">+</span> x)</span></code></pre></div>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="machine-learning.html#cb162-1" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb162-2"><a href="machine-learning.html#cb162-2" tabindex="-1"></a></span>
<span id="cb162-3"><a href="machine-learning.html#cb162-3" tabindex="-1"></a></span>
<span id="cb162-4"><a href="machine-learning.html#cb162-4" tabindex="-1"></a>sim_df_ds <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">n_sim=</span><span class="dv">1000</span>, <span class="at">n_sample=</span><span class="dv">100</span>) {</span>
<span id="cb162-5"><a href="machine-learning.html#cb162-5" tabindex="-1"></a>  vec_p_values <span class="ot">&lt;-</span> <span class="fu">numeric</span>()</span>
<span id="cb162-6"><a href="machine-learning.html#cb162-6" tabindex="-1"></a>  lista_df <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb162-7"><a href="machine-learning.html#cb162-7" tabindex="-1"></a>  </span>
<span id="cb162-8"><a href="machine-learning.html#cb162-8" tabindex="-1"></a>  <span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_sim) {</span>
<span id="cb162-9"><a href="machine-learning.html#cb162-9" tabindex="-1"></a>n <span class="ot">&lt;-</span> n_sample</span>
<span id="cb162-10"><a href="machine-learning.html#cb162-10" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> .<span class="dv">2</span></span>
<span id="cb162-11"><a href="machine-learning.html#cb162-11" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb162-12"><a href="machine-learning.html#cb162-12" tabindex="-1"></a>gamma <span class="ot">&lt;-</span> .<span class="dv">2</span></span>
<span id="cb162-13"><a href="machine-learning.html#cb162-13" tabindex="-1"></a>erro <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb162-14"><a href="machine-learning.html#cb162-14" tabindex="-1"></a></span>
<span id="cb162-15"><a href="machine-learning.html#cb162-15" tabindex="-1"></a>mean_vector <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb162-16"><a href="machine-learning.html#cb162-16" tabindex="-1"></a>cov_matrix <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="fl">0.8</span>, <span class="fl">0.8</span>, <span class="dv">1</span>), <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb162-17"><a href="machine-learning.html#cb162-17" tabindex="-1"></a></span>
<span id="cb162-18"><a href="machine-learning.html#cb162-18" tabindex="-1"></a><span class="co"># Gerando os dados</span></span>
<span id="cb162-19"><a href="machine-learning.html#cb162-19" tabindex="-1"></a>simulated_data <span class="ot">&lt;-</span> <span class="fu">mvrnorm</span>(<span class="at">n =</span> n, <span class="at">mu =</span> mean_vector, <span class="at">Sigma =</span> cov_matrix)</span>
<span id="cb162-20"><a href="machine-learning.html#cb162-20" tabindex="-1"></a></span>
<span id="cb162-21"><a href="machine-learning.html#cb162-21" tabindex="-1"></a><span class="co"># Convertendo para um data frame para facilitar a manipulação</span></span>
<span id="cb162-22"><a href="machine-learning.html#cb162-22" tabindex="-1"></a>D <span class="ot">=</span> simulated_data[,<span class="dv">1</span>]</span>
<span id="cb162-23"><a href="machine-learning.html#cb162-23" tabindex="-1"></a>x <span class="ot">=</span> simulated_data[,<span class="dv">2</span>]</span>
<span id="cb162-24"><a href="machine-learning.html#cb162-24" tabindex="-1"></a>y <span class="ot">&lt;-</span> alpha <span class="sc">+</span> beta<span class="sc">*</span>D <span class="sc">+</span> gamma<span class="sc">*</span>x <span class="sc">+</span> erro</span>
<span id="cb162-25"><a href="machine-learning.html#cb162-25" tabindex="-1"></a></span>
<span id="cb162-26"><a href="machine-learning.html#cb162-26" tabindex="-1"></a>df_sim <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(y, D, x)</span>
<span id="cb162-27"><a href="machine-learning.html#cb162-27" tabindex="-1"></a>lista_df[[i]] <span class="ot">&lt;-</span> df_sim</span>
<span id="cb162-28"><a href="machine-learning.html#cb162-28" tabindex="-1"></a></span>
<span id="cb162-29"><a href="machine-learning.html#cb162-29" tabindex="-1"></a>  }</span>
<span id="cb162-30"><a href="machine-learning.html#cb162-30" tabindex="-1"></a>  </span>
<span id="cb162-31"><a href="machine-learning.html#cb162-31" tabindex="-1"></a>  <span class="fu">return</span>(lista_df)</span>
<span id="cb162-32"><a href="machine-learning.html#cb162-32" tabindex="-1"></a>}</span>
<span id="cb162-33"><a href="machine-learning.html#cb162-33" tabindex="-1"></a></span>
<span id="cb162-34"><a href="machine-learning.html#cb162-34" tabindex="-1"></a></span>
<span id="cb162-35"><a href="machine-learning.html#cb162-35" tabindex="-1"></a>lista_df <span class="ot">&lt;-</span> <span class="fu">sim_df_ds</span>()</span>
<span id="cb162-36"><a href="machine-learning.html#cb162-36" tabindex="-1"></a></span>
<span id="cb162-37"><a href="machine-learning.html#cb162-37" tabindex="-1"></a>vec_p_values <span class="ot">&lt;-</span> <span class="fu">numeric</span>()</span>
<span id="cb162-38"><a href="machine-learning.html#cb162-38" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>) {</span>
<span id="cb162-39"><a href="machine-learning.html#cb162-39" tabindex="-1"></a>  fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span>D <span class="sc">+</span> x, <span class="at">data=</span>lista_df[[i]])</span>
<span id="cb162-40"><a href="machine-learning.html#cb162-40" tabindex="-1"></a>  summary_fit <span class="ot">&lt;-</span> <span class="fu">summary</span>(fit)</span>
<span id="cb162-41"><a href="machine-learning.html#cb162-41" tabindex="-1"></a>  </span>
<span id="cb162-42"><a href="machine-learning.html#cb162-42" tabindex="-1"></a>  <span class="co"># Obtendo o valor p associado ao coeficiente de x</span></span>
<span id="cb162-43"><a href="machine-learning.html#cb162-43" tabindex="-1"></a>  vec_p_values[i] <span class="ot">&lt;-</span> summary_fit<span class="sc">$</span>coefficients[<span class="st">&quot;D&quot;</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]</span>
<span id="cb162-44"><a href="machine-learning.html#cb162-44" tabindex="-1"></a>}</span>
<span id="cb162-45"><a href="machine-learning.html#cb162-45" tabindex="-1"></a></span>
<span id="cb162-46"><a href="machine-learning.html#cb162-46" tabindex="-1"></a><span class="fu">hist</span>(vec_p_values, <span class="at">breaks =</span> <span class="dv">40</span>, <span class="at">main =</span> <span class="st">&quot;Teste de signific. de D&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;p-valor&quot;</span>)</span>
<span id="cb162-47"><a href="machine-learning.html#cb162-47" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">0.05</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">lty =</span> <span class="dv">1</span>)</span>
<span id="cb162-48"><a href="machine-learning.html#cb162-48" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.1</span>, <span class="fu">par</span>(<span class="st">&quot;usr&quot;</span>)[<span class="dv">4</span>] <span class="sc">*</span> <span class="fl">0.75</span>, <span class="st">&quot;0.05&quot;</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">pos =</span> <span class="dv">3</span>, <span class="at">cex=</span>.<span class="dv">5</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/cap13-sim2-1.png" width="672" /></p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="machine-learning.html#cb163-1" tabindex="-1"></a><span class="co"># percentual p-valor menor que 5%</span></span>
<span id="cb163-2"><a href="machine-learning.html#cb163-2" tabindex="-1"></a><span class="fu">sum</span>(vec_p_values <span class="sc">&lt;=</span> .<span class="dv">05</span>)<span class="sc">/</span><span class="dv">1000</span></span></code></pre></div>
<pre><code>## [1] 0.059</code></pre>
<p>Nós rejeitamos a hipótese nula aproximadamente 50% do tempo.</p>
<p>E se usarmos LASSO (single LASSO)?</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="machine-learning.html#cb165-1" tabindex="-1"></a><span class="co"># Instalar e carregar o pacote glmnet, se necessário</span></span>
<span id="cb165-2"><a href="machine-learning.html#cb165-2" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb165-3"><a href="machine-learning.html#cb165-3" tabindex="-1"></a></span>
<span id="cb165-4"><a href="machine-learning.html#cb165-4" tabindex="-1"></a><span class="co"># Vetor para armazenar se x foi selecionado pelo LASSO</span></span>
<span id="cb165-5"><a href="machine-learning.html#cb165-5" tabindex="-1"></a>lasso_selected_D <span class="ot">&lt;-</span> <span class="fu">numeric</span>()</span>
<span id="cb165-6"><a href="machine-learning.html#cb165-6" tabindex="-1"></a></span>
<span id="cb165-7"><a href="machine-learning.html#cb165-7" tabindex="-1"></a><span class="co"># Loop de simulação</span></span>
<span id="cb165-8"><a href="machine-learning.html#cb165-8" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>) {</span>
<span id="cb165-9"><a href="machine-learning.html#cb165-9" tabindex="-1"></a>  y <span class="ot">&lt;-</span> lista_df[[i]]<span class="sc">$</span>y</span>
<span id="cb165-10"><a href="machine-learning.html#cb165-10" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(lista_df[[i]]<span class="sc">$</span>D, lista_df[[i]]<span class="sc">$</span>x) </span>
<span id="cb165-11"><a href="machine-learning.html#cb165-11" tabindex="-1"></a>  <span class="co"># Preparando os dados para o LASSO</span></span>
<span id="cb165-12"><a href="machine-learning.html#cb165-12" tabindex="-1"></a>  <span class="co"># Matriz de preditores (sem a interceptação)</span></span>
<span id="cb165-13"><a href="machine-learning.html#cb165-13" tabindex="-1"></a></span>
<span id="cb165-14"><a href="machine-learning.html#cb165-14" tabindex="-1"></a>  <span class="co"># Ajustando o modelo LASSO com validação cruzada</span></span>
<span id="cb165-15"><a href="machine-learning.html#cb165-15" tabindex="-1"></a>  lasso_model <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X, y, <span class="at">alpha =</span> <span class="dv">1</span>) <span class="co"># alpha = 1 para LASSO</span></span>
<span id="cb165-16"><a href="machine-learning.html#cb165-16" tabindex="-1"></a></span>
<span id="cb165-17"><a href="machine-learning.html#cb165-17" tabindex="-1"></a>  <span class="co"># Extraindo os coeficientes no valor de lambda que minimiza o erro</span></span>
<span id="cb165-18"><a href="machine-learning.html#cb165-18" tabindex="-1"></a>  lasso_coefs <span class="ot">&lt;-</span> <span class="fu">coef</span>(lasso_model, <span class="at">s =</span> <span class="st">&quot;lambda.min&quot;</span>)</span>
<span id="cb165-19"><a href="machine-learning.html#cb165-19" tabindex="-1"></a></span>
<span id="cb165-20"><a href="machine-learning.html#cb165-20" tabindex="-1"></a>  <span class="co"># Verificando se a variável x foi selecionada pelo LASSO (coeficiente diferente de zero)</span></span>
<span id="cb165-21"><a href="machine-learning.html#cb165-21" tabindex="-1"></a>  lasso_selected_D[i] <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(lasso_coefs[<span class="st">&quot;V1&quot;</span>, <span class="dv">1</span>] <span class="sc">!=</span> <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb165-22"><a href="machine-learning.html#cb165-22" tabindex="-1"></a>}</span>
<span id="cb165-23"><a href="machine-learning.html#cb165-23" tabindex="-1"></a></span>
<span id="cb165-24"><a href="machine-learning.html#cb165-24" tabindex="-1"></a><span class="co"># Analisando os resultados</span></span>
<span id="cb165-25"><a href="machine-learning.html#cb165-25" tabindex="-1"></a><span class="fu">hist</span>(lasso_selected_D, <span class="at">breaks =</span> <span class="dv">40</span>, <span class="at">main =</span> <span class="st">&quot;Seleção de x pelo LASSO&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;x selecionado (1 = sim, 0 = não)&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/cap13-sim3-1.png" width="672" /></p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="machine-learning.html#cb166-1" tabindex="-1"></a><span class="fu">sum</span>(lasso_selected_D <span class="sc">&lt;=</span> .<span class="dv">05</span>)<span class="sc">/</span><span class="dv">1000</span></span></code></pre></div>
<pre><code>## [1] 0.564</code></pre>
<p>Também não funciona, mais ou menos mesma taxa de erro.</p>
</div>
<div id="outras-soluções-ineficazes" class="section level3 hasAnchor" number="12.2.3">
<h3><span class="header-section-number">12.2.3</span> Outras soluções ineficazes<a href="machine-learning.html#outras-soluções-ineficazes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Bootstrap (não funciona)
Clássico: suponha que a covariável não é relevante
Conservador: sempre inclua quantos controles puder (pode gerar Collider Bias).</p>
<p>DL lida com essa situação fazendo uma modelagem dupla, tanto do tratamento quanto da respota. Daí o nome, Double Lasso.</p>
</div>
</div>
<div id="dl---algoritmo" class="section level2 hasAnchor" number="12.3">
<h2><span class="header-section-number">12.3</span> DL - Algoritmo<a href="machine-learning.html#dl---algoritmo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Passo 1. Inclua controle se ele for preditor significativo da resposta <span class="math inline">\(y_i\)</span> por um teste conservador (teste t, LASSO etc.)</p>
<p>PAsso 2. Inclua controle se ele preditor significativo do tratamento <span class="math inline">\(D_i\)</span> por um teste conservador (teste t, LASSO etc.).</p>
<p>Passo 3. Ajuste o modelo com as variáveis selecionadas e o tratamento. Esse passo é chamado de Pós MQO (Post OLS)</p>
<p>Np R, podemos usar o pacote “hdm” para fazer a implementação em uma linha.</p>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="machine-learning.html#cb168-1" tabindex="-1"></a><span class="fu">library</span>(hdm)</span>
<span id="cb168-2"><a href="machine-learning.html#cb168-2" tabindex="-1"></a><span class="fu">library</span>(knitr)</span>
<span id="cb168-3"><a href="machine-learning.html#cb168-3" tabindex="-1"></a>d_s_vec <span class="ot">&lt;-</span> <span class="fu">numeric</span>()</span>
<span id="cb168-4"><a href="machine-learning.html#cb168-4" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>) {</span>
<span id="cb168-5"><a href="machine-learning.html#cb168-5" tabindex="-1"></a>  my_double_selection <span class="ot">&lt;-</span> <span class="fu">rlassoEffects</span>(y<span class="sc">~</span>. , <span class="at">I=</span><span class="sc">~</span>x <span class="sc">+</span> D, <span class="at">data=</span>lista_df[[i]])</span>
<span id="cb168-6"><a href="machine-learning.html#cb168-6" tabindex="-1"></a>  d_s_vec[i] <span class="ot">&lt;-</span> <span class="fu">summary</span>(my_double_selection)<span class="sc">$</span>coefficients[<span class="st">&quot;D&quot;</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]</span>
<span id="cb168-7"><a href="machine-learning.html#cb168-7" tabindex="-1"></a>  </span>
<span id="cb168-8"><a href="machine-learning.html#cb168-8" tabindex="-1"></a>}</span>
<span id="cb168-9"><a href="machine-learning.html#cb168-9" tabindex="-1"></a></span>
<span id="cb168-10"><a href="machine-learning.html#cb168-10" tabindex="-1"></a><span class="fu">hist</span>(d_s_vec, <span class="at">breaks =</span> <span class="dv">40</span>, <span class="at">main =</span> <span class="st">&quot;Seleção de D pelo Double LASSO&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;p-valor&quot;</span>)</span>
<span id="cb168-11"><a href="machine-learning.html#cb168-11" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">0.05</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">lty =</span> <span class="dv">1</span>)</span>
<span id="cb168-12"><a href="machine-learning.html#cb168-12" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.1</span>, <span class="fu">par</span>(<span class="st">&quot;usr&quot;</span>)[<span class="dv">4</span>] <span class="sc">*</span> <span class="fl">0.75</span>, <span class="st">&quot;0.05&quot;</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">pos =</span> <span class="dv">3</span>, <span class="at">cex=</span>.<span class="dv">5</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/cap-13-hdm-1.png" width="672" /></p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="machine-learning.html#cb169-1" tabindex="-1"></a><span class="fu">sum</span>(d_s_vec <span class="sc">&lt;=</span> .<span class="dv">05</span>)<span class="sc">/</span><span class="dv">1000</span></span></code></pre></div>
<pre><code>## [1] 0.062</code></pre>
<p>Como vemos, aproximadamente 5% das vezes nós rejeitamos a hipótese nula erradamente, que é o esperado do p-valor de 5%.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="llms-e-outras.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="termos-de-interação.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/mgaldino/Causalidade/edit/main/13-ML.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": "https://github.com/mgaldino/Causalidade/blob/main/13-ML.Rmd",
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
