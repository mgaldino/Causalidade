# Desenho de Regresão Discontínua

## Outline da aula

Na aula de hoje, iremos aprender sobre identificação causal do do aspecto mais simples da RD e como funciona

Em seguida, estimação e checagem. Falaremos rapidamente de extensões.

## Características-chave da RDD

A Regressão Discontínua (RDD) é caracterizada por uma variável contínua $X_i$, que determina quem recebe tratamento, denotado por $T_i$ (1 se tratado). Por convenção, $X$ é chamada de "running variable", "assignment variable" ou "forcing variable".

### Determinação do Tratamento

Em um desenho RDD *sharp*, uma unidade é tratada se $X_i \geq c$ e não tratada se $X_i < c$. Assim, $T_i$ é uma função determinística de $X_i$: $T_i = f(X_i)$. A *running variable* determina completamente quem recebe tratamento.

## Fuzzy RDD

- Pode acontecer do ponto de corte não determinar quem recebe ou não o tratamento, mas apenas a probabilidade de receber o tratamento.

- Nesse caso, a regra serve como variável instrumental ao redor do ponto de corte.

- Ex.: regra de voto determina número de cadeiras. Mas migração partidária altera o número. Então quem fica abaixo do número mínimo em um distrito pode ter cadeiras naquele distrito via migração partidária.

### Observação e Corte

É essencial observar $X$ e conhecer o **ponto de corte** ou **limiar** $c$.

Uma das suposições da RDD é que ela requer a continuidade da variável $X$ para identificação, embora, na prática, alguns estudos de RDD tenham usado *running variables* discretas. A continuidade de $X$ é necessária porque a identificação ocorre no limite.

Mas a suposiçao chave é que os resultados potenciais devem ser contínuos ao redor do ponto de corte. Como sempre, essa suposição é intestável, devido ao problema fundamental da inferência causal. Lee (2008), em um artigo clássico, mostrou que uma condição mais restritiva é suficiente para identificação causal: que as unidades podem controlar a running varibale, exceto ao redor do ponto de corte. Isso implica também que as covariáveis de pré-tratamento são contínuas no cutoff. Isso é potencialmente testável, pelo menos nas variáveis observadas e em geral olhando para a média das variáveis, o que não é a mesma coisa que olhar para outros momentos, que podem ser descontínuos.

### Estimativa dos Efeitos do Tratamento

A comparação de $\lim_{x \uparrow c} E[Y_i | X_i = x]$ com $\lim_{x \downarrow c} E[Y_i | X_i = x]$ fornece uma estimativa dos efeitos do tratamento (note a direção das setas).

Esta comparação é equivalente a: $\lim_{x \uparrow c} E[Y_i | X_i = x, T_i=0]$ e $\lim_{x \downarrow c} E[Y_i | X_i = x, T_i=1]$, uma vez que, neste exemplo, à direita de $c$ todos recebem tratamento; à esquerda, ninguém recebe. Portanto:

- $\lim_{x \uparrow c} E[Y_i | X_i = x] \approx E[Y_{0i} | X_i = c]$
- $\lim_{x \downarrow c} E[Y_i | X_i = x] \approx E[Y_{1i} | X_i = c]$

Se fôssemos usar regressão linear, o modelo seria:
$y_i = \alpha + \beta_1 (x_i > c) + \beta_2 x_i + \beta_3 x (x_i > c) + e_i$, em que $c$ é o ponto de corte, e $x$ é a *running variable*.

## Suposição de continuidade

- A suposição de continuidade é tão crítica que vale discutirmos um pouco mais sobre ela.
- Se há continuidade, isso significa que, na auência do ponto de corte $c$, x (e outras covariáveis) não devem apresentar descontinuidade.
- Ex.: Suponha que estamos interessados em estudar o efeito da incumbência sobre a chance de reeleição futura ou riqueza futura desses políticos.
- Habilidades e carisma são variáveis que devem influenciar tanto a chance de serem incumbentes como os resultados de interesse. Em um RDD, podemos usar *close elections* para estimar o efeito. E a suposição de continuidade requer que carisma e habilidades não tenham descontinuidade no *cut off* de 50%. Na verdade, apenas o resultado eleitoral é descontínuo no *cut off*, que vai de não-eleito para eleito.

## Suposições na RDD

### Suposição de Não-manipulação com Precisão

A identificação dos efeitos do tratamento na RDD baseia-se na premissa de que $X$ atua como um aleatorizador ao redor de $c$. Imagine que $X$ seja uma variável aleatória uniforme usada para atribuir tratamento. Se $X \geq c$, uma unidade recebe tratamento. Na RDD, $X$ tem o mesmo papel, exceto que não assumimos que $X$ é independente do resultado $Y$. Na maioria das aplicações, $X$ e $Y$ são correlacionados de alguma forma.

### Problemas de Manipulação

No entanto, se $c$ não for arbitrário ou tiver uma relação determinística com $Y$, ou se as unidades puderem — com precisão — determinar seus escores $X$ e, assim, escolher receber tratamento ou não, então $X$ ao redor de $c$ não se comporta mais como um aleatorizador — há alguma forma de auto-seleção que poderia depender de variáveis não observáveis.

## Testabilidade da Suposição de não-Manipulação

Em parte, isso é testável. As unidades não pareceriam semelhantes perto de $c$ e haveria um "acúmulo" próximo a $c$. No entanto, não podemos descartar a manipulação com precisão apenas com dados — devemos argumentar isso com conhecimento do assunto (é uma restrição de exclusão).

## Estimação em RDD

### Problema de Complete Overlapping

Um problema chave na estimação em RDD estrita é a completa falta de sobreposição.

Em matching, dicustimos como a ausência de sobreposição gerava problemas de extrapolação.

Sobreposição requer que $0 < P(D_i = 1 | X_i) < 1$ para o domínio de $X_i$. No domínio da *running vairable* $X_i$, isso claramente não é satisfeito. Em RDD estrita, temos $P(D_i = 1 | X_i < c) = 0$ e $P(D_i = 1 | X_i \geq c) = 1$.

### Dependência de Extrapolação

Devido à falta de sobreposição, dependemos de extrapolação para estimar os efeitos do tratamento. Dito de outra forma, podemos não ser capazes de estimar corretamente os efeitos do tratamento se errarmos a forma funcional $Y_i = f(X_i)$. Novamente, essa foi uma motivação para usar matching. 

O problema é que nunca sabemos se acertamos, então a especificação do modelo é uma questão chave na estimação RDD.

## Métodos de Estimação

O problema sugere a necessidade de um método de estimação não paramétrico. Utilizaremos métodos paramétricos, não paramétricos (ou semiparamétricos) para tentar abordar essas questões.

### Identificação no Limite

A identificação dos efeitos do tratamento ocorre no limite, à medida que $X_i \rightarrow c$. Quanto mais usarmos observações distantes de $c$ em $X$, mais dependeremos de extrapolação e das suposições sobre a forma funcional.

## Trade-off de Viés-Variância

- **Mais perto de c:** Melhor em termos de precisão, mas pode haver uma amostra insuficiente. Resulta em menos viés, mas mais variância.
- **Mais distante de c:** Dependemos menos de extrapolação, mas introduzimos mais viés, mesmo com menor variância.

### Métodos de Largura de Banda Ótima

A ideia é restringir a estimativa a uma janela ao redor de $X_i = c$, que pode ter tamanhos diferentes à esquerda ou à direita. Estes métodos buscam equilibrar a precisão das estimativas minimizando viés e variância conforme a proximidade do ponto de corte $c$.

## Regras arbitrárias

Atribuição de "coisas" a partir de regras com pontos de cortes

Bolsa família: a partir de certa renda

Educação: aprovação no ensino superior a partir de certa nota de corte

Espacial: polítia pública para donos de áreas abaixo ou acima de certas áreas.

Data: regras para aposentadoria, idade para entrar na escola, data para perdão de dívida: Desenrola: "...cujas dívidas tenham sido incluídas no cadastro de inadimplentes no período entre 1º de janeiro de 2019 e 31 de dezembro de 2022".

Política: regras de número de vereadores, regras de população para ter segundo turno, regras para ter biometria etc.

## Simulação

```{r}
## Basic RD Model
set.seed(123)
N <- 1000 # number of observations
X <- runif (N , -5,5)
Y0 <- rnorm ( n =N , mean =X , sd=1) # control potential outcome
Y1 <- rnorm ( n =N , mean = X+2, sd=1) # treatment potential outcome
#You only get treatment if X>0
Treatment <- ( X >= 0)
# What we observe
Y = Y1* Treatment + Y0*(1- Treatment )
```


```{r, echo=FALSE, warning=FALSE, message=FALSE}
## Basic RD Model
library(ggplot2)
library(tidyverse)

# df
df <- data.frame(y=Y, x=X, treatment = Treatment, y0 = Y0, y1=Y1)
df_aux <- df
```

```{r plot-treatment-assignment, echo=FALSE}
df %>%
  ggplot(aes(x=x, y=treatment)) + geom_line() +
  labs(x = "running variable", y = "Treatment") +
  theme_minimal()  
```

## Simulação - Potential Outcomes Y0


```{r plot-po-y0, echo=FALSE}
df %>%
  ggplot(aes(x=x, y=y0, colour=treatment)) + geom_point() +
  labs(x = "running variable", y = "Potential Outcome Y0") +
  scale_colour_manual(values = c("black", "red")) +
  theme_minimal() +
  theme(legend.position = "none")

```

## Simulação - Potential Outcomes Y1


```{r plot-po-y1, echo=FALSE}

df %>%
  ggplot(aes(x=x, y=y1, colour=treatment)) + geom_point() +
  labs(x = "running variable", y = "Potential Outcome Y1") +
  scale_colour_manual(values = c("green", "blue")) +
  theme_minimal() +
  theme(legend.position = "none")

```

## Simulação - Potential Outcomes Y1 e Y0


```{r plot-po-y1-Y0, echo=FALSE, message=FALSE}
df_long <- df %>%
  pivot_longer(
    cols = c("y0", "y1"),
    names_to = "outcome_type",
    values_to = "outcome"
  )
df_long_aux <- df_long

ggplot(df_long, aes(x = x, y = outcome, colour = interaction(treatment, outcome_type))) +
  geom_point() +
  scale_colour_manual(values = c("FALSE.y0" = "black", "TRUE.y0" = "red",
                                 "FALSE.y1" = "green", "TRUE.y1" ="blue")) +
  labs(x = "Running Variable", y = "Potential Outcome") +
  theme_minimal() +
  theme(legend.position = "none")

df_long %>%
  ggplot(aes(x=x, y=outcome, group = outcome_type)) + geom_smooth(se=FALSE) +
  geom_vline(xintercept = 0)  +
  scale_color_manual(values = c(
    "y0" = "blue",
    "y1" = "red"
  ))
```

## Simulação - Y observado
```{r plot-observed, echo=FALSE}

ggplot(df, aes(x = x, y = y, colour = treatment)) +
  geom_point() +
  scale_colour_manual(values = c("black", "blue")) +
  labs(x = "Running Variable", y = "Resultados observados - Y") +
  theme_minimal() +
  theme(legend.position = "none")
```

## Quando o RDD funciona?

A suposição chave para o RDD é que tenha descontinuidade ao redor do ponto de corte, e que não haja descontinuidade ao redor do ponto de corte em outra variável omitida. Vamos ver o que isso significa, comparando quator gráficos, três em que a estimativa do RDD é válida, mas com diferentes validades "externas" e uma em que é inválida.

```{r multiplos_rdds, echo=FALSE, message=FALSE}
library(rdrobust)
set.seed(123)
N <- 1000 # number of observations
U <- rnorm(N)
X <- runif (N , -5,5) - U
X <- X - mean(X)
Y0 <- rnorm ( n =N , mean =X , sd=2) + 2*U^2  # control potential outcome
Y1 <- Y0 + 2 + 2*U^2  # treatment potential outcome
#You only get treatment if X>0
Treatment <- ( X >= 0)
# What we observe
Y = Y1* Treatment + Y0*(1- Treatment )
mean(Y1 - Y0)
df <- data.frame(y=Y, x=X, treatment = Treatment, y0 = Y0, y1=Y1)


df_long <- df %>%
  pivot_longer(
    cols = c("y0", "y1"),
    names_to = "outcome_type",
    values_to = "outcome"
  )

df_long %>%
  ggplot(aes(x=x, y=outcome, group = outcome_type, colour = outcome_type)) + geom_smooth(se=FALSE) +
  geom_vline(xintercept = 0) +
  scale_color_manual(values = c(
    "y0" = "blue",
    "y1" = "red"
  ))
# 2

Y0 <- rnorm ( n =N , mean =X , sd=1) + .5*U^2 - X*U # control potential outcome
Y1 <- Y0 + 2 + 2*X*U # treatment potential outcome
#You only get treatment if X>0
Treatment <- ( X >= 0)
# What we observe
Y = Y1* Treatment + Y0*(1- Treatment )
mean(Y1 - Y0)
df <- data.frame(y=Y, x=X, treatment = Treatment, y0 = Y0, y1=Y1, u = U)
df_u <- df

df_long <- df %>%
  pivot_longer(
    cols = c("y0", "y1"),
    names_to = "outcome_type",
    values_to = "outcome"
  )

df_long %>%
  ggplot(aes(x=x, y=outcome, group = outcome_type, colour = outcome_type)) + geom_smooth(se=FALSE) +
  geom_vline(xintercept = 0) +
  scale_color_manual(values = c(
    "y0" = "blue",
    "y1" = "red"
  ))


# 3
Y0 <- rnorm ( n =N , mean =X , sd=1) + U^2   # control potential outcome

Y1 <- Y0 + 2 - 1.5*U^3 # treatment potential outcome
#You only get treatment if X>0
Treatment <- ( X >= 0)
# What we observe
Y = Y1* Treatment + Y0*(1- Treatment )

df <- data.frame(y=Y, x=X, treatment = Treatment, y0 = Y0, y1=Y1)


df_long <- df %>%
  pivot_longer(
    cols = c("y0", "y1"),
    names_to = "outcome_type",
    values_to = "outcome"
  )

df_long %>%
  ggplot(aes(x=x, y=outcome, group = outcome_type, colour = outcome_type)) + geom_smooth(se=FALSE) +
  geom_vline(xintercept = 0) +
  scale_color_manual(values = c(
    "y0" = "blue",
    "y1" = "red"
  ))


# 4
f0 <- function(x) {  sin(x) * 1.5  - 0.1 * x    }       # E[Y(0)|X]
f1 <- function(x) {  f0(x)   +  0.5 * x      }          # E[Y(1)|X], so f1(0)=f0(0)

# 2. Build a long data.frame, tagging where each is observed
x_seq <- seq(-5, 5, length.out = 400)
df0 <- data.frame(x = x_seq, y = f0(x_seq), type = "E[Y(0)|X]")
df1 <- data.frame(x = x_seq, y = f1(x_seq), type = "E[Y(1)|X]")

df <- rbind(df0, df1)

# 3. Plot
ggplot(df, aes(x = x, y = y, color = type)) +
  geom_line(size = 1.2) +
  scale_color_manual(values = c(
    "E[Y(0)|X]" = "blue",
    "E[Y(1)|X]" = "red"
  ))

# 5
Y0 <- rnorm ( n =N , mean =X , sd=1)    # control potential outcome
m <- length(X[X < .4 & X > -.4])
Y1 <- Y0 + 2 # treatment potential outcome
Y0[X < .4 & X > -.4] <- rnorm(m , 2, sd = .3)
Treatment <- ( X >= 0)
# What we observe
Y = Y1* Treatment + Y0*(1- Treatment )

df <- data.frame(y=Y, x=X, treatment = Treatment, y0 = Y0, y1=Y1)

df <- data.frame(y=Y, x=X, treatment = Treatment, y0 = Y0, y1=Y1, u = U)


df_long <- df %>%
  pivot_longer(
    cols = c("y0", "y1"),
    names_to = "outcome_type",
    values_to = "outcome"
  )

df_long %>%
  ggplot(aes(x=x, y=outcome, group = outcome_type, colour = outcome_type)) + geom_smooth(se=FALSE) +
  geom_vline(xintercept = 0) +
  scale_color_manual(values = c(
    "y0" = "blue",
    "y1" = "red"
  ))

ggplot(df, aes(x = x, y = y, colour = treatment)) +
  geom_point() +
  scale_colour_manual(values = c("black", "blue")) +
  labs(x = "Running Variable", y = "Resultados observados - Y") +
  theme_minimal() +
  theme(legend.position = "none")

# mean(df$y1 - df$y0)
# mean(Y1 - Y0)
# basic_model <- rdrobust(y = df$y, x = df$x, c = 0)
# summary(basic_model)
# summary(lm(y ~ x, data=df))
# library(rdrobust)
rdplot(y=df$y, x=df$x, binselect = "qs")

```




## Raw Data versus Bin

```{r plot-binscatter, echo=FALSE}
df <- df_aux
df_long <- df_long_aux
ggplot(df, aes(x = x, y = y, color = treatment)) +
  stat_summary_bin(
    fun = mean,        # calcula a média de Y_cont em cada bin
    bins = 40,         # número de bins
    geom = "point",    # plota um ponto para cada bin
    size = 2
  ) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  labs(
    x     = "Variável de corte (X)",
    y     = "Média de Y",
    color = "Grupo",
    title = "Binscatter: médias nos bins em vez de dados brutos"
  ) +
  theme_minimal()
```

Como escolher os bins?
1. Espaçamentos iguais ou quantis?
2. Quantos bins?

No exemplo, escolhi espaçamento igual e 20 bins. Podemos usar quantis.
```{r plot-binscatter-quantis, echo=FALSE}
df2 <- df %>%
  mutate(bin = ntile(x, 40)) %>%           # 20 quantis
  group_by(bin, treatment) %>%
  summarize(
    x = mean(x),                           # posição média de x no bin
    y = mean(y),                           # média de y no bin
    .groups = "drop"
  )

ggplot(df2, aes(x = x, y = y, color = treatment)) +
  geom_point(size = 2) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  labs(
    x     = "Variável de corte (X)",
    y     = "Média de Y (por quantil)",
    color = "Grupo",
    title = "Binscatter com bins por quantis"
  ) +
  theme_minimal()
```

Não faz muita diferença neste exemplo, mas usar quantis é mais transparente e mais crível retoricamente, pois não mascara a densidade.

Sobre o número de bins, Cattaneo et. al (2020) discutem o tema e sugerem duas abordagens: 
1. IMSE-minimizing (proporcional a $n^{1/3}$)
2. Mimmicking-variance (proporcional a $n/log(n)^2$)

E usamos o pacote rdplot para implementar isso automaticamente

```{r plot-binscatter-quantis-rdplot-qs, echo=FALSE}
library(rddensity)
library(rdrobust)
rdplot(y=df$y, x=df$x, binselect = "qs")
```

```{r plot-binscatter-quantis-rdplot-qsmv, echo=FALSE}

rdplot(y=df$y, x=df$x, binselect = "qsmv")
```

## Permutation tests (balancing)

Para checar balancing, podemos usar testes de permutação.

```{r permutation-test, echo=TRUE, message=FALSE}
library(RATest)
df <- df_u
head(df)
resultado <- RDperm(
  W = "u",  # Substitua pelos nomes das suas covariáveis
  z = "x",              # Substitua pelo nome da sua variável de corte
  data = df,                # Substitua pelo seu data frame
  cutoff = 0                            # Substitua pelo valor do ponto de corte, se diferente de 0
)
summary(resultado)

plot(resultado, w="u", "cdf")
```

Canay& Kamat (2018) utiolizaram esse teste pars revisitar o trabalho de Lee (2008) e descobrem que havia problema de balanceamento.

Caughey and Sekhon (2011) na political analysis mostraram que de fato havia problemas de balanceamento no estudo de Lee (2008).



Do paper da PA:

```{r quote, echo=FALSE}

knitr::include_graphics("/Users/manoelgaldino/Documents/DCP/Cursos/Causalidade/Causalidade/imagens/quote.png")

knitr::include_graphics("/Users/manoelgaldino/Documents/DCP/Cursos/Causalidade/Causalidade/imagens/quote2.png")
```

Houve um debate na ciência política sobre isso.  Erikson & Rader (2017) e Cuesta & Imai (2016) argumentam que o RDD é identificado. Até onde eu sei, cientistas políticos não revisitaram a controvérsia com os novos metodos desenvolvidos pelos economistas.

De todo modo, as evidências de De Magalhães et. al (2025) sugerem que a recomendação que estou adotando no curso de quais práticas usar são as melhores e mais robustas.



## McCray test

Um dos principais desafios à identificação causal em RDDs é a possibilidade de manipulação por parte dos agentes sobre ficar acima ou abaixo do ponto de corte. A lógica esperada é que se o tratamento é desejável, indivíduos tentarão receber o tratanto, levando a um gap justamente abaixo do ponte de corte. Se o tratamento é indesejável (efeitos negativos), indivíduos vão evitar o tratamento, levando a um gap justamente acima do ponto de corte.

O exemplo mais evidente para nós cientistas políticos é a aprovação de um projeto de lei no legislativo. Nós sabemos que os legisladores agem estrategicamente retirando propostas que não vão ser aprovadas ou postergando a votação, até terem a maioria, ainda que por margem mínima. Nesse caso, a aplicação de RDD nesse caso produirá estimativas viesadas. McCray, em um artigo de 2008, argumentou que tais casos apareceriam como descontinuidade na densidade da *running variable* ao redor do ponto de corte. Eis o gráfico feito por McCray em seu estudo original:

```{r McCay-test, echo=FALSE}

knitr::include_graphics("/Users/manoelgaldino/Documents/DCP/Cursos/Causalidade/Causalidade/imagens/manipulation test.png")
```

Para formalizar essa ideia, McCray estima os limites da densidade pela esquerda e pela direita e avalia se a diferença (do logaritmo) das estimativas é estatisticamente significante diferente de zero. Portanto, rejeitar a hipótese nula é encontrar evidências de que há manipulação.  Cattaneo, Jansson, & Ma 2018; 2020 introduziram uma versão alternativa do teste, com espírito similar.

Na prática, de um ponto de vista retórico, o que pesquisadores querem é falhar em rejeitar a nula. Como o teste tem baixo poder de rejeitar a nula, ausência de evidência não quer dizer evidência de ausência.

```{r McCay-test1, message=FALSE}
library(rdd)
# Simulated data without discontinuity

DCdensity(df$x, 0)  # No discontinuity

```

Cattaneo Density Test (Improved Version)

```{r Cattaneo-test, message=FALSE}
library(rddensity)

# Simulated continuous density
rdd <- rddensity(X = df$x, vce = "jackknife")
summary(rdd)
```

Essa é uma área ativa de pesquisa, com novos testes sendo desenvolvidos, por exemplo, Fitzgerald (2025), que é um working paper.


## Robustez

Mostrar várias estimativas, para várias escolhas de estimações (bandwith etc.)

Uma possibilidade é simplesmente apresentar várias estimativas, como faremos abaixo. Ou então, uma tabela. Mas o mais simples seria um gráfico dos efeitos com seus respectivos ICs, em que cada entrada no eixo x é uma estimação, e no y temos o efeito.
Abaixo apresento duas dessas possbilidades para ilustrar como a última é a melhor.

```{r plot-estimator-1, echo=FALSE, message=FALSE, warning=FALSE}

# Calculate means for each treatment group
mean_values <- df_long %>%
  group_by(treatment) %>%
  summarise(mean_y = mean(y, na.rm = TRUE))

# Extract means for annotations
mean_black <- mean_values$mean_y[mean_values$treatment == FALSE]
mean_blue <- mean_values$mean_y[mean_values$treatment == TRUE]

# Calculate the difference (RDD estimator)
basic_model <- rdrobust(df$y, df$x, p=1)
rdd_estimate <- basic_model$coef[1]
vec_estimate <- rdd_estimate
se_estimate <- basic_model$se[2]


# Define the position for the bracket and text
bracket_height <- max(mean_black, mean_blue) + abs(mean_blue - mean_black)*0.001 
mid_y <- mean(mean_black, mean_blue)  # Midpoint between means for text

# Create the plot
ggplot(df_long, aes(x = x, y = y, colour = treatment)) +
  geom_point() +
  scale_colour_manual(values = c("black", "blue")) +
   geom_segment(aes(x = min(x), xend = 0, y = mean_black, yend = mean_black), colour = "black") +
  geom_segment(aes(x = 0, xend = max(x), y = mean_blue, yend = mean_blue), colour = "blue") +
  labs(x = "Running Variable", y = "Resultados observados - Y") +
  theme_minimal()  +  
  theme(legend.position = "none") +
  geom_segment(aes(x = 0, y = mean_black, xend = 0, yend = bracket_height), colour = "black") +
  geom_segment(aes(x = 0, y = mean_blue, xend = 0, yend = bracket_height), colour = "blue") +
  annotate("text", x = 1.5, y = mid_y, label = paste("RDD Estimator: ", round(rdd_estimate, 2), "-5 < x < 5"), 
           size = 5, colour = "red", vjust = -1)
```

```{r plot-estimator2, echo=FALSE, message=FALSE, warning=FALSE}

df_long <- df_long %>%
  filter ( x > -1 & x < 1)
# Calculate means for each treatment group
mean_values <- df_long %>%
  group_by(treatment) %>%
  summarise(mean_y = mean(y, na.rm = TRUE))

# Extract means for annotations
mean_black <- mean_values$mean_y[mean_values$treatment == FALSE]
mean_blue <- mean_values$mean_y[mean_values$treatment == TRUE]

# Calculate the difference (RDD estimator)
basic_model <- rdrobust(df$y, df$x, p=1, h=1)
rdd_estimate <- basic_model$coef[1]
vec_estimate[2] <- rdd_estimate
se_estimate[2] <- basic_model$se[2]

# Define the position for the bracket and text
bracket_height <- max(mean_black, mean_blue) + abs(mean_blue - mean_black)*0.001
mid_y <- mean(mean_black, mean_blue)  # Midpoint between means for text


# Create the plot
ggplot(df_long, aes(x = x, y = y, colour = treatment)) +
  geom_point() +
  scale_colour_manual(values = c("black", "blue")) +
   geom_segment(aes(x = min(x), xend = 0, y = mean_black, yend = mean_black), colour = "black") +
  geom_segment(aes(x = 0, xend = max(x), y = mean_blue, yend = mean_blue), colour = "blue") +
  labs(x = "Running Variable", y = "Resultados observados - Y") +
  theme_minimal()  + 
  theme(legend.position = "none") +
  geom_segment(aes(x = 0, y = mean_black, xend = 0, yend = bracket_height), colour = "black") +
  geom_segment(aes(x = 0, y = mean_blue, xend = 0, yend = bracket_height), colour = "blue") +
  annotate("text", x = .5, y = mid_y, label = paste("RDD Estimator: ", round(rdd_estimate, 2), "-1 < x < 1"), 
           size = 5, colour = "red", vjust = -1) 

```


```{r plot-estimator3, echo=FALSE, message=FALSE, warning=FALSE}

df_long <- df_long %>%
  filter ( x > -.5 & x < .5)
# Calculate means for each treatment group
mean_values <- df_long %>%
  group_by(treatment) %>%
  summarise(mean_y = mean(y, na.rm = TRUE))

# Extract means for annotations
mean_black <- mean_values$mean_y[mean_values$treatment == FALSE]
mean_blue <- mean_values$mean_y[mean_values$treatment == TRUE]

# Calculate the difference (RDD estimator)
basic_model <- rdrobust(df$y, df$x, p=1, h=.5)
rdd_estimate <- basic_model$coef[1]
vec_estimate[3] <- rdd_estimate
se_estimate[3] <- basic_model$se[2]


# Define the position for the bracket and text
bracket_height <- max(mean_black, mean_blue) + abs(mean_blue - mean_black)*0.001 
mid_y <- mean(mean_black, mean_blue)  # Midpoint between means for text


# Create the plot
ggplot(df_long, aes(x = x, y = y, colour = treatment)) +
  geom_point() +
  scale_colour_manual(values = c("black", "blue")) +
  geom_segment(aes(x = min(x), xend = 0, y = mean_black, yend = mean_black), colour = "black") +
  geom_segment(aes(x = 0, xend = max(x), y = mean_blue, yend = mean_blue), colour = "blue") +
  labs(x = "Running Variable", y = "Resultados observados - Y") +
  theme_minimal()  + 
  theme(legend.position = "none") +
  geom_segment(aes(x = 0, y = mean_black, xend = 0, yend = bracket_height), colour = "black") +
  geom_segment(aes(x = 0, y = mean_blue, xend = 0, yend = bracket_height), colour = "blue") +
  annotate("text", x = .1, y = mid_y, label = paste("RDD Estimator: ", round(rdd_estimate, 2), "-.5 < x < .5"), 
           size = 5, colour = "red", vjust = -1) 

```


```{r plot-estimator4, echo=FALSE, message=FALSE, warning=FALSE}

df_long <- df_long %>%
  filter ( x > -.1 & x < .1)
# Calculate means for each treatment group
mean_values <- df_long %>%
  group_by(treatment) %>%
  summarise(mean_y = mean(y, na.rm = TRUE))

# Extract means for annotations
mean_black <- mean_values$mean_y[mean_values$treatment == FALSE]
mean_blue <- mean_values$mean_y[mean_values$treatment == TRUE]

# Calculate the difference (RDD estimator)
basic_model <- rdrobust(df$y, df$x, p=1, h=.1)
rdd_estimate <- basic_model$coef[1]
vec_estimate[4] <- rdd_estimate
se_estimate[4] <- basic_model$se[2]


# Define the position for the bracket and text
bracket_height <- max(mean_black, mean_blue) + abs(mean_blue - mean_black) * 0.001  # slightly above the highest line

mid_y <- mean(mean_black, mean_blue)  # Midpoint between means for text


# Create the plot
ggplot(df_long, aes(x = x, y = y, colour = treatment)) +
  geom_point() +
  scale_colour_manual(values = c("black", "blue")) +
   geom_segment(aes(x = min(x), xend = 0, y = mean_black, yend = mean_black), colour = "black") +
  geom_segment(aes(x = 0, xend = max(x), y = mean_blue, yend = mean_blue), colour = "blue") +
  labs(x = "Running Variable", y = "Resultados observados - Y") +
  theme_minimal()  +
  geom_segment(aes(x = 0, y = mean_black, xend = 0, yend = bracket_height), colour = "black") +
  geom_segment(aes(x = 0, y = mean_blue, xend = 0, yend = bracket_height), colour = "blue") +
  annotate("text", x = 0, y = mid_y, label = paste("RDD Estimator: ", round(rdd_estimate, 2), "-.1 < x < .1"), 
           size = 5, colour = "red", vjust = -1) 

```


```{r plot-efeitos, echo=TRUE, message=FALSE, warning=FALSE}
df1 <- data.frame(
  estimate = vec_estimate,
  se       = se_estimate,
  lower    = vec_estimate - 2 * se_estimate,
  upper    = vec_estimate + 2 * se_estimate,
  h     = c("Aut" , "h=1", "h=.5" , "h=.1")  # ou names(vec_estimate) se o vetor for nomeado
)

# 2) Plote com pontos e barras de erro
ggplot(df1, aes(x = h, y = estimate)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.1) +
  labs(
    x     = "h",
    y     = "Estimativa",
    title = "Efeitos estimados com IC (±2×SE)"
  ) +
  theme_minimal()

```


## Densidade descontínua - results
```{r density-plot3, echo=FALSE, eval=TRUE}

# Generate a random sample with a density discontinuity at 0
set.seed(42)
x <- rnorm(2000, mean = -0.5)
x[x > 0] <- x[x > 0] * 2

# Estimation
rdd <- rddensity(X = x)
```



## Regressão RDD
```{r reg-rdd, echo=TRUE, eval=TRUE}
library(rdrobust)
# Assuming the cutoff is at x=0
basic_model <- rdrobust(y = df$y, x = df$x, c = 0)
summary(basic_model)
```

## Placebo Tests

Testando descontinuidade em covariáveis predeterminadas: covariáveis que não devem ser afetadas pelo tratamento não devem apresentar salto no ponto de corte.

Testando descontinuidades em outros pontos: verificar a existência de descontinuidades em pontos arbitrários ao longo da variável de ordenação.

Uso de VDs placebos: se uma variável dependente que não deveria ser afetada pelo tratamento apresentar descontinuidade significativa, isso levanta dúvidas sobre a validade do desenho RD.

Avaliação de sensibilidade às covariáveis: as estimativas de RD não devem ser altamente sensíveis à inclusão ou exclusão de covariáveis.

## PCRD

Marhsall (2024) na AJPS introduz a nomenclatura do desenho de pesquisa Politician characteristic regression discontinuity (PCRD). Basicamente, o argumento é que RDD não permite identificar efeito de características de políticos (como gênero, profissão, raça, ideologia, alinhamento com govenro federal etc.)

"In contrast, the treatment in PCRD designs — which instead seek to estimate the LATE of an elected politician characteristic — is defined by possessing (or not) predetermined characteristic X, conditional on narrowly winning an election. (...) restricting attention to close elections entails conditioning on candidate vote shares that may be affected by X. (...) [It] generally introduce bias — even when X is independent of other predetermined variables and the weak continuity assumption underpinning standard RD designs holds." (p. 495)

Basicamente, Marshall está dizendo que nesses casos, close election é um collider, e isso abre as portas para viéses de variáveis que causem $y$ e se a eleição é apertada.

```{r DAG, echo=FALSE}

library(ggdag)
dag <- dagify(
  y ~ genero + competencia,
  close_election ~ competencia + genero
)

ggdag(dag)

```

## Checlist para um paper

Teste de balancemaneto de variáveis de pré-tratamento (não impactadas pelo tratamento)

Teste de permutação no cuttoff (outra forma de olhar balanceamento)

Densidade da running variable (teste de McCrary)

Testes de placebo (cutoffs arbitrários. Estimativa não muda)

Gráfico com a descontinuidade

Estimativas baseadas em bandwith ótimos, e local linear regression

Análise de robustez junto com a escolha do bandwith (apresente graficamente)

Ordem preferida: primeiro estabelecer a validade da estratégia, depois detalhes da estimação.

## Referências

Canay, I. A., & Kamat, V. (2018). Approximate permutation tests and induced order statistics in the regression discontinuity design. The Review of Economic Studies, 85(3), 1577-1608.

Cattaneo, M. D., Idrobo, N., & Titiunik, R. (2024). A practical introduction to regression discontinuity designs: Extensions. Cambridge University Press.

Cattaneo, M. D., Idrobo, N., & Titiunik, R. (2019). A Practical Introduction to Regression Discontinuity Designs: Foundations. Elements in Quantitative and Computational Methods for the Social Sciences.

Cattaneo, M. D., & Titiunik, R. (2022). Regression discontinuity designs. Annual Review of Economics, 14(1), 821-851.

De Magalhães, L., Hangartner, D., Hirvonen, S., Meriläinen, J., Ruiz, N. A., & Tukiainen, J. (2025). When Can We Trust Regression Discontinuity Design Estimates from Close Elections? Evidence from Experimental Benchmarks. Political Analysis, 1-8.

Fitzgerald, J. (2025). Manipulation Tests in Regression Discontinuity Design: The Need for Equivalence Testing.

Gelman, A., & Imbens, G. (2019). Why high-order polynomials should not be used in regression discontinuity designs. Journal of Business & Economic Statistics, 37(3), 447-456.

Marshall, J. (2024). Can close election regression discontinuity designs identify effects of winning politician characteristics?. American Journal of Political Science, 68(2), 494-510.

Erikson, R. S., & Rader, K. (2017). Much ado about nothing: rdd and the incumbency advantage. Political Analysis, 25(2), 269-275.

De la Cuesta, B., & Imai, K. (2016). Misunderstandings about the regression discontinuity design in the study of close elections. Annual Review of Political Science, 19(1), 375-396.

Marshall, J. (2024). Can close election regression discontinuity designs identify effects of winning politician characteristics?. American Journal of Political Science, 68(2), 494-510.

- Tutorial: https://congressdata.joshuamccrain.com/regression_discontinuity.html