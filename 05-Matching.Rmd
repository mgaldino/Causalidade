# Propensity Score e Matching

## Introdução

Na aula de hoje, iremos aprender sobre a principal estratégia de "seleção em observáveis", que é matching. Mas antes, vamos falar de subclassificação ,que é uma técnica mais simples e é útil para introduzir a ideia de matching.

## Propensity Score

O propensity score nada mais é que a probabilidade de uma unidade ser tratada, dada as covariáveis, ou seja, $Pr(D_i = 1| X_i)$.

A ideia chave para propensity-score vem de um paper de Rosenbaum-Rubin (1983) em que eles mostram que, se a condição 1 de ignorabilidade forte (isto é, $Y_i(1), Y_i(0) \perp D_i|X_i$) for satisfeita, então também é verdade que a condição $Y_i(1), Y_i(0) \perp D_i|\pi(X_i)$ também é satisfeita. E por que isso é importante? Nós nunca sabemos o verdadeiro modelo que relaciona as convariáveis $X_i$ com $D_i$ e $Y_i$, de modo que podemos ter algum problema de modelo mal especificado (por exemplo, supomos um modelo linear, quando na verdade é não-linear). Então, em vez de estimar dezenas de modelos, posso condicionar ("controlar") apenas pelo propensity score $\pi(X_i)$. A intuição é que o propensity score cria balanceamento entre tratados e não-tratados. 

Para ilustrar o poder desse reusltado, vamos considerar um exemplo simulado, em que ignorability forte é satisfeita, mas um modelo mal-especificado gera amostras não-balanceadas e, portanto, estimativas viesadas.

```{r modelo-mal-especificado-DAG, message=FALSE}
library(knitr)
library(tidyverse)
library(ggdag)
library(arm)
# true DGP
dag <- dagify(
  y ~ D + w1,
  D ~ w1
)

ggdag(dag)
```

O DAG acima ilustra bem qual a relação causal entre variáveis. Para estimar o ATE de $D$ sobre $Y$, precisamos fechar o backdoor de $w_1$. A forma usual como fazemos isso é com regressão. O problema que estamos abordando aqui é quando a amostra é não-balanceada entre tratados e não-tratados, isto é. Vamos visualizar dois tipos de relações (uma linear e outra não-linear) entre a variável de controle $w_1$ e a resposta $Y$ para ilustrar o problema do desbalanceamento:

```{r modelo-mal-especificado-plot1, message=FALSE}
library(ggplot2)
set.seed(202)
n  <- 1e4
w1 <- rnorm(n)                       # único confundidor
tau <- 3                             # efeito causal verdadeiro

# GERAMOS UM PROPENSITY SCORE NÃO‐LINEAR
p  <- plogis(-0.5 + 2 * w1) 
D  <- rbinom(n, 1, p)

# GERAÇÃO DOS RESULTADOS POTENCIAIS linear (apenas função de w1, forte ignorabilidade):
y0 <-  5 * w1 + rnorm(n)
y1 <- y0 - tau                       # efeito constante

y  <- ifelse(D == 1, y1, y0)



df <- data.frame(y=y, D=D, w1=w1)

df %>%
  mutate(
    D = factor(D, levels = c(0,1),
               labels = c("Controle (D = 0)", "Tratado (D = 1)"))
  ) %>%
  ggplot(aes(x = w1, y = y, colour = D)) +
  geom_point(alpha = 0.6) +
  scale_colour_manual(
    name   = "Tratamento (binário)",
    values = c("Controle (D = 0)" = "steelblue", 
               "Tratado (D = 1)"  = "firebrick")
  ) + theme_bw()
```

No primeiro gráfico, o efeito causal (ATE) do tratamento é $-3$ e podemos ver nos dados que de fato em média a resposta é menor entre tratados que no controle. Além disso, vemos também que o efeito é basicamente linear. Mas o pontpo importante aqui é que existem duas regiões dos dados em que praticamente só temos unidades no controle ($w_1 < -2$) e ou no tratamento ($w_1 > -2$). Isso significa que para que a regressão possa estimar o efeito causal deve extrapolar a estimativa da região em que ambos tratamento e controle estão presentes nos dados para uma região em que não estão presentes. Como o efeito é constante para todas as regiões de $w_1$, isso não causa problema e a regressão consegue recuperar o ATE sem viés. O gráfico abaixo ilustra o que a regressão está fazendo:

```{r modelo-mal-especificado-plot1-reg, message=FALSE}

df %>%
  mutate(
    D = factor(D, levels = c(0,1),
               labels = c("Controle (D = 0)", "Tratado (D = 1)"))
  ) %>%
  ggplot(aes(x = w1, y = y, colour = D)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm") +
  scale_colour_manual(
    name   = "Tratamento (binário)",
    values = c("Controle (D = 0)" = "steelblue", 
               "Tratado (D = 1)"  = "firebrick")
  ) + theme_bw()
```

O gráfico mostra duas retas de regressão ajustadas, uma para o controle (em azul) e outra para o tratamento (em vermelho). Efetivamente, temos de estender as duas retas para as regiões em que não há dados, por meio de extrapolação, que no caso significa continuar a linha reta. Assim, temos uma estimativa dos resultados potenciais nessas regiões e podemos computar o efeito causal médio. Como a extrapolação é razoável, não há problema.

Vejamos agora uma situação em que o efeito de $w_1$ é não linear sobre $Y$.
 

```{r modelo-mal-especificado-plot2, message=FALSE}

set.seed(202)
n  <- 1e4
w1 <- rnorm(n)                       # único confundidor
tau <- 3                             # efeito causal verdadeiro

# GERAMOS UM PROPENSITY SCORE NÃO‐LINEAR
p  <- plogis(-0.5 + 2 * w1) 
D  <- rbinom(n, 1, p)

# GERAÇÃO DOS RESULTADOS POTENCIAIS não-linear (apenas função de w1, forte ignorabilidade):
y0 <-  5 * w1^2 + rnorm(n)
y1 <- y0 - tau                       # efeito constante

y  <- ifelse(D == 1, y1, y0)



df <- data.frame(y=y, D=D, w1=w1)

df %>%
  mutate(
    D = factor(D, levels = c(0,1),
               labels = c("Controle (D = 0)", "Tratado (D = 1)"))
  ) %>%
  ggplot(aes(x = w1, y = y, colour = D)) +
  geom_point(alpha = 0.6) +
  scale_colour_manual(
    name   = "Tratamento (binário)",
    values = c("Controle (D = 0)" = "steelblue", 
               "Tratado (D = 1)"  = "firebrick")
  ) + theme_bw()
```

Aqui, vemos que o efeito é não-linear de $w_1$ sobre $Y$ e também o desbalanceamento na amostra. Vamos ver o mesmo gráfico com as duas retas ajustadas para entender como a extrapolação pode ficar bem ruim nesse caso. 


```{r modelo-mal-especificado-plot2-reg, message=FALSE}

df %>%
  mutate(
    D = factor(D, levels = c(0,1),
               labels = c("Controle (D = 0)", "Tratado (D = 1)"))
  ) %>%
  ggplot(aes(x = w1, y = y, colour = D)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm") +
  scale_colour_manual(
    name   = "Tratamento (binário)",
    values = c("Controle (D = 0)" = "steelblue", 
               "Tratado (D = 1)"  = "firebrick")
  ) + theme_bw()
```

Um problema óbvio do modelo é que o efeito de w1 é quadrático, então podemos tentar corrigir isso incluindo um termo quadrático.

```{r modelo-mal-especificado-reg-sq, message=FALSE}
reg_sq <- lm(y ~ D + w1 + w1^2, data = df)
summary(reg_sq)
```
O efeito causal é negativo, o que é bom, pois está na direção certa, mas ainda está distante do efeito verdadeiro. Isso ilustra também como a estimativa é dependente do modelo, o que é bem ruim, pois não sabemos qual o modelo certo.

Em resumo, quando há desbalancamento, causamos dependência do modelo, o que é problemático.

Agora, vamos comparar com o propensity score:

```{r modelo-mal-especificado, message=FALSE}
library(knitr)
library(tidyverse)
library(ggdag)
# true DGP

reg_aux<- glm(D  ~ w1, family = binomial, data=df)
p_score <- reg_aux$fitted.values
reg1 <- lm(y ~ D + p_score)
summary(reg1)

w <- ifelse(D == 1, 1/p_score, 1/(1-p_score))   # pesos IPTW

reg2 <- lm(y ~ D , weights = w)
summary(reg2)

```


Conseguimos recuperar o ATE sem problemas. E não precisei especificar corretamente a forma funcional da variáveil de controle $w_1$ no modelo principal, pois usei o propensity score. Note que precisei modelar corretamente a regreessão que calcula o propensity score. 

É útil ver como o pscore está distribuído entre os grupos de tratamento e controle:


```{r distribuicao-pscore, message=FALSE}
library(knitr)
library(tidyverse)
library(ggdag)
# true DGP

df <- df %>%
  mutate(pscore = p_score)

df %>%
  ggplot(aes(pscore, group=D)) + geom_boxplot()

df %>%
  mutate(D = as.factor(D)) %>%
  ggplot()+
  geom_density(aes(x=pscore, group=D, colour = D))

```

Há desbalanceamento e falta de overlap ou suporte comum, o que leva à extrapolação.

## Matching

A Ideia do matching pode ser ilustrada se notarmos o seguinte. A projeção da reta vermelha para pontos abaixo de $-2$ é de um $y$ médio muito baixo, enquanto que o $y$ médio é muito alto para o controle. O oposto é verificado para a região em que $w_1 > 2$. Portanto, se eu restringir (excluir os casos) a análise para uma região onde a necessidade de extrapolação é menor, o resultado tende a ser aproximar do ATE

```{r modelo-mal-especificado-reg-sub, message=FALSE}
library(knitr)
library(tidyr)
library(broom)
library(kableExtra)

reg_sub <- lm(y ~ D + w1, data = df)

reg_sub %>%
  tidy() %>%
  kable(digits = c(0, 2, 3, 2, 3))

reg_sub <- lm(y ~ D + w1, data = subset(df, w1 > -2 & w1 < 2))

reg_sub %>%
  tidy() %>%
  kable(digits = c(0, 2, 3, 2, 3))


reg_sub <- lm(y ~ D + w1, data = subset(df, w1 > -1.5 & w1 < 1.5))

reg_sub %>%
  tidy() %>%
  kable(digits = c(0, 2, 3, 2, 3))


reg_sub <- lm(y ~ D + w1, data = subset(df, w1 > -1 & w1 < 1))

reg_sub %>%
  tidy() %>%
  kable(digits = c(0, 2, 3, 2, 3))


reg_sub <- lm(y ~ D + w1, data = subset(df, w1 > -1 & w1 < 1))

reg_sub %>%
  tidy() %>%
  kable(digits = c(0, 2, 3, 2, 3))

```

A ideia do matching é um pouco diferente do que fizemos acima, pois estamos excluindo as observações que estão no tratamento e que não possuem controle correspondente, e do controle que não possuem tratamento correspondente. Não há erro em excluir os dois tipos de observações, mas sempre temos de nos perguntar qual é o estimando de interesse. Se faço esse procedimento, o meu estimando não é nenhum dos usuais ATT ou ATE.

No matchingf, nós nos concentramos em estimar o ATT, de forma que procuramos achar observações no controle que são próximas das tratadas, ou seja, excluímos os controles que não são um match para as observações tratadas.

## Suposições de identificação

Supondo para simplificar um tratamento binário $T$, e uma covariável categórica $X$, temos:

1. $(Y^1, Y^0) \perp T|X \text{ (Independência Condicional)}$

2. $0 < P(T=1|A) < 1 \text{ (Suporte comum)}$

Temos então a seguinte derivação (usando o fato de os resultados potenciais são independentes do *treatment assignment*, condicional à covariável) e a *switching equation* no último passo:

\begin{align}
   \mathbb{E}[Y^1-Y^0|X] & = \mathbb{E}[Y^1 - Y^0 | X, T=1] \\
            & = \mathbb{E}[Y^1| X, T=1] - \mathbb{E}[Y^0| X,T=0] \\
            & = \mathbb{E}[Y| X, D=1] - \mathbb{E}[Y| X, D=0]
\end{align}

E o estimador que usamos pode ser representado (supondo suporte comum) como:

$\widehat{\delta_{ATE}} = \sum_{x\in X}{(\mathbb{E}[Y| X=x, D=1] - \mathbb{E}[Y| X=x, D=0])P(X=x)}$

E o que estamos fazendo é computar a média do efeito do tratamento condicional ponderado pela distribuição de $X$.

Para identificar o ATE, nós precisamos supor independência condicional a ambos os resultados potenciais. Se porém isso for crível apenas para $Y^0$, podemos estimar o ATT. Basta lembrarmos que $\mathbb{E}[Y_i|T_i=1] - \mathbb{E}[Y_i|T_i=0] =  \mathbb{E}[Y_i^1 - Y_i^0|T_i=1] + \mathbb{E}[Y_i^0|T_i=1] - \mathbb{E}[Y_i^0|T_i=0]$

## Matching

A técnica de matching trata os resultados potenciais como *missing data*. Assim, pudermos supor CIA com credibilidade, pelo menos com relação a $Y^0$, então podemos imputar esses resultados potenciais e estimar o ATT. A ideia é achar uma unidade a mais similar possível a unidade tratada para servir como contrafactual. Assim, poderíamos computar "diretamente" o ATT, já que teríamos os $Y^1$ e $Y^0$ para cada unidade, este último imputado.

Há dois grandes grupos de métodos de matching: exato e aproximado. 

## Matching exato

Nesse método, nós achamos uma unidade (ou mais) que tenham um valor exatamente igual nas covariáveis (ou no propensity score), e imputamos o controle.

## Matching aproximado

Para aproximar o matching, utilizamos alguma noção de distância entre variáveis. Para mais de uma variável, podemos utilizar algumas métricas de distância. A primeira é a distância euclidiana (supondo $K$ variáveis).

$$
\lVert X_i - X_j \rVert = \sqrt{(X_i - X_j)'(X_i - X_j)}
$$
$$
\lVert X_i - X_j \rVert = \sqrt{\sum_{n=1}^k(X_{ni} - X_{nj})}
$$

A distância euclidiana utiliza a escala das próprias variáveis, então é comum usar a distância euclidiana normalizada:

$$
\lVert X_i - X_j \rVert = \sqrt{\sum_{n=1}^k(\frac{X_{ni} - X_{nj})}{\hat{\sigma}_n^2}}
$$

Outra métrica é a distância de Mahalanobis, que basicamente divide pela covariância (amostral) entre as variáveis em vez da variância. Mas na prática a gente usa a euclidiana.

## Estimando

Uma vez que fizemos o matching entre unidades, qual nosso estimador? Lemrbando que o estimando é o ATT.
$$
\widehat{\delta}_{ATT} = \dfrac{1}{N_T} \sum_{D_i=1} (Y_i - Y_{j(i)})
$$

```{r balanceamento, message=FALSE}
library(MatchIt)
result_0 <- matchit(D ~ w1, data = df, method = NULL, distance = 'glm')
summary(result_0)
```


## Declare Design e Matching

Pode ser útil usar o declare design para investigar o uso de matching. Vamos fazer isso para o dataset lalonde.

Esse é um banco de dados famoso na economia, pois o pesquisador Lalonde (1986) foi investigar se aplicação de métodos (então) tradicionais de modelagem econométrica eram capaz de recuperar o efeito causal de um estudo experimental chamada National Supported Work Demonstration (NSW), um programa de emprego temporário para dar experiência de trabalho. Ele coletou dados de um survey "representativo" de trabalhadores americanos (PSID) e elencou esses trabalhadores como grupo controle e empregou métodos econométricos para tentat estimar o efeito causal. Os resultados foram desastrosos, no sentido de altamente variáveis dependendo do modelo e subconjunto de dados e longe da estimativa experimental (incluindo com sinal errado).

Vamos replicar esse trabalho, usando matching e pscore. A variável resposta do banco de dados é ``re78`` (real earnings in 1978). O tratamento é a variável ``treat``. As demais variáveis são covariáveis.

```{r setup-lalonde, echo=TRUE, eval=TRUE, message=FALSE}
library(tidyverse)
library(data.table)
library(here, quietly=TRUE)
library(fixest)
here()
set.seed(1234)
```

```{r lalonde, echo=TRUE, eval=TRUE, message=FALSE}
lalonde <- fread(here("Dados", "lalonde_nsw.csv"))

dt <- lalonde[, .(re78, treat)] %>%
    rename(Y = re78, D = treat)

dt %>%
    group_by(D) %>%
    sample_n(3) %>%
    kableExtra::kable(digits = 0, col.names = c("Income", "Treatment"))
```



```{r}
dt %>%
    group_by(D) %>%
    summarize(mean(Y)) %>%
    kableExtra::kable(digits = 0, col.names = c("Treatment", "Income"))
y1 = dt[dt$D == 1, Y]
y0 <- dt[dt$D == 0, Y]
tau <- mean(y1) - mean(y0)
```

A diferença simples na média é `r round(tau, digits = 0)`.

### Matching e Propensity scores

Usando ``age, education, hispanic, black, married, nodegree, RE74`` e ``RE75``, vamos moelar o propensity score usando o grupo dos tratados em ``lalonde_nsw.csv`` e a amostra de controle de ``lalonde_psid.csv``. Report the average p-score for the treated and control samples, and plot the propensity score densities for the treatment and control groups.

```{r observational-data, message = FALSE}
nsw_data <- lalonde
psid_data <- fread(here("Dados", "lalonde_psid.csv"))

nsw_treat <- nsw_data[nsw_data$treat == 1, ]
psid_control <- psid_data[psid_data$treat == 0, ]

dw_data <- rbind(nsw_treat, psid_control)

library(MatchIt)
m.out1 <- matchit(treat ~ age + education + hispanic + black + married + nodegree + re74 + re75,
                  data = dw_data,
                  method = "nearest",
                  distance = "glm")

summary(m.out1)

plot(summary(m.out1))

m.data <- match_data(m.out1)

head(m.data)

library("marginaleffects")

fit <- lm(re78 ~ treat * (age + education + black + married +
                            nodegree + re74 + re75),
          data = m.data,
          weights = weights)

avg_comparisons(fit,
                variables = "treat",
                vcov = ~subclass,
                newdata = subset(treat == 1))

```

```{r exact-matching, message = FALSE}
library(MatchIt)
library(DeclareDesign)
exact_matching <-
  function(data) {
    matched <- matchit(D ~ X, method = "exact", data = data)
    match.data(matched)
  }

declaration_16.2 <-
  declare_model(
    N = 100,
    U = rnorm(N),
    X = rbinom(N, 1, prob = 0.5),
    D = rbinom(N, 1, prob = 0.25 + 0.5 * X),
    Y_D_0 = 0.2 * X + U,
    Y_D_1 = Y_D_0 + 0.5
  ) +
  declare_inquiry(ATT = mean(Y_D_1[D == 1] - Y_D_0[D == 1])) +
  declare_step(handler = exact_matching) +
  declare_measurement(Y = reveal_outcomes(Y ~ D)) +
  declare_estimator(Y ~ D,
                    weights = weights,
                    .method = difference_in_means,
                    inquiry = "ATT",
                    label = "Matched difference-in-means") +
  declare_estimator(Y ~ D,
                    .method = difference_in_means,
                    inquiry = "ATT",
                    label = "Raw difference-in-means")

```



```{r balance}
library(MatchIt)
m.out0 <- matchit(treat ~ age + education + hispanic + black + married + nodegree + re74 + re75,
                  data = dw_data,
                  method = NULL,
                  distance = "glm")

# Checking balance prior to matching
summary(m.out0)

```

```{r propensity-scores-matching}
library(MatchIt)
m.out1 <- matchit(treat ~ age + education + hispanic + black + married + nodegree + re74 + re75,
                  data = dw_data,
                  method = "nearest",
                  distance = "glm")

# Full matching on a probit PS
m.out2 <- matchit(treat ~ age + education + black + married + 
                    nodegree + re74 + re75,
                  data = lalonde,
                  method = "full",
                  distance = "glm",
                  link = "probit")

m.data <- match_data(m.out2)

library("marginaleffects")

fit <- lm(re78 ~ treat * (age + education + black + married +
                            nodegree + re74 + re75),
          data = m.data,
          weights = weights)

avg_comparisons(fit,
                variables = "treat",
                vcov = ~subclass,
                newdata = subset(treat == 1))
```



```{r DD-full-matching, message = FALSE}


full_matching <-
  function(data) {
    matched <- matchit(treat ~ age + education + hispanic + black + married + nodegree + re74 + re75, method = "full", data = data)
    match.data(matched)
  }

declaration_16.2 <-
  declare_model(
    N = 1000,
    U = rnorm(N),
    X = rbinom(N, 1, prob = 0.5),
    D = rbinom(N, 1, prob = 0.25 + 0.5 * X),
    Y_D_0 = 0.2 * X + U,
    Y_D_1 = Y_D_0 + 0.5
  ) +
  declare_inquiry(ATT = mean(Y_D_1[D == 1] - Y_D_0[D == 1])) +
  declare_step(handler = exact_matching) +
  declare_measurement(Y = reveal_outcomes(Y ~ D)) +
  declare_estimator(Y ~ D,
                    weights = weights,
                    .method = difference_in_means,
                    inquiry = "ATT",
                    label = "Matched difference-in-means") +
  declare_estimator(Y ~ D,
                    .method = difference_in_means,
                    inquiry = "ATT",
                    label = "Raw difference-in-means")

```

## Recomendações Práticas sobre Matching

Rotina ou algoritmo:

1. Defina o que é proximidade: alguma distância de medida para determinar se um caso é um bom match e quais variáveis utilizar. Em geral, distância euclidiana.

2. Implemente o método do match.

3. Avalie a qualidade do método, por meio do balanceamento antes e depois do match. Se necessário, altere o passo 1 ou 2 e itere.

4. Faça a inferência sobre o efeito causal do tratamento sobre a resposta, dado o matching feito em 3. 
### Avaliação do matching feito

1. É melhor usar matching exato ou aproximado do que propensity score matching, pois o poder do teste é melhor (cf. King & Nielsen, 2019).

2. Não devemos fazer teste de hipótese para checar que o balanceamento após matching é melhor do que antes (amostra menor reduz o poder do teste de detectar desbalanceamento. Além disso, não há superpopulação alvo da inferência, pois balanceamento é uma propriedade de uma amostra em particular). Cf. Austin 2009.

3. Além de comparar médias, é recomendado comparar variâncias ou desvios-padrão (Austin 2009). Por exemplo, razão de variâncias.

4. Jamais use a variável resposta para fazer o matching.

5. Matching com reposição gera dificuldades para calcular o erro padrão, já que as observações não são independentes.

## Referências

Austin, P. C. (2009). Balance diagnostics for comparing the distribution of baseline covariates between treatment groups in propensity‐score matched samples. Stat Med.

King, G., & Nielsen, R. (2019). Why propensity scores should not be used for matching. Political analysis, 27(4), 435-454.

Stuart, E. A. (2010). Matching methods for causal inference: A review and a look forward. Statistical science: a review journal of the Institute of Mathematical Statistics, 25(1), 1.
