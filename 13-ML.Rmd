# Machine Learning

## Introdução

Em estudos observacionais, como vimos, análises baseadas no pressuposto de *conditional ignorability* do tratamento e positividade permitem a estimação de quantidades causais de interesse.
As técnicas de machine learning foram desenvolvidas em geral voltadas para  problema de previsão, não de inferência causal. Por isso, não são normalmente uma alternativa boa para as questões de identificação causal que temos discutido no curso. Contudo, com algumas adaptações, podem ser usadas para análise de causa e efeito.

Uma das abordagens mais populares é a sugerida por Belloni et. al (2014), de usar LASSO (Least Absolute Shrinkage and Selection Operator) para inferir causalidade.

## LASSO

A ideia é simples. Conside a regressão linear estimada por OLS:

$$
\hat{\beta} = \text{arg}\,\min\limits_{\beta}\ \sum_i (Y_i - X_i\beta)^2 
$$
Nós estamos procurando o $\beta$ que minimiza a soma dos quadrados do resíduos. A ideia da regressão LASSO é adicionar uma penalização, tal que vamos minimzar:

$$
\hat{\beta} = \text{arg}\,\min\limits_{\beta}\ \sum_i (Y_i - X_i\beta)^2 + \lambda ||\beta||
$$
Essa penalização é chamada também de $L_1$.

## Terminologia

Estatística Machine Learning

observações


### LASSO

O estimador de Mínimos Quadrados Ordinários é obtido minimizando a soma dos quadrados dos resíduos, isto é, em uma regressão $y_i = beta_0 + \beta_1x_{1i} + beta_2{x_2i} + \ldots + beta_px_{pi} + e_i$, minimizamos $\sum_{i=1}^n [y_i - (\alpha + \beta_1x_{1i} + beta_2{x_2i} + \ldots + beta_px_{pi})]^2$. Nós podemos pensar essa minimização como uma função de custo. Quanto menor o erro total, menor o custo.

O estimador de LASSO adiciona uma penalidade a essa função de minimização $\lambda \sum_{j=1}^p |\beta_j|$, ou seja, passamos a minimizar: $\sum_{i=1}^n [y_i - (\alpha + \beta_1x_{1i} + beta_2{x_2i} + \ldots + beta_px_{pi})]^2 + \lambda \sum_{j=1}^p |\beta_j|$

O termo $\sum_{j=1}^p |\beta_j|$ é chamado de norma L1. Ele envolve a soma absoluta dos parâmetros. Existem outras normas (L0, L2 etc.), isto é, outras formas de penalizar a estimação dos coeficientes. A Norma L1 é conhecida como distância de Manhathan, e a intuição é que, se tenho dois pontos em Manhatan, $(x_1, y_1)$ e $(x_2, y_2)$, que são ruas em esquinas opostas de uma quadra (na diagonal). Como as ruas são, em geral, em formato de grade, temos de andar uma quadra na vertical e outra na horizontal para sair de um ponto a outro. Essa distância é a norma L1. Se usássamos a norma L2, por exemplo, poderíamos ir na diagonal, que é dada pela distância euclidiana. 

E $\lambda$ é um parâmetro não negativo que controla a força da penalização. Veja que coeficientes positivos dos $\beta$ aumentam o custo total, de modo que eles precisam ser compensados pelo ganho gerado na capacidade preditiva da variável associada (quanto maior a correlação parcial, menor o erro). Assim, ao introduzir essa penalidade, o LASSO estimula que apenas as variáveis com maior capacidade preditiva possuam coeficientes positivos, enquanto as de baixa capacidade preditiva terão coeficiente igual a zero. Nós chamamos isso de esparsividade do voetor de coeficientes, já que muitos deles serão zero. Dizemos também que a regressão foi estimada com regularização. Veja que o LASSO é o equivalente a uma regressão Bayesiana com uma priori nos parâmetros igual a um dupla exponencial, levando à interpretação de que a priori é uma forma de regularizar estimativas.

Quando $\lambda \to 0$, of coeficientes convergem para os estimadores de MQO, e quando $\lambda \to \infty$ apenas o intercepto resta. Em ML, o método usual para achar $\lambda$ é validação cruzada (CV, de cross-validation), que é utilizada para favorecer previsões fora da amostra. Belloni et al. (2012) advoga escolhada baseada em teoria, também conhecido como LASSO rigoroso. Angrist & Frandsen (2022) concluiram que essa abordagem rigorosa tende a favorecer modelos mais parsimoniosos ($\lambda$ maiores) do que com CV.

### Double Lasso

O estimador robusto mais popular é o Double Lasso. A ideia é que se eu tentar usar LASSO diretamente na equação de regressão $y_i = \alpha + \beta_1D_i + BX + e_i$, variáveis correlacionadas entre si terão coeficientes zero, e potencialmente o tratamento será um delas, impedindo a estimação da quantidade causal de interesse. Estratégias como forçar D_i a permanecer na equação, o que significa que ficará fora da equação de penalização. Contudo, isso pode causar viés na estimação de $\beta_1$ (Belloni et al., 2014). A regularização força variáveis correlacionadas com o tratamento a serem dropadas, o que significa dropar potenciais variáveis de confusão.

Resumo: não use as técnicas de ML diretamente na equação de regressão.

Exemplo.


```{r echo=TRUE, eval=FALSE}

# vou rodar mil simulações com n=100
set.seed(10)
n <- 100
alpha <- .2
beta <- 0
gamma <- .2
erro <- rnorm(n)
x <- rnorm(n)
D <- .8 + .8*x + rnorm(n)
y <- alpha + beta*D + gamma*x + erro
fit <- lm(y ~D + x)

```

```{r echo=TRUE, eval=TRUE}
library(MASS)


sim_df_ds <- function(n_sim=1000, n_sample=100) {
  vec_p_values <- numeric()
  lista_df <- list()
  
  for ( i in 1:n_sim) {
n <- n_sample
alpha <- .2
beta <- 0
gamma <- .2
erro <- rnorm(n)

mean_vector <- c(0, 0)
cov_matrix <- matrix(c(1, 0.8, 0.8, 1), nrow = 2, ncol = 2)

# Gerando os dados
simulated_data <- mvrnorm(n = n, mu = mean_vector, Sigma = cov_matrix)

# Convertendo para um data frame para facilitar a manipulação
D = simulated_data[,1]
x = simulated_data[,2]
y <- alpha + beta*D + gamma*x + erro

df_sim <- data.frame(y, D, x)
lista_df[[i]] <- df_sim

  }
  
  return(lista_df)
}


lista_df <- sim_df_ds()

vec_p_values <- numeric()
for (i in 1:1000) {
  fit <- lm(y ~D + x, data=lista_df[[i]])
  summary_fit <- summary(fit)
  
  # Obtendo o valor p associado ao coeficiente de x
  vec_p_values[i] <- summary_fit$coefficients["D", "Pr(>|t|)"]
}

hist(vec_p_values, breaks = 40, main = "Teste de signific. de D", xlab = "p-valor")
abline(v = 0.05, col = "red", lwd = 1, lty = 1)
text(0.1, par("usr")[4] * 0.75, "0.05", col = "red", pos = 3, cex=.5)

# percentual p-valor menor que 5%
sum(vec_p_values <= .05)/1000

```

Nós rejeitamos a hipótese nula aproximadamente 50% do tempo.


E se usarmos LASSO (single LASSO)?

```{r, echo=TRUE, eval = TRUE}

# Instalar e carregar o pacote glmnet, se necessário
library(glmnet)

# Vetor para armazenar se x foi selecionado pelo LASSO
lasso_selected_D <- numeric()

# Loop de simulação
for (i in 1:1000) {
  y <- lista_df[[i]]$y
  X <- cbind(lista_df[[i]]$D, lista_df[[i]]$x) 
  # Preparando os dados para o LASSO
  # Matriz de preditores (sem a interceptação)

  # Ajustando o modelo LASSO com validação cruzada
  lasso_model <- cv.glmnet(X, y, alpha = 1) # alpha = 1 para LASSO

  # Extraindo os coeficientes no valor de lambda que minimiza o erro
  lasso_coefs <- coef(lasso_model, s = "lambda.min")

  # Verificando se a variável x foi selecionada pelo LASSO (coeficiente diferente de zero)
  lasso_selected_D[i] <- ifelse(lasso_coefs["V1", 1] != 0, 1, 0)
}

# Analisando os resultados
hist(lasso_selected_D, breaks = 40, main = "Seleção de x pelo LASSO", xlab = "x selecionado (1 = sim, 0 = não)")

sum(lasso_selected_D <= .05)/1000
```

Também não funciona, mais ou menos mesma taxa de erro.

### Outras soluções ineficazes

Bootstrap (não funciona)
Clássico: suponha que a covariável não é relevante
Conservador: sempre inclua quantos controles puder (pode gerar Collider Bias).

DL lida com essa situação fazendo uma modelagem dupla, tanto do tratamento quanto da respota. Daí o nome, Double Lasso.


## DML - Algoritmo

Passo 1. Inclua controle se ele for preditor significativo da resposta $y_i$ por um teste conservador (teste t, LASSO etc.)

PAsso 2. Inclua controle se ele preditor significativo do tratamento $D_i$ por um teste conservador (teste t, LASSO etc.).

Passo 3. Ajuste o modelo com as variáveis selecionadas e o tratamento. Esse passo é chamado de Pós MQO (Post OLS)

Np R, podemos usar o pacote "hdm" para fazer a implementação em uma linha.

```{r, echo=TRUE}
library(hdm)
library(knitr)
d_s_vec <- numeric()
for ( i in 1:1000) {
  my_double_selection <- rlassoEffects(y~. , I=~x + D, data=lista_df[[i]])
  d_s_vec[i] <- summary(my_double_selection)$coefficients["D", "Pr(>|t|)"]
  
}

hist(d_s_vec, breaks = 40, main = "Seleção de D pelo Double LASSO", xlab = "p-valor")
abline(v = 0.05, col = "red", lwd = 1, lty = 1)
text(0.1, par("usr")[4] * 0.75, "0.05", col = "red", pos = 3, cex=.5)
 
sum(d_s_vec <= .05)/1000
```

Como vemos, aproximadamente 5% das vezes nós rejeitamos a hipótese nula erradamente, que é o esperado do p-valor de 5%.


## Aplicação

o Único exempl oque encontrei em ciência política de aplicação do Double LASSO foi o argtigo (working paper) de Dahlum et. al (2024).



## DML

A estratégia de identificação canônica em nosso curso tem girado sempre em torno de suposições críveis de identificação do efeito de um tratamento (em geral binário) $D$ sobre a variável resposta (em geral contínua) $Y$. E com frequência precisamos empregar controles para garantir a identificação causal e fechar as portas abertas (back-doors). Nesse contexto, as variáveis de controle são o que chamamos de *nuisance variables*, isto é, variáveis que não são de interesse para a pergunta de pesquisa, mas que precisam ser levadas em consideração para que possamos estimar sem viés o parâmetro de interesse.

Considere o modelo de regressão padrão em um estudo observacional:

$y_i = \alpha + \beta_1D_i + BX + e_i$, em que $D_i$ é o tratamento (binário) e $X$ é um vetor de $p$ potenciais variáveis de confusão: $\mathbf{X} = (x_1, x_2, \ldots, x_p)$ e $B$ o vetor de parâmetros das variáveis de controle.

Dado que a regressão está aproximando uma esperança condicional $\mathbb{E}[Y|D=d, \mathbf{X}= \mathbf{x}]$, ela pode ser escrita como: 

$\mathbb{E}[Y|D=d, \mathbf{X}= \mathbf{x}] = \eta_0(\mathbf{X}) + \theta_0(\mathbf{X})d$, em que $\eta_0 = \mathbb{E}[Y|D=0, \mathbf{X}= \mathbf{x}]$ é um *functional nuisance* e $\theta_0 = \mathbb{E}[Y|D=1, \mathbf{X}= \mathbf{x}] - \mathbb{E}[Y|D=0, \mathbf{X}= \mathbf{x}]$ é o funcional de interesse.

Tipicamente, quando usamos regressão linear, estamos assumindo uma forma funcional específica para a função de *nuisance*. Se houver erro de especificação, iremos introduzir um viés na estimativa do parâmetrode interesse. Aí é que entra o Double/Debiased Machine Learning

## Double Debiasing 

O chamado Double/Debiased Machine Learning (DML) foi desenvolvido por  Chernozhukov et al. (2018). Sua inpsiração vem do teorema de Frisch-Waugh- Lovell (FWL). Vamos começar por ele. Suponha o seguinte modelo de regressão múltipla:

$$
Y = \beta_0 + \beta_1X + \beta_2W_1 + \dots + \beta_{k+1}W_k + \epsilon
$$
Em que $X$ é a variável causal dei nteresse (tratamento) e os $W$ são variáveis de controle. São os *nuisance variables*. O teorema de FWL diz que posso estimar $\beta_1$ rodando diretamente a regressão acima, ou então pelos seguintes passos:

1.Rodo uma regressão em que o tratamento é a VD, e os controles as VIs.
$$
X = \alpha_0 +  \alpha_1W_1 + \dots + \alpha_{k}W_k + \epsilon
$$
2. Calculo os resíduos $\tilde{X} = X - \hat{X}$, em que $\hat{X} = \hat{\alpha}_0 +  \hat{\alpha}_1W_1 + \dots + \hat{\alpha}_{k}W_k$.

3. 

A ideia do DML é usar ML para estimar os dois resíduos como no teorema de FWL, e então rodar uma regressão linear para estimar o efeito causal do tratamento. E Chernukov et. al. (2018) mostram que usar ML gera resíduos ortogonais e, portanto, permitem estimar o efeito causal.


## Cross-fitting

Uma questão importante para nós é como fazer a validação cruzada em um contexto de TSCS. De acordo com Ahrens et. al (2025), devemos sortear as partições entre unidades $i = 1, 2, \dots, n$, mantendo todas as séries temporais por unidades juntas. 

## Questões Práticas

Para usar DML, precisamos fazer escolhas (não-óbvias) sobre três aspectos do processo:

1. Qual modelo de ML usar para estimar o *nuisance parameter*. Isso inclui escolher o parâmetro de fine-tuning, típico de aplicações de ML.

2. Quantas partições realizar na amostra (aka, valor de $k$).

3. Como fazer a divisão das amostras em *folds*.

Uma exemplo de aplicação onde o DML é útil é em DiD. Nós sabemos que a suposição de tendências parelalas, condicional a controles, dependem de uma suposição da forma paramétrica dessa relação (em geral linear). Se a forma paramétrica não for corretamente especificada, a estimativa será viesada. Ao usar DML, nós ganhamos a flexibilidade de estimar o nuisance parameter corretamente e estimar o efeito causal de interesse.
  

## Referências
Ahrens, A., Chernozhukov, V., Hansen, C., Kozbur, D., Schaffer, M., & Wiemann, T. (2025). An Introduction to Double/Debiased Machine Learning. arXiv preprint arXiv:2504.08324.

Belloni, A., Chernozhukov, V., & Hansen, C. (2014). High-dimensional methods and inference on structural and treatment effects. Journal of Economic Perspectives, 28(2), 29-50.

Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, James Robins, Double/debiased machine learning for treatment and structural parameters, The Econometrics Journal, Volume 21, Issue 1, 1 February 2018, Pages C1–C68, https://doi.org/10.1111/ectj.12097

Dahlum, S., Hanson, T., Johnsen, Å., Kotsadam, A., & Wuttke, A. (2024). “Is Support for Authoritarian Rule Contagious? Evidence from Field and Survey Experiments.” CESifo Working Paper Series No. 11490.

Mellon, J. (2023). Rain, Rain, Go Away: 195 Potential Exclusion-Restriction Violations for Studies Using Weather as an Instrumental Variable. Available at SSRN 3715610.

White, A. (2019). Misdemeanor disenfranchisement? The demobilizing effects of brief jail spells on potential voters. American Political Science Review, 113(2), 311-324.





```{r DML-cap-13, echo=FALSE, message=FALSE, warning=FALSE}
# install.packages('scpi')
library(data.table)


```

